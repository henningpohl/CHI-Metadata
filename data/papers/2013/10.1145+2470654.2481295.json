{
  "doi": "10.1145/2470654.2481295",
  "title": "SeeSay and HearSay CAPTCHA for mobile interaction",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2147-2156",
  "year": 2013,
  "badges": [],
  "abstract": "Speech certainly has advantages as an input modality for smartphone applications, especially in scenarios where using touch or keyboard entry is difficult, on increasingly miniaturized devices where useable keyboards are difficult to accommodate, or in scenarios where only small amounts of text need to be input, such as when entering SMS texts or responding to a CAPTCHA challenge. In this paper, we propose two new alternative ways to design CAPTCHAs in which the user says the answer instead of typing it with (a) output stimuli provided visually (SeeSay) or (b) auditorily (HearSay). Our user study results show that SeeSay CAPTCHA requires less time to be solved and users prefer it over current text-based CAPTCHA methods.",
  "authors": [
    {
      "name": "Sajad Shirali-Shahreza",
      "institution": "University of Toronto, Toronto, Ontario, Canada",
      "img": "/do/10.1145/contrib-81317500199/rel-imgonly/sajad.jpg",
      "acmid": "81317500199",
      "orcid": "missing"
    },
    {
      "name": "Gerald Penn",
      "institution": "University of Toronto, Toronto, Ontario, Canada",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100263138",
      "orcid": "missing"
    },
    {
      "name": "Ravin Balakrishnan",
      "institution": "University of Toronto, Toronto, Ontario, Canada",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100503904",
      "orcid": "0000-0002-3379-7680"
    },
    {
      "name": "Yashar Ganjali",
      "institution": "University of Toronto, Toronto, Ontario, Canada",
      "img": "/do/10.1145/contrib-81100415294/rel-imgonly/yg.png",
      "acmid": "81100415294",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Basapur, S., Xu, S., Ahlenius, M., Lee, Y. S. User Expectations from Dictation on Mobile Devices. In Proc. HCII 2007, 217--225. ",
      "doi": "10.5555/1757268.1757294"
    },
    {
      "text": "Bhatt, K., Evens, M., Argamon, S. Hedged Responses and Expressions of Affect in Human/Human and Human/Computer Tutorial Interactions. In Proc. COGSCI 2004.",
      "doi": ""
    },
    {
      "text": "Bigham, J. P., Cavender, A. C. Evaluating existing audio CAPTCHAs and an interface optimized for non-visual use. In Proc. CHI '09, 1829--1838.  ",
      "doi": "10.1145/1518701.1518983"
    },
    {
      "text": "Bursztein, E., et al. How Good Are Humans at Solving CAPTCHAs? A Large Scale Evaluation. In Proc. S&P '10, 399--413.  ",
      "doi": "10.1109/SP.2010.31"
    },
    {
      "text": "Bursztein, E., Martin, M., Mitchell, J. Text-based CAPTCHA strengths and weaknesses. In Proc. CCS '11, 125--138.  ",
      "doi": "10.1145/2046707.2046724"
    },
    {
      "text": "Bursztein, E., et al. The failure of Noise-Based non-continuous audio captchas. In Proc. S&P 2011, 19--31.  ",
      "doi": "10.1109/SP.2011.14"
    },
    {
      "text": "Cox, A. L., Cairns, P. A., Walton, A., Lee, S. Tlk or txt? Using voice input for SMS composition. Pers. Ubiquit. Comput. 12, 8, 567--588.  ",
      "doi": "10.1007/s00779-007-0178-8"
    },
    {
      "text": "Fidas, C. A., Voyiatzis, A. G., Avouris, N. M. On the necessity of user-friendly CAPTCHA. In Proc. CHI '11, 2623--2626.  ",
      "doi": "10.1145/1978942.1979325"
    },
    {
      "text": "Grover, et al. HIV Health Information Access using Spoken Dialogue Systems - Touchtone vs. Speech. In Proc. ICTD 2009, 95--107. ",
      "doi": "10.5555/1812530.1812541"
    },
    {
      "text": "Jeon, M., Walker, B. N., Srivastava, A. Spindex (Speech Index) Enhances Menus on Touch Screen Devices with Tapping, Wheeling, and Flicking. ACM Trans. Comput. Hum. Interact. 19, 2, Article 14 (July 2012).  ",
      "doi": "10.1145/2240156.2240162"
    },
    {
      "text": "Johnston, M., et al. Multimodal Language Processing for Mobile Information Access. In Proc. ICSLP 2002.",
      "doi": ""
    },
    {
      "text": "Kumar, A., Paek, T., Lee, B. Voice typing: a new speech interaction model for dictation on touchscreen devices. In Proc. CHI '12, 2277--2286.  ",
      "doi": "10.1145/2207676.2208386"
    },
    {
      "text": "Lazar, J., et al. The SoundsRight CAPTCHA: an improved approach to audio human interaction proofs for blind users. In Proc. CHI '12, 2267--2276.  ",
      "doi": "10.1145/2207676.2208385"
    },
    {
      "text": "MacKenzie, I. S., and Soukore, R. W. Text Entry for Mobile Computing: Models and Methods, Theory and Practice. Human-Computer Interaction, 17(2), 147--198.",
      "doi": ""
    },
    {
      "text": "Medhi, I., et al. Designing mobile interfaces for novice and low-literacy users. ACM Trans. Comput.-Hum. Interact. 18, 1, Article 2 (May 2011).  ",
      "doi": "10.1145/1959022.1959024"
    },
    {
      "text": "Oulasvirta, A., Tamminen, S., Roto, V., Kuorelahti, J. Interaction in 4-second bursts: the fragmented nature of attentional resources in mobile HCI. In Proc. CHI '05, 919--928.  ",
      "doi": "10.1145/1054972.1055101"
    },
    {
      "text": "Rabiner, L., Juang, B. H. Fundamentals of speech recognition. Prentice hall, 1993. ",
      "doi": "10.5555/153687"
    },
    {
      "text": "Rico, J. Evaluating the social acceptability of multimodal mobile interactions. In Ext. Abstracts CHI '10, 2887--2890.  ",
      "doi": "10.1145/1753846.1753877"
    },
    {
      "text": "Sauer, G., Hochheiser, H., Feng, J., Lazar, J. Towards a universally usable CAPTCHA. In Proc. SOAPS '08.",
      "doi": ""
    },
    {
      "text": "Sauer, G., Lazar, J., Hochheiser, H., Feng, J. 2010. Towards A Universally Usable Human Interaction Proof: Evaluation of Task Completion Strategies. ACM Trans. Access. Comput. 2, 4, Article 15 (June 2010).  ",
      "doi": "10.1145/1786774.1786776"
    },
    {
      "text": "Shirali-Shahreza, S., Penn, G. Realistic Answer Verification: An Analysis of User Errors in a Sentence-Repetition Task. To appear in Proc. SLT 2012.",
      "doi": ""
    },
    {
      "text": "Shirali-Shahreza, S., Ganjali, Y., Balakrishnan, R. Verifying human users in Speech-Based interactions. In Proc. INTERSPEECH 2011, 1585--1588.",
      "doi": ""
    },
    {
      "text": "Shirali-Shahreza, S., Shirali-Shahreza, M. A survey of human interactive proof systems. International Journal of Innovative Computing, Information and Control (IJICIC), 6, 3A, 855--876 (March 2010).",
      "doi": ""
    },
    {
      "text": "Vertanen, K., Kristensson, P. O. Parakeet: a continuous speech recognition system for mobile touch-screen devices. In Proc. IUI '09, 237--246.  ",
      "doi": "10.1145/1502650.1502685"
    },
    {
      "text": "von Ahn, L., Blum, M., Langford, J.. Telling humans and computers apart automatically. Communications of the ACM 47, 2, 56--60 (Feb. 2004).  ",
      "doi": "10.1145/966389.966390"
    }
  ]
}