{
  "doi": "10.1145/2470654.2481301",
  "title": "PixelTone: a multimodal interface for image editing",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2185-2194",
  "year": 2013,
  "badges": [],
  "abstract": "Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone, a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.",
  "authors": [
    {
      "name": "Gierad P. Laput",
      "institution": "University of Michigan, Ann Arbor, Michigan & Adobe Research, San Francisco, California, USA",
      "img": "/do/10.1145/contrib-81502797271/rel-imgonly/gierad_laput_c2_425x425_gradient2_shift.jpg",
      "acmid": "81502797271",
      "orcid": "missing"
    },
    {
      "name": "Mira Dontcheva",
      "institution": "Adobe Research, San Francisco, California, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100654713",
      "orcid": "missing"
    },
    {
      "name": "Gregg Wilensky",
      "institution": "Adobe Research, San Francisco, California, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81319504256",
      "orcid": "missing"
    },
    {
      "name": "Walter Chang",
      "institution": "Adobe Research, San Francisco, California, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81558072756",
      "orcid": "missing"
    },
    {
      "name": "Aseem Agarwala",
      "institution": "Adobe Research, San Francisco, California, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100035467",
      "orcid": "missing"
    },
    {
      "name": "Jason Linder",
      "institution": "Adobe Research, San Francisco, California, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81502773744",
      "orcid": "missing"
    },
    {
      "name": "Eytan Adar",
      "institution": "University of Michigan, Ann Arbor, Michigan, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100589033",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Androutsopoulos, L. Natural language interfaces to databases - an introduction. Journal of Natural Language Engineering 1 (1995), 29--81.",
      "doi": ""
    },
    {
      "text": "Apple. iPhoto. http://www.apple.com/ilife/iphoto/. Online; accessed Sept 18, 2012.",
      "doi": ""
    },
    {
      "text": "Apple. Siri. http://www.apple.com/ios/siri/. Online; accessed Sept 18, 2012.",
      "doi": ""
    },
    {
      "text": "Banerjee, S., and Pedersen, T. An adapted lesk algorithm for word sense disambiguation using wordnet. In Proc. of the 3rd International Conference on Computational Linguistics and Intelligent Text Processing, CICLing '02, Springer-Verlag (London, UK, 2002), 136--145. ",
      "doi": "10.5555/647344.724142"
    },
    {
      "text": "Bolt, R. A. Put-that-there: Voice and gesture at the graphics interface. SIGGRAPH Computer Graphics 14, 3 (July 1980), 262--270.  ",
      "doi": "10.1145/965105.807503"
    },
    {
      "text": "Brill, E. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics 21, 4 (June 1995), 543--565. ",
      "doi": "10.5555/218355.218367"
    },
    {
      "text": "Chang, J. C., Lien, A., Lathrop, B., and Hees, H. Usability evaluation of a volkswagen group in-vehicle speech system. In Proc. of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications, AutomotiveUI '09 (2009), 137--144.  ",
      "doi": "10.1145/1620509.1620535"
    },
    {
      "text": "Coelho, J., Duarte, C., Biswas, P., and Langdon, P. Developing accessible tv applications. In The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility, ASSETS '11 (2011), 131--138.  ",
      "doi": "10.1145/2049536.2049561"
    },
    {
      "text": "Gelfand, N., Adams, A., Park, S. H., and Pulli, K. Multi-exposure imaging on mobile devices. In Proceedings of the international conference on Multimedia, MM '10 (2010), 823--826.  ",
      "doi": "10.1145/1873951.1874088"
    },
    {
      "text": "Gorniak, P., and Roy, D. Augmenting user interfaces with adaptive speech commands. In Proc. of the 5th international conference on Multimodal interfaces, ICMI '03 (2003), 176--179.  ",
      "doi": "10.1145/958432.958467"
    },
    {
      "text": "Hauptmann, A. G. Speech and gestures for graphic image manipulation. In Proc. of the SIGCHI conference on Human factors in computing systems, CHI '89 (1989), 241--245.  ",
      "doi": "10.1145/67449.67496"
    },
    {
      "text": "Healey, P. G. T., McCabe, R., and Katagiri, Y. A comparison of graphics and speech in a task-oriented interaction. In Proc. of the 1st International Conference on Theory and Application of Diagrams, Diagrams '00, Springer-Verlag (London, UK, 2000), 245--256. ",
      "doi": "10.5555/645970.675047"
    },
    {
      "text": "iSpeech. iSpeech. http://www.ispeech.org/api. Online; accessed Sept 18, 2012.",
      "doi": ""
    },
    {
      "text": "Lau, T., Cerruti, J., Manzato, G., Bengualid, M., Bigham, J. P., and Nichols, J. A conversational interface to web automation. In Proc. of the 23rd annual ACM symposium on User interface software and technology, UIST '10 (2010), 229--238.  ",
      "doi": "10.1145/1866029.1866067"
    },
    {
      "text": "Little, G., and Miller, R. C. Translating keyword commands into executable code. In Proc. of the 19th annual ACM symposium on User interface software and technology, UIST '06 (2006), 135--144.  ",
      "doi": "10.1145/1166253.1166275"
    },
    {
      "text": "Marcus, M. P., Santorini, B., and Marcinkiewicz, M. A. Building a large annotated corpus of english: The penn treebank. vol. 19 (June 1993), 313--330. ",
      "doi": "10.5555/972470.972475"
    },
    {
      "text": "Miller, R. C., Chou, V. H., Bernstein, M., Little, G., Van Kleek, M., Karger, D., and schraefel, m. Inky: a sloppy command line for the web with rich visual feedback. In Proc. of the 21st annual ACM symposium on User interface software and technology, UIST '08 (2008), 131--140.  ",
      "doi": "10.1145/1449715.1449737"
    },
    {
      "text": "Milota, A. D. Modality fusion for graphic design applications. In Proc. of the 6th international conference on Multimodal interfaces, ICMI '04 (2004), 167--174.  ",
      "doi": "10.1145/1027933.1027963"
    },
    {
      "text": "Nuance Communications. Dragon. http://www.nuance.com/dragon/index.htm. Online; accessed Sept 18, 2012.",
      "doi": ""
    },
    {
      "text": "Oviatt, S. Multimodal interactive maps: designing for human performance. Human Computer Interaction 12, 1 (Mar. 1997), 93--129.  ",
      "doi": "10.1207/s15327051hci1201%25262_4"
    },
    {
      "text": "Pajari, M. Color mark up terminology. Tech. rep., Widen Enterprises Inc., 2009.",
      "doi": ""
    },
    {
      "text": "Patwardhan, S., Banerjee, S., and Pedersen, T. Using measures of semantic relatedness for word sense disambiguation. In Proc. of the 4th international conference on Computational linguistics and intelligent text processing, CICLing'03, Springer-Verlag (2003), 241--257. ",
      "doi": "10.5555/1791562.1791592"
    },
    {
      "text": "Pausch, R., and Leatherby, J. H. An empirical study: Adding voice input to a graphical editor. J. of the American Voice Input/Output Society 9 (1991), 2--55.",
      "doi": ""
    },
    {
      "text": "Politepix. OpenEars: speech recognition and speech synthesis for the iPhone. http://www.politepix.com/openears/. Online; accessed Sept 18, 2012.",
      "doi": ""
    },
    {
      "text": "Riley, E. How to talk to a retoucher, 2012.",
      "doi": ""
    },
    {
      "text": "Samad, T., and Director, S. W. Towards a natural language interface for cad. In Proc. of the 22nd ACM/IEEE Design Automation Conference, ACM/IEEE DAC '85 (1985), 2--8. ",
      "doi": "10.5555/317825.317826"
    },
    {
      "text": "Sedivy, J., and Johnson, H. Supporting creative work tasks: the potential of multimodal tools to support sketching. In Proc. of the 3rd conference on Creativity & cognition, C&C '99 (1999), 42--49.  ",
      "doi": "10.1145/317561.317571"
    },
    {
      "text": "Woolfe, G. Making color adjustment accessible to non-experts through the use of language. In Proc. of IS&T 15th Color Imaging Conference (2007).",
      "doi": ""
    },
    {
      "text": "Xiong, Y., and Pulli, K. Gradient domain image blending and implementation on mobile devices. In Mobile Computing, Applications, and Services. Springer Berlin Heidelberg, 2010, 293--306.",
      "doi": ""
    },
    {
      "text": "Zhao, Y., Bala, R., Braun, K. M., Langford, Z., Rolleston, R. J., and Stevens, M. T. Language-based color editing for mobile device. In Proc. of the SPIE, Volume 7879 (2011).",
      "doi": ""
    }
  ]
}