{
  "doi": "10.1145/2470654.2470684",
  "title": "Crowdsourcing performance evaluations of user interfaces",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "207-216",
  "year": 2013,
  "badges": [],
  "abstract": "Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings. However, because the experimenter gives up the direct control over the participants' environments and behavior, concerns about the quality of the data collected in online settings are pervasive. In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk. The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments. These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.",
  "tags": [
    "crowdsourcing",
    "mechanical turk",
    "user interface evaluation"
  ],
  "authors": [
    {
      "name": "Steven Komarov",
      "institution": "Harvard University, Cambridge, Massachusetts, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81557130156",
      "orcid": "missing"
    },
    {
      "name": "Katharina Reinecke",
      "institution": "Harvard University, Cambridge, Massachusetts, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81350583575",
      "orcid": "0000-0001-7897-9325"
    },
    {
      "name": "Krzysztof Z. Gajos",
      "institution": "Harvard University, Cambridge, Massachusetts, USA",
      "img": "/do/10.1145/contrib-81100593751/rel-imgonly/81100593751.jpg",
      "acmid": "81100593751",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Callison-Burch, C. Fast, cheap, and creative: evaluating translation quality using amazon's mechanical turk. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP '09, Association for Computational Linguistics (Stroudsburg, PA, USA, 2009), 286--295. ",
      "doi": "10.5555/1699510.1699548"
    },
    {
      "text": "Chandler, D., and Kapelner, A. Breaking monotony with meaning: Motivation in crowdsourcing markets. Working Paper, May 2010.",
      "doi": ""
    },
    {
      "text": "Cole, F., Sanik, K., DeCarlo, D., Finkelstein, A., Funkhouser, T., Rusinkiewicz, S., and Singh, M. How well do line drawings depict shape? SIGGRAPH '09: SIGGRAPH 2009 papers (July 2009).  ",
      "doi": "10.1145/1576246.1531334"
    },
    {
      "text": "Devore, J. Probability and Statistics for Engineering and the Sciences, seventh ed. Thomson Higher Education, 2008.",
      "doi": ""
    },
    {
      "text": "Gajos, K. Z., Czerwinski, M., Tan, D. S., and Weld, D. S. Exploring the design space for adaptive graphical user interfaces. In AVI '06: Proceedings of the working conference on Advanced visual interfaces, ACM Press (New York, NY, USA, 2006), 201--208.  ",
      "doi": "10.1145/1133265.1133306"
    },
    {
      "text": "Gajos, K. Z., Everitt, K., Tan, D. S., Czerwinski, M., and Weld, D. S. Predictability and accuracy in adaptive user interfaces. In CHI '08: Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems, ACM (New York, NY, USA, 2008), 1271--1274.  ",
      "doi": "10.1145/1357054.1357252"
    },
    {
      "text": "Grossman, T., and Balakrishnan, R. The bubble cursor: enhancing target acquisition by dynamic resizing of the cursor's activation area. In Proceedings of the SIGCHI conference on Human factors in computing systems, CHI '05, ACM (New York, NY, USA, 2005), 281--290.  ",
      "doi": "10.1145/1054972.1055012"
    },
    {
      "text": "Heer, J., and Bostock, M. Crowdsourcing graphical perception: using mechanical turk to assess visualization design. In Proceedings of the 28th international conference on Human factors in computing systems, CHI '10, ACM (New York, NY, USA, 2010), 203--212.  ",
      "doi": "10.1145/1753326.1753357"
    },
    {
      "text": "Horton, J. J., Rand, D. G., and Zeckhauser, R. J. The online laboratory: Conducting experiments in a real labor market. Experimental Economics (2011).",
      "doi": ""
    },
    {
      "text": "Kapelner, A., and Chandler, D. Preventing Satisficing in Online Surveys: A \"Kapcha\" to Ensure Higher Quality Data. In CrowdConf (2010).",
      "doi": ""
    },
    {
      "text": "Kittur, A., Chi, E. H., and Suh, B. Crowdsourcing user studies with mechanical turk. In Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems, CHI '08, ACM (New York, NY, USA, 2008), 453--456.  ",
      "doi": "10.1145/1357054.1357127"
    },
    {
      "text": "Kong, N., Heer, J., and Agrawala, M. Perceptual Guidelines for Creating Rectangular Treemaps. Visualization and Computer Graphics, IEEE Transactions on 16, 6 (2010), 990--998.  ",
      "doi": "10.1109/TVCG.2010.186"
    },
    {
      "text": "Little, G., Chilton, L., Goldman, M., and Miller, R. Turkit: human computation algorithms on mechanical turk. In Proceedings of the 23nd annual ACM symposium on User interface software and technology, ACM (2010), 57--66.  ",
      "doi": "10.1145/1866029.1866040"
    },
    {
      "text": "Mao, A., Chen, Y., Gajos, K., Parkes, D., Procaccia, A., and Zhang, H. Turkserver: Enabling synchronous and longitudinal online experiments. In Proceedings of HCOMP'12 (2012).",
      "doi": ""
    },
    {
      "text": "Mason, W., and Suri, S. Conducting behavioral research on amazon's mechanical turk. Behavior Research Methods (2010), 1--23.",
      "doi": ""
    },
    {
      "text": "Mason, W., and Watts, D. Financial incentives and the \"performance of crowds\". HCOMP '09: Proceedings of the ACM SIGKDD Workshop on Human Computation (June 2009).  ",
      "doi": "10.1145/1600150.1600175"
    },
    {
      "text": "Noronha, J., Hysen, E., Zhang, H., and Gajos, K. Z. Platemate: Crowdsourcing nutrition analysis from food photographs. In Proceedings of UIST'11 (2011).  ",
      "doi": "10.1145/2047196.2047198"
    },
    {
      "text": "Oleson, D., Sorokin, A., Laughlin, G., Hester, V., Le, J., and Biewald, L. Programmatic gold: Targeted and scalable quality assurance in crowdsourcing. In Proceedings of HCOMP'11 (2011).",
      "doi": ""
    },
    {
      "text": "Oppenheimer, D., Meyvis, T., and Davidenko, N. Instructional manipulation checks: Detecting satisficing to increase statistical power. Journal of Experimental Social Psychology 45, 4 (2009), 867--872.",
      "doi": ""
    },
    {
      "text": "Paolacci, G., Chandler, J., and Ipeirotis, P. Running experiments on amazon mechanical turk. Judgment and Decision Making 5, 5 (2010), 411--419.",
      "doi": ""
    },
    {
      "text": "Prelec, D. A Bayesian Truth Serum for Subjective Data. Science 306, 5695 (Oct. 2004), 462--466.",
      "doi": ""
    },
    {
      "text": "Rand, D. G. The promise of Mechanical Turk: How online labor markets can help theorists run behavioral experiments. Journal of theoretical biology (2012).",
      "doi": ""
    },
    {
      "text": "Rzeszotarski, J. M., and Kittur, A. Instrumenting the crowd: Using implicit behavioral measures to predict task performance. In Proceedings of the 24th annual ACM symposium on User interface software and technology, UIST '11, ACM (New York, NY, USA, 2011).  ",
      "doi": "10.1145/2047196.2047199"
    },
    {
      "text": "Schmidt, L. Crowdsourcing for human subjects research. In CrowdConf (2010).",
      "doi": ""
    },
    {
      "text": "Sears, A., and Shneiderman, B. Split menus: effectively using selection frequency to organize menus. ACM Trans. Comput.-Hum. Interact. 1, 1 (1994), 27--51.  ",
      "doi": "10.1145/174630.174632"
    },
    {
      "text": "Shaw, A. D., Horton, J. J., and Chen, D. L. Designing incentives for inexpert human raters. In Proceedings of the ACM 2011 conference on Computer supported cooperative work, CSCW '11, ACM (New York, NY, USA, 2011), 275--284.  ",
      "doi": "10.1145/1958824.1958865"
    },
    {
      "text": "Suri, S., and Watts, D. Cooperation and contagion in networked public goods experiments. Arxiv preprint arXiv10081276 (2010).",
      "doi": ""
    }
  ]
}