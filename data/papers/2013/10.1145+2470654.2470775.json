{
  "doi": "10.1145/2470654.2470775",
  "title": "SideWays: a gaze interface for spontaneous interaction with situated displays",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "851-860",
  "year": 2013,
  "badges": [],
  "abstract": "Eye gaze is compelling for interaction with situated displays as we naturally use our eyes to engage with them. In this work we present SideWays, a novel person-independent eye gaze interface that supports spontaneous interaction with displays: users can just walk up to a display and immediately interact using their eyes, without any prior user calibration or training. Requiring only a single off-the-shelf camera and lightweight image processing, SideWays robustly detects whether users attend to the centre of the display or cast glances to the left or right. The system supports an interaction model in which attention to the central display is the default state, while \"sidelong glances\" trigger input or actions. The robustness of the system and usability of the interaction model are validated in a study with 14 participants. Analysis of the participants' strategies in performing different tasks provides insights on gaze control strategies for design of SideWays applications.",
  "tags": [
    "eye tracking",
    "situated display",
    "spontaneous interaction",
    "eye-based interaction",
    "calibration-free"
  ],
  "authors": [
    {
      "name": "Yanxia Zhang",
      "institution": "Lancaster University, Lancaster, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81488650749",
      "orcid": "missing"
    },
    {
      "name": "Andreas Bulling",
      "institution": "Max Planck Institute for Informatics, Saarbr\u00fccken, Germany",
      "img": "/do/10.1145/contrib-81372593219/rel-imgonly/portraet_cut.jpg",
      "acmid": "81372593219",
      "orcid": "0000-0001-6317-7303"
    },
    {
      "name": "Hans Gellersen",
      "institution": "Lancaster University, Lancaster, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81452616827",
      "orcid": "0000-0003-2233-2121"
    }
  ],
  "references": [
    {
      "text": "Brignull, H., and Rogers, Y. Enticing people to interact with large public displays in public spaces. In Proc. INTERACT 2003, IOS Press (2003), 17--24.",
      "doi": ""
    },
    {
      "text": "Duchowski, A. T. Eye Tracking Methodology: Theory and Practice. Springer-Verlag New York, Inc., 2003. ",
      "doi": "10.5555/640601"
    },
    {
      "text": "Eaddy, M., Blasko, G., Babcock, J., and Feiner, S. My own private kiosk: Privacy-preserving public displays. In Proc. ISWC 2004, IEEE Computer Society (2004), 132--135.  ",
      "doi": "10.1109/ISWC.2004.32"
    },
    {
      "text": "Geusebroek, J.-M., van den Boomgaard, R., Smeulders, A. W., and Geerts, H. Color invariance. IEEE Trans. Pattern Anal. Mach. Intell. 23, 12 (2001), 1338--1350.  ",
      "doi": "10.1109/34.977559"
    },
    {
      "text": "Hansen, D., and Ji, Q. In the eye of the beholder: A survey of models for eyes and gaze. IEEE Trans. Pattern Anal. Mach. Intell. 32, 3 (2010), 478--500.  ",
      "doi": "10.1109/TPAMI.2009.30"
    },
    {
      "text": "Hutchinson, T., White, K. P. J., Martin, W., Reichert, K., and Frey, L. Human-computer interaction using eye-gaze input. Trans. Sys. Man Cyber Part C 19, 6 (1989), 1527--1534.",
      "doi": ""
    },
    {
      "text": "Jacob, R. J. K. The use of eye movements in human-computer interaction techniques: what you look at is what you get. ACM Trans. Inf. Syst. 9, 2 (1991), 152--169.  ",
      "doi": "10.1145/123078.128728"
    },
    {
      "text": "Kumar, M., and Winograd, T. Gaze-enhanced scrolling techniques. In Proc. UIST 2007, ACM Press (2007), 213--216.  ",
      "doi": "10.1145/1294211.1294249"
    },
    {
      "text": "Magee, J. J., Betke, M., Gips, J., Scott, M. R., and Waber, B. N. A human-computer interface using symmetry between eyes to detect gaze direction. Trans. Sys. Man Cyber. Part A 38, 6 (2008), 1248--1261.  ",
      "doi": "10.1109/TSMCA.2008.2003466"
    },
    {
      "text": "Morimoto, C. H., and Mimica, M. R. M. Eye gaze tracking techniques for interactive applications. Comput. Vis. Image Underst. 98, 1 (2005), 4--24.  ",
      "doi": "10.5555/1061935.1649095"
    },
    {
      "text": "Mubin, O., Lashina, T., and Loenen, E. How not to become a buffoon in front of a shop window: A solution allowing natural head movement for interaction with a public display. In Proc. INTERACT 2009, Springer-Verlag (2009), 250--263.  ",
      "doi": "10.1007/978-3-642-03658-3_32"
    },
    {
      "text": "M\u00fcller, J., Walter, R., Bailly, G., Nischt, M., and Alt, F. Looking glass: a field study on noticing interactivity of a shop window. In Proc. CHI 2012, ACM Press (2012), 297--306.  ",
      "doi": "10.1145/2207676.2207718"
    },
    {
      "text": "Nakanishi, Y., Fujii, T., Kiatjima, K., Sato, Y., and Koike, H. Vision-based face tracking system for large displays. In Proc. UbiComp 2002, Springer-Verlag (2002), 152--159. ",
      "doi": "10.5555/647988.741495"
    },
    {
      "text": "Noris, B., Benmachiche, K., and Billard, A. Calibration-free eye gaze direction detection with gaussian processes. In Proc. VISAPP 2008, INSTICC (2008), 611--616.",
      "doi": ""
    },
    {
      "text": "Peltonen, P., Kurvinen, E., Salovaara, A., Jacucci, G., Ilmonen, T., Evans, J., Oulasvirta, A., and Saarikko, P. It's mine, don't touch!: interactions at a large multi-touch display in a city centre. In Proc. CHI 2008, ACM Press (2008), 1285--1294.  ",
      "doi": "10.1145/1357054.1357255"
    },
    {
      "text": "San Agustin, J., Hansen, J. P., and Tall, M. Gaze-based interaction with public displays using off-the-shelf components. In Ubicomp 2010 Adjunct, ACM Press (2010), 377--378.  ",
      "doi": "10.1145/1864431.1864444"
    },
    {
      "text": "Sesma, L., Villanueva, A., and Cabeza, R. Evaluation of pupil center-eye corner vector for gaze estimation using a web cam. In Proc. ETRA 2012, ACM Press (2012), 217--220.  ",
      "doi": "10.1145/2168556.2168598"
    },
    {
      "text": "Sibert, L. E., and Jacob, R. J. K. Evaluation of eye gaze interaction. In Proc. CHI 2000, ACM Press (2000), 281--288.  ",
      "doi": "10.1145/332040.332445"
    },
    {
      "text": "Sippl, A., Holzmann, C., Zachhuber, D., and Ferscha, A. Real-time gaze tracking for public displays. In Proc. AmI 2010, Springer-Verlag (2010), 167--176. ",
      "doi": "10.5555/1926743.1926760"
    },
    {
      "text": "Smith, J. D., Vertegaal, R., and Sohn, C. Viewpointer: lightweight calibration-free eye tracking for ubiquitous handsfree deixis. In Proc. UIST 2005, ACM Press (2005), 53--61.  ",
      "doi": "10.1145/1095034.1095043"
    },
    {
      "text": "Sugano, Y., Matsushita, Y., and Sato, Y. Calibration-free gaze sensing using saliency maps. In Proc. CVPR 2010, IEEE Computer Society (2010), 2667--2674.",
      "doi": ""
    },
    {
      "text": "Valenti, R., and Gevers, T. Accurate eye center location and tracking using isophote curvature. In Proc. CVPR 2008, IEEE Computer Society (2008), 1--8.",
      "doi": ""
    },
    {
      "text": "Vertegaal, R., Mamuji, A., Sohn, C., and Cheng, D. Media eyepliances: using eye tracking for remote control focus selection of appliances. In Ext. Abstracts CHI 2005, ACM Press (2005), 1861--1864.  ",
      "doi": "10.1145/1056808.1057041"
    },
    {
      "text": "Vertegaal, R., Shell, J. S., Chen, D., and Mamuji, A. Designing for augmented attention: Towards a framework for attentive user interfaces. Computers in Human Behavior 22, 4 (2006), 771--789.",
      "doi": ""
    },
    {
      "text": "Viola, P., and Jones, M. Rapid object detection using a boosted cascade of simple features. In Proc. CVPR 2001, IEEE Computer Society (2001), 511--518.",
      "doi": ""
    },
    {
      "text": "Ward, D. J., and MacKay, D. J. C. Fast hands-free writing by gaze direction. Nature 418, 6900 (2002), 838.",
      "doi": ""
    },
    {
      "text": "Zhang, Y., Bulling, A., and Gellersen, H. Towards pervasive eye tracking using low-level image features. In Proc. ETRA 2012, ACM Press (2012), 261--264.  ",
      "doi": "10.1145/2168556.2168611"
    },
    {
      "text": "Zhu, Z., and Ji, Q. Eye and gaze tracking for interactive graphic display. Mach. Vision Appl. 15, 3 (2004), 139--148.  ",
      "doi": "10.1007/s00138-004-0139-4"
    },
    {
      "text": "Zhu, Z., and Ji, Q. Eye gaze tracking under natural head movements. In Proc. CVPR 2005, IEEE Computer Society (2005), 918--923.  ",
      "doi": "10.1109/CVPR.2005.148"
    }
  ]
}