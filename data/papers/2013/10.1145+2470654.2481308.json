{
  "doi": "10.1145/2470654.2481308",
  "title": "Designing engagement-aware agents for multiparty conversations",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2233-2242",
  "year": 2013,
  "badges": [],
  "abstract": "Recognizing users' engagement state and intentions is a pressing task for computational agents to facilitate fluid conversations in situated interactions. We investigate how to quantitatively evaluate high-level user engagement and intentions based on low-level visual cues, and how to design engagement-aware behaviors for the conversational agents to behave in a sociable manner. Drawing on machine learning techniques, we propose two computational models to quantify users' attention saliency and engagement intentions. Their performances are validated by a close match between the predicted values and the ground truth annotation data. Next, we design a novel engagement-aware behavior model for the agent to adjust its direction of attention and manage the conversational floor based on the estimated users' engagement. In a user study, we evaluated the agent's behaviors in a multiparty dialog scenario. The results show that the agent's engagement-aware behaviors significantly improved the effectiveness of communication and positively affected users' experience.",
  "authors": [
    {
      "name": "Qianli Xu",
      "institution": "Institute for Infocomm Research Singapore, Singapore, Singapore",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81442612320",
      "orcid": "missing"
    },
    {
      "name": "Liyuan Li",
      "institution": "Institute for Infocomm Research Singapore, Singapore, Singapore",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81455605472",
      "orcid": "missing"
    },
    {
      "name": "Gang Wang",
      "institution": "Institute for Infocomm Research Singapore, Singapore, Singapore",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81488662754",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Agarwal, S., Awan, A. and Roth, D. Learning to detect objects in images via a sparse, part-based representation. IEEE TPAMI, 26 (2004), 1475--1490.  ",
      "doi": "10.1109/TPAMI.2004.108"
    },
    {
      "text": "Andrist, S., Pejsa, T., Mutlu, B. and Gleicher, M. Designing effective gaze mechanisms for virtual agents. In Proc. CHI'12, ACM Press (2012), 705--714.  ",
      "doi": "10.1145/2207676.2207777"
    },
    {
      "text": "Bee, N., Wagner, J., Andr\u00e9, E., Vogt, T., Charles, F., Pizzi, D. and Cavazza, M. Discovering eye gaze behavior during human-agent conversation in an interactive storytelling application. In Proc. ICMI-MLMI'10, ACM Press (2010).  ",
      "doi": "10.1145/1891903.1891915"
    },
    {
      "text": "Bennewitz, M., Faber, F., Joho, D., Schreiber, M. and Behnke, S. Towards a humanoid museum guide robot that interacts with multiple persons. In Proc. HUMANOIDS 2005, (2005), 418--423.",
      "doi": ""
    },
    {
      "text": "Bohus, D. and Horvitz, E. Computational models for multiparty turn-taking. Microsoft Research Technical Report MSR-TR 2010--115, (2010).",
      "doi": ""
    },
    {
      "text": "Bohus, D. and Horvitz, E. Facilitating multiparty dialog with gaze, gesture, and speech. ICMI-MLMI '10, (2010).  ",
      "doi": "10.1145/1891903.1891910"
    },
    {
      "text": "Bohus, D. and Horvitz, E. Learning to predict engagement with a spoken dialog system in open-world settings. In Proc. SIGDIAL'09, (2009), 244--251. ",
      "doi": "10.5555/1708376.1708411"
    },
    {
      "text": "Bohus, D. and Horvitz, E. Multiparty turn taking in situated dialog: Study, lessens, and directions. In Proc. SIGDIAL'11, (2011), 98--109. ",
      "doi": "10.5555/2132890.2132903"
    },
    {
      "text": "Burgoon, J.K. and Dillman, L. Gender, immediacy, and nonverbal communication. in Kalbfleisch, P.J. and Cody, M.J. eds. Gender, power, and communication in human relationships, Psychology Press, 1995.",
      "doi": ""
    },
    {
      "text": "Castellano, G., Pereira, A. and McOwan, P.W. Detecting user engagement with a robot companion using task and social interaction-based features. In Proc. ICMI-MLMI'09, ACM Press (2009), 119--125.  ",
      "doi": "10.1145/1647314.1647336"
    },
    {
      "text": "Chidambaram, V., Shiang, Y.-H. and Mutlu, B. Designing persuasive robots: How robots might persuade people using vocal and nonverbal cues. HRI'12, (2012), 293--300.  ",
      "doi": "10.1145/2157689.2157798"
    },
    {
      "text": "Clark, H. and Carlson, T. Hearers and speech acts. Language, 58, (1982), 332--373.",
      "doi": ""
    },
    {
      "text": "Huang, C.-M. and Mutlu, B. Robot behavior toolkit: Generating effective social behaviors for robots. In Proc. HRI'12, (2012), ACM/IEEE, 25--32.  ",
      "doi": "10.1145/2157689.2157694"
    },
    {
      "text": "Jokinen, K., Nishida, M. and Yamamoto, S. On eye-gaze and turn-taking. In Proc. EGIHMI'10, (2010), 118--123.  ",
      "doi": "10.1145/2002333.2002352"
    },
    {
      "text": "Katzenmaier, M., Stiefelhagen, R. and Schultz, T. Identifying the addressee in human-human-robot interactions based on head pose and speech. In Proc. ICMI'04, (2004), 144--151.  ",
      "doi": "10.1145/1027933.1027959"
    },
    {
      "text": "Kendon, A. Conducting Interaction: Patterns of Behavior in Focused Encounters. Cambridge University Press, 1990.",
      "doi": ""
    },
    {
      "text": "Kuno, Y., Sadazuka, K., Kawashima, M., Yamazaki, K., Yamazaki, A. and Kuzuoka, H. Museum guide robot based on sociological interaction analysis. In Proc. CHI'07, ACM Press (2007), 1191--1194.  ",
      "doi": "10.1145/1240624.1240804"
    },
    {
      "text": "Kuzuoka, H., Suzuki, Y., Yamashita, J. and Yamazaki, K. Reconfiguring spatial formation arrangement by robot body orientation. In Proc. HRI'10, (2010), 285--292. ",
      "doi": "10.5555/1734454.1734557"
    },
    {
      "text": "Lang, S., Kleinehagenbrock, M., Hohenner, S., Fritsch, J., Fink, G.A. and Sagerer, G. Providing the basis for humanrobot-interaction: A multi-modal attention system for a mobile robot. In Proc. ICMI'03, (2003), 28--35.  ",
      "doi": "10.1145/958432.958441"
    },
    {
      "text": "Langton, S.R., Watt, R.J. and Bruce, V. Do the eyes have it? Cues to the direction of social attention. Trends in Cognitive Sciences, 2, 2 (2003), 50--59.",
      "doi": ""
    },
    {
      "text": "Lee, M.K., Kiesler, S. and Forlizzi, J. Receptionist or information kiosk: How do people talk with a robot? In Proc. CSCW 2010, ACM Press (2010), 31--40.  ",
      "doi": "10.1145/1718918.1718927"
    },
    {
      "text": "Li, L., Yu, X., Li, J., Wang, G., Shi, J.-Y., Tan, Y.K. and Li, H., Vision-based attention estimation and selection for social robot to perform natural interaction in the open world. In Proc. HRI'12, ACM/IEEE (2012), 183--184.  ",
      "doi": "10.1145/2157689.2157746"
    },
    {
      "text": "Michalowski, M.P., Sabanovic, S. and Simmons, R. A spatial model of engagement for a social robot. In Proc. 9th IEEE International Workshop on Advanced Motion Control, (2006), 762--767.",
      "doi": ""
    },
    {
      "text": "Morency, L.-P., Christoudias, C.M. and Darrell, T. Recognizing gaze aversion gestures in embodied conversational discourse. ICMI'06, (2006), 287--294.  ",
      "doi": "10.1145/1180995.1181051"
    },
    {
      "text": "Mumm, J. and Mutlu, B. Human-robot proxemics: Physical and psychological distancing in human-robot interaction. In Proc. HRI'11, ACM/IEEE (2011), 331--338.  ",
      "doi": "10.1145/1957656.1957786"
    },
    {
      "text": "Mutlu, B., Kanda, T., Forlizzi, J., Hodgins, J. and Ishiguro, H. Conversational gaze mechanisms for humanlike robots. ACM Trans. Interactive Intelligent Systems, 1, 2 (2012) 12(1--33).  ",
      "doi": "10.1145/2070719.2070725"
    },
    {
      "text": "Mutlu, B., Shiwa, T., Takayuki K, Ishiguro, H. and Hagita, N. Footing in human-robot conversations: How robots might shape participant roles using gaze cues. In Proc. HRI'09, ACM/IEEE (2009), 61--68.  ",
      "doi": "10.1145/1514095.1514109"
    },
    {
      "text": "Nakano, Y., Reinstein, G., Stocky, T. and Cassell, J. Towards a model of face-to-face grounding. 41st meeting of the Assoc. Comput. Linguistics, (2003), 553--561.  ",
      "doi": "10.3115/1075096.1075166"
    },
    {
      "text": "Nakano, Y.I. and Ishii, R. Estimating user's engagement from eye-gaze behaviors in human-agent conversations. In Proc. IUI'10, ACM Press (2010), 139--148.  ",
      "doi": "10.1145/1719970.1719990"
    },
    {
      "text": "Patterson, M. An arousal model of interpersonal intimacy. Psychological Review, 83, 3 (1976), 235--245.",
      "doi": ""
    },
    {
      "text": "Peters, C. Direction of attention perception for conversation initiation in virtual environments. In Proc. 5th Int. Conf. Intelligent Virtual Agents, (2005), 215--228.  ",
      "doi": "10.1007/11550617_19"
    },
    {
      "text": "Peters, C., Pelachaud, C., Bevacqua, E., Mancini, M. and Poggi, I. A model of attention and interest using gaze behavior. In Proc. IVA2005, (2005), 229--240.  ",
      "doi": "10.1007/11550617_20"
    },
    {
      "text": "Rich, C., Ponsler, B., Holroyd, A. and Sidner, C. Recognizing engagement in human-robot interaction. In Proc. HRI'10, ACM/IEEE (2010), 375--382. ",
      "doi": "10.5555/1734454.1734580"
    },
    {
      "text": "Sidner, C. Engagement: Looking and not looking as evidence for disengagement. Workshop at HRI'12, (2012).",
      "doi": ""
    },
    {
      "text": "Sidner, C.L., Kidd, C.D., Lee, C. and Lesh, N. Where to look: A study of human-robot engagement. In Proc. IUI'04, ACM Press (2004), 78--84.  ",
      "doi": "10.1145/964442.964458"
    },
    {
      "text": "Sidner, C.L., Lee, C., Kidd, C.D. and Rich, C. Explorations in engagement for humans and robots. Artificial Intelligence, 166 (2005),140--164.  ",
      "doi": "10.5555/1090725.1644610"
    },
    {
      "text": "Szafir, D. and Mutlu, B. Pay attention! Designing adaptive agents that monitor and improve user engagement. In Proc. CHI'12, ACM Press (2012), 11--20.  ",
      "doi": "10.1145/2207676.2207679"
    },
    {
      "text": "Tojo, T., Matsusaka, Y., Ishii, T. and Kobayashi, T. A conversational robot utilizing facial and body expressions. IEEE Int. Conf. on Systems, Man, and Cybernetics (SMC), (2000), 858--863.",
      "doi": ""
    },
    {
      "text": "Vertegaal, R. and Ding, Y. Explaining effects of eye gaze on mediated group conversations: Amount or synchronization? In Proc. CSCW'02, ACM Press (2002), 41--48.  ",
      "doi": "10.1145/587078.587085"
    },
    {
      "text": "Vertegaal, R., Slagter, R., van der Veer, G.C. and Nijholt, A. Eye gaze patterns in conversations: There is more to conversational agents than meet the eyes. In Proc. CHI'01, ACM Press (2001), 301--308.  ",
      "doi": "10.1145/365024.365119"
    },
    {
      "text": "Yamaoka, F., Kanda, T. and Ishiguro, H., How close? Model of proximity control for information-presenting robots. In Proc. HRI'08, ACM/IEEE (2008), 137--144.  ",
      "doi": "10.1145/1349822.1349841"
    },
    {
      "text": "Yamaoka, F., Kanda, T., Ishiguro, H. and Hagita, N. Developing a model of robot behavior to identify and appropriately respond to implicit attention-shifting. In Proc. HRI'09, ACM/IEEE (2009), 133--140.  ",
      "doi": "10.1145/1514095.1514120"
    },
    {
      "text": "Yamaoka, F., Kanda, T., Ishiguro, H. and Hagita, N. A model of proximity control for information-presenting robots. IEEE Trans. Robotics, 26,1 (2010), 187--195  ",
      "doi": "10.1109/TRO.2009.2035747"
    },
    {
      "text": "Yamazaki, A., Yamazaki, K., Ohyama, T., Kobayashi, Y. and Kuno, Y. A techno-sociological solution for designing a museum guide robot: Regarding choosing an appropriate visitor. In Proc. HRI'12, ACM/IEEE (2012), 309--316.  ",
      "doi": "10.1145/2157689.2157800"
    },
    {
      "text": "Yamazaki, A., Yamazaki, K., Kuno, Y., Burdelski, M., Kawashima, M. and Kuzuoka, H. Precision timing in human-robot interaction: Coordination of head movement and utterance. In Proc. CHI'08, ACM Press (2008), 131140.  ",
      "doi": "10.1145/1357054.1357077"
    },
    {
      "text": "Yamazaki, K., Yamazaki, A., Okada, M., Kuno, Y., Kobayashi, Y., Hoshi, Y., Pitsch, K., Luff, P., vom Lehn, D. and Heath, C. Revealing Gauguin: Engaging visitors in robot guide's explanation in an art museum. In Proc. CHI'09, ACM Press (2009), 1437--1446.  ",
      "doi": "10.1145/1518701.1518919"
    },
    {
      "text": "Yonezawa, T., Yamazoe, H., Utsumi, A. and Abe, S. Evaluating crossmodal awareness of daily-partner robot to user's behaviors with gaze and utterance detection. In Proc. CASEMANS'09, ACM Press (2009), 1--8.  ",
      "doi": "10.1145/1538864.1538866"
    }
  ]
}