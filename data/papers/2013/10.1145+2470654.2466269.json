{
  "doi": "10.1145/2470654.2466269",
  "title": "Warping time for more effective real-time crowdsourcing",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2033-2036",
  "year": 2013,
  "badges": [],
  "abstract": "In this paper, we introduce the idea of \"warping time\" to improve crowd performance on the difficult task of captioning speech in real-time. Prior work has shown that the crowd can collectively caption speech in real-time by merging the partial results of multiple workers. Because non-expert workers cannot keep up with natural speaking rates, the task is frustrating and prone to errors as workers buffer what they hear to type later. The TimeWarp approach automatically increases and decreases the speed of speech playback systematically across individual workers who caption only the periods played at reduced speed. Studies with 139 remote crowd workers and 24 local participants show that this approach improves median coverage (14.8%), precision (11.2%), and per-word latency (19.1%). Warping time may also help crowds outperform individuals on other difficult real-time performance tasks.",
  "authors": [
    {
      "name": "Walter S. Lasecki",
      "institution": "University of Rochester, Rochester, New York, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81490695200",
      "orcid": "missing"
    },
    {
      "name": "Christopher D. Miller",
      "institution": "University of Rochester, Rochester, New York, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81557747456",
      "orcid": "missing"
    },
    {
      "name": "Jeffrey P. Bigham",
      "institution": "University of Rochester, Rochester, New York, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81338487593",
      "orcid": "0000-0002-2072-0625"
    }
  ],
  "references": [
    {
      "text": "Bernstein, M. S., Brandt, J. R., Miller, R. C., and Karger, D. R. Crowds in two seconds: Enabling realtime crowd-powered interfaces. In UIST 2011.  ",
      "doi": "10.1145/2047196.2047201"
    },
    {
      "text": "Bigham, J. P., Jayant, C., Ji, H., Little, G., Miller, A., Miller, R. C., Miller, R., Tatarowicz, A., White, B., White, S., and Yeh, T. Vizwiz: nearly real-time answers to visual questions. In UIST 2010.  ",
      "doi": "10.1145/1866029.1866080"
    },
    {
      "text": "Driedger, J. Time-scale modication algorithms for music audio signals. Master's thesis, Saarland University, 2011.",
      "doi": ""
    },
    {
      "text": "C. Jensema, R. McCann, S. Ramsey. Closed-captioned TV presentation speed and vocabulary. In Am Ann Deaf. 141(4):284--92. 1996.",
      "doi": ""
    },
    {
      "text": "Lasecki, W., and Bigham, J. Online quality control for real-time crowd captioning. In ASSETS 2012.  ",
      "doi": "10.1145/2384916.2384942"
    },
    {
      "text": "Lasecki, W., Murray, K., White, S., Miller, R. C., and Bigham, J. P. Real-time crowd control of existing interfaces. In UIST 2011.  ",
      "doi": "10.1145/2047196.2047200"
    },
    {
      "text": "Lasecki, W. S., Miller, C. D., Sadilek, A., Abumoussa, A., Borrello, D., Kushalnagar, R., and Bigham, J. P. Real-time captioning by groups of non-experts. In UIST 2012.  ",
      "doi": "10.1145/2380116.2380122"
    },
    {
      "text": "Y. C. Beatrice Liem, H. Zhang. An iterative dual pathway structure for speech-to-text transcription. In HCOMP 2011.",
      "doi": ""
    },
    {
      "text": "Luz, S. and Masoodian, M. and Rogers, B. Supporting collaborative transcription of recorded speech with a 3D game interface. In KES 2010. ",
      "doi": "10.5555/1893971.1894019"
    },
    {
      "text": "Lasecki, W. S., Song, Y. C., Kautz, H., and Bigham, J. P. Real-time crowd labeling for deployable activity recognition. In CSCW 2013.  ",
      "doi": "10.1145/2441776.2441912"
    },
    {
      "text": "Verhelst, W., and Roelands, M. An overlap-add technique based on waveform similarity (wsola) for high quality time-scale modification of speech. In ICASSP 1993. ",
      "doi": "10.5555/1946943.1947097"
    }
  ]
}