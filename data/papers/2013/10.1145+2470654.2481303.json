{
  "doi": "10.1145/2470654.2481303",
  "title": "Reflexive loopers for solo musical improvisation",
  "published": "2013-04-27",
  "proctitle": "CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2205-2208",
  "year": 2013,
  "badges": [],
  "abstract": "Loop pedals are real-time samplers that playback audio played previously by a musician. Such pedals are routinely used for music practice or outdoor \"busking\". However, loop pedals always playback the same material, which can make performances monotonous and boring both to the musician and the audience, preventing their widespread uptake in professional concerts. In response, we propose a new approach to loop pedals that addresses this issue, which is based on an analytical multi-modal representation of the audio input. Instead of simply playing back prerecorded audio, our system enables real-time generation of an audio accompaniment reacting to what is currently being performed by the musician. By combining different modes of performance - e.g. bass line, chords, solo - from the musician and system automatically, solo musicians can perform duets or trios with themselves, without engendering the so-called canned (boringly repetitive and unresponsive) music effect of loop pedals. We describe the technology, based on supervised classification and concatenative synthesis, and then illustrate our approach on solo performances of jazz standards by guitar. We claim this approach opens up new avenues for concert performance.",
  "authors": [
    {
      "name": "Fran\u00e7ois Pachet",
      "institution": "Sony CSL Paris, Paris, France",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100218356",
      "orcid": "missing"
    },
    {
      "name": "Pierre Roy",
      "institution": "Sony CSL Paris, Paris, France",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100653192",
      "orcid": "missing"
    },
    {
      "name": "Julian Moreira",
      "institution": "Sony CSL Paris, Paris, France",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81557388156",
      "orcid": "missing"
    },
    {
      "name": "Mark d'Inverno",
      "institution": "Goldsmiths & Sony CSL Paris, Paris, France",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100588827",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Aebersold, J., How To Play Jazz & Improvise, Book & CD Set, Vol. 1, 2000.",
      "doi": ""
    },
    {
      "text": "Boss, RC-3 Loop Station Owner's Manual, 2011.",
      "doi": ""
    },
    {
      "text": "Cherla, S. Automatic Phrase Continuation from Guitar and Bass-guitar Melodies, Master thesis, UPF, 2011.",
      "doi": ""
    },
    {
      "text": "Hamanaka, M., Goto, M., Asoh, H., and Otsu, N., A learning-based jam session system that imitates a player's personality model. IJCAI, pp. 51--58, 2003. ",
      "doi": "10.5555/1630659.1630667"
    },
    {
      "text": "Jordan, S., Magic Touch, Blue Note Records 1985.",
      "doi": ""
    },
    {
      "text": "L\u00e4hdeoja, O., An approach to instrument augmentation: the electric guitar, Proc. New Interfaces for Musical Expression conference, NIME 2008.",
      "doi": ""
    },
    {
      "text": "L\u00e9vy, B., Bloch, G., and Assayag, G., OMaxist Dialectics: Capturing, Visualizing and Expanding Improvisations, Proc. NIME 2012, Ann Arbor, 2012.",
      "doi": ""
    },
    {
      "text": "Peeters, G., A large set of audio features for sound description (similarity and classification) in the CUIDADO project, Ircam Report 2000.",
      "doi": ""
    },
    {
      "text": "Reboursi\u00e8re, L., Frisson, C., L\u00e4hdeoja, O., Anderson, J., Iii, M., Picard, C., and Todoroff, T., Multimodal Guitar: A Toolbox For Augmented Guitar Performances, Proc. of NIME, 2010.",
      "doi": ""
    },
    {
      "text": "Schwarz, D. Current research in Concatenative Sound Synthesis, Proc. Int. Computer Music Conf., 2005.",
      "doi": ""
    },
    {
      "text": "Lachambre, H., Andre-Obrecht, R., and Pinquier, J., Distinguishing monophonies from polyphonies using Weibull bivariate distributions, IEEE Trans. Audio, Speech and Lang. Process., 19 (6), pp. 1837--1842, Aug. 2011.  ",
      "doi": "10.1109/TASL.2010.2089517"
    }
  ]
}