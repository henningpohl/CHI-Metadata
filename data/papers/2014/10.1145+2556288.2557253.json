{
  "doi": "10.1145/2556288.2557253",
  "title": "ISSE: an interactive source separation editor",
  "published": "2014-04-26",
  "proctitle": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "257-266",
  "year": 2014,
  "badges": [],
  "abstract": "Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.). Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source, freely available, and cross-platform audio editing tool that enables a user to perform source separation by painting on time-frequency visualizations of sound, resulting in an interactive machine learning system. The system brings to life our previously proposed interaction paradigm and separation algorithm that learns from user-feedback to perform separation. For evaluation, we conducted user studies and compared results between inexperienced and expert users. For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality.",
  "tags": [
    "interactive machine learning",
    "intelligent user interface",
    "source separation",
    "audio interface"
  ],
  "authors": [
    {
      "name": "Nicholas J. Bryan",
      "institution": "Stanford University, Palo Alto, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81474670246",
      "orcid": "missing"
    },
    {
      "name": "Gautham J. Mysore",
      "institution": "Adobe Systems Inc., San Francisco, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81418598351",
      "orcid": "missing"
    },
    {
      "name": "Ge Wang",
      "institution": "Stanford University, Palo Alto, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81450592499",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Amershi, S., Lee, B., Kapoor, A., Mahajan, R., and Christian, B. Cuet: Human-guided fast and accurate network alarm triage. In Proc. CHI (2011), 157--166.  ",
      "doi": "10.1145/1978942.1978966"
    },
    {
      "text": "Battenberg, E., and Wessel, D. Accelerating non-negative matrix factorization for audio source separation on multi-core and many-core architectures. In Proc. ISMIR (2009), 501--506.",
      "doi": ""
    },
    {
      "text": "Bogaards, N., R\u00f6bel, A., and Rodet, X. Sound analysis and processing with audiosculpt 2. In Proc. ICMC (2004).",
      "doi": ""
    },
    {
      "text": "Boogaart, C. G. v. d., and Lienhart, R. Audio brush: a tool for computer-assisted smart audio editing. In ACM Workshop on Audio and Music Computing Multimedia (2006), 115--124.  ",
      "doi": "10.1145/1178723.1178741"
    },
    {
      "text": "Bryan, N. J., and Mysore, G. J. An efficient posterior regularized latent variable model for interactive sound source separation. In Proc. ICML (2013).",
      "doi": ""
    },
    {
      "text": "Bryan, N. J., and Mysore, G. J. Interactive refinement of supervised and semi-supervised sound source separation estimates. In Proc. ICASSP (2013).",
      "doi": ""
    },
    {
      "text": "Bryan, N. J., Mysore, G. J., and Wang, G. Source separation of polyphonic music with interactive user-feedback on a piano roll display. In Proc. ISMIR (2013).",
      "doi": ""
    },
    {
      "text": "Cohn, D., Caruana, R., and Mccallum, A. Semi-supervised clustering with user feedback. In Constrained Clustering: Advances in Algorithms, Theory, and Applications, S. Basu, I. Davidson, and K. Wagstaff, Eds. Chapman & Hall/CRC, 2008.",
      "doi": ""
    },
    {
      "text": "Durrieu, J.-L., and Thiran, J.-P. Musical audio source separation based on user-selected f0 track. In Proc. LVA/ICA (2012), 438--445.  ",
      "doi": "10.1007/978-3-642-28551-6_54"
    },
    {
      "text": "Emiya, V., Vincent, E., Harlander, N., and Hohmann, V. Subjective and objective quality assessment of audio source separation. IEEE Transactions on Audio, Speech, and Language Processing 19, 7 (2011), 2046--2057.  ",
      "doi": "10.1109/TASL.2011.2109381"
    },
    {
      "text": "Fails, J. A., and Olsen, Jr., D. R. Interactive machine learning. In Proc. IUI (2003), 39--45.  ",
      "doi": "10.1145/604045.604056"
    },
    {
      "text": "F\u00e9votte, C., Bertin, N., and Durrieu, J.-L. Nonnegative matrix factorization with the itakura-saito divergence: With application to music analysis. Neural Computation 21, 3 (2009), 793--830.  ",
      "doi": "10.5555/2696354.2696362"
    },
    {
      "text": "Fiebrink, R. Real-time Human Interaction with Supervised Learning Algorithms for Music Composition and Performance. PhD thesis, Princeton University, 2011. ",
      "doi": "10.5555/2125776"
    },
    {
      "text": "Fogarty, J., Tan, D., Kapoor, A., and Winder, S. Cueflik: interactive concept learning in image search. In Proc. CHI (2008), 29--38.  ",
      "doi": "10.1145/1357054.1357061"
    },
    {
      "text": "Fowler, T. Giraffe (modified). http://www.flickr.com/photos/j33pman/7701103436/, 2012. Attribution-NonCommercial-ShareAlike 2.0 Generic License.",
      "doi": ""
    },
    {
      "text": "Free Software Foundation. GPL Version 3. http://gplv3.fsf.org/, 2007.",
      "doi": ""
    },
    {
      "text": "Frigo, M., and Johnson, S. G. The design and implementation of FFTW3. Proc. of the IEEE Special Issue on Program Generation, Optimization, and Platform Adaptation 93, 2 (2005), 216--231.",
      "doi": ""
    },
    {
      "text": "Ganchev, K., Gra\u00e7a, J., Gillenwater, J., and Taskar, B. Posterior regularization for structured latent variable models. Journal of Machine Learning Research 11 (2010), 2001--2049. ",
      "doi": "10.5555/1756006.1859918"
    },
    {
      "text": "Guennebaud, G., Jacob, B., et al. Eigen v3. http://eigen.tuxfamily.org, 2010.",
      "doi": ""
    },
    {
      "text": "Hofmann, T. Probabilistic latent semantic indexing. In Proc. SIGIR (1999), 50--57.  ",
      "doi": "10.1145/312624.312649"
    },
    {
      "text": "Lee, D. D., and Seung, H. S. Algorithms for non-negative matrix factorization. In Proc. NIPS (2001), 556--562.",
      "doi": ""
    },
    {
      "text": "Lef\u00e8vre, A., Bach, F., and F\u00e9votte, C. Semi-supervised nmf with time-frequency annotations for single-channel source separation. In Proc. ISMIR (2012).",
      "doi": ""
    },
    {
      "text": "Ono, N., Koldovsky, Z., Miyabe, S., and Ito, N. The 2013 signal separation evaluation campaign. In Machine Learning for Signal Processing (MLSP), 2013 IEEE International Workshop on, IEEE (2013), 1--6.",
      "doi": ""
    },
    {
      "text": "Ozerov, A., F\u00e9votte, C., Blouet, R., and Durrieu, J.-L. Multichannel nonnegative tensor factorization with structured constraints for user-guided audio source separation. In Proc. ICASSP (May 2011), 257--260.",
      "doi": ""
    },
    {
      "text": "Ozerov, A., Vincent, E., and Bimbot, F. A general flexible framework for the handling of prior information in audio source separation. IEEE Transactions on Audio, Speech, and Language Processing 20, 4 (2012), 1118--1133.",
      "doi": "10.1109/TASL.2011.2172425"
    },
    {
      "text": "Raj, B., and Smaragdis, P. Latent variable decomposition of spectrograms for single channel speaker separation. In Proc. IEEE WASPAA (2005), 17--20.",
      "doi": ""
    },
    {
      "text": "Rother, C., Kolmogorov, V., and Blake, A. \"grabcut\": interactive foreground extraction using iterated graph cuts. Proc. SIGGRAPH 23, 3 (2004), 309--314.  ",
      "doi": "10.1145/1186562.1015720"
    },
    {
      "text": "Settles, B. Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances. In Proc. EMNLP (2011), 1467--1478. ",
      "doi": "10.5555/2145432.2145588"
    },
    {
      "text": "SiSEC Audio Committee. Signal separation evaluation campaign (sisec). http://sisec.wiki.irisa.fr/tiki-index.php, 2013.",
      "doi": ""
    },
    {
      "text": "Smaragdis, P. User guided audio selection from complex sound mixtures. In Proc. UIST (2009), 89--92.  ",
      "doi": "10.1145/1622176.1622193"
    },
    {
      "text": "Smaragdis, P., and Brown, J. Non-negative matrix factorization for polyphonic music transcription. In IEEE WASPAA (2003), 177--180.",
      "doi": ""
    },
    {
      "text": "Smaragdis, P., and Mysore, G. J. Separation by \"humming\": User-guided sound extraction from monophonic mixtures. In Proc. IEEE WASPAA (2009), 69--72.",
      "doi": ""
    },
    {
      "text": "Smaragdis, P., Raj, B., and Shashanka, M. A probabilistic latent variable model for acoustic modeling. In NIPS Workshop on Advances in Modeling for Acoustic Processing (2006).",
      "doi": ""
    },
    {
      "text": "Smaragdis, P., Raj, B., and Shashanka, M. Supervised and semi-supervised separation of sounds from single-channel mixtures. In Proc. LVA/ICA (2007), 414--421. ",
      "doi": "10.5555/1776684.1776739"
    },
    {
      "text": "Storer, J. JUCE (Jules' Utility Class Extensions). http://rawmaterialsoftware.com/juce.php, 2013. online.",
      "doi": ""
    },
    {
      "text": "Stumpf, S., Rajaram, V., Li, L., Burnett, M., Dietterich, T., Sullivan, E., Drummond, R., and Herlocker, J. Toward harnessing user feedback for machine learning. In Proc. IUI (2007), 82--91.  ",
      "doi": "10.1145/1216295.1216316"
    },
    {
      "text": "Talbot, J., Lee, B., Kapoor, A., and Tan, D. Ensemblematrix: Interactive visualization to support machine learning with multiple classifiers. In Proc. CHI (2009).  ",
      "doi": "10.1145/1518701.1518895"
    },
    {
      "text": "Vincent, E., Gribonval, R., and F\u00e9votte, C. Performance measurement in blind audio source separation. IEEE Transactions on Audio, Speech, and Language Processing 14, 4 (2006), 1462--1469.  ",
      "doi": "10.1109/TSA.2005.858005"
    },
    {
      "text": "Virtanen, T. Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria. IEEE Transactions on Audio, Speech and Language Processing 15, 3 (2007), 1066--1074.  ",
      "doi": "10.1109/TASL.2006.885253"
    }
  ]
}