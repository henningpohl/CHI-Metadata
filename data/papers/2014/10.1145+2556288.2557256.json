{
  "doi": "10.1145/2556288.2557256",
  "title": "Smart subtitles for vocabulary learning",
  "published": "2014-04-26",
  "proctitle": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "853-862",
  "year": 2014,
  "badges": [],
  "abstract": "Language learners often use subtitled videos to help them learn. However, standard subtitles are geared more towards comprehension than vocabulary learning, as translations are nonliteral and are provided only for phrases, not vocabulary. This paper presents Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning. Smart Subtitles can be automatically generated from common video sources such as subtitled DVDs. They provide features such as vocabulary definitions on hover, and dialog-based video navigation. In our pilot study with intermediate learners studying Chinese, participants correctly defined over twice as many new words in a post-viewing vocabulary test when they used Smart Subtitles, compared to dual Chinese-English subtitles. Learners spent the same amount of time watching clips with each tool, and enjoyed viewing videos with Smart Subtitles as much as with dual subtitles. Learners understood videos equally well using either tool, as indicated by self-assessments and independent evaluations of their summaries.",
  "authors": [
    {
      "name": "Geza Kovacs",
      "institution": "Stanford University, Palo Alto, CA, USA",
      "img": "/do/10.1145/contrib-81502669221/rel-imgonly/geza.png",
      "acmid": "81502669221",
      "orcid": "missing"
    },
    {
      "name": "Robert C. Miller",
      "institution": "Massachusetts Institute of Technology, Cambridge, MA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100162232",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Bansal, M., DeNero, J., and Lin, D. Unsupervised translation sense clustering. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics (2012), 773--782. ",
      "doi": "10.5555/2382029.2382154"
    },
    {
      "text": "Bianchi, F., and Ciabattoni, T. Captions and Subtitles in EFL Learning: an investigative study in a comprehensive computer environment. EUT-Edizioni Universit\u00e0 di Trieste (2008).",
      "doi": ""
    },
    {
      "text": "Bird, S., Klein, E., and Loper, E. Natural Language Processing with Python. O'Reilly, 2009. ",
      "doi": "10.5555/1717171"
    },
    {
      "text": "Breen, J. WWWJDIC - A Feature-Rich WWW-Based Japanese Dictionary. eLEX2009 (2009), 31.",
      "doi": ""
    },
    {
      "text": "Danan, M. Reversed subtitling and dual coding theory: New directions for foreign language instruction. Language Learning 42, 4 (1992), 497--527.",
      "doi": ""
    },
    {
      "text": "Danan, M. Captioning and subtitling: Undervalued language learning strategies. Meta: Translators? Journal 49, 1 (2004), 67--77.",
      "doi": ""
    },
    {
      "text": "Dummitt, N. Chinese Through Tone and Color. Hippocrene Books, 2008.",
      "doi": ""
    },
    {
      "text": "d'Ydewalle, G. Foreign-language acquisition by watching subtitled television programs. Journal of Foreign Language Education and Research 12 (2002), 59--77.",
      "doi": ""
    },
    {
      "text": "Fukunaga, N. \"Those anime students\": Foreign language literacy development through Japanese popular culture. Journal of Adolescent & Adult Literacy 50, 3 (2006), 206--222.",
      "doi": ""
    },
    {
      "text": "Harris, C., and Stephens, M. A combined corner and edge detector. In Alvey vision conference, vol. 15, Manchester, UK (1988), 50.",
      "doi": ""
    },
    {
      "text": "Herron, C. An investigation of the effectiveness of using an advance organizer to introduce video in the foreign language classroom. The Modern Language Journal 78, 2 (1994), 190--198.",
      "doi": ""
    },
    {
      "text": "Katsamanis, A., Black, M., Georgiou, P. G., Goldstein, L., and Narayanan, S. SailAlign: Robust long speech-text alignment. In Proc. of Workshop on New Tools and Methods for Very-Large Scale Phonetics Research (2011).",
      "doi": ""
    },
    {
      "text": "Koolstra, C. M., Peeters, A. L., and Spinhof, H. The pros and cons of dubbing and subtitling. European Journal of Communication 17, 3 (2002), 325--354.",
      "doi": ""
    },
    {
      "text": "Krippendorff, K. Computing Krippendorff's alpha reliability. Departmental Papers (ASC) (2007), 43.",
      "doi": ""
    },
    {
      "text": "Kurohashi, S., Nakamura, T., Matsumoto, Y., and Nagao, M. Improvements of Japanese morphological analyzer JUMAN. In Proceedings of The International Workshop on Sharable Natural Language (1994), 22--28.",
      "doi": ""
    },
    {
      "text": "Lee, D.-S. Effective gaussian mixture learning for video background subtraction. Pattern Analysis and Machine Intelligence, IEEE Transactions on 27, 5 (2005), 827--832.  ",
      "doi": "10.1109/TPAMI.2005.102"
    },
    {
      "text": "MDBG. CC-CEDICT Chinese-English Dictionary. MDBG (2013).",
      "doi": ""
    },
    {
      "text": "Microsoft. Microsoft Office OneNote 2010. Microsoft (2010).",
      "doi": ""
    },
    {
      "text": "Mitterer, H., and McQueen, J. M. Foreign subtitles help but native-language subtitles harm foreign speech perception. PloS one 4, 11 (2009), e7785.",
      "doi": ""
    },
    {
      "text": "Raine, P. Incidental Learning of Vocabulary through Authentic Subtitled Videos. JALT - The Japan Association for Language Teaching (2012).",
      "doi": ""
    },
    {
      "text": "Sakunkoo, N., and Sakunkoo, P. GliFlix: Using Movie Subtitles for Language Learning. In UIST 2013 Adjunct, ACM (2009).",
      "doi": ""
    },
    {
      "text": "Secules, T., Herron, C., and Tomasello, M. The effect of video context on foreign language learning. The Modern Language Journal 76, 4 (1992), 480--490.",
      "doi": ""
    },
    {
      "text": "Shea, P. Leveling the playing field: A study of captioned interactive video for second language learning. Journal of Educational Computing Research 22, 3 (2000), 243--264.",
      "doi": ""
    },
    {
      "text": "Smith, R. An overview of the Tesseract OCR engine. In Document Analysis and Recognition, 2007. ICDAR 2007. Ninth International Conference on, vol. 2, IEEE (2007), 629--633. ",
      "doi": "10.5555/1304596.1304846"
    },
    {
      "text": "Speed, E. Rikaikun. Google Chrome Web Store (2013).",
      "doi": ""
    },
    {
      "text": "Tseng, H., Chang, P., Andrew, G., Jurafsky, D., and Manning, C. A Conditional Random Field Word Segmenter for SIGHAN bakeoff 2005. In Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing, vol. 171, Jeju Island, Korea (2005).",
      "doi": ""
    },
    {
      "text": "W3C. WebVTT: The Web Video Text Tracks Format. W3C (2013).",
      "doi": ""
    },
    {
      "text": "Wesche, M., and Paribakht, T. S. Assessing Second Language Vocabulary Knowledge: Depth Versus Breadth. Canadian Modern Language Review 53, 1 (1996), 13--40.",
      "doi": ""
    },
    {
      "text": "Zesch, T., M\u00fcller, C., and Gurevych, I. Extracting Lexical Semantic Knowledge from Wikipedia and Wiktionary. In LREC, vol. 8 (2008), 1646--1652.",
      "doi": ""
    },
    {
      "text": "Zuggy, B. SubRip (2011).",
      "doi": ""
    }
  ]
}