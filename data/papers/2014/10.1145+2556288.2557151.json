{
  "doi": "10.1145/2556288.2557151",
  "title": "Understanding finger input above desktop devices",
  "published": "2014-04-26",
  "proctitle": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "1083-1092",
  "year": 2014,
  "badges": [],
  "abstract": "Using the space above desktop input devices adds a rich new input channel to desktop interaction. Input in this elevated layer has been previously used to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access vertically stacked menus. However, designing these interactions is challenging because the lack of haptic and direct visual feedback easily leads to input errors. For bare finger input, the user's fingers needs to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space. In this paper, we present the results of two user studies that inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume that users can reliably remain within. We found that when accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into midair. Finally, we propose a technique that reliably distinguishes clicking from homing movements, based on the user's hand shape. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.",
  "authors": [
    {
      "name": "Chat Wacharamanotham",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/do/10.1145/contrib-81484657903/rel-imgonly/chat150x200-201604.png",
      "acmid": "81484657903",
      "orcid": "0000-0003-4831-2516"
    },
    {
      "name": "Kashyap Todi",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659693175",
      "orcid": "missing"
    },
    {
      "name": "Marty Pye",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87959056257",
      "orcid": "missing"
    },
    {
      "name": "Jan Borchers",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/do/10.1145/contrib-81100443423/rel-imgonly/borchers_7154.jpg",
      "acmid": "81100443423",
      "orcid": "0000-0003-1509-3257"
    }
  ],
  "references": [
    {
      "text": "A. Banerjee, J. Burstyn, A. Girouard, and R. Vertegaal. Pointable: an in-air pointing technique to manipulate out-of-reach targets on tabletops. In ITS '11, 11--20. 2011.  ",
      "doi": "10.1145/2076354.2076357"
    },
    {
      "text": "W. Buxton. A three-state model of graphical input. In INTERACT '90, 449--456. 1990. ",
      "doi": "10.5555/647402.725582"
    },
    {
      "text": "F. Camp, A. Schick, and R. Stiefelhagen. How to click in mid-air. In Distributed, Ambient, and Pervasive Interactions, volume 8028 of LCNS, 78--86. 2013.",
      "doi": ""
    },
    {
      "text": "M. Desmurget, M. Jordan, C. Prablanc, and M. Jeannerod. Constrained and unconstrained movements involve different control strategies. J NEUROPHYSIOL, 77(3):1644--1650, 1997.",
      "doi": ""
    },
    {
      "text": "O. Hilliges, S. Izadi, A. D. Wilson, S. Hodges, A. Garcia-Mendoza, and A. Butz. Interactions in the air: adding further depth to interactive tabletops. In UIST '09, 139--148. 2009.  ",
      "doi": "10.1145/1622176.1622203"
    },
    {
      "text": "M. Jeannerod. The timing of natural prehension movements. J MOTOR BEHAV, 16(3):235, 1984.",
      "doi": ""
    },
    {
      "text": "H. Kato and H. Yanagihara. Pacman ui: vision-based finger detection for positioning and clicking manipulations. In MobileHCI '13, 464--467. 2013.  ",
      "doi": "10.1145/2493190.2494652"
    },
    {
      "text": "R. S. Kattinakere, T. Grossman, and S. Subramanian. Modeling steering within above-the-surface interaction layers. In CHI '07, 317--326. 2007.  ",
      "doi": "10.1145/1240624.1240678"
    },
    {
      "text": "J. Lee, A. Olwal, H. Ishii, and C. Boulanger. SpaceTop: integrating 2D and spatial 3D interactions in a see-through desktop environment. In CHI '13, 189--192. 2013.  ",
      "doi": "10.1145/2470654.2470680"
    },
    {
      "text": "N. Marquardt, R. Jota, S. Greenberg, and J. Jorge. The continuous interaction space: Interaction techniques unifying touch and gesture on and above a digital surface. In INTERACT '11, 461--476. 2011. ",
      "doi": "10.5555/2042182.2042224"
    },
    {
      "text": "C. Mueller-Tomfelde, A. Wessels, and C. Schremmer. Tilted tabletops: In between horizontal and vertical workspaces. In Wksp on Horizontal Interactive Human Computer Systems, TABLETOP '08, 49--56. 2008.",
      "doi": ""
    },
    {
      "text": "T. Mysliwiec. Fingermouse: A freehand computer pointing interface. In Int'l Conference on Automatic Face and Gesture Recognition, 372--377. 1994.",
      "doi": ""
    },
    {
      "text": "M. Ortega and L. Nigay. Airmouse: Finger gesture for 2d and 3d interaction. In INTERACT '09, 214--227. 2009.  ",
      "doi": "10.1007/978-3-642-03658-3_28"
    },
    {
      "text": "D. Pyryeskin, M. Hancock, and J. Hoey. Comparing Elicited Gestures to Designer-created Gestures for Selection Above a Multitouch Surface. In ITS '12, 1--10. 2012.  ",
      "doi": "10.1145/2396636.2396638"
    },
    {
      "text": "M. Spindler, M. Martsch, and R. Dachselt. Going beyond the surface: studying multi-layer interaction above the tabletop. In CHI '12, 1277--1286. 2012.  ",
      "doi": "10.1145/2207676.2208583"
    },
    {
      "text": "M. Spindler, S. Stellmach, and R. Dachselt. Paperlens: advanced magic lens interaction above the tabletop. In ITS '09, 69--76. 2009.  ",
      "doi": "10.1145/1731903.1731920"
    },
    {
      "text": "S. Subramanian, D. Aliakseyeu, and A. Lucero. Multi-layer interaction for digital tables. In UIST '06, 269--272. 2006.  ",
      "doi": "10.1145/1166253.1166295"
    },
    {
      "text": "D. Vogel and R. Balakrishnan. Distant freehand pointing and clicking on very large, high resolution displays. In UIST '05, 33--42. 2005.  ",
      "doi": "10.1145/1095034.1095041"
    },
    {
      "text": "A. D. Wilson. Robust computer vision-based detection of pinching for one and two-handed gesture input. In UIST '06, 255--258. 2006.  ",
      "doi": "10.1145/1166253.1166292"
    },
    {
      "text": "A. D. Wilson and H. Benko. Combining multiple depth cameras and projectors for interactions on, above and between surfaces. In UIST '10, 273--282. 2010.  ",
      "doi": "10.1145/1866029.1866073"
    },
    {
      "text": "J. O. Wobbrock, L. Findlater, D. Gergle, and J. J. Higgins. The aligned rank transform for nonparametric factorial analyses using only anova procedures. In CHI '11, 143--146. 2011.  ",
      "doi": "10.1145/1978942.1978963"
    },
    {
      "text": "C. Yu, X. Tan, Y. Shi, and Y. Shi. Air finger: enabling multi-scale navigation by finger height above the surface. In UbiComp '11, 495--496. 2011.  ",
      "doi": "10.1145/2030112.2030188"
    }
  ]
}