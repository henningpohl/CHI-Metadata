{
  "doi": "10.1145/2556288.2557021",
  "title": "Simplifying orientation measurement for mobile audio augmented reality applications",
  "published": "2014-04-26",
  "proctitle": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "615-624",
  "year": 2014,
  "badges": [],
  "abstract": "Audio augmented reality systems overlay the physical world with a virtual audio space. Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. To achieve this, information about the user's location and orientation is necessary which requires additional hardware. In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio. To verify this approach, we present two studies: Our first study in examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. We found that when navigating close to sound sources head tracking is necessary, but that it can potentially be replaced by device tracking in larger or more explorative usage scenarios. These findings help reduce the technical complexity of mobile audio augmented reality systems (MAARS), and enable their wider dissemination as mobile software-only apps.",
  "authors": [
    {
      "name": "Florian Heller",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/do/10.1145/contrib-81416598157/rel-imgonly/heller.jpg",
      "acmid": "81416598157",
      "orcid": "missing"
    },
    {
      "name": "Aaron Kr\u00e4mer",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87958786557",
      "orcid": "missing"
    },
    {
      "name": "Jan Borchers",
      "institution": "RWTH Aachen University, Aachen, NRW, Germany",
      "img": "/do/10.1145/contrib-81100443423/rel-imgonly/borchers_7154.jpg",
      "acmid": "81100443423",
      "orcid": "0000-0003-1509-3257"
    }
  ],
  "references": [
    {
      "text": "Alais, D., and Burr, D. The ventriloquist effect results from near-optimal bimodal integration. Current biology 14, 3 (2004), 257--262.",
      "doi": ""
    },
    {
      "text": "Ankolekar, A., Sandholm, T., and Yu, L. Play it by ear: a case for serendipitous discovery of places with musicons. In Proc. CHI '13, ACM (2013), 2959--2968.  ",
      "doi": "10.1145/2470654.2481411"
    },
    {
      "text": "Blauert, J. Spatial Hearing: Psychophysics of Human Sound Localization, 2nd ed. MIT Press, 1996.",
      "doi": ""
    },
    {
      "text": "Brungart, D. S., Simpson, B. D., and Kordik, A. J. The detectability of headtracker latency in virtual audio displays. In Proc. ICAD '05 (2005), 37--42.",
      "doi": ""
    },
    {
      "text": "Holland, S., Morse, D. R., and Gedenryd, H. AudioGPS: Spatial Audio Navigation with a Minimal Attention Interface. Personal and Ubiquitous computing 6, 4 (Jan. 2002).  ",
      "doi": "10.1007/s007790200025"
    },
    {
      "text": "Kajastila, R., and Lokki, T. Eyes-free methods for accessing large auditory menus. In Proc. ICAD '10 (2010), 223--230.",
      "doi": ""
    },
    {
      "text": "Loomis, J. M., Hebert, C., and Cicinelli, J. G. Active localization of virtual sounds. The Journal of the Acoustical Society of America 88 (1990), 1757.",
      "doi": ""
    },
    {
      "text": "Lyons, K., Gandy, M., and Starner, T. Guided by voices: An audio augmented reality system. In Proc. ICAD '00 (2000).",
      "doi": ""
    },
    {
      "text": "Mackay, W. E. Augmented reality: linking real and virtual worlds: a new paradigm for interacting with computers. In Proc. AVI '98, ACM (1998), 13--21.  ",
      "doi": "10.1145/948496.948498"
    },
    {
      "text": "Marentakis, G. N., and Brewster, S. A. Effects of feedback, mobility and index of difficulty on deictic spatial audio target acquisition in the horizontal plane. In Proc. CHI '06, ACM (2006), 359--368.  ",
      "doi": "10.1145/1124772.1124826"
    },
    {
      "text": "Mariette, N. Navigation performance effects of render method and head-turn latency in mobile audio augmented reality. In Proc. ICAD '09. Springer, Copenhagen, 2010, 239--265.  ",
      "doi": "10.1007/978-3-642-12439-6_13"
    },
    {
      "text": "McGookin, D., Brewster, S., and Priego, P. Audio Bubbles: Employing Non-speech Audio to Support Tourist Wayfinding. In Proc. HAID '09. Springer, Dresden, Germany, 2009, 41--50.  ",
      "doi": "10.1007/978-3-642-04076-4_5"
    },
    {
      "text": "Middlebrooks, J. C., and Green, D. M. Sound localization by human listeners. Annual review of psychology 42, 1 (1991), 135--159.",
      "doi": ""
    },
    {
      "text": "Reid, J., Hull, R., Cater, K., and Fleuriot, C. Magic moments in situated mediascapes. In Proc. ACE '05, ACM (2005), 290--293.  ",
      "doi": "10.1145/1178477.1178529"
    },
    {
      "text": "Sander, C., Wefers, F., and Leckschat, D. Scalable Binaural Synthesis on Mobile Devices. In AES Convention 133 (Oct. 2012).",
      "doi": ""
    },
    {
      "text": "Stahl, C. The roaring navigator: a group guide for the zoo with shared auditory landmark display. In Proc. MobileHCI '07, ACM (2007).  ",
      "doi": "10.1145/1377999.1378042"
    },
    {
      "text": "Terrenghi, L., and Zimmermann, A. Tailored audio augmented environments for museums. In Proc. IUI '04, ACM (2004).  ",
      "doi": "10.1145/964442.964523"
    },
    {
      "text": "Tran, T. V., Letowski, T., and Abouchacra, K. S. Evaluation of acoustic beacon characteristics for navigation tasks. Ergonomics 43, 6 (2000), 807--827.",
      "doi": ""
    },
    {
      "text": "Vazquez-Alvarez, Y., Oakley, I., and Brewster, S. Auditory display design for exploration in mobile audio-augmented reality. Personal and Ubiquitous computing 16, 8 (2012), 987--999.  ",
      "doi": "10.1007/s00779-011-0459-0"
    },
    {
      "text": "Vorl\u00e4nder, M. Auralization: Fundamentals of Acoustics, Modelling, Simulation, Algorithms and Acoustic Virtual Reality, 1st ed. Springer, 2007. ",
      "doi": "10.5555/1564843"
    },
    {
      "text": "Wakkary, R., and Hatala, M. ec(h)o: situated play in a tangible and audio museum guide. In Proc. DIS '06, ACM (2006).  ",
      "doi": "10.1145/1142405.1142448"
    },
    {
      "text": "Walker, B. N., and Lindsay, J. Navigation Performance With a Virtual Auditory Display: Effects of Beacon Sound, Capture Radius, and Practice. Human Factors 48, 2 (2006), 265--278.",
      "doi": ""
    },
    {
      "text": "Witmer, B. G., and Singer, M. J. Measuring Presence in Virtual Environments: A Presence Questionnaire. Presence: Teleoper. Virtual Environ. 7, 3 (1998), 225--240.  ",
      "doi": "10.1162/105474698565686"
    },
    {
      "text": "Zotkin, D. N., Duraiswami, R., and Davis, L. Rendering localized spatial audio in a virtual auditory space. IEEE Transactions on Multimedia 6, 4 (2004), 553--564.  ",
      "doi": "10.1109/TMM.2004.827516"
    }
  ]
}