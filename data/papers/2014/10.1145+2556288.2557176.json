{
  "doi": "10.1145/2556288.2557176",
  "title": "Finding dependencies between actions using the crowd",
  "published": "2014-04-26",
  "proctitle": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "3095-3098",
  "year": 2014,
  "badges": [],
  "abstract": "Activity recognition can provide computers with the context underlying user inputs, enabling more relevant responses and more fluid interaction. However, training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity. Prior work has enabled the crowd to provide labels in real-time to train automated systems on-the-fly, but numerous examples are still needed before the system can recognize an activity on its own. To reduce the need to collect this data by observing users, we introduce ARchitect, a system that uses the crowd to capture the dependency structure of the actions that make up activities. Our tests show that over seven times as many examples can be collected using our approach versus relying on direct observation alone, demonstrating that by leveraging the understanding of the crowd, it is possible to more easily train automated systems.",
  "authors": [
    {
      "name": "Walter S. Lasecki",
      "institution": "University of Rochester, Rochester, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81490695200",
      "orcid": "missing"
    },
    {
      "name": "Leon Weingard",
      "institution": "University of Rochester, Rochester, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "82458917057",
      "orcid": "missing"
    },
    {
      "name": "George Ferguson",
      "institution": "University of Rochester, Rochester, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81341490175",
      "orcid": "missing"
    },
    {
      "name": "Jeffrey P. Bigham",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81338487593",
      "orcid": "0000-0002-2072-0625"
    }
  ],
  "references": [
    {
      "text": "Allen, J. F. Towards a general theory of action and time. Artificial intelligence 23 (2). 123--154. 1984.  ",
      "doi": "10.1016/0004-3702%2884%2990008-0"
    },
    {
      "text": "Chilton, L. B., Little, G., Edge, D., Weld, D. S., and Landay, J. A. Cascade: Crowdsourcing taxonomy creation. CHI 2013.  ",
      "doi": "10.1145/2470654.2466265"
    },
    {
      "text": "Lasecki, W.S., White, S., Murray, K.I., and Bigham, J. P. Crowd memory: Learning the collective. CI 2012.",
      "doi": ""
    },
    {
      "text": "Lasecki, W. S., Song, Y. C., Kautz, H., and Bigham, J. P. Training activity recognition systems online using real-time crowdsourcing. CSCW 2012.",
      "doi": ""
    },
    {
      "text": "Little, G., Chilton, L. B., Goldman, M., and Miller, R. C. Turkit: human computation algorithms on mechanical turk. UIST 2010.  ",
      "doi": "10.1145/1866029.1866040"
    },
    {
      "text": "Quinn, E. J., Bederson, B. B., Yeh, T., and Lin, J. Crowdflow: Integrating machine learning with mechanical turk for speed-cost-quality flexibility. Tech. Rep., University of Maryland, 2010.",
      "doi": ""
    },
    {
      "text": "Richardson, M., and Domingos, P. Learning with knowledge from multiple experts ICML 2003.",
      "doi": ""
    },
    {
      "text": "Tapia, E., Intille, S., and Larson, K. Activity recognition the home using simple and ubiquitous sensors. Pervasive 2004.",
      "doi": ""
    },
    {
      "text": "Zhao, L., Sukthankar, G., and Sukthankar, R. Robust active learning using crowdsourced annotations for activity recognition. HC 2011.",
      "doi": ""
    }
  ]
}