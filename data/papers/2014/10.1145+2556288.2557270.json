{
  "doi": "10.1145/2556288.2557270",
  "title": "Visual recognition in museum guide apps: do visitors want it?",
  "published": "2014-04-26",
  "proctitle": "CHI '14: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "635-638",
  "year": 2014,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "In this paper, visual recognition (VisRec) is evaluated as a method to access background information on artworks in mobile museum guide applications (apps) by means of a field experiment. While museums and previous research have explored technical aspects, it is unclear whether visitors actually want to use VisRec. A prototype featuring VisRec, QR codes and number codes was developed and assessed with a usability study in two museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm for VisRec. Compared to previous literature, the results highlight the context-dependency of perceived usability and variability in the importance of usability factors. The results reveal a clear preference for VisRec among participants (53%); only 14% preferred QR codes. Ease of use, enjoyability and distance are identified as the main factors. This provides strong evidence to further explore the potential of VisRec to improve visitors' museum experiences.",
  "tags": [
    "access methods",
    "visual recognition",
    "usability test",
    "museum guide",
    "mobile applications"
  ],
  "authors": [
    {
      "name": "Leonard Wein",
      "institution": "Amsterdam University College, Amsterdam, Netherlands",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87959065457",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Albertini, A. Brunelli, R. Stock, O. and Zancanaro, M. (2005). Communicating user's focus of attention by image processing as input for a mobile museum guide. In Proc. IUI '05, 299--301.  ",
      "doi": "10.1145/1040830.1040905"
    },
    {
      "text": "American Association of Museums (2011). AAM: 2011 Mobile Technology Survey.",
      "doi": ""
    },
    {
      "text": "Bay, H. Fasel, B. and Gool, L. Van. (2006). Interactive museum guide: Fast and robust recognition of museum objects. Proc. of the first international workshop on mobile vision.",
      "doi": ""
    },
    {
      "text": "Brooke, J. (1996). SUS - A quick and dirty usability scale. Usability evaluation in industry, 189--194.",
      "doi": ""
    },
    {
      "text": "F\u00f6ckler, P. Zeidler, T. Brombach, B. Bruns, E. and Bimber, O. (2005). PhoneGuide: Museum guidance supported by on-device object recognition on mobile phones. Proc. MUM '05, 3--10.  ",
      "doi": "10.1145/1149488.1149490"
    },
    {
      "text": "Long, S. Kooper, R. Abowd, G. D. and Atkeson, C. G. (1996). Rapid prototyping of mobile context-aware applications: The Cyberguide case Study. Proc. MobiCom '96, 97--107.  ",
      "doi": "10.1145/236387.236412"
    },
    {
      "text": "M\u00f6ller, A. Diewald, S. Roalter, L. and Kranz, M. (2012). MobiMed: Comparing object identification techniques on smartphones. Proc. NordiCHI '12, 31--40.  ",
      "doi": "10.1145/2399016.2399022"
    },
    {
      "text": "Rublee, E. Rabaud, V. Konolige, K. And Bradski, G. (2011). ORB: An efficient alternative to SIFT or SURF. International Conference on Computer Vision, 2564--2571.  ",
      "doi": "10.1109/ICCV.2011.6126544"
    },
    {
      "text": "Ruf, B. Kokiopoulou, E. and Detyniecki, M. (2010). Mobile Museum Guide Based on Fast SIFT Recognition. Adaptive Multimedia Retrieval, 5811, 170--183.  ",
      "doi": "10.1007/978-3-642-14758-6_14"
    }
  ]
}