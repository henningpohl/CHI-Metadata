{
  "doi": "10.1145/3544548.3580687",
  "title": "PathFinder: Designing a Map-less Navigation System for Blind People in Unfamiliar Buildings",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-16",
  "year": 2023,
  "badges": [],
  "abstract": "Indoor navigation systems with prebuilt maps have shown great potential in navigating blind people even in unfamiliar buildings. However, blind people cannot always benefit from them in every building, as prebuilt maps are expensive to build. This paper explores a map-less navigation system for blind people to reach destinations in unfamiliar buildings, which is implemented on a robot. We first conducted a participatory design with five blind people, which revealed that intersections and signs are the most relevant information in unfamiliar buildings. Then, we prototyped PathFinder, a navigation system that allows blind people to determine their way by detecting and conveying information about intersections and signs. Through a participatory study, we improved the interface of PathFinder, such as the feedback for conveying the detection results. Finally, a study with seven blind participants validated that PathFinder could assist users in navigating unfamiliar buildings with increased confidence compared to their regular aid.",
  "tags": [
    "orientation and mobility",
    "sign recognition",
    "intersection detection",
    "visual impairment"
  ],
  "authors": [
    {
      "name": "Masaki Kuribayashi",
      "institution": "Waseda University, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659701839",
      "orcid": "0000-0001-8412-223X"
    },
    {
      "name": "Tatsuya Ishihara",
      "institution": "IBM Research - Tokyo, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81319494009",
      "orcid": "0000-0001-9618-0349"
    },
    {
      "name": "Daisuke Sato",
      "institution": "Robotics Institute, Carnegie Mellon University, United States",
      "img": "/do/10.1145/contrib-81327491464/rel-imgonly/daisuke2018-200x200.jpg",
      "acmid": "81327491464",
      "orcid": "0000-0002-7670-9177"
    },
    {
      "name": "Jayakorn Vongkulbhisal",
      "institution": "IBM Research - Tokyo, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87658971357",
      "orcid": "0000-0002-9764-7382"
    },
    {
      "name": "Karnik Ram",
      "institution": "Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660780398",
      "orcid": "0000-0002-5835-7104"
    },
    {
      "name": "Seita Kayukawa",
      "institution": "Waseda University, Japan",
      "img": "/do/10.1145/contrib-99659261707/rel-imgonly/_____1_.jpg",
      "acmid": "99659261707",
      "orcid": "0000-0002-0678-1157"
    },
    {
      "name": "Hironobu Takagi",
      "institution": "IBM Research - Tokyo, Japan",
      "img": "/do/10.1145/contrib-81408594028/rel-imgonly/1428.jpeg",
      "acmid": "81408594028",
      "orcid": "0000-0003-3087-3251"
    },
    {
      "name": "Shigeo Morishima",
      "institution": "Waseda Research Institute for Science and Engineering, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100066959",
      "orcid": "0000-0001-8859-6539"
    },
    {
      "name": "Chieko Asakawa",
      "institution": "Robotics Institute, Carnegie Mellon University, United States and IBM Research, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100044475",
      "orcid": "0000-0002-5447-1305"
    }
  ],
  "references": [
    {
      "text": "Mouna Afif, Yahia Said, Edwige Pissaloux, Mohamed Atri, 2020. Recognizing signs and doors for Indoor Wayfinding for Blind and Visually Impaired Persons. In 2020 5th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP). IEEE, Los Alamitos, CA, USA, 1\u20134. https://doi.org/10.1109/ATSIP49331.2020.9231933",
      "doi": ""
    },
    {
      "text": "David Alejo, Gonzalo Mier, Carlos Marques, Fernando Caballero, Lu\u00eds Merino, and Paulo Alvito. 2019. SIAR: A Ground Robot Solution for Semi-autonomous Inspection of Visitable Sewers. Advances in Robotics Research: From Lab to Market: ECHORD++: Robotic Science Supporting Innovation 132 (2019), 275. https://doi.org/10.1007/978-3-030-22327-4_13",
      "doi": ""
    },
    {
      "text": "Mrouj Almuhajri and Ching\u00a0Y. Suen. 2022. A Complete Framework for Shop Signboards Detection and Classification. In 2022 26th International Conference on Pattern Recognition (ICPR). IEEE, Piscataway, NJ, USA, 4671\u20134677. https://doi.org/10.1109/ICPR56361.2022.9956399",
      "doi": ""
    },
    {
      "text": "John Brooke 1996. SUS-A quick and dirty usability scale. Usability evaluation in industry 189, 194 (1996), 4\u20137. https://doi.org/10.1201/9781498710411-35",
      "doi": ""
    },
    {
      "text": "Hsuan-Eng Chen, Yi-Ying Lin, Chien-Hsing Chen, and I-Fang Wang. 2015. BlindNavi: A navigation app for the visually impaired smartphone user. In Proceedings of the 33rd annual ACM conference extended abstracts on human factors in computing systems. ACM, New York, NY, USA, 19\u201324. https://doi.org/10.1145/2702613.2726953",
      "doi": "10.1145/2702613.2726953"
    },
    {
      "text": "Qiang Chen, Yinong Chen, Jinhui Zhu, Gennaro De\u00a0Luca, Mei Zhang, and Ying Guo. 2020. Traffic light and moving object detection for a guide-dog robot. The Journal of Engineering 2020, 13 (2020), 675\u2013678.",
      "doi": ""
    },
    {
      "text": "Qihe Chen, Luyao Wang, Yan Zhang, Ziang Li, Tingmin Yan, Fan Wang, Guyue Zhou, and Jiangtao Gong. 2022. Can Quadruped Navigation Robots be Used as Guide Dogs?https://doi.org/10.48550/ARXIV.2210.08727",
      "doi": ""
    },
    {
      "text": "Xiaoxue Chen, Lianwen Jin, Yuanzhi Zhu, Canjie Luo, and Tianwei Wang. 2021. Text Recognition in the Wild: A Survey. ACM Comput. Surv. 54, 2, Article 42 (2021), 35\u00a0pages. https://doi.org/10.1145/3440756",
      "doi": "10.1145/3440756"
    },
    {
      "text": "Zhichao Chen and Stanley\u00a0T Birchfield. 2009. Qualitative vision-based path following. IEEE Transactions on Robotics 25, 3 (2009), 749\u2013754. https://doi.org/10.1109/TRO.2009.2017140",
      "doi": "10.1109/TRO.2009.2017140"
    },
    {
      "text": "Angela Constantinescu, Karin M\u00fcller, Monica Haurilet, Vanessa Petrausch, and Rainer Stiefelhagen. 2020. Bring the Environment to Life: A Sonification Module for People with Visual Impairments to Improve Situation Awareness. In Proceedings of the 2020 International Conference on Multimodal Interaction. ACM, New York, NY, USA, 50\u201359. https://doi.org/10.1145/3382507.3418874",
      "doi": "10.1145/3382507.3418874"
    },
    {
      "text": "Guilherme\u00a0N DeSouza and Avinash\u00a0C Kak. 2002. Vision for mobile robot navigation: A survey. IEEE transactions on pattern analysis and machine intelligence 24, 2(2002), 237\u2013267. https://doi.org/10.1109/34.982903",
      "doi": "10.1109/34.982903"
    },
    {
      "text": "Andr\u00e9s\u00a0A D\u00edaz-Toro, Sixto\u00a0E Campa\u00f1a-Bastidas, and Eduardo\u00a0F Caicedo-Bravo. 2021. Vision-Based System for Assisting Blind People to Wander Unknown Environments in a Safe Way. Journal of Sensors 2021(2021). https://doi.org/10.1155/2021/6685686",
      "doi": ""
    },
    {
      "text": "Barzin Doroodgar, Yugang Liu, and Goldie Nejat. 2014. A learning-based semi-autonomous controller for robotic exploration of unknown disaster scenes while searching for victims. IEEE Transactions on Cybernetics 44, 12 (2014), 2719\u20132732. https://doi.org/10.1109/TCYB.2014.2314294",
      "doi": ""
    },
    {
      "text": "Christin Engel, Karin M\u00fcller, Angela Constantinescu, Claudia Loitsch, Vanessa Petrausch, Gerhard Weber, and Rainer Stiefelhagen. 2020. Travelling More Independently: A Requirements Analysis for Accessible Journeys to Unknown Buildings for People with Visual Impairments. In ASSETS \u201920. ACM, New York, NY, USA. https://doi.org/10.1145/3373625.3417022",
      "doi": "10.1145/3373625.3417022"
    },
    {
      "text": "Glenn\u00a0Jocher et. al.2021. ultralytics/yolov5: v6.0 - YOLOv5n \u2019Nano\u2019 models, Roboflow integration, TensorFlow export, OpenCV DNN support. Zenodo. https://doi.org/10.5281/zenodo.5563715",
      "doi": ""
    },
    {
      "text": "Navid Fallah, Ilias Apostolopoulos, Kostas Bekris, and Eelke Folmer. 2012. The user as a sensor: navigating users with visual impairments in indoor spaces using tactile landmarks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 425\u2013432. https://doi.org/10.1145/2207676.2207735",
      "doi": "10.1145/2207676.2207735"
    },
    {
      "text": "Alexander Fiannaca, Ilias Apostolopoulous, and Eelke Folmer. 2014. Headlock: a wearable navigation aid that helps blind cane users traverse large open spaces. In Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility. ACM, New York, NY, USA, 19\u201326. https://doi.org/10.1145/2661334.2661453",
      "doi": "10.1145/2661334.2661453"
    },
    {
      "text": "German Flores and Roberto Manduchi. 2018. Easy return: an app for indoor backtracking assistance. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3173574.3173591",
      "doi": "10.1145/3173574.3173591"
    },
    {
      "text": "Adriano Garcia, Edward Mattison, and Kanad Ghose. 2015. High-speed vision-based autonomous indoor navigation of a quadcopter. In 2015 international conference on unmanned aircraft systems (ICUAS). IEEE, Los Alamitos, CA, USA, 338\u2013347. https://doi.org/10.1109/ICUAS.2015.7152308",
      "doi": ""
    },
    {
      "text": "Adriano Garcia, Sandeep\u00a0S Mittal, Edward Kiewra, and Kanad Ghose. 2019. A convolutional neural network vision system approach to indoor autonomous quadrotor navigation. In 2019 International Conference on Unmanned Aircraft Systems (ICUAS). IEEE, Los Alamitos, CA, USA, 1344\u20131352. https://doi.org/10.1109/ICUAS.2019.8798183",
      "doi": ""
    },
    {
      "text": "Jo\u00e3o Guerreiro, Daisuke Sato, Saki Asakawa, Huixu Dong, Kris\u00a0M Kitani, and Chieko Asakawa. 2019. CaBot: Designing and Evaluating an Autonomous Navigation Robot for Blind People. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 68\u201382. https://doi.org/10.1145/3308561.3353771",
      "doi": "10.1145/3308561.3353771"
    },
    {
      "text": "A Hong, O Igharoro, Yugang Liu, Farzad Niroui, Goldie Nejat, and Beno Benhabib. 2019. Investigating human-robot teams for learning-based semi-autonomous control in urban search and rescue environments. Journal of Intelligent & Robotic Systems 94, 3 (2019), 669\u2013686. https://doi.org/10.1007/s10846-018-0899-0",
      "doi": "10.1007/s10846-018-0899-0"
    },
    {
      "text": "Hochul Hwang, Tim Xia, Ibrahima Keita, Ken Suzuki, Joydeep Biswas, Sunghoon\u00a0I. Lee, and Donghyun Kim. 2022. System Configuration and Navigation of a Guide Dog Robot: Toward Animal Guide Dog-Level Guiding Work. https://doi.org/10.48550/ARXIV.2210.13368",
      "doi": ""
    },
    {
      "text": "Hiroki Ishida, Kouchi Matsutani, Miho Adachi, Shingo Kobayashi, and Ryusuke Miyamoto. 2019. Intersection Recognition Using Results of Semantic Segmentation for Visual Navigation. In Computer Vision Systems. Springer, New York, NY, USA, 153\u2013163. https://doi.org/10.1007/978-3-030-34995-0_15",
      "doi": ""
    },
    {
      "text": "Watthanasak Jeamwatthanachai, M. Wald, and G. Wills. 2019. Indoor navigation by blind people: Behaviors and challenges in unfamiliar spaces and buildings. The British Journal of Visual Impairment 37 (2019), 140 \u2013 153. https://doi.org/10.1177/0264619619833723",
      "doi": ""
    },
    {
      "text": "Robert\u00a0K Katzschmann, Brandon Araki, and Daniela Rus. 2018. Safe local navigation for visually impaired users with a time-of-flight and haptic feedback device. IEEE Transactions on Neural Systems and Rehabilitation Engineering 26, 3(2018), 583\u2013593. https://doi.org/10.1109/TNSRE.2018.2800665",
      "doi": ""
    },
    {
      "text": "Seita Kayukawa, Keita Higuchi, Jo\u00e3o Guerreiro, Shigeo Morishima, Yoichi Sato, Kris Kitani, and Chieko Asakawa. 2019. BBeep: A sonic collision avoidance system for blind travellers and nearby pedestrians. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3290605.3300282",
      "doi": "10.1145/3290605.3300282"
    },
    {
      "text": "Seita Kayukawa, Tatsuya Ishihara, Hironobu Takagi, Shigeo Morishima, and Chieko Asakawa. 2020. Guiding Blind Pedestrians in Public Spaces by Understanding Walking Behavior of Nearby Pedestrians. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 3 (2020), 1\u201322. https://doi.org/10.1145/3411825",
      "doi": "10.1145/3411825"
    },
    {
      "text": "Seita Kayukawa, Daisuke Sato, Masayuki Murata, Tatsuya Ishihara, Akihiro Kosugi, Hironobu Takagi, Shigeo Morishima, and Chieko Asakawa. 2022. How Users, Facility Managers, and Bystanders Perceive and Accept a Navigation Robot for Visually Impaired People in Public Buildings. In Proceedings of the 31st IEEE International Conference on Robot & Human Interactive Communication(IEEE RO-MAN 2022). IEEE, Piscataway, NJ, USA, 8\u00a0pages.",
      "doi": "10.1109/RO-MAN53752.2022.9900717"
    },
    {
      "text": "Sulaiman Khan, Shah Nazir, and Habib\u00a0Ullah Khan. 2021. Analysis of Navigation Assistants for Blind and Visually Impaired People: A Systematic Review. IEEE Access 9(2021), 26712\u201326734. https://doi.org/10.1109/ACCESS.2021.3052415",
      "doi": ""
    },
    {
      "text": "Jee-Eun Kim, Masahiro Bessho, Shinsuke Kobayashi, Noboru Koshizuka, and Ken Sakamura. 2016. Navigating Visually Impaired Travelers in a Large Train Station Using Smartphone and Bluetooth Low Energy. In Proceedings of the 31st Annual ACM Symposium on Applied Computing. ACM, New York, NY, USA, 604\u2013611. https://doi.org/10.1145/2851613.2851716",
      "doi": "10.1145/2851613.2851716"
    },
    {
      "text": "Shinji Kotani, Hideo Mori, and Noriaki Kiyohiro. 1996. Development of the robotic travel aid \u201cHITOMI\u201d. Robotics and Autonomous Systems 17, 1-2 (1996), 119\u2013128. https://doi.org/10.1016/0921-8890(95)00067-4",
      "doi": ""
    },
    {
      "text": "Vladimir Kulyukin, Chaitanya Gharpure, Pradnya Sute, Nathan De\u00a0Graw, John Nicholson, and S Pavithran. 2004. A robotic wayfinding system for the visually impaired. In Proceedings of the National Conference on Artificial Intelligence. AAAI Press, Palo Alto, California, USA, 864\u2013869. https://doi.org/10.5555/1597321.1597337",
      "doi": "10.5555/1597321.1597337"
    },
    {
      "text": "Bineeth Kuriakose, Raju Shrestha, and Frode\u00a0Eika Sandnes. 2020. Tools and Technologies for Blind and Visually Impaired Navigation Support: A Review. IETE Technical Review 0, 0 (2020), 1\u201316. https://doi.org/10.1080/02564602.2020.1819893",
      "doi": ""
    },
    {
      "text": "Masaki Kuribayashi, Seita Kayukawa, Hironobu Takagi, Chieko Asakawa, and Shigeo Morishima. 2021. LineChaser: A Smartphone-Based Navigation System for Blind People to Stand in Lines. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3411764.3445451",
      "doi": "10.1145/3411764.3445451"
    },
    {
      "text": "Masaki Kuribayashi, Seita Kayukawa, Jayakorn Vongkulbhisal, Chieko Asakawa, Daisuke Sato, Hironobu Takagi, and Shigeo Morishima. 2022. Corridor-Walker: Mobile Indoor Walking Assistance for Blind People to Avoid Obstacles and Recognize Intersections. Proceedings of the ACM on Human-Computer Interaction 6, MHCI(2022), 1\u201322. https://doi.org/10.1145/3546714",
      "doi": "10.1145/3546714"
    },
    {
      "text": "Gerard Lacey and Shane MacNamara. 2000. Context-aware shared control of a robot mobility aid for the elderly blind. The International Journal of Robotics Research 19, 11 (2000), 1054\u20131065. https://doi.org/10.1177/02783640022067968",
      "doi": ""
    },
    {
      "text": "Johan Larsson, Mathias Broxvall, and Alessandro Saffiotti. 2008. Laser based intersection detection for reactive navigation in an underground mine. In 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, Piscataway, NJ, USA, 2222\u20132227. https://doi.org/10.1109/IROS.2008.4650911",
      "doi": ""
    },
    {
      "text": "Young\u00a0Hoon Lee and Gerard Medioni. 2014. Wearable RGBD indoor navigation system for the blind. In European Conference on Computer Vision. Springer, New York, NY, USA, 493\u2013508. https://doi.org/10.1007/978-3-319-16199-0_35",
      "doi": ""
    },
    {
      "text": "Bing Li, J\u00a0Pablo Munoz, Xuejian Rong, Jizhong Xiao, Yingli Tian, and Aries Arditi. 2016. ISANA: wearable context-aware indoor assistive navigation with obstacle avoidance for the blind. In European Conference on Computer Vision. Springer, New York, NY, USA, 448\u2013462. https://doi.org/10.1007/978-3-319-48881-3_31",
      "doi": ""
    },
    {
      "text": "Chen-Lung Lu, Zi-Yan Liu, Jui-Te Huang, Ching-I Huang, Bo-Hui Wang, Yi Chen, Nien-Hsin Wu, Hsueh-Cheng Wang, Laura Giarr\u00e9, and Pei-Yi Kuo. 2021. Assistive Navigation Using Deep Reinforcement Learning Guiding Robot With UWB/Voice Beacons and Semantic Feedbacks for Blind and Visually Impaired People. Frontiers in Robotics and AI 8 (2021), 1\u201323\u00a0pages. https://doi.org/10.3389/frobt.2021.654132",
      "doi": ""
    },
    {
      "text": "Kanak Manjari, Madhushi Verma, and Gaurav Singal. 2020. A survey on Assistive Technology for visually impaired. Internet of Things 11(2020), 100188. https://doi.org/10.1016/j.iot.2020.100188",
      "doi": ""
    },
    {
      "text": "Ronja M\u00f6ller, Antonino Furnari, Sebastiano Battiato, Aki H\u00e4rm\u00e4, and Giovanni\u00a0Maria Farinella. 2021. A survey on human-aware robot navigation. Robotics and Autonomous Systems 145 (2021), 103837. https://doi.org/10.1016/j.robot.2021.103837",
      "doi": "10.1016/j.robot.2021.103837"
    },
    {
      "text": "Piyoosh Mukhija, Siddharth Tourani, and K\u00a0Madhava Krishna. 2012. Outdoor intersection detection for autonomous exploration. In 2012 15th International IEEE Conference on Intelligent Transportation Systems. IEEE, Piscataway, NJ, USA, 218\u2013223. https://doi.org/10.1109/ITSC.2012.6338647",
      "doi": ""
    },
    {
      "text": "Karin M\u00fcller, Christin Engel, Claudia Loitsch, Rainer Stiefelhagen, and Gerhard Weber. 2022. Traveling More Independently: A Study on the Diverse Needs and Challenges of People with Visual or Mobility Impairments in Unfamiliar Indoor Environments. ACM Trans. Access. Comput. 15, 2 (2022), 1\u201344. https://doi.org/10.1145/3514255",
      "doi": "10.1145/3514255"
    },
    {
      "text": "Saeid Nahavandi, Roohallah Alizadehsani, Darius Nahavandi, Shady Mohamed, Navid Mohajer, Mohammad Rokonuzzaman, and Ibrahim Hossain. 2022. A Comprehensive Review on Autonomous Navigation. https://doi.org/10.48550/ARXIV.2212.12808",
      "doi": ""
    },
    {
      "text": "Anh-Tu Nguyen, Jagat\u00a0Jyoti Rath, Chen Lv, Thierry-Marie Guerra, and Jimmy Lauber. 2021. Human-machine shared driving control for semi-autonomous vehicles using level of cooperativeness. Sensors 21, 14 (2021), 4647. https://doi.org/10.3390/s21144647",
      "doi": ""
    },
    {
      "text": "Suraj\u00a0R. Pardeshi, Vikul\u00a0J. Pawar, Kailas\u00a0D. Kharat, and Sachin Chavan. 2021. Assistive Technologies for Visually Impaired Persons Using Image Processing Techniques \u2013 A Survey. In Recent Trends in Image Processing and Pattern Recognition, K.\u00a0C. Santosh and Bharti Gawali (Eds.). Springer Singapore, Singapore, 95\u2013110. https://doi.org/10.1007/978-981-16-0507-9_9",
      "doi": ""
    },
    {
      "text": "Xavier Perrin, Ricardo Chavarriaga, Francis Colas, Roland Siegwart, and Jos\u00e9 del\u00a0R Mill\u00e1n. 2010. Brain-coupled interaction for semi-autonomous navigation of an assistive robot. Robotics and Autonomous Systems 58, 12 (2010), 1246\u20131255. https://doi.org/10.1016/j.robot.2010.05.010",
      "doi": "10.1016/j.robot.2010.05.010"
    },
    {
      "text": "Giorgio Presti, Dragan Ahmetovic, Mattia Ducci, Cristian Bernareggi, Luca Ludovico, Adriano Barat\u00e8, Federico Avanzini, and Sergio Mascetti. 2019. WatchOut: Obstacle sonification for people with visual impairment or blindness. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 402\u2013413. https://doi.org/10.1145/3308561.3353779",
      "doi": "10.1145/3308561.3353779"
    },
    {
      "text": "Pablo-Alejandro Quinones, Tammy Greene, Rayoung Yang, and Mark Newman. 2011. Supporting visually impaired navigation: a needs-finding study. In CHI\u201911 Extended Abstracts on Human Factors in Computing Systems. ACM, New York, NY, USA, 1645\u20131650. https://doi.org/10.1145/1979742.1979822",
      "doi": "10.1145/1979742.1979822"
    },
    {
      "text": "Santhosh\u00a0K Ramakrishnan, Ziad Al-Halah, and Kristen Grauman. 2020. Occupancy anticipation for efficient exploration and navigation. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part V 16. Springer, New York, NY, USA, 400\u2013418. https://doi.org/10.1007/978-3-030-58558-7_24",
      "doi": "10.1007/978-3-030-58558-7_24"
    },
    {
      "text": "David\u00a0A Ross and Alexander Lightman. 2005. Talking braille: a wireless ubiquitous computing network for orientation and wayfinding. In Proceedings of the 7th international ACM SIGACCESS conference on Computers and accessibility. ACM, New York, NY, USA, 98\u2013105. https://doi.org/10.1145/1090785.1090805",
      "doi": "10.1145/1090785.1090805"
    },
    {
      "text": "Manaswi Saha, Alexander\u00a0J Fiannaca, Melanie Kneisel, Edward Cutrell, and Meredith\u00a0Ringel Morris. 2019. Closing the gap: Designing for the last-few-meters wayfinding problem for people with visual impairments. In The 21st international acm sigaccess conference on computers and accessibility. ACM, New York, NY, USA, 222\u2013235. https://doi.org/10.1145/3308561.3353776",
      "doi": "10.1145/3308561.3353776"
    },
    {
      "text": "Nuzhah\u00a0Gooda Sahib, Tony Stockman, Anastasios Tombros, and Oussama Metatla. 2013. Participatory design with blind users: a scenario-based approach. In IFIP Conference on Human-Computer Interaction. Springer, New York, NY, USA, 685\u2013701. https://doi.org/10.1007/978-3-642-40483-2_48",
      "doi": ""
    },
    {
      "text": "Daisuke Sato, Uran Oh, Jo\u00e3o Guerreiro, Dragan Ahmetovic, Kakuya Naito, Hironobu Takagi, Kris\u00a0M Kitani, and Chieko Asakawa. 2019. NavCog3 in the wild: Large-scale blind indoor navigation assistant with semantic features. ACM Transactions on Accessible Computing (TACCESS) 12, 3 (2019), 14. https://doi.org/10.1145/3340319",
      "doi": "10.1145/3340319"
    },
    {
      "text": "Hiroaki Seki, S Kobayashi, Yoshitsugu Kamiya, Masatoshi Hikizu, and Hisanao Nomura. 2000. Autonomous/semi-autonomous navigation system of a wheelchair by active ultrasonic beacons. In Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No. 00CH37065), Vol.\u00a02. IEEE, Piscataway, NJ, USA, 1366\u20131371. https://doi.org/10.1109/ROBOT.2000.844788",
      "doi": ""
    },
    {
      "text": "Mahendran Subramanian, Noyan Songur, Darrell Adjei, Pavel Orlov, and A\u00a0Aldo Faisal. 2019. A. Eye Drive: Gaze-based semi-autonomous wheelchair interface. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, Piscataway, NJ, USA, 5967\u20135970. https://doi.org/10.1109/EMBC.2019.8856608",
      "doi": ""
    },
    {
      "text": "Haobin Tan, Chang Chen, Xinyu Luo, Jiaming Zhang, Constantin Seibold, Kailun Yang, and Rainer Stiefelhagen. 2021. Flying guide dog: Walkable path discovery for the visually impaired utilizing drones and transformer-based semantic segmentation. In 2021 IEEE International Conference on Robotics and Biomimetics (ROBIO). IEEE, Piscataway, NJ, USA, 1123\u20131128. https://doi.org/10.1109/ROBIO54168.2021.9739520",
      "doi": "10.1109/ROBIO54168.2021.9739520"
    },
    {
      "text": "Hongru Tang, Xiaosong Cao, Aiguo Song, Yan Guo, and Jiatong Bao. 2009. Human-robot collaborative teleoperation system for semi-autonomous reconnaissance robot. In 2009 International Conference on Mechatronics and Automation. IEEE, Piscataway, NJ, USA, 1934\u20131939. https://doi.org/10.1109/ICMA.2009.5246589",
      "doi": ""
    },
    {
      "text": "N Veeranjaneyulu. 2019. A Meta-Analysis on Obstacle Detection for Visually Impaired People. i-manager\u2019s Journal on Pattern Recognition 6, 1 (2019), 40\u201362. https://doi.org/10.26634/jpr.6.1.15523",
      "doi": ""
    },
    {
      "text": "Liyang Wang, Jinxin Zhao, and Liangjun Zhang. 2021. Navdog: robotic navigation guide dog via model predictive control and human-robot modeling. In Proceedings of the 36th Annual ACM Symposium on Applied Computing. New York, NY, USA, ACM, 815\u2013818. https://doi.org/10.1145/3412841.3442098",
      "doi": "10.1145/3412841.3442098"
    },
    {
      "text": "Yue Wang and Fumin Zhang. 2017. Trends in control and decision-making for human-robot collaboration systems. Springer, New York, NY, USA. https://doi.org/10.1007/978-3-319-40533-9",
      "doi": ""
    },
    {
      "text": "Anxing Xiao, Wenzhe Tong, Lizhi Yang, Jun Zeng, Zhongyu Li, and Koushil Sreenath. 2021. Robotic guide dog: Leading a human with leash-guided hybrid physical interaction. In 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, Piscataway, NJ, USA, 11470\u201311476. https://doi.org/10.1109/ICRA48506.2021.9561786",
      "doi": "10.1109/ICRA48506.2021.9561786"
    },
    {
      "text": "Yutaro Yamanaka, Seita Kayukawa, Hironobu Takagi, Yuichi Nagaoka, Yoshimune Hiratsuka, and Satoshi Kurihara. 2021. One-Shot Wayfinding Method for Blind People via OCR and Arrow Analysis with a 360-degree Smartphone Camera. In Proceedings of the 18th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services (Beppu, Japan) (MobiQuitous \u201921). Springer, New York, NY, USA, 19\u00a0pages. https://doi.org/10.1007/978-3-030-94822-1_9",
      "doi": ""
    },
    {
      "text": "Fan Yang, Dung-Han Lee, John Keller, and Sebastian Scherer. 2021. Graph-based topological exploration planning in large-scale 3d environments. In 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, Piscataway, NJ, USA, 12730\u201312736. https://doi.org/10.1109/ICRA48506.2021.9561830",
      "doi": "10.1109/ICRA48506.2021.9561830"
    },
    {
      "text": "Chris Yoon, Ryan Louie, Jeremy Ryan, MinhKhang Vu, Hyegi Bang, William Derksen, and Paul Ruvolo. 2019. Leveraging Augmented Reality to Create Apps for People with Visual Disabilities: A Case Study in Indoor Navigation. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 210\u2013221. https://doi.org/10.1145/3308561.3353788",
      "doi": "10.1145/3308561.3353788"
    },
    {
      "text": "Limin Zeng, Bj\u00f6rn Einert, Alexander Pitkin, and Gerhard Weber. 2018. Hapticrein: Design and development of an interactive haptic rein for a guidance robot. In International Conference on Computers Helping People with Special Needs. Springer, New York, NY, USA, 94\u2013101. https://doi.org/10.1007/978-3-319-94274-2_14",
      "doi": ""
    },
    {
      "text": "Kai Zhu and Tao Zhang. 2021. Deep reinforcement learning based mobile robot navigation: A review. Tsinghua Science and Technology 26, 5 (2021), 674\u2013691. https://doi.org/10.26599/TST.2021.9010012",
      "doi": ""
    },
    {
      "text": "Quanwen Zhu, Long Chen, Qingquan Li, Ming Li, Andreas N\u00fcchter, and Jian Wang. 2012. 3d lidar point cloud based intersection recognition for autonomous driving. In 2012 IEEE Intelligent Vehicles Symposium. IEEE, Piscataway, NJ, USA, 456\u2013461. https://doi.org/10.1109/IVS.2012.6232219",
      "doi": ""
    },
    {
      "text": "Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph\u00a0J Lim, Abhinav Gupta, Li Fei-Fei, and Ali Farhadi. 2017. Target-driven visual navigation in indoor scenes using deep reinforcement learning. In 2017 IEEE international conference on robotics and automation (ICRA). IEEE, Piscataway, NJ, USA, 3357\u20133364. https://doi.org/10.1109/ICRA.2017.7989381",
      "doi": "10.1109/ICRA.2017.7989381"
    }
  ]
}