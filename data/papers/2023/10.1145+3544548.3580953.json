{
  "doi": "10.1145/3544548.3580953",
  "title": "Blaming Humans and Machines: What Shapes People\u2019s Reactions to Algorithmic Harm",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-26",
  "year": 2023,
  "badges": [],
  "abstract": "Artificial intelligence (AI) systems can cause harm to people. This research examines how individuals react to such harm through the lens of blame. Building upon research suggesting that people blame AI systems, we investigated how several factors influence people\u2019s reactive attitudes towards machines, designers, and users. The results of three studies (N = 1,153) indicate differences in how blame is attributed to these actors. Whether AI systems were explainable did not impact blame directed at them, their developers, and their users. Considerations about fairness and harmfulness increased blame towards designers and users but had little to no effect on judgments of AI systems. Instead, what determined people\u2019s reactive attitudes towards machines was whether people thought blaming them would be a suitable response to algorithmic harm. We discuss implications, such as how future decisions about including AI systems in the social and moral spheres will shape laypeople\u2019s reactions to AI-caused harm.",
  "tags": [
    "Algorithmic Decision-Making",
    "Artificial Intelligence",
    "Harm",
    "Explainability",
    "Discrimination",
    "Decision-Making",
    "Responsibility",
    "Algorithms",
    "Blame"
  ],
  "authors": [
    {
      "name": "Gabriel Lima",
      "institution": "School of Computing, KAIST, Korea, Republic of and Institute for Basic Science (IBS), Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659353893",
      "orcid": "0000-0002-2361-350X"
    },
    {
      "name": "Nina Grgi\u0107-Hla\u010da",
      "institution": "Max Planck Institute for Software Systems, Germany and Max Planck Institute for Research on Collective Goods, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659260207",
      "orcid": "0000-0003-3397-2984"
    },
    {
      "name": "Meeyoung Cha",
      "institution": "Institute for Basic Science (IBS), Korea, Republic of and School of Computing, KAIST, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100205660",
      "orcid": "0000-0003-4085-9648"
    }
  ],
  "references": [
    {
      "text": "Ameena\u00a0T Ahmed, Selina\u00a0A Mohammed, David\u00a0R Williams, 2007. Racial discrimination & health: Pathways & evidence. Indian Journal of Medical Research 126, 4 (2007), 318.",
      "doi": ""
    },
    {
      "text": "Salman Ahmed, Cameron\u00a0T Nutt, Nwamaka\u00a0D Eneanya, Peter\u00a0P Reese, Karthik Sivashanker, Michelle Morse, Thomas Sequist, and Mallika\u00a0L Mendu. 2021. Examining the potential impact of race multiplier utilization in estimated glomerular filtration rate calculation on African-American care outcomes. Journal of General Internal Medicine 36, 2 (2021), 464\u2013471.",
      "doi": ""
    },
    {
      "text": "Athanasios Andreou, Giridhari Venkatadri, Oana Goga, Krishna Gummadi, Patrick Loiseau, and Alan Mislove. 2018. Investigating ad transparency mechanisms in social media: A case study of Facebook\u2019s explanations. In proc. of the Network and Distributed System Security Symposium. 1\u201315.",
      "doi": ""
    },
    {
      "text": "Julia Angwin, Madeleine Varner, and Ariana Tobin. 2016. Machine Bias: There\u2019s Software Used Across the Country to Predict Future Criminals. And it\u2019s Biased Against Blacks.ProPublica. https://tinyurl.com/5t3apr69.",
      "doi": ""
    },
    {
      "text": "Alejandro\u00a0Barredo Arrieta, Natalia D\u00edaz-Rodr\u00edguez, Javier Del\u00a0Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc\u00eda, Sergio Gil-L\u00f3pez, Daniel Molina, Richard Benjamins, 2020. Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion 58(2020), 82\u2013115.",
      "doi": "10.1016/j.inffus.2019.12.012"
    },
    {
      "text": "Edmond Awad, Sohan Dsouza, Jean-Fran\u00e7ois Bonnefon, Azim Shariff, and Iyad Rahwan. 2020. Crowdsourcing moral machines. Commun. ACM 63, 3 (2020), 48\u201355.",
      "doi": "10.1145/3339904"
    },
    {
      "text": "Edmond Awad, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-Fran\u00e7ois Bonnefon, and Iyad Rahwan. 2018. The moral machine experiment. Nature 563, 7729 (2018), 59\u201364.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Walter\u00a0S Lasecki, Daniel\u00a0S Weld, and Eric Horvitz. 2019. Beyond accuracy: The role of mental models in human-AI team performance. In proc. of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 2\u201311.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhu, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel\u00a0S Weld. 2020. Does the whole exceed its parts? the effect of ai explanations on complementary team performance. arXiv preprint arXiv:2006.14779(2020).",
      "doi": ""
    },
    {
      "text": "Solon Barocas and Andrew\u00a0D Selbst. 2016. Big data\u2019s disparate impact. Calif. L. Rev. 104(2016), 671.",
      "doi": ""
    },
    {
      "text": "Adrien Bibal, Michael Lognoul, Alexandre de Streel, and Beno\u00eet Fr\u00e9nay. 2020. Legal requirements on explainability in machine learning. Artificial Intelligence and Law(2020), 1\u201321.",
      "doi": ""
    },
    {
      "text": "Yochanan Bigman, Kurt Gray, Adam Waytz, Mads Arnestad, and Desman Wilson. [n.d.]. Algorithmic discrimination causes less moral outrage than human discrimination. ([n. d.]).",
      "doi": ""
    },
    {
      "text": "Yochanan\u00a0E Bigman, Adam Waytz, Ron Alterovitz, and Kurt Gray. 2019. Holding robots responsible: The elements of machine morality. Trends in cognitive sciences 23, 5 (2019), 365\u2013368.",
      "doi": ""
    },
    {
      "text": "Jean-Fran\u00e7ois Bonnefon, Azim Shariff, and Iyad Rahwan. 2020. The moral psychology of AI and the ethical opt-out problem. Oxford University Press.",
      "doi": ""
    },
    {
      "text": "Anna Brown, Alexandra Chouldechova, Emily Putnam-Hornstein, Andrew Tobin, and Rhema Vaithianathan. 2019. Toward algorithmic accountability in public services: A qualitative study of affected community perspectives on algorithmic decision-making in child welfare services. In proc. of the ACM Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3290605.3300271"
    },
    {
      "text": "Bartosz Bro\u017cek and Bartosz Janik. 2019. Can artificial intelligences be moral agents?New Ideas in Psychology 54 (2019), 101\u2013106.",
      "doi": ""
    },
    {
      "text": "Joanna\u00a0J Bryson. 2010. Robots should be slaves. Close Engagements with Artificial Companions: Key social, psychological, ethical and design issues 8(2010), 63\u201374.",
      "doi": ""
    },
    {
      "text": "Joanna\u00a0J Bryson, Mihailis\u00a0E Diamantis, and Thomas\u00a0D Grant. 2017. Of, for, and by the people: the legal lacuna of synthetic persons. Artificial Intelligence and Law 25, 3 (2017), 273\u2013291.",
      "doi": "10.1007/s10506-017-9214-9"
    },
    {
      "text": "Zana Bu\u00e7inca, Maja\u00a0Barbara Malaya, and Krzysztof\u00a0Z Gajos. 2021. To trust or to think: cognitive forcing functions can reduce overreliance on AI in AI-assisted decision-making. proc. of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201321.",
      "doi": "10.1145/3449287"
    },
    {
      "text": "Noah Castelo, Maarten\u00a0W Bos, and Donald\u00a0R Lehmann. 2019. Task-dependent algorithm aversion. Journal of Marketing Research 56, 5 (2019), 809\u2013825.",
      "doi": ""
    },
    {
      "text": "Stephen Cave, Claire Craig, Kanta Dihal, Sarah Dillon, Jessica Montgomery, Beth Singler, and Lindsay Taylor. 2018. Portrayals and perceptions of AI and why they matter. (2018).",
      "doi": ""
    },
    {
      "text": "Stephen Cave and Kanta Dihal. 2019. Hopes and fears for intelligent machines in fiction and reality. Nature Machine Intelligence 1, 2 (2019), 74\u201378.",
      "doi": ""
    },
    {
      "text": "Marc Champagne. 2021. The Mandatory Ontology of Robot Responsibility. Cambridge Quarterly of Healthcare Ethics 30, 3 (2021), 448\u2013454.",
      "doi": ""
    },
    {
      "text": "Karen\u00a0W Clarke, David Gray, Nicola\u00a0A Keating, and John\u00a0R Hampton. 1994. Do women with acute myocardial infarction receive the same treatment as men?BMJ 309, 6954 (1994), 563\u2013566.",
      "doi": ""
    },
    {
      "text": "Mark Coeckelbergh. 2009. Virtual moral agency, virtual moral responsibility: on the moral significance of the appearance, perception, and performance of artificial agents. AI & Society 24, 2 (2009), 181\u2013189.",
      "doi": "10.1007/s00146-009-0208-3"
    },
    {
      "text": "A\u00a0Feder Cooper, Emanuel Moss, Benjamin Laufer, and Helen Nissenbaum. 2022. Accountability in an algorithmic society: relationality, responsibility, and robustness in machine learning. In proc. of the ACM Conference on Fairness, Accountability, and Transparency (FAccT). 864\u2013876.",
      "doi": "10.1145/3531146.3533150"
    },
    {
      "text": "John Danaher. 2016. Robots, law and the retribution gap. Ethics and Information Technology 18, 4 (2016), 299\u2013309.",
      "doi": "10.1007/s10676-016-9403-3"
    },
    {
      "text": "Jeffrey Dastin. 2018. Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. https://tinyurl.com/y64598bh.",
      "doi": ""
    },
    {
      "text": "Amit Datta, Michael\u00a0Carl Tschantz, and Anupam Datta. 2015. Automated experiments on ad privacy settings: A tale of opacity, choice, and discrimination. Proceedings on Privacy Enhancing Technologies1 (2015), 92\u2013112.",
      "doi": ""
    },
    {
      "text": "Celso\u00a0M de Melo, Stacy Marsella, and Jonathan Gratch. 2019. Human cooperation when acting through autonomous machines. PNAS 116, 9 (2019), 3482\u20133487.",
      "doi": ""
    },
    {
      "text": "Filippo\u00a0Santoni de Sio and Giulio Mecacci. 2021. Four Responsibility Gaps with Artificial Intelligence: Why they Matter and How to Address them. Philosophy & Technology(2021), 1\u201328.",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J Dietvorst and Soaham Bharti. 2020. People reject algorithms in uncertain decision domains because they have diminishing sensitivity to forecasting error. Psychological Science 31, 10 (2020), 1302\u20131314.",
      "doi": ""
    },
    {
      "text": "Elias\u00a0Fern\u00e1ndez Domingos, In\u00eas Terrucha, R\u00e9mi Suchon, Jelena Gruji\u0107, Juan\u00a0C Burguillo, Francisco\u00a0C Santos, and Tom Lenaerts. 2021. Delegation to autonomous agents promotes cooperation in collective-risk dilemmas. arXiv preprint arXiv:2103.07710(2021).",
      "doi": ""
    },
    {
      "text": "Upol Ehsan, Samir Passi, Q\u00a0Vera Liao, Larry Chan, I Lee, Michael Muller, Mark\u00a0O Riedl, 2021. The Who in Explainable AI: How AI Background Shapes Perceptions of AI Explanations. arXiv preprint arXiv:2107.13509(2021).",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee Rickman, Kevin Hamilton, and Alex Kirlik. 2016. First I\" like\" it, then I hide it: Folk Theories of Social Feeds. In proc. of the ACM Conference on Human Factors in Computing Systems. 2371\u20132382.",
      "doi": "10.1145/2858036.2858494"
    },
    {
      "text": "Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy Vuong, Karrie Karahalios, Kevin Hamilton, and Christian Sandvig. 2015. \" I always assumed that I wasn\u2019t really that close to [her]\" Reasoning about Invisible Algorithms in News Feeds. In proc. of the ACM Conference on Human Factors in Computing Systems. 153\u2013162.",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Kristen Vaccaro, Min\u00a0Kyung Lee, Amit Elazari Bar\u00a0On, Eric Gilbert, and Karrie Karahalios. 2019. User attitudes towards algorithmic opacity and transparency in online reviewing platforms. In proc. of the ACM Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3290605.3300724"
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto\u00a0A Novoa, Justin Ko, Susan\u00a0M Swetter, Helen\u00a0M Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 7639 (2017), 115\u2013118.",
      "doi": ""
    },
    {
      "text": "Ernst Fehr and Urs Fischbacher. 2004. Third-party punishment and social norms. Evolution and Human Behavior 25, 2 (2004), 63\u201387.",
      "doi": ""
    },
    {
      "text": "Nic Fleming. 2018. How artificial intelligence is changing drug discovery. Nature 557, 7706 (2018), S55\u2013S55.",
      "doi": ""
    },
    {
      "text": "Matija Franklin, Edmond Awad, and David Lagnado. 2021. Blaming automated vehicles in difficult situations. Iscience 24, 4 (2021), 102252.",
      "doi": ""
    },
    {
      "text": "Caleb Furlough, Thomas Stokes, and Douglas\u00a0J Gillan. 2021. Attributing blame to robots: I. The influence of robot autonomy. Human factors 63, 4 (2021), 592\u2013602.",
      "doi": ""
    },
    {
      "text": "Donald\u00a0E Gibson and Scott\u00a0J Schroeder. 2003. Who ought to be blamed? The effect of organizational roles on blame and credit attributions. International Journal of Conflict Management (2003).",
      "doi": ""
    },
    {
      "text": "Jin\u00a0X Goh, Judith\u00a0A Hall, and Robert Rosenthal. 2016. Mini meta-analysis of your own studies: Some arguments on why and a primer on how. Social and Personality Psychology Compass 10, 10 (2016), 535\u2013549.",
      "doi": ""
    },
    {
      "text": "Jesse Graham, Jonathan Haidt, Sena Koleva, Matt Motyl, Ravi Iyer, Sean\u00a0P Wojcik, and Peter\u00a0H Ditto. 2013. Moral foundations theory: The pragmatic validity of moral pluralism. In Advances in experimental social psychology. Vol.\u00a047. Elsevier, 55\u2013130.",
      "doi": ""
    },
    {
      "text": "Kurt Gray, Liane Young, and Adam Waytz. 2012. Mind perception is the essence of morality. Psychological inquiry 23, 2 (2012), 101\u2013124.",
      "doi": ""
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Christoph Engel, and Krishna\u00a0P Gummadi. 2019. Human decision making with machine assistance: An experiment on bailing and jailing. proc. of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201325.",
      "doi": ""
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Gabriel Lima, Adrian Weller, and Elissa\u00a0M. Redmiles. 2020. Dimensions of Diversity in Human Perceptions of Algorithmic Fairness. https://doi.org/10.48550/ARXIV.2005.00808",
      "doi": ""
    },
    {
      "text": "V\u00a0Lee Hamilton. 1986. Chains of Command: Responsibility Attribution in Hierarchies 1. Journal of Applied Social Psychology 16, 2 (1986), 118\u2013138.",
      "doi": ""
    },
    {
      "text": "F\u00a0Allan Hanson. 2009. Beyond the skin bag: On the moral responsibility of extended agencies. Ethics and information technology 11, 1 (2009), 91\u201399.",
      "doi": ""
    },
    {
      "text": "C\u00e9sar\u00a0A Hidalgo, Diana Orghiain, Jordi\u00a0Albo Canals, Filipa De\u00a0Almeida, and Natalia Martin. 2021. How humans judge machines. MIT Press.",
      "doi": ""
    },
    {
      "text": "Fatimah Ishowo-Oloko, Jean-Fran\u00e7ois Bonnefon, Zakariyah Soroye, Jacob Crandall, Iyad Rahwan, and Talal Rahwan. 2019. Behavioural evidence for a transparency\u2013efficiency tradeoff in human\u2013machine cooperation. Nature Machine Intelligence 1, 11 (2019), 517\u2013521.",
      "doi": ""
    },
    {
      "text": "Anna Jobin, Marcello Ienca, and Effy Vayena. 2019. The global landscape of AI ethics guidelines. Nature Machine Intelligence 1, 9 (2019), 389\u2013399.",
      "doi": ""
    },
    {
      "text": "Deborah\u00a0G Johnson. 2006. Computer systems: Moral entities but not moral agents. Ethics and Information Technology 8, 4 (2006), 195\u2013204.",
      "doi": "10.1007/s10676-006-9111-5"
    },
    {
      "text": "Deborah\u00a0G Johnson. 2015. Technology with no human responsibility?Journal of Business Ethics 127, 4 (2015), 707\u2013715.",
      "doi": ""
    },
    {
      "text": "Peter\u00a0H Kahn\u00a0Jr, Takayuki Kanda, Hiroshi Ishiguro, Brian\u00a0T Gill, Jolina\u00a0H Ruckert, Solace Shen, Heather\u00a0E Gary, Aimee\u00a0L Reichert, Nathan\u00a0G Freier, and Rachel\u00a0L Severson. 2012. Do people hold a humanoid robot morally accountable for the harm it causes?. In proc. of the ACM/IEEE International Conference on Human-Robot Interaction. 33\u201340.",
      "doi": "10.1145/2157689.2157696"
    },
    {
      "text": "Shivani Kapania, Oliver Siy, Gabe Clapper, Azhagu\u00a0Meena SP, and Nithya Sambasivan. 2022. \u201d Because AI is 100% right and safe\u201d: User Attitudes and Sources of AI Authority in India. In proc. of the CHI Conference on Human Factors in Computing Systems. 1\u201318.",
      "doi": ""
    },
    {
      "text": "Taemie Kim and Pamela Hinds. 2006. Who should I blame? Effects of autonomy and transparency on attributions in human-robot interaction. In proc. of the IEEE International Symposium on Robot and Human Interactive Communication. 80\u201385.",
      "doi": ""
    },
    {
      "text": "Lauren Kirchner. 2020. Can Algorithms Violate Fair Housing Laws?The Markup. https://tinyurl.com/mr49a7yd.",
      "doi": ""
    },
    {
      "text": "Joshua Knobe. 2003. Intentional action and side effects in ordinary language. Analysis 63, 3 (2003), 190\u2013194.",
      "doi": ""
    },
    {
      "text": "Nils K\u00f6bis, Jean-Fran\u00e7ois Bonnefon, and Iyad Rahwan. 2021. Bad machines corrupt good morals. Nature Human Behaviour 5, 6 (2021), 679\u2013685.",
      "doi": ""
    },
    {
      "text": "Moritz K\u00f6rber, Eva Baseler, and Klaus Bengler. 2018. Introduction matters: Manipulating trust in automation and reliance in automated driving. Applied Ergonomics 66(2018), 18\u201331.",
      "doi": ""
    },
    {
      "text": "Markus Langer, Tim Hunsicker, Tina Feldkamp, Cornelius\u00a0J. K\u00f6nig, and Nina Grgi\u0107-Hla\u010da. 2021. \"Look! It\u2019s a Computer Program! It\u2019s an Algorithm! It\u2019s AI!\": Does Terminology Affect Human Perceptions and Evaluations of Intelligent Systems?arxiv:2108.11486\u00a0[cs.HC]",
      "doi": ""
    },
    {
      "text": "Markus Langer, Cornelius\u00a0J K\u00f6nig, and Maria Papathanasiou. 2019. Highly automated job interviews: Acceptance under the influence of stakes. International Journal of Selection and Assessment 27, 3(2019), 217\u2013234.",
      "doi": ""
    },
    {
      "text": "Markus Langer, Daniel Oster, Timo Speith, Holger Hermanns, Lena K\u00e4stner, Eva Schmidt, Andreas Sesing, and Kevin Baum. 2021. What do we want from Explainable Artificial Intelligence (XAI)?\u2013A stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research. Artificial Intelligence 296 (2021), 103473.",
      "doi": ""
    },
    {
      "text": "Minha Lee, Peter Ruijten, Lily Frank, Yvonne de Kort, and Wijnand IJsselsteijn. 2021. People May Punish, But Not Blame Robots. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201311.",
      "doi": "10.1145/3411764.3445284"
    },
    {
      "text": "Min\u00a0Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 2053951718756684.",
      "doi": ""
    },
    {
      "text": "Jamy Li, Xuan Zhao, Mu-Jung Cho, Wendy Ju, and Bertram\u00a0F Malle. 2016. From trolley to autonomous vehicle: Perceptions of responsibility and moral norms in traffic accidents with self-driving cars. SAE Technical paper 10(2016), 2016\u201301.",
      "doi": ""
    },
    {
      "text": "Gabriel Lima, Meeyoung Cha, Chihyung Jeon, and Kyung\u00a0Sin Park. 2021. The Conflict Between People\u2019s Urge to Punish AI and Legal Systems. Frontiers in Robotics and AI 8 (2021), 339. https://doi.org/10.3389/frobt.2021.756242",
      "doi": ""
    },
    {
      "text": "Gabriel Lima, Nina Grgi\u0107-Hla\u010da, and Meeyoung Cha. 2021. Human Perceptions on Moral Responsibility of AI: A Case Study in AI-Assisted Bail Decision-Making. In proc. of the CHI Conference on Human Factors in Computing Systems. 1\u201317.",
      "doi": ""
    },
    {
      "text": "Gabriel Lima, Nina Grgi\u0107-Hla\u010da, Jin\u00a0Keun Jeong, and Meeyoung Cha. 2022. The Conflict Between Explainable and Accountable Decision-Making Algorithms. In proc. of the ACM Conference on Fairness, Accountability, and Transparency (FAccT).",
      "doi": ""
    },
    {
      "text": "Anat Lior. 2019. AI entities as AI agents: Artificial intelligence liability and the AI respondeat superior analogy. Mitchell Hamline L. Rev. 46 (2019), 1043.",
      "doi": ""
    },
    {
      "text": "Peng Liu and Yong Du. 2021. Blame Attribution Asymmetry in Human\u2013Automation Cooperation. Risk Analysis (2021).",
      "doi": ""
    },
    {
      "text": "Bertram\u00a0F Malle, Steve Guglielmo, and Andrew\u00a0E Monroe. 2014. A theory of blame. Psychological Inquiry 25, 2 (2014), 147\u2013186.",
      "doi": ""
    },
    {
      "text": "Bertram\u00a0F Malle, Stuti\u00a0Thapa Magar, and Matthias Scheutz. 2019. AI in the sky: How people morally evaluate human and machine decisions in a lethal strike dilemma. In Robotics and well-being. Springer, 111\u2013133.",
      "doi": ""
    },
    {
      "text": "Bertram\u00a0F Malle, Matthias Scheutz, Thomas Arnold, John Voiklis, and Corey Cusimano. 2015. Sacrifice one for the good of many? People apply different moral norms to human and robot agents. In 2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 117\u2013124.",
      "doi": ""
    },
    {
      "text": "Andreas Matthias. 2004. The responsibility gap: Ascribing responsibility for the actions of learning automata. Ethics and information technology 6, 3 (2004), 175\u2013183.",
      "doi": ""
    },
    {
      "text": "Blakeley\u00a0B McShane and Ulf B\u00f6ckenholt. 2017. Single-paper meta-analysis: Benefits for study summary, theory testing, and replicability. Journal of Consumer Research 43, 6 (2017), 1048\u20131063.",
      "doi": ""
    },
    {
      "text": "Laxmi\u00a0S Mehta, Theresa\u00a0M Beckie, Holli\u00a0A DeVon, Cindy\u00a0L Grines, Harlan\u00a0M Krumholz, Michelle\u00a0N Johnson, Kathryn\u00a0J Lindley, Viola Vaccarino, Tracy\u00a0Y Wang, Karol\u00a0E Watson, 2016. Acute myocardial infarction in women: a scientific statement from the American Heart Association. Circulation 133, 9 (2016), 916\u2013947.",
      "doi": ""
    },
    {
      "text": "Dana\u00eb Metaxa, Michelle\u00a0A Gan, Su Goh, Jeff Hancock, and James\u00a0A Landay. 2021. An Image of Society: Gender and Racial Representation and Impact in Image Search Results for Occupations. proc. of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201323.",
      "doi": "10.1145/3449100"
    },
    {
      "text": "Tim Miller. 2019. Explanation in artificial intelligence: Insights from the social sciences. Artificial Intelligence 267 (2019), 1\u201338.",
      "doi": ""
    },
    {
      "text": "Keith\u00a0C Norris, Nwamaka\u00a0D Eneanya, and L\u00a0Ebony Boulware. 2021. Removal of race from estimates of kidney function: first, do no harm. JAMA 325, 2 (2021), 135\u2013137.",
      "doi": ""
    },
    {
      "text": "Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. Dissecting racial bias in an algorithm used to manage the health of populations. Science 366, 6464 (2019), 447\u2013453.",
      "doi": ""
    },
    {
      "text": "Institute of\u00a0Medicine (US). Committee\u00a0on Women\u2019s Health\u00a0Research. 2010. Women\u2019s health research: Progress, pitfalls, and promise. National Academies Press.",
      "doi": ""
    },
    {
      "text": "Stefan Palan and Christian Schitter. 2018. Prolific. ac\u2014A subject pool for online experiments. Journal of Behavioral and Experimental Finance 17 (2018), 22\u201327.",
      "doi": ""
    },
    {
      "text": "Emma Pierson. 2017. Gender differences in beliefs about algorithmic fairness. (2017). arXiv:1712.09124",
      "doi": ""
    },
    {
      "text": "Bryan Pietsch. 2021. 2 Killed in Driverless Tesla Car Crash, Officials Say. New York Times. https://tinyurl.com/3r85htt4.",
      "doi": ""
    },
    {
      "text": "Angelisa\u00a0C Plane, Elissa\u00a0M Redmiles, Michelle\u00a0L Mazurek, and Michael\u00a0Carl Tschantz. 2017. Exploring user perceptions of discrimination in online targeted advertising. In proc. of the USENIX Security Symposium. 935\u2013951.",
      "doi": ""
    },
    {
      "text": "Scott Robbins. 2019. A misdirected principle with a catch: explicability for AI. Minds and Machines 29, 4 (2019), 495\u2013514.",
      "doi": "10.1007/s11023-019-09509-3"
    },
    {
      "text": "Simon Romero. 2018. Wielding Rocks and Knives, Arizonans Attack Self-Driving Cars. New York Times. https://www.nytimes.com/2018/12/31/us/waymo-self-driving-cars-arizona-attacks.html.",
      "doi": ""
    },
    {
      "text": "Henrik\u00a0Skaug S\u00e6tra. 2021. Confounding complexity of machine action: a hobbesian account of machine responsibility. International Journal of Technoethics (IJT) 12, 1 (2021), 87\u2013100.",
      "doi": ""
    },
    {
      "text": "Thomas\u00a0Michael Scanlon. 2013. Interpreting blame. Blame. Its nature and norms(2013), 84\u201399.",
      "doi": ""
    },
    {
      "text": "Matthias Scheutz and Bertram\u00a0F Malle. 2020. May machines take lives to save lives? Human perceptions of autonomous robots (with the capacity to kill). Lethal autonomous weapons: Re-examining the law & ethics of robotic warfare (2020).",
      "doi": ""
    },
    {
      "text": "Guido Schwarzer 2007. meta: An R package for meta-analysis. R news 7, 3 (2007), 40\u201345.",
      "doi": ""
    },
    {
      "text": "David Shoemaker and Manuel Vargas. 2021. Moral torch fishing: A signaling theory of blame. No\u00fbs 55, 3 (2021), 581\u2013602.",
      "doi": ""
    },
    {
      "text": "Bernd\u00a0Carsten Stahl. 2006. Responsible computers? A case for ascribing quasi-responsibility to computers independent of personhood or agency. Ethics and Information Technology 8, 4 (2006), 205\u2013213.",
      "doi": "10.1007/s10676-006-9112-4"
    },
    {
      "text": "Peter Strawson. 2018. Freedom and Resentment. Cornell University Press.",
      "doi": ""
    },
    {
      "text": "Hannah\u00a0R Sullivan and Scott\u00a0J Schweikart. 2019. Are current tort liability doctrines adequate for addressing injury caused by AI?AMA Journal of Ethics 21, 2 (2019), 160\u2013166.",
      "doi": ""
    },
    {
      "text": "Leigh Thompson and George Loewenstein. 1992. Egocentric interpretations of fairness and interpersonal conflict. Organizational Behavior and Human Decision Processes 51, 2 (1992), 176\u2013197.",
      "doi": ""
    },
    {
      "text": "Daniel\u00a0W Tigard. 2021. Artificial moral responsibility: How we can and cannot hold machines responsible. Cambridge Quarterly of Healthcare Ethics 30, 3 (2021), 435\u2013447.",
      "doi": ""
    },
    {
      "text": "Steve Torrance. 2008. Ethics and consciousness in artificial agents. Ai & Society 22, 4 (2008), 495\u2013521.",
      "doi": "10.5555/3114838.3115264"
    },
    {
      "text": "Ibo Van\u00a0de Poel. 2011. The relation between forward-looking and backward-looking responsibility. In Moral Responsibility. Springer, 37\u201352.",
      "doi": ""
    },
    {
      "text": "Ibo Van\u00a0de Poel. 2015. Moral responsibility. Routledge.",
      "doi": ""
    },
    {
      "text": "Aimee van Wynsberghe. 2021. Responsible Robotics and Responsibility Attribution.",
      "doi": ""
    },
    {
      "text": "Michael Veale and Frederik\u00a0Zuiderveen Borgesius. 2021. Demystifying the Draft EU Artificial Intelligence Act\u2014Analysing the good, the bad, and the unclear elements of the proposed approach. Computer Law Review International 22, 4 (2021), 97\u2013112.",
      "doi": ""
    },
    {
      "text": "Carissa V\u00e9liz. 2021. Moral zombies: why algorithms are not moral agents. AI & SOCIETY (2021), 1\u201311.",
      "doi": ""
    },
    {
      "text": "David\u00a0C Vladeck. 2014. Machines without principals: liability rules and artificial intelligence. Wash. L. Rev. 89(2014), 117.",
      "doi": ""
    },
    {
      "text": "Daisuke Wakabayashi. 2018. Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam. New York Times. https://tinyurl.com/58wsubvd.",
      "doi": ""
    },
    {
      "text": "Julie Weed. 2021. R\u00e9sum\u00e9-Writing Tips to Help You Get Past the A.I. Gatekeepers. New York Times. https://tinyurl.com/yc2hz9tp.",
      "doi": ""
    },
    {
      "text": "Deborah\u00a0R Zucker, John\u00a0L Griffith, Joni\u00a0R Beshansky, and Harry\u00a0P Selker. 1997. Presentations of acute myocardial infarction in men and women. Journal of General Internal Medicine 12, 2 (1997), 79\u201387.",
      "doi": ""
    }
  ]
}