{
  "doi": "10.1145/3544548.3581026",
  "title": "Understanding Practices, Challenges, and Opportunities for User-Engaged Algorithm Auditing in Industry Practice",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-18",
  "year": 2023,
  "badges": [],
  "abstract": "Recent years have seen growing interest among both researchers and practitioners in user-engaged approaches to algorithm auditing, which directly engage users in detecting problematic behaviors in algorithmic systems. However, we know little about industry practitioners\u2019 current practices and challenges around user-engaged auditing, nor what opportunities exist for them to better leverage such approaches in practice. To investigate, we conducted a series of interviews and iterative co-design activities with practitioners who employ user-engaged auditing approaches in their work. Our findings reveal several challenges practitioners face in appropriately recruiting and incentivizing user auditors, scaffolding user audits, and deriving actionable insights from user-engaged audit reports. Furthermore, practitioners shared organizational obstacles to user-engaged auditing, surfacing a complex relationship between practitioners and user auditors. Based on these findings, we discuss opportunities for future HCI research to help realize the potential (and mitigate risks) of user-engaged auditing in industry practice.",
  "authors": [
    {
      "name": "Wesley Hanwen Deng",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659578025",
      "orcid": "0000-0003-3375-5285"
    },
    {
      "name": "Boyuan Guo",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660238206",
      "orcid": "0000-0002-8303-4649"
    },
    {
      "name": "Alicia Devrio",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660780719",
      "orcid": "0000-0002-9912-4198"
    },
    {
      "name": "Hong Shen",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659589829",
      "orcid": "0000-0002-5364-3718"
    },
    {
      "name": "Motahhare Eslami",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87959132657",
      "orcid": "0000-0002-1499-3045"
    },
    {
      "name": "Kenneth Holstein",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659133171",
      "orcid": "0000-0001-6730-922X"
    }
  ],
  "references": [
    {
      "text": "Rediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish Raghavan, and David\u00a0G Robinson. 2020. Roles for computing in social change. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 252\u2013260.",
      "doi": "10.1145/3351095.3372871"
    },
    {
      "text": "IBM Resaerch\u00a0Trusted AI. 2021. AIF360 API. (2021). https://aif360.mybluemix.net/",
      "doi": ""
    },
    {
      "text": "IBM Resaerch\u00a0Trusted AI. 2021. AIX360 API. (2021). https://aix360.mybluemix.net/",
      "doi": ""
    },
    {
      "text": "Open AI. 2022. ChatGPT Feedback Contest: Official Rules. https://cdn.openai.com/chatgpt/ChatGPT_Feedback_Contest_Rules.pdf",
      "doi": ""
    },
    {
      "text": "Dimitra Anastasiou and Rajat Gupta. 2011. Comparison of crowdsourcing translation with Machine Translation. Journal of Information Science 37, 6 (2011), 637\u2013659.",
      "doi": "10.1177/0165551511418760"
    },
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias. ProPublica (May 2016). https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing",
      "doi": ""
    },
    {
      "text": "Joshua Asplund, Motahhare Eslami, Hari Sundaram, Christian Sandvig, and Karrie Karahalios. 2020. Auditing race and gender discrimination in online housing markets. In Proceedings of the International AAAI Conference on Web and Social Media, Vol.\u00a014. 24\u201335.",
      "doi": ""
    },
    {
      "text": "Joshua Attenberg, Panos Ipeirotis, and Foster Provost. 2015. Beat the machine: Challenging humans to find a predictive model\u2019s \u201cunknown unknowns\u201d. Journal of Data and Information Quality (JDIQ) 6, 1 (2015), 1\u201317.",
      "doi": "10.1145/2700832"
    },
    {
      "text": "Josh\u00a0M Attenberg, Pagagiotis\u00a0G Ipeirotis, and Foster Provost. 2011. Beat the machine: Challenging workers to find the unknown unknowns. In Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Solon Barocas and Andrew\u00a0D Selbst. 2016. Big data\u2019s disparate impact. Calif. L. Rev. 104(2016), 671.",
      "doi": ""
    },
    {
      "text": "Rachel\u00a0KE Bellamy, Kuntal Dey, Michael Hind, Samuel\u00a0C Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovi\u0107, 2019. AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias. IBM Journal of Research and Development 63, 4/5 (2019), 4\u20131.",
      "doi": ""
    },
    {
      "text": "Jeffrey\u00a0P Bigham, Michael\u00a0S Bernstein, and Eytan Adar. 2015. Human-computer interaction and collective intelligence. Handbook of collective intelligence 57 (2015).",
      "doi": ""
    },
    {
      "text": "Sarah Bird. 2020. Fairlearn API. https://fairlearn.github.io/v0.5.0/api_reference/fairlearn.datasets.html",
      "doi": ""
    },
    {
      "text": "Sarah Bird, Miro Dud\u00edk, Richard Edgar, Brandon Horn, Roman Lutz, Vanessa Milan, Mehrnoosh Sameki, Hanna Wallach, and Kathleen Walker. 2020. Fairlearn: A toolkit for assessing and improving fairness in AI. Technical Report MSR-TR-2020-32. Microsoft. https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/",
      "doi": ""
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2019. Reflecting on reflexive thematic analysis. Qualitative research in sport, exercise and health 11, 4 (2019), 589\u2013597.",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on fairness, accountability and transparency. PMLR, 77\u201391.",
      "doi": ""
    },
    {
      "text": "\u00c1ngel\u00a0Alexander Cabrera, Abraham\u00a0J Druck, Jason\u00a0I Hong, and Adam Perer. 2021. Discovering and validating ai errors with crowdsourced failure reports. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201322.",
      "doi": "10.1145/3479569"
    },
    {
      "text": "Chris Callison-Burch and Mark Dredze. 2010. Creating speech and language data with amazon\u2019s mechanical turk. In Proceedings of the NAACL HLT 2010 workshop on creating speech and language data with Amazon\u2019s Mechanical Turk. 1\u201312.",
      "doi": "10.5555/1866696.1866697"
    },
    {
      "text": "Steve Campbell, Melanie Greenwood, Sarah Prior, Toniele Shearer, Kerrie Walkem, Sarah Young, Danielle Bywaters, and Kim Walker. 2020. Purposive sampling: complex or simple? Research case examples. Journal of research in Nursing 25, 8 (2020), 652\u2013661.",
      "doi": ""
    },
    {
      "text": "Jiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, and Madeleine Udell. 2019. Fairness under unawareness: Assessing disparity when protected class is unobserved. In Proceedings of the conference on fairness, accountability, and transparency. 339\u2013348.",
      "doi": "10.1145/3287560.3287594"
    },
    {
      "text": "Rumman Chowdhury and Jutta Williams. 2021. Introducing Twitter\u2019s first algorithmic bias bounty challenge. URl: https://blog. twitter. com/engineering/en_us/topics/insights/2021/algorithmic-bias-bountychallenge(2021).",
      "doi": ""
    },
    {
      "text": "Henriette Cramer, Jean Garcia-Gathright, Aaron Springer, and Sravana Reddy. 2018. Assessing and addressing algorithmic bias in practice. Interactions 25, 6 (2018), 58\u201363.",
      "doi": "10.1145/3278156"
    },
    {
      "text": "Kate Crawford. 2017. The trouble with bias. In Conference on Neural Information Processing Systems, invited speaker.",
      "doi": ""
    },
    {
      "text": "Wesley\u00a0Hanwen Deng, Manish Nagireddy, Michelle Seng\u00a0Ah Lee, Jatinder Singh, Zhiwei\u00a0Steven Wu, Kenneth Holstein, and Haiyi Zhu. 2022. Exploring How Machine Learning Practitioners (Try To) Use Fairness Toolkits. In 2022 ACM Conference on Fairness, Accountability, and Transparency. ACM, Seoul Republic of Korea, 473\u2013484. https://doi.org/10.1145/3531146.3533113",
      "doi": "10.1145/3531146.3533113"
    },
    {
      "text": "Alicia DeVos, Aditi Dhabalia, Hong Shen, Kenneth Holstein, and Motahhare Eslami. 2022. Toward User-Driven Algorithm Auditing: Investigating users\u2019 strategies for uncovering harmful algorithmic behavior. CHI Conference on Human Factors in Computing Systems (2022).",
      "doi": "10.1145/3491102.3517441"
    },
    {
      "text": "Bryan Dosono and Bryan Semaan. 2019. Moderation practices as emotional labor in sustaining online communities: The case of AAPI identity work on Reddit. In Proceedings of the 2019 CHI conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3290605.3300372"
    },
    {
      "text": "Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee Rickman, Kevin Hamilton, and Alex Kirlik. 2016. First I \"like\" It, Then I Hide It: Folk Theories of Social Feeds. Association for Computing Machinery, New York, NY, USA, 2371\u20132382. https://doi.org/10.1145/2858036.2858494",
      "doi": "10.1145/2858036.2858494"
    },
    {
      "text": "Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy Vuong, Karrie Karahalios, Kevin Hamilton, and Christian Sandvig. 2015. \"I Always Assumed That I Wasn\u2019t Really That Close to [Her]\": Reasoning about Invisible Algorithms in News Feeds. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (Seoul, Republic of Korea) (CHI \u201915). Association for Computing Machinery, New York, NY, USA, 153\u2013162. https://doi.org/10.1145/2702123.2702556",
      "doi": "10.1145/2702123.2702556"
    },
    {
      "text": "Motahhare Eslami, Kristen Vaccaro, Karrie Karahalios, and Kevin Hamilton. 2017. Be careful; Things can be worse than they appear - Understanding biased algorithms and users\u2019 behavior around them in rating platforms\". (2017), 62\u201371. Funding Information: This work was funded by NSF grant CHS-1564041. Publisher Copyright: \u00a9 Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.; 11th International Conference on Web and Social Media, ICWSM 2017 ; Conference date: 15-05-2017 Through 18-05-2017.",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Kristen Vaccaro, Karrie Karahalios, and Kevin Hamilton. 2017. \u201cBe careful; things can be worse than they appear\u201d: Understanding Biased Algorithms and Users\u2019 Behavior around Them in Rating Platforms. In Proceedings of the International AAAI Conference on Web and Social Media, Vol.\u00a011.",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Kristen Vaccaro, Min\u00a0Kyung Lee, Amit Elazari Bar\u00a0On, Eric Gilbert, and Karrie Karahalios. 2019. User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms. (2019), 1\u201314. https://doi.org/10.1145/3290605.3300724",
      "doi": "10.1145/3290605.3300724"
    },
    {
      "text": "Virginia Eubanks. 2018. Automating inequality: How high-tech tools profile, police, and punish the poor. St. Martin\u2019s Press.",
      "doi": "10.5555/3208509"
    },
    {
      "text": "Shelley Evenson. 2006. Directed storytelling: Interpreting experience for design. Design Studies: Theory and research in graphic design (2006), 231\u2013240.",
      "doi": ""
    },
    {
      "text": "Batya Friedman and Helen Nissenbaum. 1996. Bias in Computer Systems. ACM Trans. Inf. Syst. 14, 3 (July 1996), 330\u2013347. https://doi.org/10.1145/230538.230561",
      "doi": "10.1145/230538.230561"
    },
    {
      "text": "Mitchell\u00a0L Gordon, Michelle\u00a0S Lam, Joon\u00a0Sung Park, Kayur Patel, Jeff Hancock, Tatsunori Hashimoto, and Michael\u00a0S Bernstein. 2022. Jury learning: Integrating dissenting voices into machine learning models. In CHI Conference on Human Factors in Computing Systems. 1\u201319.",
      "doi": "10.1145/3491102.3502004"
    },
    {
      "text": "Alex Groce, Todd Kulesza, Chaoqiang Zhang, Shalini Shamasunder, Margaret Burnett, Weng-Keen Wong, Simone Stumpf, Shubhomoy Das, Amber Shinsel, Forrest Bice, 2013. You are the only possible oracle: Effective test selection for end users of interactive machine learning systems. IEEE Transactions on Software Engineering 40, 3 (2013), 307\u2013323.",
      "doi": "10.1109/TSE.2013.59"
    },
    {
      "text": "Aniko Hannak, Gary Soeller, David Lazer, Alan Mislove, and Christo Wilson. 2014. Measuring price discrimination and steering on e-commerce web sites. In Proceedings of the 2014 Conference on Internet Measurement Conference. 305\u2013318.",
      "doi": "10.1145/2663716.2663744"
    },
    {
      "text": "Christina Harrington, Sheena Erete, and Anne\u00a0Marie Piper. 2019. Deconstructing community-based collaborative design: Towards more equitable participatory design engagements. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201325.",
      "doi": "10.1145/3359318"
    },
    {
      "text": "Jamie Harris. 2022. Facebook forced to ban its AI after it \u2018revealed how to make napalm and made racist comments. https://www.the-sun.com/tech/6729391/meta-withdraws-ai-galactica-controversy/",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Erik Harpstead, Rebecca Gulotta, and Jodi Forlizzi. 2020. Replay enactments: Exploring possible futures through historical data. In Proceedings of the 2020 ACM Designing Interactive Systems Conference. 1607\u20131618.",
      "doi": "10.1145/3357236.3395427"
    },
    {
      "text": "Kenneth Holstein, Bruce\u00a0M McLaren, and Vincent Aleven. 2019. Designing for complementarity: Teacher and student needs for orchestration support in AI-enhanced classrooms. (2019), 157\u2013171.",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Jennifer Wortman\u00a0Vaughan, Hal Daum\u00e9\u00a0III, Miro Dudik, and Hanna Wallach. 2019. Improving fairness in machine learning systems: What do industry practitioners need?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3290605.3300830"
    },
    {
      "text": "Mokter Hossain. 2012. Users\u2019 motivation to participate in online crowdsourcing platforms. In 2012 International Conference on Innovation Management and Technology Research. IEEE, 310\u2013315.",
      "doi": ""
    },
    {
      "text": "Yen-Chia Hsu, Himanshu Verma, Andrea Mauri, Illah Nourbakhsh, Alessandro Bozzon, 2022. Empowering local communities using artificial intelligence. Patterns 3, 3 (2022), 100449.",
      "doi": ""
    },
    {
      "text": "Lilly\u00a0C Irani and M\u00a0Six Silberman. 2013. Turkopticon: Interrupting worker invisibility in amazon mechanical turk. In Proceedings of the SIGCHI conference on human factors in computing systems. 611\u2013620.",
      "doi": "10.1145/2470654.2470742"
    },
    {
      "text": "Nicolas Kaufmann, Thimo Schulze, and Daniel Veit. 2011. More than fun and money. worker motivation in crowdsourcing\u2013a study on mechanical turk. (2011).",
      "doi": ""
    },
    {
      "text": "Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, and Jennifer Wortman\u00a0Vaughan. 2020. Interpreting interpretability: understanding data scientists\u2019 use of interpretability tools for machine learning. In Proceedings of the 2020 CHI conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3313831.3376219"
    },
    {
      "text": "Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, 2021. Dynabench: Rethinking benchmarking in NLP. arXiv preprint arXiv:2104.14337(2021).",
      "doi": ""
    },
    {
      "text": "Aniket Kittur, Jeffrey\u00a0V Nickerson, Michael Bernstein, Elizabeth Gerber, Aaron Shaw, John Zimmerman, Matt Lease, and John Horton. 2013. The future of crowd work. In Proceedings of the 2013 conference on Computer supported cooperative work. 1301\u20131318.",
      "doi": "10.1145/2441776.2441923"
    },
    {
      "text": "Aniket Kittur, Jeffrey\u00a0V. Nickerson, Michael\u00a0S. Bernstein, Elizabeth Gerber, Aaron\u00a0D. Shaw, John Zimmerman, Matthew Lease, and John\u00a0Joseph Horton. 2013. The future of crowd work. Proceedings of the 2013 conference on Computer supported cooperative work (2013).",
      "doi": "10.1145/2441776.2441923"
    },
    {
      "text": "Robert\u00a0E Kraut and Paul Resnick. 2011. Encouraging contribution to online communities. Building successful online communities: Evidence-based social design (2011), 21\u201376.",
      "doi": ""
    },
    {
      "text": "Joshua\u00a0A Kroll, Solon Barocas, Edward\u00a0W Felten, Joel\u00a0R Reidenberg, David\u00a0G Robinson, and Harlan Yu. 2016. Accountable algorithms. U. Pa. L. Rev. 165(2016), 633.",
      "doi": ""
    },
    {
      "text": "Michelle\u00a0S. Lam, Mitchell\u00a0L. Gordon, Dana\u00eb Metaxa, Jeffrey\u00a0T. Hancock, James\u00a0A. Landay, and Michael\u00a0S. Bernstein. 2022. End-User Audits: A System Empowering Communities to Lead Large-Scale Investigations of Harmful Algorithmic Behavior. Proc. ACM Hum.-Comput. Interact. 6, CSCW2, Article 512 (Nov 2022), 34\u00a0pages. https://doi.org/10.1145/3555625",
      "doi": "10.1145/3555625"
    },
    {
      "text": "Michelle Seng\u00a0Ah Lee and Jatinder Singh. 2020. The Landscape and Gaps in Open Source Fairness Toolkits. Available at SSRN (2020).",
      "doi": ""
    },
    {
      "text": "Kimberly Ling, Gerard Beenen, Pamela Ludford, Xiaoqing Wang, Klarissa Chang, Xin Li, Dan Cosley, Dan Frankowski, Loren Terveen, Al\u00a0Mamunur Rashid, 2005. Using social psychology to motivate contributions to online communities. Journal of Computer-Mediated Communication 10, 4 (2005), 00\u201300.",
      "doi": ""
    },
    {
      "text": "Michael Madaio, Lisa Egede, Hariharan Subramonyam, Jennifer\u00a0Wortman Vaughan, and Hanna Wallach. 2021. Assessing the Fairness of AI Systems: AI Practitioners\u2019 Processes, Challenges, and Needs for Support. arXiv preprint arXiv:2112.05675(2021).",
      "doi": ""
    },
    {
      "text": "Michael\u00a0A Madaio, Luke Stark, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2020. Co-designing checklists to understand organizational challenges and opportunities around fairness in ai. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3313831.3376445"
    },
    {
      "text": "Suresh\u00a0S Malladi and Hemang\u00a0C Subramanian. 2019. Bug bounty programs for cybersecurity: Practices, issues, and recommendations. IEEE Software 37, 1 (2019), 31\u201339.",
      "doi": "10.1109/MS.2018.2880508"
    },
    {
      "text": "Nora McDonald, Sarita Schoenebeck, and Andrea Forte. 2019. Reliability and inter-rater reliability in qualitative research: Norms and guidelines for CSCW and HCI practice. Proceedings of the ACM on human-computer interaction 3, CSCW(2019), 1\u201323.",
      "doi": "10.1145/3359174"
    },
    {
      "text": "Dana\u00eb Metaxa, Joon\u00a0Sung Park, Ronald\u00a0E Robertson, Karrie Karahalios, Christo Wilson, Jeff Hancock, Christian Sandvig, 2021. Auditing algorithms: Understanding algorithmic systems from the outside in. Foundations and Trends\u00ae in Human\u2013Computer Interaction 14, 4(2021), 272\u2013344.",
      "doi": ""
    },
    {
      "text": "Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa\u00a0Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency. 220\u2013229.",
      "doi": "10.1145/3287560.3287596"
    },
    {
      "text": "Safiya\u00a0Umoja Noble. 2018. Algorithms of oppression: How search engines reinforce racism. NYU Press.",
      "doi": ""
    },
    {
      "text": "Besmira Nushi, Ece Kamar, and Eric Horvitz. 2018. Towards accountable ai: Hybrid human-machine analyses for characterizing system failure. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a06. 126\u2013135.",
      "doi": ""
    },
    {
      "text": "Rodrigo Ochigame and Katherine Ye. 2021. Search Atlas: Visualizing Divergent Search Results Across Geopolitical Borders. In Designing Interactive Systems Conference 2021. 1970\u20131983.",
      "doi": ""
    },
    {
      "text": "Giada Pistilli. 2022. HuggingFace announcedthe new feature to flag any Model, Dataset, or Space on the Hub. https://twitter.com/GiadaPistilli/status/1571865167092396033?s=20&t=LRhhEu63s6ftPmtZdfz8Cw",
      "doi": ""
    },
    {
      "text": "Marcelo\u00a0OR Prates, Pedro\u00a0H Avelar, and Lu\u00eds\u00a0C Lamb. 2020. Assessing gender bias in machine translation: a case study with google translate. Neural Computing and Applications 32, 10 (2020), 6363\u20136381.",
      "doi": "10.1007/s00521-019-04144-6"
    },
    {
      "text": "Inioluwa\u00a0Deborah Raji and Joy Buolamwini. 2019. Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial AI products. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 429\u2013435.",
      "doi": "10.1145/3306618.3314244"
    },
    {
      "text": "Inioluwa\u00a0Deborah Raji, Andrew Smart, Rebecca\u00a0N White, Margaret Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron, and Parker Barnes. 2020. Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing. In Proceedings of the 2020 conference on fairness, accountability, and transparency. 33\u201344.",
      "doi": "10.1145/3351095.3372873"
    },
    {
      "text": "Inioluwa\u00a0Deborah Raji, Peggy Xu, Colleen Honigsberg, and Daniel Ho. 2022. Outsider Oversight: Designing a Third Party Audit Ecosystem for AI Governance. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society. 557\u2013571.",
      "doi": "10.1145/3514094.3534181"
    },
    {
      "text": "Bogdana Rakova, Jingying Yang, Henriette Cramer, and Rumman Chowdhury. 2021. Where responsible AI meets reality: Practitioner perspectives on enablers for shifting organizational practices. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201323.",
      "doi": "10.1145/3449081"
    },
    {
      "text": "Microsoft Research. 2022. AI Fairness Checklist. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/",
      "doi": ""
    },
    {
      "text": "People +\u00a0AI Research. 2021. People AI Guidebook. (2021). https://pair.withgoogle.com/guidebook/",
      "doi": ""
    },
    {
      "text": "Brianna Richardson, Jean Garcia-Gathright, Samuel\u00a0F Way, Jennifer Thom, and Henriette Cramer. 2021. Towards Fairness in Practice: A Practitioner-Oriented Rubric for Evaluating Fair ML Toolkits. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3411764.3445604"
    },
    {
      "text": "Samantha Robertson and Niloufar Salehi. 2020. What If I Don\u2019t Like Any Of The Choices? The Limits of Preference Elicitation for Participatory Algorithm Design. In Workshop on Participatory Approaches to Machine Learning at ICML 2020.",
      "doi": ""
    },
    {
      "text": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, 2015. Imagenet large scale visual recognition challenge. International journal of computer vision 115, 3 (2015), 211\u2013252.",
      "doi": "10.1007/s11263-015-0816-y"
    },
    {
      "text": "Niloufar Salehi, Lilly\u00a0C Irani, Michael\u00a0S Bernstein, Ali Alkhatib, Eva Ogbe, and Kristy Milland. 2015. We are dynamo: Overcoming stalling and friction in collective action for crowd workers. In Proceedings of the 33rd annual ACM conference on human factors in computing systems. 1621\u20131630.",
      "doi": "10.1145/2702123.2702508"
    },
    {
      "text": "Christian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric Langbort. 2014. Auditing algorithms: Research methods for detecting discrimination on internet platforms. Data and Discrimination: Converting Critical Concerns into Productive Inquiry (2014).",
      "doi": ""
    },
    {
      "text": "Oscar Schwartz. 2019. Microsoft\u2019s Racist Chatbot Revealed the Dangers of Online Conversation The bot learned language from people on Twitter\u2014but it also learned values. https://spectrum.ieee.org/in-2016-microsofts-racist-chatbot-revealed-the-dangers-of-online-conversation",
      "doi": ""
    },
    {
      "text": "Andrew\u00a0D. Selbst, Danah Boyd, Sorelle\u00a0A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical Systems. (2019), 59\u201368. https://doi.org/10.1145/3287560.3287598",
      "doi": "10.1145/3287560.3287598"
    },
    {
      "text": "Hong Shen, Alicia DeVos, Motahhare Eslami, and Kenneth Holstein. 2021. Everyday algorithm auditing: Understanding the power of everyday users in surfacing harmful algorithmic behaviors. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201329.",
      "doi": "10.1145/3479577"
    },
    {
      "text": "Hong Shen, Leijie Wang, Wesley\u00a0H Deng, Ciell Brusse, Ronald Velgersdijk, and Haiyi Zhu. 2022. The Model Card Authoring Toolkit: Toward Community-centered, Deliberation-driven AI Design. In 2022 ACM Conference on Fairness, Accountability, and Transparency. 440\u2013451.",
      "doi": "10.1145/3531146.3533110"
    },
    {
      "text": "Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2020. Participation is not a design fix for machine learning. arXiv preprint arXiv:2007.02423(2020).",
      "doi": ""
    },
    {
      "text": "Rion Snow, Brendan O\u2019connor, Dan Jurafsky, and Andrew\u00a0Y Ng. 2008. Cheap and fast\u2013but is it good? evaluating non-expert annotations for natural language tasks. In Proceedings of the 2008 conference on empirical methods in natural language processing. 254\u2013263.",
      "doi": ""
    },
    {
      "text": "Miriah Steiger, Timir\u00a0J Bharucha, Sukrit Venkatagiri, Martin\u00a0J Riedl, and Matthew Lease. 2021. The psychological well-being of content moderators: the emotional labor of commercial moderation and avenues for improving support. In Proceedings of the 2021 CHI conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3411764.3445092"
    },
    {
      "text": "Jina Suh, Soroush Ghorashi, Gonzalo Ramos, Nan-Chen Chen, Steven Drucker, Johan Verwey, and Patrice Simard. 2019. AnchorViz: Facilitating Semantic Data Exploration and Concept Discovery for Interactive Machine Learning. ACM Trans. Interact. Intell. Syst. 10, 1, Article 7 (Aug. 2019), 38\u00a0pages. https://doi.org/10.1145/3241379",
      "doi": "10.1145/3241379"
    },
    {
      "text": "Latanya Sweeney. 2013. Discrimination in online ad delivery. Queue 11, 3 (2013), 10\u201329.",
      "doi": "10.1145/2460276.2460278"
    },
    {
      "text": "Kush\u00a0R Varshney. 2019. Trustworthy machine learning and artificial intelligence. XRDS: Crossroads, The ACM Magazine for Students 25, 3 (2019), 26\u201329.",
      "doi": "10.1145/3313109"
    },
    {
      "text": "Jennifer\u00a0Wortman Vaughan. 2017. Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research.J. Mach. Learn. Res. 18, 1 (2017), 7026\u20137071.",
      "doi": "10.5555/3122009.3242050"
    },
    {
      "text": "Michael Veale and Reuben Binns. 2017. Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data. Big Data & Society 4, 2 (2017), 2053951717743530.",
      "doi": ""
    },
    {
      "text": "Tris Warkentin and Josh Woodward. 2022. AI Test Kitchen. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/",
      "doi": ""
    },
    {
      "text": "Tongshuang Wu, Marco\u00a0Tulio Ribeiro, Jeffrey Heer, and Daniel\u00a0S Weld. 2019. Errudite: Scalable, reproducible, and testable error analysis. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 747\u2013763.",
      "doi": ""
    },
    {
      "text": "Meg Young, Lassana Magassa, and Batya Friedman. 2019. Toward inclusive tech policy design: a method for underrepresented voices to strengthen tech policy documents. Ethics and Information Technology 21, 2 (2019), 89\u2013103.",
      "doi": "10.1007/s10676-019-09497-z"
    },
    {
      "text": "Omar Zaidan and Chris Callison-Burch. 2011. Crowdsourcing translation: Professional quality from non-professionals. In Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies. 1220\u20131229.",
      "doi": ""
    },
    {
      "text": "Sharon Zhou, Mitchell Gordon, Ranjay Krishna, Austin Narcomey, Li\u00a0F Fei-Fei, and Michael Bernstein. 2019. Hype: A benchmark for human eye perceptual evaluation of generative models. Advances in neural information processing systems 32 (2019).",
      "doi": ""
    },
    {
      "text": "James Zou and Londa Schiebinger. 2018. AI can be sexist and racist\u2014it\u2019s time to make it fair. Nature 559(2018), 324\u2013326.",
      "doi": ""
    }
  ]
}