{
  "doi": "10.1145/3544548.3581076",
  "title": "Haptic-Captioning: Using Audio-Haptic Interfaces to Enhance Speaker Indication in Real-Time Captions for Deaf and Hard-of-Hearing Viewers",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-14",
  "year": 2023,
  "badges": [],
  "abstract": "Captions make the audio content of videos accessible and understandable for deaf or hard-of-hearing people (DHH). However, in real-time captioning scenarios, captions alone can be challenging for DHH users to identify the active speaker in a real time in multiple-speaker scenarios. To enhance the accessibility of real-time captioning, we propose Haptic-Captioning which provides real-time vibration feedback on the wrist by directly translating the sound of content into vibrations. We conducted three experiments to examine: (1) the haptic perception (Preliminary Study), (2) the feasibility of the haptic modality along with real-time and non-real-time visual captioning methods (Study 1), and (3) the user experience of using the Haptic-Captioning system in different media contexts (Study 2). Our results highlight that the Haptic-Captioning complements visual captions by improving caption readability, maintaining media engagement, enhancing understanding of emotions, and assisting speaker indication in real-time captioning scenarios. Furthermore, we discuss design implications for the future development of Haptic-Captioning.",
  "authors": [
    {
      "name": "Yiwen Wang",
      "institution": "College of Information Studies, University of Maryland, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660784040",
      "orcid": "0000-0002-1234-7621"
    },
    {
      "name": "Ziming Li",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660608505",
      "orcid": "0000-0003-4302-9949"
    },
    {
      "name": "Pratheep Kumar Chelladurai",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660778322",
      "orcid": "0000-0003-1823-7738"
    },
    {
      "name": "Wendy Dannels",
      "institution": "NTID Center on Culture and Language, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660621044",
      "orcid": "0000-0002-2344-6828"
    },
    {
      "name": "Tae Oh",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81414603980",
      "orcid": "0000-0002-6390-8927"
    },
    {
      "name": "Roshan L Peiris",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81385592390",
      "orcid": "0000-0002-4191-3565"
    }
  ],
  "references": [
    {
      "text": "Akhter\u00a0Al Amin, Abraham Glasser, Raja Kushalnagar, Christian Vogler, and Matt Huenerfauth. 2021. Preferences of Deaf or Hard of Hearing Users for Live-TV Caption Appearance. In Universal Access in Human-Computer Interaction. Access to Media, Learning and Assistive Environments, Margherita Antona and Constantine Stephanidis (Eds.). Springer International Publishing, Cham, 189\u2013201.",
      "doi": ""
    },
    {
      "text": "Akhter\u00a0Al Amin, Saad Hassan, and Matt Huenerfauth. 2021. Caption-Occlusion Severity Judgments across Live-Television Genres from Deaf and Hard-of-Hearing Viewers. In Proceedings of the 18th International Web for All Conference (Ljubljana, Slovenia) (W4A \u201921). Association for Computing Machinery, New York, NY, USA, Article 26, 12\u00a0pages. https://doi.org/10.1145/3430263.3452429",
      "doi": "10.1145/3430263.3452429"
    },
    {
      "text": "Akhter\u00a0Al Amin, Joseph Mendis, Raja Kushalnagar, Christian Vogler, Sooyeon Lee, and Matt Huenerfauth. 2022. Deaf and Hard of Hearing Viewers\u2019 Preference for Speaker Identifier Type in Live TV Programming. In Universal Access in Human-Computer Interaction. Access to Media, Learning and Assistive Environments, Margherita Antona and Constantine Stephanidis (Eds.). Springer International Publishing, Cham. https://doi.org/10.1007/978-3-031-05028-2_13",
      "doi": "10.1007/978-3-031-05028-2_13"
    },
    {
      "text": "Larwan Berke, Khaled Albusays, Matthew Seita, and Matt Huenerfauth. 2019. Preferred appearance of captions generated by automatic speech recognition for deaf and hard-of-hearing viewers. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u20136.",
      "doi": "10.1145/3290607.3312921"
    },
    {
      "text": "Larwan Berke, Christopher Caulfield, and Matt Huenerfauth. 2017. Deaf and Hard-of-Hearing Perspectives on Imperfect Automatic Speech Recognition for Captioning One-on-One Meetings. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (Baltimore, Maryland, USA) (ASSETS \u201917). Association for Computing Machinery, New York, NY, USA, 155\u2013164. https://doi.org/10.1145/3132525.3132541",
      "doi": "10.1145/3132525.3132541"
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2012. Thematic analysis.(2012).",
      "doi": ""
    },
    {
      "text": "Andy Brown, Rhia Jones, Michael Crabb, James Sandford, Matthew Brooks, Michael Armstrong, and Caroline Jay. 2015. Dynamic Subtitles: The User Experience. https://doi.org/10.1145/2745197.2745204",
      "doi": "10.1145/2745197.2745204"
    },
    {
      "text": "Janine Butler. 2020. The Visual Experience of Accessing Captioned Television and Digital Videos. Television & New Media 21, 7 (2020), 679\u2013696. https://doi.org/10.1177/1527476418824805 arXiv:https://doi.org/10.1177/1527476418824805",
      "doi": ""
    },
    {
      "text": "Angela Chang and Conor O\u2019Sullivan. 2005. Audio-haptic feedback in mobile phones. In CHI\u201905 extended abstracts on Human factors in computing systems. 1264\u20131267.",
      "doi": ""
    },
    {
      "text": "Artem Dementyev, Pascal Getreuer, Dimitri Kanevsky, Malcolm Slaney, and Richard\u00a0F Lyon. 2021. VHP: Vibrotactile Haptics Platform for On-Body Applications(UIST \u201921). Association for Computing Machinery, New York, NY, USA, 598\u2013612. https://doi.org/10.1145/3472749.3474772",
      "doi": "10.1145/3472749.3474772"
    },
    {
      "text": "Described and Captioned Media Program. 2022. Captioning key - speaker identification. https://dcmp.org/learn/603-captioning-key\u2014speaker-identification. Accessed: 2022-04-12.",
      "doi": ""
    },
    {
      "text": "Leah Findlater, Bonnie Chinh, Dhruv Jain, Jon Froehlich, Raja Kushalnagar, and Angela\u00a0Carey Lin. 2019. Deaf and Hard-of-Hearing Individuals\u2019 Preferences for Wearable and Mobile Sound Awareness Technologies. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI \u201919). Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3290605.3300276",
      "doi": "10.1145/3290605.3300276"
    },
    {
      "text": "Morton\u00a0Ann Gernsbacher. 2015. Video Captions Benefit Everyone. Policy Insights from the Behavioral and Brain Sciences 2, 1 (2015), 195\u2013202. https://doi.org/10.1177/2372732215602130 arXiv:https://doi.org/10.1177/2372732215602130PMID: 28066803.",
      "doi": ""
    },
    {
      "text": "Abraham Glasser, Edward Mason\u00a0Riley, Kaitlyn Weeks, and Raja Kushalnagar. 2019. Mixed Reality Speaker Identification as an Accessibility Tool for Deaf and Hard of Hearing Users. In 25th ACM Symposium on Virtual Reality Software and Technology (Parramatta, NSW, Australia) (VRST \u201919). Association for Computing Machinery, New York, NY, USA, Article 80, 3\u00a0pages. https://doi.org/10.1145/3359996.3364720",
      "doi": "10.1145/3359996.3364720"
    },
    {
      "text": "Steven Goodman, Susanne Kirchner, Rose Guttman, Dhruv Jain, Jon Froehlich, and Leah Findlater. 2020. Evaluating Smartwatch-Based Sound Feedback for Deaf and Hard-of-Hearing Users Across Contexts. Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376406",
      "doi": "10.1145/3313831.3376406"
    },
    {
      "text": "Stephen\u00a0R Gulliver and George Ghinea. 2003. How level and type of deafness affect user perception of multimedia video clips. Universal Access in the Information Society 2, 4 (2003), 374\u2013386.",
      "doi": "10.1007/s10209-003-0067-5"
    },
    {
      "text": "Richang Hong, Meng Wang, Xiao-Tong Yuan, Mengdi Xu, Jianguo Jiang, Shuicheng Yan, and Tat-Seng Chua. 2011. Video Accessibility Enhancement for Hearing-Impaired Users. ACM Trans. Multimedia Comput. Commun. Appl. 7S, 1, Article 24 (nov 2011), 19\u00a0pages. https://doi.org/10.1145/2037676.2037681",
      "doi": "10.1145/2037676.2037681"
    },
    {
      "text": "Yongtao Hu, Jan Kautz, Yizhou Yu, and Wenping Wang. 2015. Speaker-Following Video Subtitles. ACM Trans. Multimedia Comput. Commun. Appl. 11, 2, Article 32 (jan 2015), 17\u00a0pages. https://doi.org/10.1145/2632111",
      "doi": "10.1145/2632111"
    },
    {
      "text": "Dhruv Jain, Brendon Chiu, Steven Goodman, Chris Schmandt, Leah Findlater, and Jon\u00a0E. Froehlich. 2020. Field Study of a Tactile Sound Awareness Device for Deaf Users. In Proceedings of the 2020 International Symposium on Wearable Computers (Virtual Event, Mexico) (ISWC \u201920). Association for Computing Machinery, New York, NY, USA, 55\u201357. https://doi.org/10.1145/3410531.3414291",
      "doi": "10.1145/3410531.3414291"
    },
    {
      "text": "Dhruv Jain, Rachel Franz, Leah Findlater, Jackson Cannon, Raja Kushalnagar, and Jon Froehlich. 2018. Towards Accessible Conversations in a Mobile Context for People who are Deaf and Hard of Hearing. 81\u201392. https://doi.org/10.1145/3234695.3236362",
      "doi": "10.1145/3234695.3236362"
    },
    {
      "text": "Kuno Kurzhals, Emine Cetinkaya, Yongtao Hu, Wenping Wang, and Daniel Weiskopf. 2017. Close to the Action: Eye-Tracking Evaluation of Speaker-Following Subtitles. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 6559\u20136568. https://doi.org/10.1145/3025453.3025772",
      "doi": "10.1145/3025453.3025772"
    },
    {
      "text": "Raja Kushalnagar, Gary Behm, Kevin Wolfe, Peter Yeung, Becca Dingman, Shareef Ali, Abraham Glasser, and Claire Ryan. 2019. RTTD-ID: Tracked captions with multiple speakers for deaf students. arXiv preprint arXiv:1909.08172(2019).",
      "doi": ""
    },
    {
      "text": "Raja\u00a0S. Kushalnagar, Gary\u00a0W. Behm, Joseph\u00a0S. Stanislow, and Vasu Gupta. 2014. Enhancing Caption Accessibility through Simultaneous Multimodal Information: Visual-Tactile Captions(ASSETS \u201914). Association for Computing Machinery, New York, NY, USA, 185\u2013192. https://doi.org/10.1145/2661334.2661381",
      "doi": "10.1145/2661334.2661381"
    },
    {
      "text": "Jaebong Lee and Seungmoon Choi. 2013. Real-time perception-level translation from audio signals to vibrotactile effects. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 2567\u20132576.",
      "doi": "10.1145/2470654.2481354"
    },
    {
      "text": "Tomosuke Maeda, Roshan Peiris, Nakatani Masashi, Yoshihiro Tanaka, and Kouta Minamizawa. 2016. HapticAid: Wearable Haptic Augmentation System for Enhanced, Enchanted and Empathised Haptic Experiences. In SIGGRAPH ASIA 2016 Emerging Technologies (Macau) (SA \u201916). Association for Computing Machinery, New York, NY, USA, Article 4, 2\u00a0pages. https://doi.org/10.1145/2988240.2988253",
      "doi": "10.1145/2988240.2988253"
    },
    {
      "text": "Tomosuke Maeda, Roshan Peiris, Masashi Nakatani, Yoshihiro Tanaka, and Kouta Minamizawa. 2016. Wearable Haptic Augmentation System Using Skin Vibration Sensor. In Proceedings of the 2016 Virtual Reality International Conference (Laval, France) (VRIC \u201916). Association for Computing Machinery, New York, NY, USA, Article 25, 4\u00a0pages. https://doi.org/10.1145/2927929.2927946",
      "doi": "10.1145/2927929.2927946"
    },
    {
      "text": "Tomosuke Maeda, Keitaro Tsuchiya, Roshan Peiris, Yoshihiro Tanaka, and Kouta Minamizawa. 2017. Hapticaid: Haptic experiences system using mobile platform. In Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction. 397\u2013402.",
      "doi": "10.1145/3024969.3025063"
    },
    {
      "text": "Mishaim Malik, Muhammad\u00a0Kamran Malik, Khawar Mehmood, and Imran Makhdoom. 2021. Automatic speech recognition: a survey. Multimedia Tools and Applications 80, 6 (01 Mar 2021), 9411\u20139457. https://doi.org/10.1007/s11042-020-10073-7",
      "doi": "10.1007/s11042-020-10073-7"
    },
    {
      "text": "Emma\u00a0J. McDonnell, Ping Liu, Steven\u00a0M. Goodman, Raja Kushalnagar, Jon\u00a0E. Froehlich, and Leah Findlater. 2021. Social, Environmental, and Technical: Factors at Play in the Current Use and Future Design of Small-Group Captioning. Proc. ACM Hum.-Comput. Interact. 5, CSCW2, Article 434 (oct 2021), 25\u00a0pages. https://doi.org/10.1145/3479578",
      "doi": "10.1145/3479578"
    },
    {
      "text": "Kouta Minamizawa, Yasuaki Kakehi, Masashi Nakatani, Soichiro Mihara, and Susumu Tachi. 2012. TECHTILE toolkit. In IEEE Haptics Symposium.",
      "doi": ""
    },
    {
      "text": "Suranga Nanayakkara, Elizabeth Taylor, Lonce Wyse, and S\u00a0H Ong. 2009. An enhanced musical experience for the deaf: design and evaluation of a music display and a haptic chair. In Proceedings of the sigchi conference on human factors in computing systems. 337\u2013346.",
      "doi": "10.1145/1518701.1518756"
    },
    {
      "text": "Andrew\u00a0J. Oxenham. 2018. How We Hear: The Perception and Neural Coding of Sound. Annual Review of Psychology 69, 1 (2018), 27\u201350. https://doi.org/10.1146/annurev-psych-122216-011635 arXiv:https://doi.org/10.1146/annurev-psych-122216-011635PMID: 29035691.",
      "doi": ""
    },
    {
      "text": "Claudio Pacchierotti, Stephen Sinclair, Massimiliano Solazzi, Antonio Frisoli, Vincent Hayward, and Domenico Prattichizzo. 2017. Wearable haptic systems for the fingertip and the hand: taxonomy, review, and perspectives. IEEE transactions on haptics 10, 4 (2017), 580\u2013600.",
      "doi": "10.1109/TOH.2017.2689006"
    },
    {
      "text": "Frank\u00a0A Saunders, William\u00a0A Hill, and Barbara Franklin. 1981. A wearable tactile sensory aid for profoundly deaf children. Journal of Medical Systems 5, 4 (1981), 265\u2013270.",
      "doi": ""
    },
    {
      "text": "Radu-Daniel Vatavu. 2021. Accessibility of Interactive Television and Media Experiences: Users with Disabilities Have Been Little Voiced at IMX and TVX. In ACM International Conference on Interactive Media Experiences (Virtual Event, USA) (IMX \u201921). Association for Computing Machinery, New York, NY, USA, 218\u2013222. https://doi.org/10.1145/3452918.3465485",
      "doi": "10.1145/3452918.3465485"
    },
    {
      "text": "Quoc\u00a0V Vy and Deborah\u00a0I Fels. 2010. Using placement and name for speaker identification in captioning. In International Conference on Computers for Handicapped Persons. Springer, 247\u2013254.",
      "doi": ""
    },
    {
      "text": "Maximilian Weber and Charalampos Saitis. 2020. Towards a framework for ubiquitous audio-tactile design. In International Workshop on Haptic and Audio Interaction Design. Montreal, Canada. https://hal.archives-ouvertes.fr/hal-02901209",
      "doi": ""
    },
    {
      "text": "Antoine Weill\u2013Duflos, Feras Al\u00a0Taha, Pascal\u00a0E. Fortin, and Jeremy\u00a0R. Cooperstock. 2019. BarryWhaptics: Towards Countering Social Biases Using Real-Time Haptic Enhancement of Voice. In 2019 IEEE World Haptics Conference (WHC). 365\u2013370. https://doi.org/10.1109/WHC.2019.8816153",
      "doi": ""
    },
    {
      "text": "J\u00a0M Weisenberger, S\u00a0M Broadstone, and L Kozma-Spytek. 1991. Relative performance of single-channel and multichannel tactile aids for speech perception. J Rehabil Res Dev 28, 2 (1991), 45\u201356.",
      "doi": ""
    },
    {
      "text": "J\u00a0M Weisenberger, S\u00a0M Broadstone, and F\u00a0A Saunders. 1989. Evaluation of two multichannel tactile aids for the hearing impaired. J Acoust Soc Am 86, 5 (Nov. 1989), 1764\u20131775.",
      "doi": ""
    }
  ]
}