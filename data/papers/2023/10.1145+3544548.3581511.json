{
  "doi": "10.1145/3544548.3581511",
  "title": "Visualization of Speech Prosody and Emotion in Captions: Accessibility\u00a0for\u00a0Deaf\u00a0and\u00a0Hard-of-Hearing Users",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-15",
  "year": 2023,
  "badges": [],
  "abstract": "Speech is expressive in ways that caption text does not capture, with emotion or emphasis information not conveyed. We interviewed eight Deaf and Hard-of-Hearing (dhh) individuals to understand if and how captions\u2019 inexpressiveness impacts them in online meetings with hearing peers. Automatically captioned speech, we found, lacks affective depth, lending it a hard-to-parse ambiguity and general dullness. Interviewees regularly feel excluded, which some understand is an inherent quality of these types of meetings rather than a consequence of current caption text design. Next, we developed three novel captioning models that depicted, beyond words, features from prosody, emotions, and a mix of both. In an empirical study, 16 dhh participants compared these models with conventional captions. The emotion-based model outperformed traditional captions in depicting emotions and emphasis, with only a moderate loss in legibility, suggesting its potential as a more inclusive design for captions.",
  "tags": [
    "Individuals with Disabilities & Assistive Technologies",
    "Emotion / Affective Computing",
    "Accessibility",
    "Empirical study that tells us about how people use a system"
  ],
  "authors": [
    {
      "name": "Calu\u00e3 de Lacerda Pataca",
      "institution": "Computing and Information Sciences, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-99659509389/rel-imgonly/1x1.jpg",
      "acmid": "99659509389",
      "orcid": "0000-0001-5046-9884"
    },
    {
      "name": "Matthew Watkins",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660237368",
      "orcid": "0000-0003-3133-8664"
    },
    {
      "name": "Roshan Peiris",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81385592390",
      "orcid": "0000-0002-4191-3565"
    },
    {
      "name": "Sooyeon Lee",
      "institution": "Informatics/Ying Wu College of Computing, New Jersey Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659135375",
      "orcid": "0000-0002-4971-2004"
    },
    {
      "name": "Matt Huenerfauth",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-81100240888/rel-imgonly/huenerfauth-matt-headshot-1.jpg",
      "acmid": "81100240888",
      "orcid": "0000-0001-6290-2681"
    }
  ],
  "references": [
    {
      "text": "Al\u00ebna Aks\u00ebnova, Daan van Esch, James Flynn, and Pavel Golik. 2021. How Might We Create Better Benchmarks for Speech Recognition?. In Proceedings of the 1st Workshop on Benchmarking: Past, Present and Future. Association for Computational Linguistics, Online, 22\u201334. https://doi.org/10.18653/v1/2021.bppf-1.4",
      "doi": ""
    },
    {
      "text": "Aviad Albert, Francesco Cangemi, and Martine Grice. 2018. Using periodic energy to enrich acoustic representations of pitch in speech: A demonstration. In Proceedings Speech Prosody, Vol.\u00a09. International Speech Communications Association, Poznan, Poland, 13\u201316.",
      "doi": ""
    },
    {
      "text": "Akhter\u00a0Al Amin, Saad Hassan, and Matt Huenerfauth. 2021. Effect of Occlusion on Deaf and Hard of Hearing Users\u2019 Perception of Captioned Video Quality. In Universal Access in Human-Computer Interaction. Access to Media, Learning and Assistive Environments, Margherita Antona and Constantine Stephanidis (Eds.). Springer International Publishing, Cham, 202\u2013220.",
      "doi": ""
    },
    {
      "text": "Carl Armon, Dan Glisson, and Larry Goldberg. 1992. How Closed Captioning in the U.S. Today can Become the Advanced Television Captioning System of Tomorrow. SMPTE Journal 101, 7 (1992), 495\u2013498. https://doi.org/10.5594/J02244",
      "doi": ""
    },
    {
      "text": "Salvatore Attardo, Manuela\u00a0Maria Wagner, and Eduardo Urios-Aparisi. 2011. Prosody and humor. Pragmatics & Cognition 19, 2 (2011), 189\u2013201.",
      "doi": ""
    },
    {
      "text": "Pl\u00ednio\u00a0A. Barbosa. 2019. Pros\u00f3dia. Par\u00e1bola Editorial, Brazil.",
      "doi": ""
    },
    {
      "text": "Lyn Bartram, Abhisekh Patra, and Maureen Stone. 2017. Affective Color in Visualization. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 1364\u20131374. https://doi.org/10.1145/3025453.3026041",
      "doi": "10.1145/3025453.3026041"
    },
    {
      "text": "Sofie Beier, Sam Berlow, Esat Boucaud, Zoya Bylinskii, Tianyuan Cai, Jenae Cohn, Kathy Crowley, Stephanie\u00a0L. Day, Tilman Dingler, Jonathan Dobres, Jennifer Healey, Rajiv Jain, Marjorie Jordan, Bernard Kerr, Qisheng Li, Dave\u00a0B. Miller, Susanne Nobles, Alexandra Papoutsaki, Jing Qian, Tina Rezvanian, Shelley Rodrigo, Ben\u00a0D. Sawyer, Shannon\u00a0M. Sheppard, Bram Stein, Rick Treitman, Jen Vanek, Shaun Wallace, and Benjamin Wolfe. 2021. Readability Research: An Interdisciplinary Approach. CoRR abs/2107.09615(2021), 85\u00a0pages. arXiv:2107.09615https://arxiv.org/abs/2107.09615",
      "doi": ""
    },
    {
      "text": "Larwan Berke, Khaled Albusays, Matthew Seita, and Matt Huenerfauth. 2019. Preferred Appearance of Captions Generated by Automatic Speech Recognition for Deaf and Hard-of-Hearing Viewers. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI EA \u201919). Association for Computing Machinery, New York, NY, USA, 1\u20136. https://doi.org/10.1145/3290607.3312921",
      "doi": "10.1145/3290607.3312921"
    },
    {
      "text": "Larwan Berke, Christopher Caulfield, and Matt Huenerfauth. 2017. Deaf and Hard-of-Hearing Perspectives on Imperfect Automatic Speech Recognition for Captioning One-on-One Meetings. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (Baltimore, Maryland, USA) (ASSETS \u201917). Association for Computing Machinery, New York, NY, USA, 155\u2013164. https://doi.org/10.1145/3132525.3132541",
      "doi": "10.1145/3132525.3132541"
    },
    {
      "text": "Ann Bessemans, Maarten Renckens, Kevin Bormans, Erik Nuyts, and Kevin Larson. 2019. Visual prosody supports reading aloud expressively. Visible Language 53, 3 (2019), 28\u201349.",
      "doi": ""
    },
    {
      "text": "Natesh\u00a0M Bhat. 2021. Text-to-speech x-platform\u00b6. https://pyttsx3.readthedocs.io/en/latest/",
      "doi": ""
    },
    {
      "text": "Kirsten Boehner, Rog\u00e9rio DePaula, Paul Dourish, and Phoebe Sengers. 2005. Affect: From Information to Interaction. In Proceedings of the 4th Decennial Conference on Critical Computing: Between Sense and Sensibility (Aarhus, Denmark) (CC \u201905). Association for Computing Machinery, New York, NY, USA, 59\u201368. https://doi.org/10.1145/1094562.1094570",
      "doi": "10.1145/1094562.1094570"
    },
    {
      "text": "Paul Boersma. 2006. Praat: doing phonetics by computer. http://www.praat.org/. Accessed on August 24, 2022.",
      "doi": ""
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative research in psychology 3, 2 (2006), 77\u2013101.",
      "doi": ""
    },
    {
      "text": "Michele\u00a0A. Buchanan. 2015. @ Face Value // Expanding Our Typographic Repertoire. Communication Design 3, 1 (Jan. 2015), 27\u201350. https://doi.org/10.1080/20557132.2015.1057373",
      "doi": ""
    },
    {
      "text": "Doris\u00a0C Caldwell. 1981. Closed-Captioned Television for Hearing-Impaired Viewers. Media Information Australia 19, 1 (Feb. 1981), 56\u201360. https://doi.org/10.1177/1329878X8101900113",
      "doi": ""
    },
    {
      "text": "Jo\u00e3o Couceiro\u00a0e Castro, Pedro Martins, Ana Boavida, and Penousal Machado. 2019. \u00abM\u00e1quina de Ouver\u00bb - From Sound to Type: Finding the Visual Representation of Speech by Mapping Sound Features to Typographic Variables. In Proceedings of the 9th International Conference on Digital and Interactive Arts (Braga, Portugal) (ARTECH 2019). Association for Computing Machinery, New York, NY, USA, Article 13, 8\u00a0pages. https://doi.org/10.1145/3359852.3359892",
      "doi": "10.1145/3359852.3359892"
    },
    {
      "text": "Anna\u00a0C. Cavender, Jeffrey\u00a0P. Bigham, and Richard\u00a0E. Ladner. 2009. ClassInFocus: Enabling Improved Visual Attention Strategies for Deaf and Hard of Hearing Students. In Proceedings of the 11th International ACM SIGACCESS Conference on Computers and Accessibility (Pittsburgh, Pennsylvania, USA) (Assets \u201909). Association for Computing Machinery, New York, NY, USA, 67\u201374. https://doi.org/10.1145/1639642.1639656",
      "doi": "10.1145/1639642.1639656"
    },
    {
      "text": "Qinyue Chen, Yuchun Yan, and Hyeon-Jeong Suk. 2021. Bubble Coloring to Visualize the Speech Emotion. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI EA \u201921). Association for Computing Machinery, New York, NY, USA, Article 361, 6\u00a0pages. https://doi.org/10.1145/3411763.3451698",
      "doi": "10.1145/3411763.3451698"
    },
    {
      "text": "Qinyue Chen, Yuchun Yan, and Hyeon-Jeong Suk. 2022. Designing voice-aware text in voice media with background color and typography. Journal of the International Colour Association 28 (2022), 56\u201362.",
      "doi": ""
    },
    {
      "text": "Wellington da Silva, Plinio\u00a0Almeida Barbosa, and \u00c5sa Abelin. 2016. Cross-Cultural and Cross-Linguistic Perception of Authentic Emotions through Speech: An Acoustic-Phonetic Study with Brazilian and Swedish Listeners. DELTA: Documenta\u00e7\u00e3o de Estudos em Ling\u00fc\u00edstica Te\u00f3rica e Aplicada 32, 2 (Aug. 2016), 449\u2013480. https://doi.org/10.1590/0102-445003263701432483",
      "doi": ""
    },
    {
      "text": "Calu\u00e3 de Lacerda\u00a0Pataca and Paula Dornhofer\u00a0Paro Costa. 2020. Speech Modulated Typography: Towards an Affective Representation Model. In Proceedings of the 25th International Conference on Intelligent User Interfaces (Cagliari, Italy) (IUI \u201920). Association for Computing Machinery, New York, NY, USA, 139\u2013143. https://doi.org/10.1145/3377325.3377526",
      "doi": "10.1145/3377325.3377526"
    },
    {
      "text": "Jo\u00e3o\u00a0Ant\u00f4nio de Moraes and Albert Rilliard. 2016. Prosody and Emotion in Brazilian Portuguese. In Issues in Hispanic and Lusophone Linguistics, Meghan\u00a0E. Armstrong, Nicholas Henriksen, and Maria del Mar Vanrell (Eds.). Vol.\u00a06. John Benjamins Publishing Company, Amsterdam, 135\u2013152. https://doi.org/10.1075/ihll.6.07mor",
      "doi": ""
    },
    {
      "text": "Jorge dos Reis and Valerie Hazan. 2012. Speechant: a vowel notation system to teach English pronunciation. ELT journal 66, 2 (2012), 156\u2013165.",
      "doi": ""
    },
    {
      "text": "Lisa Elliot, Michael Stinson, James Mallory, Donna Easton, and Matt Huenerfauth. 2016. Deaf and Hard of Hearing Individuals\u2019 Perceptions of Communication with Hearing Colleagues in Small Groups. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (Reno, Nevada, USA) (ASSETS \u201916). Association for Computing Machinery, New York, NY, USA, 271\u2013272. https://doi.org/10.1145/2982142.2982198",
      "doi": "10.1145/2982142.2982198"
    },
    {
      "text": "Siyuan Feng, Olya Kudina, Bence\u00a0Mark Halpern, and Odette Scharenborg. 2021. Quantifying Bias in Automatic Speech Recognition. https://doi.org/10.48550/ARXIV.2103.15122",
      "doi": ""
    },
    {
      "text": "Jodi Forlizzi, Johnny Lee, and Scott Hudson. 2003. The Kinedit System: Affective Messages Using Dynamic Texts. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Ft. Lauderdale, Florida, USA) (CHI \u201903). Association for Computing Machinery, New York, NY, USA, 377\u2013384. https://doi.org/10.1145/642611.642677",
      "doi": "10.1145/642611.642677"
    },
    {
      "text": "William\u00a0W. Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a Resource for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Ft. Lauderdale, Florida, USA) (CHI \u201903). Association for Computing Machinery, New York, NY, USA, 233\u2013240. https://doi.org/10.1145/642611.642653",
      "doi": "10.1145/642611.642653"
    },
    {
      "text": "Morton\u00a0Ann Gernsbacher. 2015. Video Captions Benefit Everyone. Policy Insights from the Behavioral and Brain Sciences 2, 1 (Oct. 2015), 195\u2013202. https://doi.org/10.1177/2372732215602130",
      "doi": ""
    },
    {
      "text": "Sandrine Gil and Ludovic Le\u00a0Bigot. 2016. Colour and emotion: children also associate red with negative valence. Developmental science 19, 6 (2016), 1087\u20131094.",
      "doi": ""
    },
    {
      "text": "Awni Hannun. 2021. The History of Speech Recognition to the Year 2030. https://doi.org/10.48550/ARXIV.2108.00084",
      "doi": ""
    },
    {
      "text": "Kristina H\u00f6\u00f6k, Anna St\u00e5hl, Petra Sundstr\u00f6m, and Jarmo Laaksolaahti. 2008. Interactional Empowerment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Florence, Italy) (CHI \u201908). Association for Computing Machinery, New York, NY, USA, 647\u2013656. https://doi.org/10.1145/1357054.1357157",
      "doi": "10.1145/1357054.1357157"
    },
    {
      "text": "Jiaxiong Hu, Qianyao Xu, Limin\u00a0Paul Fu, and Yingqing Xu. 2019. Emojilization: An Automated Method For Speech to Emoji-Labeled Text. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI EA \u201919). Association for Computing Machinery, New York, NY, USA, 1\u20136. https://doi.org/10.1145/3290607.3313071",
      "doi": "10.1145/3290607.3313071"
    },
    {
      "text": "Gary Hustwit. 2015. Helvetica/Objectified/Urbanized: The Complete Interviews: The Design Trilogy Interviews. Versions Publishing, London, UK.",
      "doi": ""
    },
    {
      "text": "Carl\u00a0J Jensema, Ramalinga\u00a0Sarma Danturthi, and Robert Burch. 2000. Time spent viewing captions on television programs. American annals of the deaf 145, 5 (2000), 464\u2013468.",
      "doi": ""
    },
    {
      "text": "Sushant Kafle and Matt Huenerfauth. 2019. Predicting the Understandability of Imperfect English Captions for People Who Are Deaf or Hard of Hearing. ACM Trans. Access. Comput. 12, 2, Article 7 (jun 2019), 32\u00a0pages. https://doi.org/10.1145/3325862",
      "doi": "10.1145/3325862"
    },
    {
      "text": "Yeon\u00a0Soo Kim, Sunok Lee, and Sangsu Lee. 2022. A Participatory Design Approach to Explore Design Directions for Enhancing Videoconferencing Experience for Non-Signing Deaf and Hard of Hearing Users. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility(Athens, Greece) (ASSETS \u201922). Association for Computing Machinery, New York, NY, USA, Article 47, 4\u00a0pages. https://doi.org/10.1145/3517428.3550375",
      "doi": "10.1145/3517428.3550375"
    },
    {
      "text": "Maria Kraxenberger, Winfried Menninghaus, Anna Roth, and Mathias Scharinger. 2018. Prosody-based sound-emotion associations in poetry. Frontiers in Psychology 9 (2018), 1284.",
      "doi": ""
    },
    {
      "text": "Jan-Louis Kruger, Mar\u00eda\u00a0T. Soto-Sanfiel, Stephen Doherty, and Ronny Ibrahim. 2016. Towards a cognitive audiovisual translatology. In Reembedding Translation Process Research. John Benjamins Publishing Company, Amsterdam, 171\u2013194. https://doi.org/10.1075/btl.128.09kru",
      "doi": ""
    },
    {
      "text": "Christof Kuhbandner and Reinhard Pekrun. 2013. Joint effects of emotion and color on memory.Emotion 13, 3 (2013), 375.",
      "doi": ""
    },
    {
      "text": "Raja\u00a0S. Kushalnagar and Christian Vogler. 2020. Teleconference Accessibility and Guidelines for Deaf and Hard of Hearing Users. In The 22nd International ACM SIGACCESS Conference on Computers and Accessibility(Virtual Event, Greece) (ASSETS \u201920). Association for Computing Machinery, New York, NY, USA, Article 9, 6\u00a0pages. https://doi.org/10.1145/3373625.3417299",
      "doi": "10.1145/3373625.3417299"
    },
    {
      "text": "Walter\u00a0S. Lasecki, Raja Kushalnagar, and Jeffrey\u00a0P. Bigham. 2014. Helping Students Keep up with Real-Time Captions by Pausing and Highlighting. In Proceedings of the 11th Web for All Conference (Seoul, Korea) (W4A \u201914). Association for Computing Machinery, New York, NY, USA, Article 39, 8\u00a0pages. https://doi.org/10.1145/2596695.2596701",
      "doi": "10.1145/2596695.2596701"
    },
    {
      "text": "Daniel\u00a0G Lee, Deborah\u00a0I Fels, and John\u00a0Patrick Udo. 2007. Emotive captioning. Computers in Entertainment (CIE) 5, 2 (2007), 11.",
      "doi": "10.1145/1236224.1236242"
    },
    {
      "text": "Einat Liebenthal, David\u00a0A Silbersweig, and Emily Stern. 2016. The language, tone and prosody of emotions: neural substrates and dynamics of spoken-word emotion perception. Frontiers in neuroscience 10 (2016), 506.",
      "doi": ""
    },
    {
      "text": "Jason Livingston. 2012. Closed Captioning Challenges for IP Video Delivery. In The 2012 Annual Technical Conference & Exhibition. SMPTE, Hollywood, CA, USA, 1\u20139.",
      "doi": ""
    },
    {
      "text": "Fernando Loizides, Sara Basson, Dimitri Kanevsky, Olga Prilepova, Sagar Savla, and Susanna Zaraysky. 2020. Breaking Boundaries with Live Transcribe: Expanding Use Cases Beyond Standard Captioning Scenarios. In The 22nd International ACM SIGACCESS Conference on Computers and Accessibility. ACM, Virtual Event Greece, 1\u20136. https://doi.org/10.1145/3373625.3417300",
      "doi": "10.1145/3373625.3417300"
    },
    {
      "text": "Catarina Ma\u00e7\u00e3s, David Palma, and Artur Rebelo. 2019. TypEm: A Generative Typeface That Represents the Emotion of the Text. In Proceedings of the 9th International Conference on Digital and Interactive Arts (Braga, Portugal) (ARTECH 2019). Association for Computing Machinery, New York, NY, USA, Article 5, 10\u00a0pages. https://doi.org/10.1145/3359852.3359874",
      "doi": "10.1145/3359852.3359874"
    },
    {
      "text": "Tim Mahrt. 2022. PraatIO. https://github.com/timmahrt/praatIO. Accessed on August 3, 2022.",
      "doi": ""
    },
    {
      "text": "Sabrina Malik, Jonathan Aitken, and Judith\u00a0Kelly Waalen. 2009. Communicating emotion with animated text. visual communication 8, 4 (2009), 469\u2013479.",
      "doi": ""
    },
    {
      "text": "James\u00a0R. Mallory, Michael Stinson, Lisa Elliot, and Donna Easton. 2017. Personal Perspectives on Using Automatic Speech Recognition to Facilitate Communication between Deaf Students and Hearing Customers. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, Baltimore Maryland USA, 419\u2013421. https://doi.org/10.1145/3132525.3134779",
      "doi": "10.1145/3132525.3134779"
    },
    {
      "text": "Emma\u00a0J. McDonnell, Ping Liu, Steven\u00a0M. Goodman, Raja Kushalnagar, Jon\u00a0E. Froehlich, and Leah Findlater. 2021. Social, Environmental, and Technical: Factors at Play in the Current Use and Future Design of Small-Group Captioning. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2 (Oct. 2021), 1\u201325. https://doi.org/10.1145/3479578",
      "doi": "10.1145/3479578"
    },
    {
      "text": "Alexsandro\u00a0R Meireles, Jo\u00e3o\u00a0Paulo Tozetti, and Rog\u00e9rio\u00a0R Borges. 2010. Speech rate and rhythmic variation in Brazilian Portuguese. In Speech Prosody 2010-Fifth International Conference. International Speech Communication Association (ISCA), Chicago, USA, 1\u20134.",
      "doi": ""
    },
    {
      "text": "Chris Mikul. 2014. Caption quality: Approaches to standards and measurement. Media Access Australia, Sydney, Australia.",
      "doi": ""
    },
    {
      "text": "Virginia Murphy-Berman and Linda Whobrey. 1983. The Impact of Captions On Hearing-Impaired Children\u2019s Affective Reactions To Television. The Journal of Special Education 17, 1 (April 1983), 47\u201362. https://doi.org/10.1177/002246698301700107",
      "doi": ""
    },
    {
      "text": "National Eye Institute 2019. Types of color blindness. National Eye Institute. https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/color-blindness/types-color-blindnessAccessed on August 3, 2022.",
      "doi": ""
    },
    {
      "text": "Marina Nespor, Mohinish Shukla, and Jacques Mehler. 2011. Stress-Timed vs. Syllable-Timed Languages. John Wiley & Sons, Ltd, Oxford, UK, Chapter\u00a048, 1\u201313. https://doi.org/10.1002/9781444335262.wbctp0048 arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781444335262.wbctp0048",
      "doi": ""
    },
    {
      "text": "Robert\u00a0M Ochshorn and Max Hawkins. 2015. Gentle: a robust yet lenient forced aligner built on Kaldi.https://lowerquality.com/gentle/",
      "doi": ""
    },
    {
      "text": "Desmond Ong, Zhengxuan Wu, Zhi-Xuan Tan, Marianne Reddan, Isabella Kahhale, Alison Mattek, and Jamil Zaki. 2019. Modeling emotion in complex stories: the Stanford Emotional Narratives Dataset. IEEE Transactions on Affective Computing 12 (2019), 579\u2013594.",
      "doi": ""
    },
    {
      "text": "Calua de\u00a0Lacerda Pataca and Paula Dornhofer\u00a0Paro Costa. 2022. Hidden bawls, whispers, and yelps: can text convey the sound of speech, beyond words. IEEE Transactions on Affective Computing pre-print (2022), 1\u20131. https://doi.org/10.1109/TAFFC.2022.3174721",
      "doi": "10.1109/TAFFC.2022.3174721"
    },
    {
      "text": "Suksumek Promphan. 2017. Emotional Type: Emotional expression in text message. Master\u2019s thesis. Basel School of Design, Switzerland.",
      "doi": ""
    },
    {
      "text": "Dhevi\u00a0J Rajendran, Andrew\u00a0T Duchowski, Pilar Orero, Juan Mart\u00ednez, and Pablo Romero-Fresco. 2013. Effects of text chunking on subtitling: A quantitative and qualitative examination. Perspectives 21, 1 (2013), 5\u201321.",
      "doi": ""
    },
    {
      "text": "Raisa Rashid, Jonathan Aitken, and Deborah\u00a0I Fels. 2006. Expressing emotions using animated text captions. In International Conference on Computers for Handicapped Persons. Springer, Linz, Austria, 24\u201331.",
      "doi": "10.1007/11788713_5"
    },
    {
      "text": "Raisa Rashid, Quoc Vy, Richard Hunt, and Deborah\u00a0I Fels. 2008. Dancing with words: Using animated text for captioning. Intl. Journal of Human\u2013Computer Interaction 24, 5(2008), 505\u2013519.",
      "doi": ""
    },
    {
      "text": "Nancy\u00a0A Remington, Leandre\u00a0R Fabrigar, and Penny\u00a0S Visser. 2000. Reexamining the circumplex model of affect.Journal of personality and social psychology 79, 2(2000), 286.",
      "doi": ""
    },
    {
      "text": "Tara Rosenberger and Ronald\u00a0L. MacNeil. 1999. Prosodic Font: Translating Speech into Graphics. In CHI \u201999 Extended Abstracts on Human Factors in Computing Systems (Pittsburgh, Pennsylvania) (CHI EA \u201999). Association for Computing Machinery, New York, NY, USA, 252\u2013253. https://doi.org/10.1145/632716.632872",
      "doi": "10.1145/632716.632872"
    },
    {
      "text": "Jazz Rui Xia\u00a0Ang, Ping Liu, Emma McDonnell, and Sarah Coppola. 2022. \u201cIn This Online Environment, We\u2019re Limited\u201d: Exploring Inclusive Video Conferencing Design for Signers. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI \u201922). Association for Computing Machinery, New York, NY, USA, Article 609, 16\u00a0pages. https://doi.org/10.1145/3491102.3517488",
      "doi": "10.1145/3491102.3517488"
    },
    {
      "text": "James\u00a0A Russell. 1980. A circumplex model of affect.Journal of personality and social psychology 39, 6(1980), 1161.",
      "doi": ""
    },
    {
      "text": "V\u00edt Rus\u00f1\u00e1k, Pavel Troubil, Desana Daxnerov\u00e1, Pavel Kajaba, Matej Min\u00e1rik, Svatoslav Ondra, Tom\u00e1s Sklen\u00e1k, and Eva Hladk\u00e1. 2016. CoUnSiL: A video conferencing environment for interpretation of sign language in higher education. In 2016 15th International Conference on Information Technology Based Higher Education and Training (ITHET). IEEE, Istanbul, Turkey, 1\u20138. https://doi.org/10.1109/ITHET.2016.7760711",
      "doi": ""
    },
    {
      "text": "Tim Schlippe, Shaimaa Alessai, Ghanimeh El-Taweel, Matthias W\u00f6lfel, and Wajdi Zaghouani. 2020. Visualizing voice characteristics with type design in closed captions for arabic. In 2020 International Conference on Cyberworlds (CW). IEEE, IEEE, Caen, France, 196\u2013203.",
      "doi": ""
    },
    {
      "text": "Matthew Seita, Khaled Albusays, Sushant Kafle, Michael Stinson, and Matt Huenerfauth. 2018. Behavioral Changes in Speakers Who Are Automatically Captioned in Meetings with Deaf or Hard-of-Hearing Peers. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility (Galway, Ireland) (ASSETS \u201918). Association for Computing Machinery, New York, NY, USA, 68\u201380. https://doi.org/10.1145/3234695.3236355",
      "doi": "10.1145/3234695.3236355"
    },
    {
      "text": "Matthew Seita and Matt Huenerfauth. 2020. Deaf Individuals\u2019 Views on Speaking Behaviors of Hearing Peers When Using an Automatic Captioning App. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI EA \u201920). Association for Computing Machinery, New York, NY, USA, 1\u20138. https://doi.org/10.1145/3334480.3383083",
      "doi": "10.1145/3334480.3383083"
    },
    {
      "text": "Hyeon-Jeong Suk and Hans Irtel. 2010. Emotional response to color across media. Color Research & Application: Endorsed by Inter-Society Color Council, The Colour Group (Great Britain), Canadian Society for Color, Color Science Association of Japan, Dutch Society for the Study of Color, The Swedish Colour Centre Foundation, Colour Society of Australia, Centre Fran\u00e7ais de la Couleur 35, 1 (2010), 64\u201377.",
      "doi": ""
    },
    {
      "text": "[74] Andreas Triantafyllopoulos.2022. Personal communication.",
      "doi": ""
    },
    {
      "text": "Andreas Triantafyllopoulos, Johannes Wagner, Hagen Wierstorf, Maximilian Schmitt, Uwe Reichel, Florian Eyben, Felix Burkhardt, and Bj\u00f6rn\u00a0W. Schuller. 2022. Probing Speech Emotion Recognition Transformers for Linguistic Knowledge. https://doi.org/10.48550/ARXIV.2204.00400",
      "doi": ""
    },
    {
      "text": "M\u00e1t\u00e9\u00a0\u00c1kos T\u00fcndik, Gy\u00f6rgy Szasz\u00e1k, G\u00e1bor Gosztolya, and Andr\u00e1s Beke. 2018. User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning. In Proceedings of Interspeech 2018. ISCA, Hyderabad, India, 2628\u20132632. https://doi.org/10.21437/Interspeech.2018-1352",
      "doi": ""
    },
    {
      "text": "Walda Verbaenen. 2019. Phonotype. The visual identity of a language according to its phonology. Master\u2019s thesis. pxl-mad.",
      "doi": ""
    },
    {
      "text": "Christian Vogler, Paula Tucker, and Norman Williams. 2013. Mixed Local and Remote Participation in Teleconferences from a Deaf and Hard of Hearing Perspective. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility (Bellevue, Washington) (ASSETS \u201913). Association for Computing Machinery, New York, NY, USA, Article 30, 5\u00a0pages. https://doi.org/10.1145/2513383.2517035",
      "doi": "10.1145/2513383.2517035"
    },
    {
      "text": "Celina\u00a0Isabelle von Eiff, Sascha Fr\u00fchholz, Daniela Korth, Orlando Guntinas-Lichius, and Stefan\u00a0Robert Schweinberger. 2022. Crossmodal Benefits to Vocal Emotion Perception in Cochlear Implant Users. iScience 25, 12 (2022), 105711.",
      "doi": ""
    },
    {
      "text": "Johannes Wagner, Andreas Triantafyllopoulos, Hagen Wierstorf, Maximilian Schmitt, Felix Burkhardt, Florian Eyben, and Bj\u00f6rn\u00a0W. Schuller. 2022. Dawn of the transformer era in speech emotion recognition: closing the valence gap. https://doi.org/10.48550/ARXIV.2203.07378",
      "doi": ""
    },
    {
      "text": "Matthew Wickline. 2001. Coblis \u2013 Color blindness simulator. https://www.color-blindness.com/coblis-color-blindness-simulator/",
      "doi": ""
    },
    {
      "text": "Deirdre Wilson and Tim Wharton. 2006. Relevance and Prosody. Journal of Pragmatics 38, 10 (Oct. 2006), 1559\u20131579. https://doi.org/10.1016/j.pragma.2005.04.012",
      "doi": ""
    },
    {
      "text": "Matthias W\u00f6lfel, Tim Schlippe, and Angelo Stitz. 2015. Voice driven type design. In 2015 international conference on speech technology and human-computer dialogue (SpeD). IEEE, IEEE, Bucharest, Romania, 1\u20139.",
      "doi": ""
    }
  ]
}