{
  "doi": "10.1145/3544548.3580969",
  "title": "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-17",
  "year": 2023,
  "badges": [],
  "abstract": "We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. \u201cOnce upon a time, I saw a fox...\u201d), and (2) non-diegetic prompts (external, e.g. \u201cWrite about the adventures of the fox.\u201d). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.",
  "tags": [
    "Large language models",
    "Co-creative systems",
    "Human-AI collaboration",
    "User-centric natural language generation"
  ],
  "authors": [
    {
      "name": "Hai Dang",
      "institution": "Department of Computer Science, University of Bayreuth, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659702585",
      "orcid": "0000-0003-3617-5657"
    },
    {
      "name": "Sven Goller",
      "institution": "Department of Computer Science, University of Bayreuth, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660781792",
      "orcid": "0000-0001-5263-5372"
    },
    {
      "name": "Florian Lehmann",
      "institution": "Department of Computer Science, University of Bayreuth, Germany",
      "img": "/do/10.1145/contrib-99659528675/rel-imgonly/me.png",
      "acmid": "99659528675",
      "orcid": "0000-0003-0201-867X"
    },
    {
      "name": "Daniel Buschek",
      "institution": "Department of Computer Science, University of Bayreuth, Germany",
      "img": "/do/10.1145/contrib-82659024557/rel-imgonly/daniel_buschek_2019_s.jpg",
      "acmid": "82659024557",
      "orcid": "0000-0002-0013-715X"
    }
  ],
  "references": [
    {
      "text": "Kenneth\u00a0C. Arnold, Krysta Chauncey, and Krzysztof\u00a0Z. Gajos. 2018. Sentiment Bias in Predictive Text Recommendations Results in Biased Writing. In Proceedings of the 44th Graphics Interface Conference (Toronto, Canada) (GI \u201918). Canadian Human-Computer Communications Society, Waterloo, CAN, 42\u201349. https://doi.org/10.20380/GI2018.07",
      "doi": "10.20380/GI2018.07"
    },
    {
      "text": "Douglas Bates, Martin M\u00e4chler, Ben Bolker, and Steve Walker. 2015. Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software 67, 1 (2015), 1\u201348. https://doi.org/10.18637/jss.v067.i01",
      "doi": ""
    },
    {
      "text": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua\u00a0B. Tenenbaum, William\u00a0T. Freeman, and Antonio Torralba. 2018. GAN Dissection: Visualizing and Understanding Generative Adversarial Networks. Technical Report arXiv:1811.10597. arXiv. https://doi.org/10.48550/arXiv.1811.10597 arXiv:1811.10597 [cs] type: article.",
      "doi": ""
    },
    {
      "text": "Advait Bhat, Saaket Agashe, Niharika Mohile, Parth Oberoi, Ravi Jangir, and Anirudha Joshi. 2022. Studying writer-suggestion interaction: A qualitative study to understand writer interaction with aligned/misaligned next-phrase suggestion. https://doi.org/10.48550/ARXIV.2208.00636",
      "doi": ""
    },
    {
      "text": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared\u00a0D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems, H.\u00a0Larochelle, M.\u00a0Ranzato, R.\u00a0Hadsell, M.\u00a0F. Balcan, and H.\u00a0Lin (Eds.). Vol.\u00a033. Curran Associates, Inc., 1877\u20131901. https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf",
      "doi": ""
    },
    {
      "text": "Daniel Buschek, Martin Z\u00fcrn, and Malin Eiband. 2021. The Impact of Multiple Parallel Phrase Suggestions on Email Input and Composition Behaviour of Native and Non-Native English Writers. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 732, 13\u00a0pages. https://doi.org/10.1145/3411764.3445372",
      "doi": "10.1145/3411764.3445372"
    },
    {
      "text": "Alex Calderwood, Vivian Qiu, Katy\u00a0Ilonka Gero, and Lydia\u00a0B. Chilton. 2020. How Novelists Use Generative Language Models: An Exploratory User Study.. In HAI-GEN+ user2agent@ IUI.",
      "doi": ""
    },
    {
      "text": "Mia\u00a0Xu Chen, Benjamin\u00a0N. Lee, Gagan Bansal, Yuan Cao, Shuyuan Zhang, Justin Lu, Jackie Tsay, Yinan Wang, Andrew\u00a0M. Dai, Zhifeng Chen, Timothy Sohn, and Yonghui Wu. 2019. Gmail Smart Compose: Real-Time Assisted Writing. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Anchorage, AK, USA) (KDD \u201919). Association for Computing Machinery, New York, NY, USA, 2287\u20132295. https://doi.org/10.1145/3292500.3330723",
      "doi": "10.1145/3292500.3330723"
    },
    {
      "text": "John Joon\u00a0Young Chung, Wooseok Kim, Kang\u00a0Min Yoo, Hwaran Lee, Eytan Adar, and Minsuk Chang. 2022. TaleBrush: Sketching Stories with Generative Pretrained Language Models. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems(CHI \u201922). Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3491102.3501819 event-place: New Orleans, LA, USA.",
      "doi": "10.1145/3491102.3501819"
    },
    {
      "text": "Juliet\u00a0M Corbin. 1990. Basics of qualitative research: Grounded theory procedures and techniques. Sage.",
      "doi": ""
    },
    {
      "text": "Mark Dunlop and John Levine. 2012. Multidimensional Pareto Optimization of Touchscreen Keyboards for Speed, Familiarity and Improved Spell Checking. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Austin, Texas, USA) (CHI \u201912). Association for Computing Machinery, New York, NY, USA, 2669\u20132678. https://doi.org/10.1145/2207676.2208659",
      "doi": "10.1145/2207676.2208659"
    },
    {
      "text": "Andrew Fowler, Kurt Partridge, Ciprian Chelba, Xiaojun Bi, Tom Ouyang, and Shumin Zhai. 2015. Effects of Language Modeling and Its Personalization on Touchscreen Typing Performance. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (Seoul, Republic of Korea) (CHI \u201915). Association for Computing Machinery, New York, NY, USA, 649\u2013658. https://doi.org/10.1145/2702123.2702503",
      "doi": "10.1145/2702123.2702503"
    },
    {
      "text": "Katy Gero, Alex Calderwood, Charlotte Li, and Lydia Chilton. 2022. A Design Space for Writing Support Tools Using a Cognitive Process Model of Writing. In Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing 2022). Association for Computational Linguistics, Dublin, Ireland, 11\u201324. https://aclanthology.org/2022.in2writing-1.2",
      "doi": ""
    },
    {
      "text": "Katy\u00a0Ilonka Gero, Vivian Liu, and Lydia Chilton. 2022. Sparks: Inspiration for Science Writing Using Language Models. In Designing Interactive Systems Conference (Virtual Event, Australia) (DIS \u201922). Association for Computing Machinery, New York, NY, USA, 1002\u20131019. https://doi.org/10.1145/3532106.3533533",
      "doi": "10.1145/3532106.3533533"
    },
    {
      "text": "Mayank Goel, Leah Findlater, and Jacob Wobbrock. 2012. WalkType: Using Accelerometer Data to Accomodate Situational Impairments in Mobile Touch Screen Text Entry. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Austin, Texas, USA) (CHI \u201912). Association for Computing Machinery, New York, NY, USA, 2687\u20132696. https://doi.org/10.1145/2207676.2208662",
      "doi": "10.1145/2207676.2208662"
    },
    {
      "text": "Mayank Goel, Alex Jansen, Travis Mandel, Shwetak\u00a0N. Patel, and Jacob\u00a0O. Wobbrock. 2013. ContextType: Using Hand Posture Information to Improve Mobile Touch Screen Text Entry. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Paris, France) (CHI \u201913). Association for Computing Machinery, New York, NY, USA, 2795\u20132798. https://doi.org/10.1145/2470654.2481386",
      "doi": "10.1145/2470654.2481386"
    },
    {
      "text": "Steven Goodman, Erin Buehler, Patrick Clary, Andy Coenen, Aaron\u00a0Michael Donsbach, Tiffanie Horne, Michal Lahav, Bob MacDonald, Rain\u00a0Breaw Michaels, Ajit Narayanan, Mahima Pushkarna, Joel\u00a0Christopher Riley, Alex Santana, Lei Shi, Rachel Sweeney, Phil Weaver, Ann Yuan, and Meredith\u00a0Ringel Morris. 2022. LaMPost: Evaluation of an AI-assisted Writing Email Editor Prototype for Adults with Dyslexia. https://arxiv.org/abs/2207.02308",
      "doi": ""
    },
    {
      "text": "Mitchell Gordon, Tom Ouyang, and Shumin Zhai. 2016. WatchWriter: Tap and Gesture Typing on a Smartwatch Miniature Keyboard with Statistical Decoding. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (San Jose, California, USA) (CHI \u201916). Association for Computing Machinery, New York, NY, USA, 3817\u20133821. https://doi.org/10.1145/2858036.2858242",
      "doi": "10.1145/2858036.2858242"
    },
    {
      "text": "David Ha and Douglas Eck. 2017. A Neural Representation of Sketch Drawings. http://arxiv.org/abs/1704.03477 arXiv:1704.03477 [cs, stat].",
      "doi": ""
    },
    {
      "text": "Adi Haviv, Jonathan Berant, and Amir Globerson. 2021. BERTese: Learning to Speak to BERT. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. Association for Computational Linguistics, Online, 3618\u20133623. https://doi.org/10.18653/v1/2021.eacl-main.316",
      "doi": ""
    },
    {
      "text": "John\u00a0R. Hayes. 2012. Modeling and Remodeling Writing. Written Communication 29, 3 (July 2012), 369\u2013388. https://doi.org/10.1177/0741088312451260",
      "doi": ""
    },
    {
      "text": "Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\u00a0J. Cai. 2022. PromptMaker: Prompt-based Prototyping with Large Language Models. In CHI Conference on Human Factors in Computing Systems Extended Abstracts. 1\u20138.",
      "doi": ""
    },
    {
      "text": "Zhengbao Jiang, Frank\u00a0F. Xu, Jun Araki, and Graham Neubig. 2020. How Can We Know What Language Models Know?Transactions of the Association for Computational Linguistics 8 (Dec. 2020), 423\u2013438. https://doi.org/10.1162/tacl_a_00324",
      "doi": ""
    },
    {
      "text": "Anjuli Kannan, Karol Kurach, Sujith Ravi, Tobias Kaufmann, Andrew Tomkins, Balint Miklos, Greg Corrado, Laszlo Lukacs, Marina Ganea, Peter Young, and Vivek Ramavajjala. 2016. Smart Reply: Automated Response Suggestion for Email. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (San Francisco, California, USA) (KDD \u201916). Association for Computing Machinery, New York, NY, USA, 955\u2013964. https://doi.org/10.1145/2939672.2939801",
      "doi": "10.1145/2939672.2939801"
    },
    {
      "text": "Alexandra Kuznetsova, Per\u00a0B. Brockhoff, and Rune H.\u00a0B. Christensen. 2017. lmerTest Package: Tests in Linear Mixed Effects Models. Journal of Statistical Software 82, 13 (2017), 1\u201326. https://doi.org/10.18637/jss.v082.i13",
      "doi": ""
    },
    {
      "text": "Mina Lee, Percy Liang, and Qian Yang. 2022. CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI \u201922). Association for Computing Machinery, New York, NY, USA, Article 388, 19\u00a0pages. https://doi.org/10.1145/3491102.3502030",
      "doi": "10.1145/3491102.3502030"
    },
    {
      "text": "Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-$3$?http://arxiv.org/abs/2101.06804 arXiv:2101.06804 [cs].",
      "doi": ""
    },
    {
      "text": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. arXiv:2107.13586 [cs] (July 2021). http://arxiv.org/abs/2107.13586 arXiv:2107.13586.",
      "doi": ""
    },
    {
      "text": "Michael\u00a0J. Muller and Sandra Kogan. 2012. Grounded Theory Method in Human-Computer Interaction and Computer-Supported Cooperative Work. In The Human\u2013Computer Interaction Handbook (3 ed.). CRC Press. Num Pages: 21.",
      "doi": ""
    },
    {
      "text": "Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. 2021. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. (2021). https://doi.org/10.48550/ARXIV.2112.10741 Publisher: arXiv Version Number: 3.",
      "doi": ""
    },
    {
      "text": "Jakob Nielsen. 1994. Enhancing the Explanatory Power of Usability Heuristics. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Boston, Massachusetts, USA) (CHI \u201994). Association for Computing Machinery, New York, NY, USA, 152\u2013158. https://doi.org/10.1145/191666.191729",
      "doi": "10.1145/191666.191729"
    },
    {
      "text": "Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski. 2021. StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery. (2021). https://doi.org/10.48550/ARXIV.2103.17249 Publisher: arXiv Version Number: 1.",
      "doi": ""
    },
    {
      "text": "Fabio Petroni, Tim Rockt\u00e4schel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander\u00a0H. Miller, and Sebastian Riedel. 2019. Language Models as Knowledge Bases?http://arxiv.org/abs/1909.01066 arXiv:1909.01066 [cs].",
      "doi": ""
    },
    {
      "text": "Philip Quinn and Shumin Zhai. 2016. A Cost-Benefit Study of Text Entry Suggestion Interaction. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (San Jose, California, USA) (CHI \u201916). Association for Computing Machinery, New York, NY, USA, 83\u201388. https://doi.org/10.1145/2858036.2858305",
      "doi": "10.1145/2858036.2858305"
    },
    {
      "text": "R Core Team. 2020. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org",
      "doi": ""
    },
    {
      "text": "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical Text-Conditional Image Generation with CLIP Latents. (2022). https://doi.org/10.48550/ARXIV.2204.06125 Publisher: arXiv Version Number: 1.",
      "doi": ""
    },
    {
      "text": "Melissa Roemmele and Andrew\u00a0S. Gordon. 2015. Creative Help: A Story Writing Assistant. In Interactive Storytelling(Lecture Notes in Computer Science), Henrik Schoenau-Fog, Luis\u00a0Emilio Bruni, Sandy Louchart, and Sarune Baceviciute (Eds.). Springer International Publishing, Cham, 81\u201392. https://doi.org/10.1007/978-3-319-27036-4_8",
      "doi": ""
    },
    {
      "text": "Timo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio Petroni, Patrick Lewis, Gautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, and Sebastian Riedel. 2022. PEER: A Collaborative Language Model. https://doi.org/10.48550/ARXIV.2208.11663",
      "doi": ""
    },
    {
      "text": "Timo Schick and Hinrich Sch\u00fctze. 2021. Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference. http://arxiv.org/abs/2001.07676 arXiv:2001.07676 [cs].",
      "doi": ""
    },
    {
      "text": "Herbert\u00a0Alexander Simon. 1996. The sciences of the artificial(3. ed. ed.). MIT Press, Cambridge, Mass.",
      "doi": ""
    },
    {
      "text": "Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena\u00a0L. Glassman. 2022. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Trans. Comput.-Hum. Interact. (jan 2022). https://doi.org/10.1145/3511599 Just Accepted.",
      "doi": "10.1145/3511599"
    },
    {
      "text": "Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, Johanna Beyer, Hanspeter Pfister, and Alexander\u00a0M. Rush. 2022. Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models. http://arxiv.org/abs/2208.07852 arXiv:2208.07852 [cs].",
      "doi": ""
    },
    {
      "text": "Ben Swanson, Kory Mathewson, Ben Pietrzak, Sherol Chen, and Monica Dinalescu. 2021. Story Centaur: Large Language Model Few Shot Learning as a Creative Writing Tool. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations. Association for Computational Linguistics, Online, 244\u2013256. https://doi.org/10.18653/v1/2021.eacl-demos.29",
      "doi": ""
    },
    {
      "text": "Anestis Touloumis. 2015. R Package multgee: A Generalized Estimating Equations Solver for Multinomial Responses. Journal of Statistical Software 64, 8 (2015), 1\u201314. http://www.jstatsoft.org/v64/i08/",
      "doi": ""
    },
    {
      "text": "Keith Vertanen and Per\u00a0Ola Kristensson. 2014. Complementing Text Entry Evaluations with a Composition Task. ACM Trans. Comput.-Hum. Interact. 21, 2, Article 8 (feb 2014), 33\u00a0pages. https://doi.org/10.1145/2555691",
      "doi": "10.1145/2555691"
    },
    {
      "text": "Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie\u00a0J. Cai. 2022. PromptChainer: Chaining Large Language Model Prompts through Visual Programming. http://arxiv.org/abs/2203.06566 Number: arXiv:2203.06566 arXiv:2203.06566 [cs].",
      "doi": ""
    },
    {
      "text": "Tongshuang Wu, Michael Terry, and Carrie\u00a0Jun Cai. 2022. AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI \u201922). Association for Computing Machinery, New York, NY, USA, Article 385, 22\u00a0pages. https://doi.org/10.1145/3491102.3517582",
      "doi": "10.1145/3491102.3517582"
    },
    {
      "text": "Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft: Story Writing With Large Language Models. In 27th International Conference on Intelligent User Interfaces (Helsinki, Finland) (IUI \u201922). Association for Computing Machinery, New York, NY, USA, 841\u2013852. https://doi.org/10.1145/3490099.3511105",
      "doi": "10.1145/3490099.3511105"
    },
    {
      "text": "Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021. BARTScore: Evaluating Generated Text as Text Generation. http://arxiv.org/abs/2106.11520 arXiv:2106.11520 [cs].",
      "doi": ""
    },
    {
      "text": "Tony\u00a0Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate Before Use: Improving Few-Shot Performance of Language Models. http://arxiv.org/abs/2102.09690 arXiv:2102.09690 [cs].",
      "doi": ""
    }
  ]
}