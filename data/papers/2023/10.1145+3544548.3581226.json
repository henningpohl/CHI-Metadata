{
  "doi": "10.1145/3544548.3581226",
  "title": "GANravel: User-Driven Direction Disentanglement in Generative Adversarial Networks",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-15",
  "year": 2023,
  "badges": [],
  "abstract": "Generative adversarial networks (GANs) have many application areas including image editing, domain translation, missing data imputation, and support for creative work. However, GANs are considered \u2018black boxes\u2019. Specifically, the end-users have little control over how to improve editing directions through disentanglement. Prior work focused on new GAN architectures to disentangle editing directions. Alternatively, we propose GANravel\u2014a user-driven direction disentanglement tool that complements the existing GAN architectures and allows users to improve editing directions iteratively. In two user studies with 16 participants each, GANravel users were able to disentangle directions and outperformed the state-of-the-art direction discovery baselines in disentanglement performance. In the second user study, GANravel was used in a creative task of creating dog memes and was able to create high-quality edited images and GIFs.",
  "tags": [
    "Generative Adversarial Networks",
    "Explainable-AI",
    "Interactive Systems",
    "Disentanglement"
  ],
  "authors": [
    {
      "name": "Noyan Evirgen",
      "institution": "HCI Research, UCLA, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659832612",
      "orcid": "0000-0003-2408-3798"
    },
    {
      "name": "Xiang 'Anthony Chen",
      "institution": "HCI Research, UCLA, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659468135",
      "orcid": "0000-0002-8527-1744"
    }
  ],
  "references": [
    {
      "text": "Rameen Abdal, Peihao Zhu, Niloy\u00a0J Mitra, and Peter Wonka. 2021. Styleflow: Attribute-conditioned exploration of stylegan-generated images using conditional continuous normalizing flows. ACM Transactions on Graphics (ToG) 40, 3 (2021), 1\u201321.",
      "doi": "10.1145/3447648"
    },
    {
      "text": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua\u00a0B Tenenbaum, William\u00a0T Freeman, and Antonio Torralba. 2018. Gan dissection: Visualizing and understanding generative adversarial networks. arXiv preprint arXiv:1811.10597(2018).",
      "doi": ""
    },
    {
      "text": "Shu-Yu Chen, Wanchao Su, Lin Gao, Shihong Xia, and Hongbo Fu. 2020. DeepFaceDrawing: Deep generation of face images from sketches. ACM Transactions on Graphics (TOG) 39, 4 (2020), 72\u20131.",
      "doi": "10.1145/3386569.3392386"
    },
    {
      "text": "Yu Cheng, Zhe Gan, Yitong Li, Jingjing Liu, and Jianfeng Gao. 2020. Sequential Attention GAN for Interactive Image Editing. Association for Computing Machinery, New York, NY, USA, 4383\u20134391. https://doi.org/10.1145/3394171.3413551",
      "doi": "10.1145/3394171.3413551"
    },
    {
      "text": "Chia-Hsing Chiu, Yuki Koyama, Yu-Chi Lai, Takeo Igarashi, and Yonghao Yue. 2020. Human-in-the-loop differential subspace search in high-dimensional latent space. ACM Transactions on Graphics (TOG) 39, 4 (2020), 85\u20131.",
      "doi": "10.1145/3386569.3392409"
    },
    {
      "text": "Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. 2020. StarGAN v2: Diverse Image Synthesis for Multiple Domains. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
      "doi": ""
    },
    {
      "text": "Edo Collins, Raja Bala, Bob Price, and Sabine Susstrunk. 2020. Editing in Style: Uncovering the Local Semantics of GANs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).",
      "doi": ""
    },
    {
      "text": "Will Cukierski. 2013. Dogs vs. Cats. https://kaggle.com/competitions/dogs-vs-cats",
      "doi": ""
    },
    {
      "text": "Hai Dang, Lukas Mecke, and Daniel Buschek. 2022. GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information. arXiv preprint arXiv:2202.00965(2022).",
      "doi": ""
    },
    {
      "text": "Noyan Evirgen and Xiang\u2019Anthony\u2019 Chen. 2022. GANzilla: User-Driven Direction Discovery in Generative Adversarial Networks. arXiv preprint arXiv:2207.08320(2022).",
      "doi": ""
    },
    {
      "text": "Lore Goetschalckx, Alex Andonian, Aude Oliva, and Phillip Isola. 2019. GANalyze: Toward Visual Definitions of Cognitive Image Properties. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV).",
      "doi": ""
    },
    {
      "text": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2020. Generative adversarial networks. Commun. ACM 63, 11 (2020), 139\u2013144.",
      "doi": "10.1145/3422622"
    },
    {
      "text": "Hongyan Gu, Jingbin Huang, Lauren Hung, and Xiang\u00a0\u2019Anthony\u2019 Chen. 2021. Lessons Learned from Designing an AI-Enabled Diagnosis Tool for Pathologists. Proc. ACM Hum.-Comput. Interact. 5, CSCW1, Article 10 (apr 2021), 25\u00a0pages. https://doi.org/10.1145/3449084",
      "doi": "10.1145/3449084"
    },
    {
      "text": "Hongyan Gu, Yuan Liang, Yifan Xu, Christopher\u00a0Kazu Williams, Shino Magaki, Negar Khanlou, Harry Vinters, Zesheng Chen, Shuo Ni, Chunxu Yang, Wenzhong Yan, Xinhai\u00a0Robert Zhang, Yang Li, Mohammad Haeri, and Xiang\u00a0\u2019Anthony\u2019 Chen. 2022. Improving Workflow Integration with XPath: Design and Evaluation of a Human-AI Diagnosis System in Pathology. ACM Trans. Comput.-Hum. Interact. (dec 2022). https://doi.org/10.1145/3577011 Just Accepted.",
      "doi": "10.1145/3577011"
    },
    {
      "text": "Erik H\u00e4rk\u00f6nen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris. 2020. Ganspace: Discovering interpretable gan controls. Advances in Neural Information Processing Systems 33 (2020), 9841\u20139850.",
      "doi": ""
    },
    {
      "text": "Sandra\u00a0G Hart. 1986. NASA task load index (TLX). (1986).",
      "doi": ""
    },
    {
      "text": "Keke He, Yanwei Fu, Wuhao Zhang, Chengjie Wang, Yu-Gang Jiang, Feiyue Huang, and Xiangyang Xue. 2018. Harnessing Synthesized Abstraction Images to Improve Facial Attribute Recognition.. In IJCAI. 733\u2013740.",
      "doi": ""
    },
    {
      "text": "Eric Heim. 2019. Constrained generative adversarial networks for interactive image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 10753\u201310761.",
      "doi": ""
    },
    {
      "text": "Karen Holtzblatt and Hugh Beyer. 1997. Contextual design: defining customer-centered systems. Elsevier.",
      "doi": ""
    },
    {
      "text": "Drew\u00a0A Hudson and Larry Zitnick. 2021. Generative adversarial transformers. In International conference on machine learning. PMLR, 4487\u20134499.",
      "doi": ""
    },
    {
      "text": "Ali Jahanian, Lucy Chai, and Phillip Isola. 2019. On the\" steerability\" of generative adversarial networks. arXiv preprint arXiv:1907.07171(2019).",
      "doi": ""
    },
    {
      "text": "Tero Karras, Samuli Laine, and Timo Aila. 2019. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 4401\u20134410.",
      "doi": ""
    },
    {
      "text": "Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. 2020. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 8110\u20138119.",
      "doi": ""
    },
    {
      "text": "Siavash Khodadadeh, Shabnam Ghadar, Saeid Motiian, Wei-An Lin, Ladislau B\u00f6l\u00f6ni, and Ratheesh Kalarot. 2022. Latent to Latent: A Learned Mapper for Identity Preserving Editing of Multiple Face Attributes in StyleGAN-generated Images. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 3184\u20133192.",
      "doi": ""
    },
    {
      "text": "Huan Ling, Karsten Kreis, Daiqing Li, Seung\u00a0Wook Kim, Antonio Torralba, and Sanja Fidler. 2021. EditGAN: High-Precision Semantic Image Editing. Advances in Neural Information Processing Systems 34 (2021).",
      "doi": ""
    },
    {
      "text": "Bingchen Liu, Yizhe Zhu, Kunpeng Song, and Ahmed Elgammal. 2020. Towards faster and stabilized gan training for high-fidelity few-shot image synthesis. In International Conference on Learning Representations.",
      "doi": ""
    },
    {
      "text": "Deborah Mateja and Armin Heinzl. 2021. Towards Machine Learning as an Enabler of Computational Creativity. IEEE Transactions on Artificial Intelligence 2, 6(2021), 460\u2013475.",
      "doi": ""
    },
    {
      "text": "Omkar\u00a0M Parkhi, Andrea Vedaldi, and Andrew Zisserman. 2015. Deep face recognition. (2015).",
      "doi": ""
    },
    {
      "text": "Omkar\u00a0M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar. 2012. Cats and dogs. In 2012 IEEE conference on computer vision and pattern recognition. IEEE, 3498\u20133505.",
      "doi": ""
    },
    {
      "text": "Santiago Pascual, Antonio Bonafonte, and Joan Serra. 2017. SEGAN: Speech enhancement generative adversarial network. arXiv preprint arXiv:1703.09452(2017).",
      "doi": ""
    },
    {
      "text": "Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski. 2021. StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). 2085\u20132094.",
      "doi": ""
    },
    {
      "text": "Antoine Plumerault, Herv\u00e9\u00a0Le Borgne, and C\u00e9line Hudelot. 2020. Controlling generative models with continuous factors of variations. arXiv preprint arXiv:2001.10238(2020).",
      "doi": ""
    },
    {
      "text": "Alec Radford, Jong\u00a0Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, 2021. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning. PMLR, 8748\u20138763.",
      "doi": ""
    },
    {
      "text": "Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434(2015).",
      "doi": ""
    },
    {
      "text": "Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition. 815\u2013823.",
      "doi": ""
    },
    {
      "text": "Yujun Shen, Jinjin Gu, Xiaoou Tang, and Bolei Zhou. 2020. Interpreting the Latent Space of GANs for Semantic Face Editing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).",
      "doi": ""
    },
    {
      "text": "Yujun Shen, Ceyuan Yang, Xiaoou Tang, and Bolei Zhou. 2020. Interfacegan: Interpreting the disentangled face representation learned by gans. IEEE transactions on pattern analysis and machine intelligence (2020).",
      "doi": ""
    },
    {
      "text": "Yujun Shen and Bolei Zhou. 2021. Closed-Form Factorization of Latent Semantics in GANs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 1532\u20131540.",
      "doi": ""
    },
    {
      "text": "Christos Tzelepis, Georgios Tzimiropoulos, and Ioannis Patras. 2021. WarpedGANSpace: Finding non-linear RBF paths in GAN latent space. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 6393\u20136402.",
      "doi": ""
    },
    {
      "text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan\u00a0N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017).",
      "doi": ""
    },
    {
      "text": "Andrey Voynov and Artem Babenko. 2020. Unsupervised Discovery of Interpretable Directions in the GAN Latent Space. In Proceedings of the 37th International Conference on Machine Learning(Proceedings of Machine Learning Research, Vol.\u00a0119), Hal\u00a0Daum\u00e9 III and Aarti Singh (Eds.). PMLR, 9786\u20139796. https://proceedings.mlr.press/v119/voynov20a.html",
      "doi": "10.5555/3524938.3525845"
    },
    {
      "text": "Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, and Chen Change\u00a0Loy. 2018. Esrgan: Enhanced super-resolution generative adversarial networks. In Proceedings of the European conference on computer vision (ECCV) workshops. 0\u20130.",
      "doi": ""
    },
    {
      "text": "Zongze Wu, Dani Lischinski, and Eli Shechtman. 2021. StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 12863\u201312872.",
      "doi": ""
    },
    {
      "text": "Ceyuan Yang, Yujun Shen, and Bolei Zhou. 2021. Semantic hierarchy emerges in deep generative representations for scene synthesis. International Journal of Computer Vision 129, 5 (2021), 1451\u20131466.",
      "doi": ""
    },
    {
      "text": "Xin Yi, Ekta Walia, and Paul Babyn. 2019. Generative adversarial network in medical imaging: A review. Medical image analysis 58 (2019), 101552.",
      "doi": ""
    },
    {
      "text": "Enhao Zhang and Nikola Banovic. 2021. Method for Exploring Generative Adversarial Networks (GANs) via Automatically Generated Image Galleries. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 76, 15\u00a0pages. https://doi.org/10.1145/3411764.3445714",
      "doi": "10.1145/3411764.3445714"
    },
    {
      "text": "Jun-Yan Zhu, Philipp Kr\u00e4henb\u00fchl, Eli Shechtman, and Alexei\u00a0A Efros. 2016. Generative visual manipulation on the natural image manifold. In European conference on computer vision. Springer, 597\u2013613.",
      "doi": ""
    }
  ]
}