{
  "doi": "10.1145/3544548.3581025",
  "title": "Knowing About Knowing: An Illusion of Human Competence Can Hinder Appropriate Reliance on AI Systems",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-18",
  "year": 2023,
  "badges": [],
  "abstract": "The dazzling promises of AI systems to augment humans in various tasks hinge on whether humans can appropriately rely on them. Recent research has shown that appropriate reliance is the key to achieving complementary team performance in AI-assisted decision making. This paper addresses an under-explored problem of whether the Dunning-Kruger Effect (DKE) among people can hinder their appropriate reliance on AI systems. DKE is a metacognitive bias due to which less-competent individuals overestimate their own skill and performance. Through an empirical study (N = 249), we explored the impact of DKE on human reliance on an AI system, and whether such effects can be mitigated using a tutorial intervention that reveals the fallibility of AI advice, and exploiting logic units-based explanations to improve user understanding of AI advice. We found that participants who overestimate their performance tend to exhibit under-reliance on AI systems, which hinders optimal team performance. Logic units-based explanations did not help users in either improving the calibration of their competence or facilitating appropriate reliance. While the tutorial intervention was highly effective in helping users calibrate their self-assessment and facilitating appropriate reliance among participants with overestimated self-assessment, we found that it can potentially hurt the appropriate reliance of participants with underestimated self-assessment. Our work has broad implications on the design of methods to tackle user cognitive biases while facilitating appropriate reliance on AI systems. Our findings advance the current understanding of the role of self-assessment in shaping trust and reliance in human-AI decision making. This lays out promising future directions for relevant HCI research in this community.",
  "tags": [
    "Human-AI Decision Making",
    "Appropriate Reliance",
    "XAI",
    "Dunning-Kruger Effect"
  ],
  "authors": [
    {
      "name": "Gaole He",
      "institution": "Delft University of Technology, Netherlands",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660228772",
      "orcid": "0000-0002-8152-4791"
    },
    {
      "name": "Lucie Kuiper",
      "institution": "Delft University of Technology, Netherlands",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659750379",
      "orcid": "0000-0001-6847-2029"
    },
    {
      "name": "Ujwal Gadiraju",
      "institution": "Web Information Systems, Delft University of Technology, Netherlands",
      "img": "/do/10.1145/contrib-83458903457/rel-imgonly/ujwal-circle.png",
      "acmid": "83458903457",
      "orcid": "0000-0002-6189-6539"
    }
  ],
  "references": [
    {
      "text": "Ricardo Baeza-Yates. 2018. Bias on the web. Commun. ACM 61, 6 (2018), 54\u201361.",
      "doi": "10.1145/3209581"
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Walter\u00a0S Lasecki, Daniel\u00a0S Weld, and Eric Horvitz. 2019. Beyond accuracy: The role of mental models in human-AI team performance. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 2\u201311.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel Weld. 2021. Does the whole exceed its parts? the effect of ai explanations on complementary team performance. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3411764.3445717"
    },
    {
      "text": "Cynthia\u00a0Sherraden Bradley, Kristina\u00a0Thomas Dreifuerst, Brandon\u00a0Kyle Johnson, and Ann Loomis. 2022. More than a Meme: The Dunning-Kruger Effect as an Opportunity for Positive Change in Nursing Education. Clinical Simulation in Nursing 66 (2022), 58\u201365.",
      "doi": ""
    },
    {
      "text": "Zana Bu\u00e7inca, Maja\u00a0Barbara Malaya, and Krzysztof\u00a0Z Gajos. 2021. To trust or to think: cognitive forcing functions can reduce overreliance on AI in AI-assisted decision-making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201321.",
      "doi": "10.1145/3449287"
    },
    {
      "text": "Jason\u00a0W Burton, Mari-Klara Stein, and Tina\u00a0Blegind Jensen. 2020. A systematic review of algorithm aversion in augmented decision making. Journal of Behavioral Decision Making 33, 2 (2020), 220\u2013239.",
      "doi": ""
    },
    {
      "text": "Noah Castelo, Maarten\u00a0W Bos, and Donald\u00a0R Lehmann. 2019. Task-dependent algorithm aversion. Journal of Marketing Research 56, 5 (2019), 809\u2013825.",
      "doi": ""
    },
    {
      "text": "Chun-Wei Chiang and Ming Yin. 2022. Exploring the Effects of Machine Learning Literacy Interventions on Laypeople\u2019s Reliance on Machine Learning Models. In IUI 2022: 27th International Conference on Intelligent User Interfaces, Helsinki, Finland, March 22 - 25, 2022, Giulio Jacucci, Samuel Kaski, Cristina Conati, Simone Stumpf, Tuukka Ruotsalo, and Krzysztof Gajos (Eds.). ACM, 148\u2013161.",
      "doi": ""
    },
    {
      "text": "Chun-Wei Chiang and Ming Yin. 2021. You\u2019d Better Stop! Understanding Human Reliance on Machine Learning Models under Covariate Shift. In 13th ACM Web Science Conference 2021. 120\u2013129.",
      "doi": "10.1145/3447535.3462487"
    },
    {
      "text": "Leah Chong, Guanglu Zhang, Kosa Goucher-Lambert, Kenneth Kotovsky, and Jonathan Cagan. 2022. Human confidence in artificial intelligence and in themselves: The evolution and impact of confidence on adoption of AI advice. Computers in Human Behavior 127 (2022), 107018.",
      "doi": "10.1016/j.chb.2021.107018"
    },
    {
      "text": "Michael Chromik, Malin Eiband, Felicitas Buchner, Adrian Kr\u00fcger, and Andreas Butz. 2021. I think i get your point, AI! the illusion of explanatory depth in explainable AI. In 26th International Conference on Intelligent User Interfaces. 307\u2013317.",
      "doi": "10.1145/3397481.3450644"
    },
    {
      "text": "Berkeley\u00a0J Dietvorst, Joseph\u00a0P Simmons, and Cade Massey. 2015. Algorithm aversion: people erroneously avoid algorithms after seeing them err.Journal of Experimental Psychology: General 144, 1 (2015), 114.",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J Dietvorst, Joseph\u00a0P Simmons, and Cade Massey. 2018. Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them. Management Science 64, 3 (2018), 1155\u20131170.",
      "doi": "10.1287/mnsc.2016.2643"
    },
    {
      "text": "Nicole Dillen, Marko Ilievski, Edith Law, Lennart\u00a0E Nacke, Krzysztof Czarnecki, and Oliver Schneider. 2020. Keep calm and ride along: Passenger comfort and anxiety as physiological responses to autonomous driving styles. In Proceedings of the 2020 CHI conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3313831.3376247"
    },
    {
      "text": "Tim Draws, Alisa Rieger, Oana Inel, Ujwal Gadiraju, and Nava Tintarev. 2021. A checklist to combat cognitive biases in crowdsourcing. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a09. 48\u201359.",
      "doi": ""
    },
    {
      "text": "David Dunning. 2011. The Dunning\u2013Kruger effect: On being ignorant of one\u2019s own ignorance. In Advances in experimental social psychology. Vol.\u00a044. Elsevier, 247\u2013296.",
      "doi": ""
    },
    {
      "text": "David Dunning, Chip Heath, and Jerry\u00a0M Suls. 2004. Flawed self-assessment: Implications for health, education, and the workplace. Psychological science in the public interest 5, 3 (2004), 69\u2013106.",
      "doi": ""
    },
    {
      "text": "Joyce Ehrlinger, Kerri Johnson, Matthew Banner, David Dunning, and Justin Kruger. 2008. Why the unskilled are unaware: Further explorations of (absent) self-insight among the incompetent. Organizational behavior and human decision processes 105, 1(2008), 98\u2013121.",
      "doi": ""
    },
    {
      "text": "Upol Ehsan, Q\u00a0Vera Liao, Michael Muller, Mark\u00a0O Riedl, and Justin\u00a0D Weisz. 2021. Expanding explainability: Towards social transparency in ai systems. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201319.",
      "doi": "10.1145/3411764.3445188"
    },
    {
      "text": "Upol Ehsan and Mark\u00a0O Riedl. 2020. Human-centered explainable ai: towards a reflective sociotechnical approach. In International Conference on Human-Computer Interaction. Springer, 449\u2013466.",
      "doi": "10.1007/978-3-030-60117-1_33"
    },
    {
      "text": "Upol Ehsan, Philipp Wintersberger, Q\u00a0Vera Liao, Martina Mara, Marc Streit, Sandra Wachter, Andreas Riener, and Mark\u00a0O Riedl. 2021. Operationalizing Human-Centered Perspectives in Explainable AI. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u20136.",
      "doi": ""
    },
    {
      "text": "Upol Ehsan, Philipp Wintersberger, Q\u00a0Vera Liao, Elizabeth\u00a0Anne Watkins, Carina Manger, Hal Daum\u00e9\u00a0III, Andreas Riener, and Mark\u00a0O Riedl. 2022. Human-Centered Explainable AI (HCXAI): beyond opening the black-box of AI. In CHI Conference on Human Factors in Computing Systems Extended Abstracts. 1\u20137.",
      "doi": "10.1145/3491101.3503727"
    },
    {
      "text": "Alexander Erlei, Richeek Das, Lukas Meub, Avishek Anand, and Ujwal Gadiraju. 2022. For What It\u2019s Worth: Humans Overwrite Their Economic Self-interest to Avoid Bargaining With AI Systems. In CHI Conference on Human Factors in Computing Systems. 1\u201318.",
      "doi": "10.1145/3491102.3517734"
    },
    {
      "text": "Alexander Erlei, Franck Nekdem, Lukas Meub, Avishek Anand, and Ujwal Gadiraju. 2020. Impact of algorithmic decision making on human behavior: Evidence from ultimatum bargaining. In Proceedings of the AAAI conference on human computation and crowdsourcing, Vol.\u00a08. 43\u201352.",
      "doi": ""
    },
    {
      "text": "Franz Faul, Edgar Erdfelder, Axel Buchner, and Albert-Georg Lang. 2009. Statistical power analyses using G* Power 3.1: Tests for correlation and regression analyses. Behavior research methods 41, 4 (2009), 1149\u20131160.",
      "doi": ""
    },
    {
      "text": "Jennifer Fereday and Eimear Muir-Cochrane. 2006. The role of performance feedback in the self-assessment of competence: a research study with nursing clinicians. Collegian 13, 1 (2006), 10\u201315.",
      "doi": ""
    },
    {
      "text": "Riccardo Fogliato, Alexandra Chouldechova, and Zachary Lipton. 2021. The impact of algorithmic risk assessments on human predictions and its analysis via crowdsourcing studies. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201324.",
      "doi": "10.1145/3479572"
    },
    {
      "text": "Thomas Franke, Christiane Attig, and Daniel Wessel. 2019. A personal resource for technology interaction: development and validation of the affinity for technology interaction (ATI) scale. International Journal of Human\u2013Computer Interaction 35, 6(2019), 456\u2013467.",
      "doi": ""
    },
    {
      "text": "Ujwal Gadiraju, Besnik Fetahu, Ricardo Kawase, Patrick Siehndel, and Stefan Dietze. 2017. Using worker self-assessments for competence-based pre-selection in crowdsourcing microtasks. ACM Transactions on Computer-Human Interaction (TOCHI) 24, 4(2017), 1\u201326.",
      "doi": "10.1145/3119930"
    },
    {
      "text": "Ujwal Gadiraju, Ricardo Kawase, Stefan Dietze, and Gianluca Demartini. 2015. Understanding malicious behavior in crowdsourcing platforms: The case of online surveys. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 1631\u20131640.",
      "doi": "10.1145/2702123.2702443"
    },
    {
      "text": "Jan Gogoll and Matthias Uhl. 2018. Rage against the machine: Automation in the moral domain. Journal of Behavioral and Experimental Economics 74 (2018), 97\u2013103.",
      "doi": ""
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. Disparate interactions: An algorithm-in-the-loop analysis of fairness in risk assessments. In Proceedings of the conference on fairness, accountability, and transparency. 90\u201399.",
      "doi": "10.1145/3287560.3287563"
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. The principles and limits of algorithm-in-the-loop decision making. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359152"
    },
    {
      "text": "Ben Green and Yiling Chen. 2020. Algorithmic risk assessments can alter human decision-making processes in high-stakes government contexts. arXiv preprint arXiv:2012.05370(2020).",
      "doi": ""
    },
    {
      "text": "Gaole He, Agathe Balayn, Stefan Buijsman, Jie Yang, and Ujwal Gadiraju. 2022. It Is Like Finding a Polar Bear in the Savannah! Concept-Level AI Explanations with Analogical Inference from Commonsense Knowledge. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a010. 89\u2013101.",
      "doi": ""
    },
    {
      "text": "Robert\u00a0R Hoffman, Shane\u00a0T Mueller, Gary Klein, and Jordan Litman. 2018. Metrics for explainable AI: Challenges and prospects. arXiv preprint arXiv:1812.04608(2018).",
      "doi": ""
    },
    {
      "text": "Yoyo Tsung-Yu Hou and Malte\u00a0F Jung. 2021. Who is the expert? Reconciling algorithm aversion and algorithm appreciation in AI-supported decision making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201325.",
      "doi": ""
    },
    {
      "text": "Christoph Hube, Besnik Fetahu, and Ujwal Gadiraju. 2019. Understanding and mitigating worker biases in the crowdsourced collection of subjective judgments. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3290605.3300637"
    },
    {
      "text": "Rachel\u00a0A Jansen, Anna\u00a0N Rafferty, and Thomas\u00a0L Griffiths. 2021. A rational model of the Dunning\u2013Kruger effect supports insensitivity to evidence in low performers. Nature Human Behaviour 5, 6 (2021), 756\u2013763.",
      "doi": ""
    },
    {
      "text": "Ekaterina Jussupow, Izak Benbasat, and Armin Heinzl. 2020. Why are we averse towards Algorithms? A comprehensive literature Review on Algorithm aversion. In 28th European Conference on Information Systems - Liberty, Equality, and Fraternity in a Digitizing World, ECIS 2020, Marrakech, Morocco, June 15-17, 2020, Frantz Rowe, Redouane\u00a0El Amrani, Moez Limayem, Sue Newell, Nancy Pouloudi, Eric van Heck, and Ali\u00a0El Quammah (Eds.).",
      "doi": ""
    },
    {
      "text": "Moritz K\u00f6rber. 2018. Theoretical considerations and development of a questionnaire to measure trust in automation. In Congress of the International Ergonomics Association. Springer, 13\u201330.",
      "doi": ""
    },
    {
      "text": "Max\u00a0F Kramer, Jana Schaich\u00a0Borg, Vincent Conitzer, and Walter Sinnott-Armstrong. 2018. When do people want AI to make decisions?. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. 204\u2013209.",
      "doi": "10.1145/3278721.3278752"
    },
    {
      "text": "Justin Kruger and David Dunning. 1999. Unskilled and unaware of it: how difficulties in recognizing one\u2019s own incompetence lead to inflated self-assessments.Journal of personality and social psychology 77, 6(1999), 1121.",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Chacha Chen, Q\u00a0Vera Liao, Alison Smith-Renner, and Chenhao Tan. 2021. Towards a science of human-ai decision making: a survey of empirical studies. arXiv preprint arXiv:2112.11471(2021).",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Han Liu, and Chenhao Tan. 2020. \"Why is \u2019Chicago\u2019 deceptive?\" Towards Building Model-Driven Tutorials for Humans. In CHI \u201920: CHI Conference on Human Factors in Computing Systems, Honolulu, HI, USA, April 25-30, 2020, Regina Bernhaupt, Florian\u00a0\u2019Floyd\u2019 Mueller, David Verweij, Josh Andres, Joanna McGrenere, Andy Cockburn, Ignacio Avellino, Alix Goguey, Pernille Bj\u00f8n, Shengdong Zhao, Briane\u00a0Paul Samson, and Rafal Kocielnik (Eds.). ACM, 1\u201313.",
      "doi": ""
    },
    {
      "text": "Vivian Lai and Chenhao Tan. 2019. On human predictions with explanations and predictions of machine learning models: A case study on deception detection. In Proceedings of the conference on fairness, accountability, and transparency. 29\u201338.",
      "doi": "10.1145/3287560.3287590"
    },
    {
      "text": "John\u00a0D Lee and Katrina\u00a0A See. 2004. Trust in automation: Designing for appropriate reliance. Human factors 46, 1 (2004), 50\u201380.",
      "doi": ""
    },
    {
      "text": "Min\u00a0Hun Lee, Daniel\u00a0P Siewiorek, Asim Smailagic, Alexandre Bernardino, and Sergi Berm\u00fadez\u00a0i Badia. 2021. A human-ai collaborative approach for clinical decision making on rehabilitation assessment. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3411764.3445472"
    },
    {
      "text": "Mengyao Li, Brittany\u00a0E Holthausen, Rachel\u00a0E Stuck, and Bruce\u00a0N Walker. 2019. No risk no trust: Investigating perceived risk in highly automated driving. In Proceedings of the 11th International Conference on Automotive User Interfaces and Interactive Vehicular Applications. 177\u2013185.",
      "doi": "10.1145/3342197.3344525"
    },
    {
      "text": "Q\u00a0Vera Liao and Kush\u00a0R Varshney. 2021. Human-Centered Explainable AI (XAI): From Algorithms to User Experiences. arXiv preprint arXiv:2110.10790(2021).",
      "doi": ""
    },
    {
      "text": "Peter Lipton. 1990. Contrastive explanation. Royal Institute of Philosophy Supplements 27 (1990), 247\u2013266.",
      "doi": ""
    },
    {
      "text": "Han Liu, Vivian Lai, and Chenhao Tan. 2021. Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making. Proc. ACM Hum. Comput. Interact. 5, CSCW2 (2021), 1\u201345.",
      "doi": "10.1145/3479552"
    },
    {
      "text": "Jennifer\u00a0M Logg, Julia\u00a0A Minson, and Don\u00a0A Moore. 2019. Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes 151 (2019), 90\u2013103.",
      "doi": ""
    },
    {
      "text": "Chiara Longoni, Andrea Bonezzi, and Carey\u00a0K Morewedge. 2019. Resistance to medical artificial intelligence. Journal of Consumer Research 46, 4 (2019), 629\u2013650.",
      "doi": ""
    },
    {
      "text": "Zhuoran Lu and Ming Yin. 2021. Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks. In CHI \u201921: CHI Conference on Human Factors in Computing Systems, Virtual Event / Yokohama, Japan, May 8-13, 2021, Yoshifumi Kitamura, Aaron Quigley, Katherine Isbister, Takeo Igarashi, Pernille Bj\u00f8rn, and Steven\u00a0Mark Drucker (Eds.). ACM, 78:1\u201378:16.",
      "doi": "10.1145/3411764.3445562"
    },
    {
      "text": "Catherine\u00a0C Marshall and Frank\u00a0M Shipman. 2013. Experiences surveying the crowd: Reflections on methods, participation, and reliability. In Proceedings of the 5th Annual ACM Web Science Conference. 234\u2013243.",
      "doi": "10.1145/2464464.2464485"
    },
    {
      "text": "Conor\u00a0Thomas McKevitt. 2016. Engaging students with self-assessment and tutor feedback to improve performance and support assessment capacity. Journal of University Teaching & Learning Practice 13, 1 (2016), 2.",
      "doi": ""
    },
    {
      "text": "Scott\u00a0Mayer McKinney, Marcin Sieniek, Varun Godbole, Jonathan Godwin, Natasha Antropova, Hutan Ashrafian, Trevor Back, Mary Chesus, Greg\u00a0S Corrado, Ara Darzi, 2020. International evaluation of an AI system for breast cancer screening. Nature 577, 7788 (2020), 89\u201394.",
      "doi": ""
    },
    {
      "text": "Tim Miller. 2021. Contrastive explanation: A structural-model approach. The Knowledge Engineering Review 36 (2021).",
      "doi": ""
    },
    {
      "text": "Geoff Norman. 2010. Likert scales, levels of measurement and the \u201claws\u201d of statistics. Advances in health sciences education 15, 5 (2010), 625\u2013632.",
      "doi": ""
    },
    {
      "text": "Amy Rechkemmer and Ming Yin. 2022. When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models. In CHI \u201922: CHI Conference on Human Factors in Computing Systems, New Orleans, LA, USA, 29 April 2022 - 5 May 2022, Simone D.\u00a0J. Barbosa, Cliff Lampe, Caroline Appert, David\u00a0A. Shamma, Steven\u00a0Mark Drucker, Julie\u00a0R. Williamson, and Koji Yatani (Eds.). ACM, 535:1\u2013535:14.",
      "doi": "10.1145/3491102.3501967"
    },
    {
      "text": "Vincent Robbemond, Oana Inel, and Ujwal Gadiraju. 2022. Understanding the Role of Explanation Modality in AI-assisted Decision-making. In Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization. 223\u2013233.",
      "doi": "10.1145/3503252.3531311"
    },
    {
      "text": "Ioannis\u00a0Petros Samiotis, Sihang Qiu, Christoph Lofi, Jie Yang, Ujwal Gadiraju, and Alessandro Bozzon. 2021. Exploring the Music Perception Skills of Crowd Workers. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a09. 108\u2013119.",
      "doi": ""
    },
    {
      "text": "James Sawler. 2021. Economics 101-ism and the Dunning-Kruger effect: Reducing overconfidence among introductory macroeconomics students. International Review of Economics Education 36 (2021), 100208.",
      "doi": ""
    },
    {
      "text": "James Schaffer, John O\u2019Donovan, James Michaelis, Adrienne Raglin, and Tobias H\u00f6llerer. 2019. I Can Do Better than Your AI: Expertise and Explanations. In Proceedings of the 24th International Conference on Intelligent User Interfaces (Marina del Ray, California) (IUI \u201919). Association for Computing Machinery, New York, NY, USA, 240\u2013251.",
      "doi": "10.1145/3301275.3302308"
    },
    {
      "text": "Max Schemmer, Patrick Hemmer, Niklas K\u00fchl, Carina Benz, and Gerhard Satzger. 2022. Should I Follow AI-based Advice? Measuring Appropriate Reliance in Human-AI Decision-Making. In ACM Conference on Human Factors in Computing Systems (CHI\u201922), Workshop on Trust and Reliance in AI-Human Teams (trAIt).",
      "doi": ""
    },
    {
      "text": "Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger, Franziska Herbert, Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin Mahlein, and Kristian Kersting. 2020. Making deep neural networks right for the right scientific reasons by interacting with their explanations. Nature Machine Intelligence 2, 8 (2020), 476\u2013486.",
      "doi": ""
    },
    {
      "text": "Andrew Selbst and Julia Powles. 2018. \"Meaningful Information\" and the Right to Explanation. In Conference on Fairness, Accountability and Transparency, FAT 2018, 23-24 February 2018, New York, NY, USA(Proceedings of Machine Learning Research, Vol.\u00a081), Sorelle\u00a0A. Friedler and Christo Wilson (Eds.). PMLR, 48.",
      "doi": ""
    },
    {
      "text": "Amit Sheth, Manas Gaur, Kaushik Roy, and Keyur Faldu. 2021. Knowledge-intensive language understanding for explainable AI. IEEE Internet Computing 25, 5 (2021), 19\u201324.",
      "doi": ""
    },
    {
      "text": "Donghee Shin. 2022. Expanding the role of trust in the experience of algorithmic journalism: User sensemaking of algorithmic heuristics in Korean users. Journalism Practice 16, 6 (2022), 1168\u20131191.",
      "doi": ""
    },
    {
      "text": "Donghee Shin. 2022. How do people judge the credibility of algorithmic sources?Ai & Society 37, 1 (2022), 81\u201396.",
      "doi": ""
    },
    {
      "text": "Donghee Shin, Kerk\u00a0F Kee, and Emily\u00a0Y Shin. 2022. Algorithm awareness: Why user awareness is critical for personal privacy in the adoption of algorithmic platforms?International Journal of Information Management 65 (2022), 102494.",
      "doi": ""
    },
    {
      "text": "Donghee Shin, Azmat Rasul, and Anestis Fotiadis. 2021. Why am I seeing this? Deconstructing algorithm literacy through the lens of users. Internet Research (2021).",
      "doi": ""
    },
    {
      "text": "Donghee Shin, Bouziane Zaid, Frank Biocca, and Azmat Rasul. 2022. In Platforms We Trust? Unlocking the Black-Box of News Algorithms through Interpretable AI. Journal of Broadcasting & Electronic Media(2022), 1\u201322.",
      "doi": ""
    },
    {
      "text": "Donghee Shin, Bouziane Zaid, and Mohammed Ibahrine. 2020. Algorithm appreciation: Algorithmic performance, developmental processes, and user interactions. In 2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI). IEEE, 1\u20135.",
      "doi": ""
    },
    {
      "text": "Suzanne Tolmeijer, Ujwal Gadiraju, Ramya Ghantasala, Akshit Gupta, and Abraham Bernstein. 2021. Second Chance for a First Impression? Trust Development in Intelligent System Interaction. In Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization, UMAP 2021, Utrecht, The Netherlands, June, 21-25, 2021, Judith Masthoff, Eelco Herder, Nava Tintarev, and Marko Tkalcic (Eds.). ACM, 77\u201387.",
      "doi": "10.1145/3450613.3456817"
    },
    {
      "text": "Richard Tomsett, Alun Preece, Dave Braines, Federico Cerutti, Supriyo Chakraborty, Mani Srivastava, Gavin Pearson, and Lance Kaplan. 2020. Rapid trust calibration through interpretable and uncertainty-aware AI. Patterns 1, 4 (2020), 100049.",
      "doi": ""
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian\u00a0Y Lim. 2019. Designing theory-driven user-centric explainable AI. In Proceedings of the 2019 CHI conference on human factors in computing systems. 1\u201315.",
      "doi": "10.1145/3290605.3300831"
    },
    {
      "text": "Xinru Wang and Ming Yin. 2021. Are Explanations Helpful? A Comparative Study of the Effects of Explanations in AI-Assisted Decision-Making. In 26th International Conference on Intelligent User Interfaces. 318\u2013328.",
      "doi": "10.1145/3397481.3450650"
    },
    {
      "text": "Fangzhi Xu, Jun Liu, Qika Lin, Yudai Pan, and Lingling Zhang. 2022. Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning. In SIGIR \u201922: The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Madrid, Spain, July 11 - 15, 2022, Enrique Amig\u00f3, Pablo Castells, Julio Gonzalo, Ben Carterette, J.\u00a0Shane Culpepper, and Gabriella Kazai (Eds.). ACM, 1055\u20131065.",
      "doi": "10.1145/3477495.3532016"
    },
    {
      "text": "Hanqi Yan, Lin Gui, and Yulan He. 2022. Hierarchical Interpretation of Neural Text Classification. arXiv preprint arXiv:2202.09792(2022).",
      "doi": ""
    },
    {
      "text": "Ilan Yaniv and Eli Kleinberger. 2000. Advice taking in decision making: Egocentric discounting and reputation formation. Organizational behavior and human decision processes 83, 2 (2000), 260\u2013281.",
      "doi": ""
    },
    {
      "text": "Ming Yin, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2019. Understanding the effect of accuracy on trust in machine learning models. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201312.",
      "doi": "10.1145/3290605.3300509"
    },
    {
      "text": "Sangseok You, Cathy\u00a0Liu Yang, and Xitong Li. 2022. Algorithmic versus Human Advice: Does Presenting Prediction Performance Matter for Algorithm Appreciation?Journal of Management Information Systems 39, 2 (2022), 336\u2013365.",
      "doi": ""
    },
    {
      "text": "Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning. In International Conference on Learning Representations (ICLR).",
      "doi": ""
    },
    {
      "text": "Muhammad\u00a0Bilal Zafar, Philipp Schmidt, Michele Donini, C\u00e9dric Archambeau, Felix Biessmann, Sanjiv\u00a0Ranjan Das, and Krishnaram Kenthapadi. 2021. More Than Words: Towards Better Quality Interpretations of Text Classifiers. arXiv preprint arXiv:2112.12444(2021).",
      "doi": ""
    },
    {
      "text": "Yunfeng Zhang, Q.\u00a0Vera Liao, and Rachel K.\u00a0E. Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making. In FAT* \u201920: Conference on Fairness, Accountability, and Transparency, Barcelona, Spain, January 27-30, 2020, Mireille Hildebrandt, Carlos Castillo, L.\u00a0Elisa Celis, Salvatore Ruggieri, Linnet Taylor, and Gabriela Zanfir-Fortuna (Eds.). ACM, 295\u2013305.",
      "doi": ""
    }
  ]
}