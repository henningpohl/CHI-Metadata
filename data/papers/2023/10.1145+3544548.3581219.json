{
  "doi": "10.1145/3544548.3581219",
  "title": "Exploring the Use of Personalized AI for Identifying Misinformation on Social Media",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-27",
  "year": 2023,
  "badges": [],
  "abstract": "This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user\u2019s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users\u2019 judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.",
  "tags": [
    "Misinformation",
    "Social Media",
    "Democratized Content Moderation",
    "Fact Checking",
    "Artificial Intelligence"
  ],
  "authors": [
    {
      "name": "Farnaz Jahanbakhsh",
      "institution": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659160423",
      "orcid": "0000-0003-0492-3040"
    },
    {
      "name": "Yannis Katsis",
      "institution": "IBM Research, Almaden, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660594808",
      "orcid": "0000-0002-1733-6227"
    },
    {
      "name": "Dakuo Wang",
      "institution": "Northeastern University, United States",
      "img": "/do/10.1145/contrib-99658707626/rel-imgonly/dakuo_wang.jpg",
      "acmid": "99658707626",
      "orcid": "0000-0001-9371-9441"
    },
    {
      "name": "Lucian Popa",
      "institution": "IBM Research - Almaden, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100150220",
      "orcid": "0000-0002-0659-9144"
    },
    {
      "name": "Michael Muller",
      "institution": "Human AI Collaboration, IBM Research, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81332517372",
      "orcid": "0000-0001-7860-163X"
    }
  ],
  "references": [
    {
      "text": "[n.d.]. About Verified Accounts. Retrieved August 25, 2022 from https://help.twitter.com/en/managing-your-account/about-twitter-verified-accounts",
      "doi": ""
    },
    {
      "text": "[n.d.]. Label Sleuth. Retrieved August 25, 2022 from https://www.label-sleuth.org",
      "doi": ""
    },
    {
      "text": "2018. Facebook apologises for blocking Prager University\u2019s videos. Retrieved August 25, 2022 from https://www.bbc.com/news/technology-45247302",
      "doi": ""
    },
    {
      "text": "2021. How Facebook\u2019s third-party fact-checking program works. Retrieved August 25, 2022 from https://www.facebook.com/journalismproject/programs/third-party-fact-checking/how-it-works",
      "doi": ""
    },
    {
      "text": "Alim Al\u00a0Ayub Ahmed, Ayman Aljabouh, Praveen\u00a0Kumar Donepudi, and Myung\u00a0Suh Choi. 2021. Detecting fake news using machine learning: A systematic literature review. arXiv preprint arXiv:2102.04458(2021).",
      "doi": ""
    },
    {
      "text": "Jennifer Nancy\u00a0Lee Allen, Antonio\u00a0Alonso Arechar, Gordon Pennycook, and David Rand. 2020. Scaling up fact-checking using the wisdom of crowds. (2020).",
      "doi": ""
    },
    {
      "text": "Mike Ananny. 2018. The partnership press: Lessons for platform-publisher collaborations as Facebook and news outlets team to fight misinformation. (2018).",
      "doi": ""
    },
    {
      "text": "Supanya Aphiwongsophon and Prabhas Chongstitvatana. 2018. Detecting fake news with machine learning method. In 2018 15th international conference on electrical engineering/electronics, computer, telecommunications and information technology (ECTI-CON). IEEE, 528\u2013531.",
      "doi": ""
    },
    {
      "text": "Marc-Andr\u00e9 Argentino. [n.d.]. QAnon and the storm of the U.S. Capitol: The offline effect of online conspiracy theories. https://theconversation.com/qanon-and-the-storm-of-the-u-s-capitol-the-offline-effect-of-online-conspiracy-theories-152815",
      "doi": ""
    },
    {
      "text": "Cory\u00a0L Armstrong and Melinda\u00a0J McAdams. 2009. Blogs of information: How gender cues and individual motivations influence perceptions of credibility. Journal of Computer-Mediated Communication 14, 3 (2009), 435\u2013456.",
      "doi": ""
    },
    {
      "text": "Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Narendra\u00a0Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian Pan, Christine\u00a0T Wolf, 2021. AI-Assisted Human Labeling: Batching for Efficiency without Overreliance. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201327.",
      "doi": "10.1145/3449163"
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel Weld. 2021. Does the whole exceed its parts? the effect of ai explanations on complementary team performance. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3411764.3445717"
    },
    {
      "text": "Shashank Bengali. 2019. How WhatsApp is battling misinformation in India, where \u2019fake news is part of our culture\u2019. Los Angeles Times. https://www.latimes.com/world/la-fg-india-whatsapp-2019-story.html(2019).",
      "doi": ""
    },
    {
      "text": "Adam\u00a0J Berinsky, Gregory\u00a0A Huber, and Gabriel\u00a0S Lenz. 2012. Evaluating online labor markets for experimental research: Amazon. com\u2019s Mechanical Turk. Political analysis 20, 3 (2012), 351\u2013368.",
      "doi": ""
    },
    {
      "text": "Md\u00a0Momen Bhuiyan, Michael Horning, Sang\u00a0Won Lee, and Tanushree Mitra. 2021. NudgeCred: Supporting News Credibility Assessment on Social Media Through Nudges. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201330.",
      "doi": "10.1145/3479571"
    },
    {
      "text": "Md\u00a0Momen Bhuiyan, Amy\u00a0X Zhang, Connie\u00a0Moon Sehat, and Tanushree Mitra. 2020. Investigating Differences in Crowdsourced News Credibility Assessment: Raters, Tasks, and Expert Criteria. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2(2020), 1\u201326.",
      "doi": "10.1145/3415164"
    },
    {
      "text": "Monika Bickert. 2019. Combatting Vaccine Misinformation - About Facebook. Retrieved August 25, 2022 from https://about.fb.com/news/2019/03/combatting-vaccine-misinformation/",
      "doi": ""
    },
    {
      "text": "Hugo\u00a0L Borges and Ana\u00a0C Lorena. 2010. A survey on recommender systems for news data. In Smart Information and Knowledge Management. Springer, 129\u2013151.",
      "doi": ""
    },
    {
      "text": "Lukas Brozovsky and Vaclav Petricek. 2007. Recommender system for online dating service. arXiv preprint cs/0703042(2007).",
      "doi": ""
    },
    {
      "text": "Zana Bu\u00e7inca, Phoebe Lin, Krzysztof\u00a0Z Gajos, and Elena\u00a0L Glassman. 2020. Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems. In Proceedings of the 25th international conference on intelligent user interfaces. 454\u2013464.",
      "doi": "10.1145/3377325.3377498"
    },
    {
      "text": "Zana Bu\u00e7inca, Maja\u00a0Barbara Malaya, and Krzysztof\u00a0Z Gajos. 2021. To trust or to think: cognitive forcing functions can reduce overreliance on AI in AI-assisted decision-making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201321.",
      "doi": "10.1145/3449287"
    },
    {
      "text": "Robert Challen, Joshua Denny, Martin Pitt, Luke Gompels, Tom Edwards, and Krasimira Tsaneva-Atanasova. 2019. Artificial intelligence, bias and clinical safety. BMJ Quality & Safety 28, 3 (2019), 231\u2013237.",
      "doi": ""
    },
    {
      "text": "Katherine Clayton, Spencer Blair, Jonathan\u00a0A Busam, Samuel Forstner, John Glance, Guy Green, Anna Kawata, Akhila Kovvuri, Jonathan Martin, Evan Morgan, 2020. Real solutions for fake news? Measuring the effectiveness of general warnings and fact-check tags in reducing belief in false stories on social media. Political Behavior 42, 4 (2020), 1073\u20131095.",
      "doi": ""
    },
    {
      "text": "Alexander Cobleigh. 2020. TrustNet: Trust-based Moderation Using Distributed Chat Systems for Transitive Trust Propagation. (2020).",
      "doi": ""
    },
    {
      "text": "Josh Constine. 2017. Facebook puts link to 10 tips for spotting \u2018false news\u2019 atop feed. Retrieved August 25, 2022 from https://techcrunch.com/2017/04/06/facebook-puts-link-to-10-tips-for-spotting-false-news-atop-feed",
      "doi": ""
    },
    {
      "text": "Caroline\u00a0Mala Corbin. 2009. The First Amendment right against compelled listening. BUL Rev. 89(2009), 939.",
      "doi": ""
    },
    {
      "text": "Dan Cosley, Shyong\u00a0K Lam, Istvan Albert, Joseph\u00a0A Konstan, and John Riedl. 2003. Is seeing believing? How recommender system interfaces affect users\u2019 opinions. In Proceedings of the SIGCHI conference on Human factors in computing systems. 585\u2013592.",
      "doi": "10.1145/642611.642713"
    },
    {
      "text": "Pranav Dixit and Ryan Mac. 2018. How WhatsApp Destroyed A Village. Buzzfeed News (2018).",
      "doi": ""
    },
    {
      "text": "Jaimie Drozdal, Justin Weisz, Dakuo Wang, Gaurav Dass, Bingsheng Yao, Changruo Zhao, Michael Muller, Lin Ju, and Hui Su. 2020. Trust in AutoML: exploring information needs for establishing trust in automated machine learning systems. In Proceedings of the 25th international conference on intelligent user interfaces. 297\u2013307.",
      "doi": "10.1145/3377325.3377501"
    },
    {
      "text": "Tory\u00a0Newmyer Elizabeth\u00a0Dwoskin and Shibani Mahtani. 2021. The case against Mark Zuckerberg: Insiders say Facebook\u2019s CEO chose growth over safety. Retrieved August 25, 2022 from https://www.washingtonpost.com/technology/2021/10/25/mark-zuckerberg-facebook-whistleblower/",
      "doi": ""
    },
    {
      "text": "Ziv Epstein, Nicolo Foppiani, Sophie Hilgard, Sanjana Sharma, Elena Glassman, and David Rand. 2022. Do explanations increase the effectiveness of AI-crowd generated fake news warnings?. In Proceedings of the International AAAI Conference on Web and Social Media, Vol.\u00a016. 183\u2013193.",
      "doi": ""
    },
    {
      "text": "Ziv Epstein, Gordon Pennycook, and David Rand. 2020. Will the crowd game the algorithm? Using layperson judgments to combat misinformation on social media by downranking distrusted sources. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201311.",
      "doi": "10.1145/3313831.3376232"
    },
    {
      "text": "Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee Rickman, Kevin Hamilton, and Alex Kirlik. 2016. First I\" like\" it, then I hide it: Folk Theories of Social Feeds. In Proceedings of the 2016 cHI conference on human factors in computing systems. 2371\u20132382.",
      "doi": "10.1145/2858036.2858494"
    },
    {
      "text": "Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy Vuong, Karrie Karahalios, Kevin Hamilton, and Christian Sandvig. 2015. \" I always assumed that I wasn\u2019t really that close to [her]\" Reasoning about Invisible Algorithms in News Feeds. In Proceedings of the 33rd annual ACM conference on human factors in computing systems. 153\u2013162.",
      "doi": "10.1145/2702123.2702556"
    },
    {
      "text": "Jenny Fan and Amy\u00a0X Zhang. 2020. Digital juries: A civics-oriented approach to platform governance. In Proceedings of the 2020 CHI conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3313831.3376293"
    },
    {
      "text": "Elia Gabarron, Sunday\u00a0Oluwafemi Oyeyemi, and Rolf Wynn. 2021. COVID-19-related misinformation on social media: a systematic review. Bulletin of the World Health Organization 99, 6 (2021), 455.",
      "doi": ""
    },
    {
      "text": "Mingkun Gao, Ziang Xiao, Karrie Karahalios, and Wai-Tat Fu. 2018. To label or not to label: The effect of stance and credibility labels on readers\u2019 selection and perception of news articles. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201316.",
      "doi": "10.1145/3274324"
    },
    {
      "text": "R\u00a0Stuart Geiger. 2016. Bot-based collective blocklists in Twitter: the counterpublic moderation of harassment in a networked public space. Information, Communication & Society 19, 6 (2016), 787\u2013803.",
      "doi": ""
    },
    {
      "text": "Parham Ghobadi. 2022. Instagram moderators say Iran offered them bribes to remove accounts. Retrieved November 16, 2022 from https://www.bbc.com/news/world-middle-east-61516126",
      "doi": ""
    },
    {
      "text": "Kate Goddard, Abdul Roudsari, and Jeremy\u00a0C Wyatt. 2014. Automation bias: empirical results assessing influencing factors. International journal of medical informatics 83, 5(2014), 368\u2013375.",
      "doi": ""
    },
    {
      "text": "Kirsten Gollatz, Felix Beer, and Christian Katzenbach. 2018. The turn to artificial intelligence in governing communication online. (2018).",
      "doi": ""
    },
    {
      "text": "Sofia Grafanaki. 2018. Platforms, the First Amendment and Online Speech Regulating the Filters. Pace L. Rev. 39(2018), 111.",
      "doi": ""
    },
    {
      "text": "Ulrike Gretzel and Daniel\u00a0R Fesenmaier. 2006. Persuasion in recommender systems. International Journal of Electronic Commerce 11, 2 (2006), 81\u2013100.",
      "doi": "10.2753/JEC1086-4415110204"
    },
    {
      "text": "Jennifer Grygiel and Nina Brown. 2019. Are social media companies motivated to be good corporate citizens? Examination of the connection between corporate social responsibility and social media safety. Telecommunications policy 43, 5 (2019), 445\u2013460.",
      "doi": "10.1016/j.telpol.2018.12.003"
    },
    {
      "text": "Saqib Hakak, Mamoun Alazab, Suleman Khan, Thippa\u00a0Reddy Gadekallu, Praveen Kumar\u00a0Reddy Maddikunta, and Wazir\u00a0Zada Khan. 2021. An ensemble machine learning approach through effective feature extraction to classify fake news. Future Generation Computer Systems 117 (2021), 47\u201358.",
      "doi": ""
    },
    {
      "text": "Aniko Hannak, Drew Margolin, Brian Keegan, and Ingmar Weber. 2014. Get Back! You Don\u2019t Know Me Like That: The Social Mediation of Fact Checking Interventions in Twitter Conversations.. In ICWSM.",
      "doi": ""
    },
    {
      "text": "Peter\u00a0D Harms and Justin\u00a0A DeSimone. 2015. Caution! MTurk workers ahead\u2014Fines doubled. Industrial and Organizational Psychology 8, 2 (2015), 183\u2013190.",
      "doi": ""
    },
    {
      "text": "Kurtis Haut, Caleb Wohn, Victor Antony, Aidan Goldfarb, Melissa Welsh, Dillanie Sumanthiran, Ji-ze Jang, Md Ali, Ehsan Hoque, 2021. Could you become more credible by being White? Assessing impact of race on credibility with deepfakes. arXiv preprint arXiv:2102.08054(2021).",
      "doi": ""
    },
    {
      "text": "Hendrik Heuer and Elena\u00a0Leah Glassman. 2022. A Comparative Evaluation of Interventions Against Misinformation: Augmenting the WHO Checklist. In CHI Conference on Human Factors in Computing Systems. 1\u201321.",
      "doi": "10.1145/3491102.3517717"
    },
    {
      "text": "Hilary Hutchinson, Wendy Mackay, Bo Westerlund, Benjamin\u00a0B Bederson, Allison Druin, Catherine Plaisant, Michel Beaudouin-Lafon, St\u00e9phane Conversy, Helen Evans, Heiko Hansen, 2003. Technology probes: inspiring design for and with families. In Proceedings of the SIGCHI conference on Human factors in computing systems. 17\u201324.",
      "doi": "10.1145/642611.642616"
    },
    {
      "text": "Yasmin Ibrahim. 2017. Facebook and the Napalm Girl: reframing the iconic as pornographic. Social Media+ Society 3, 4 (2017), 2056305117743140.",
      "doi": ""
    },
    {
      "text": "Touseef Iqbal and Shaima Qureshi. 2020. The survey: Text generation models in deep learning. Journal of King Saud University-Computer and Information Sciences (2020).",
      "doi": ""
    },
    {
      "text": "Farnaz Jahanbakhsh, Amy\u00a0X Zhang, Adam\u00a0J Berinsky, Gordon Pennycook, David\u00a0G Rand, and David\u00a0R Karger. 2021. Exploring lightweight interventions at posting time to reduce the sharing of misinformation on social media. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201342.",
      "doi": "10.1145/3449092"
    },
    {
      "text": "Farnaz Jahanbakhsh, Amy\u00a0X Zhang, Karrie Karahalios, and David\u00a0R Karger. 2022. Our Browser Extension Lets Readers Change the Headlines on News Articles, and You Won\u2019t Believe What They Did!Proceedings of the ACM on Human-Computer Interaction 6, CSCW2(2022), 1\u201333.",
      "doi": ""
    },
    {
      "text": "Farnaz Jahanbakhsh, Amy\u00a0X Zhang, and David\u00a0R Karger. 2022. Leveraging Structured Trusted-Peer Assessments to Combat Misinformation. Proceedings of the ACM on Human-Computer Interaction 6, CSCW2(2022), 1\u201340.",
      "doi": "10.1145/3555637"
    },
    {
      "text": "Shagun Jhaver, Sucheta Ghoshal, Amy Bruckman, and Eric Gilbert. 2018. Online harassment and content moderation: The case of blocklists. ACM Transactions on Computer-Human Interaction (TOCHI) 25, 2(2018), 1\u201333.",
      "doi": "10.1145/3185593"
    },
    {
      "text": "Jooyeon Kim, Behzad Tabibian, Alice Oh, Bernhard Sch\u00f6lkopf, and Manuel Gomez-Rodriguez. 2018. Leveraging the crowd to detect and reduce the spread of fake news and misinformation. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 324\u2013332.",
      "doi": "10.1145/3159652.3159734"
    },
    {
      "text": "Jan Kirchner and Christian Reuter. 2020. Countering fake news: A comparison of possible solutions regarding user acceptance and effectiveness. Proceedings of the ACM on Human-computer Interaction 4, CSCW2(2020), 1\u201327.",
      "doi": "10.1145/3415211"
    },
    {
      "text": "Wolfgang Klein. 1994. Learning how to express temporality in a second language. In Societ\u00e0 di linguistica Italiana, SLI 34: Italiano-lingua seconda/lingua straniera: Atti del XXVI Congresso. Bulzoni, 227\u2013248.",
      "doi": ""
    },
    {
      "text": "Silvia Knobloch-Westerwick and Jingbo Meng. 2011. Reinforcement of the political self through selective exposure to political messages. Journal of Communication 61, 2 (2011), 349\u2013368.",
      "doi": ""
    },
    {
      "text": "Andr\u00e1s Koltay. 2022. The Protection of Freedom of Expression from Social Media Platforms. Mercer Law Review 73, 2 (2022), 6.",
      "doi": ""
    },
    {
      "text": "Todd Kulesza, Simone Stumpf, Margaret Burnett, and Irwin Kwan. 2012. Tell me more? The effects of mental model soundness on personalizing an intelligent agent. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 1\u201310.",
      "doi": "10.1145/2207676.2207678"
    },
    {
      "text": "Zhuoran Lu, Patrick Li, Weilong Wang, and Ming Yin. 2022. The Effects of AI-based Credibility Indicators on the Detection and Spread of Misinformation under Social Influence. Proceedings of the ACM on Human-Computer Interaction 6, CSCW2(2022), 1\u201327.",
      "doi": "10.1145/3555562"
    },
    {
      "text": "Kaitlin Mahar, Amy\u00a0X Zhang, and David Karger. 2018. Squadbox: A tool to combat email harassment using friendsourced moderation. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3173574.3174160"
    },
    {
      "text": "Ehesas\u00a0Mia Mahir, Saima Akhter, Mohammad\u00a0Rezwanul Huq, 2019. Detecting fake news using machine learning and deep learning algorithms. In 2019 7th International Conference on Smart Computing & Communications (ICSCC). IEEE, 1\u20135.",
      "doi": ""
    },
    {
      "text": "Pranav Malhotra. 2020. A Relationship-Centered and Culturally Informed Approach to Studying Misinformation on COVID-19. Social Media+ Society 6, 3 (2020), 2056305120948224.",
      "doi": ""
    },
    {
      "text": "Drew\u00a0B Margolin, Aniko Hannak, and Ingmar Weber. 2018. Political fact-checking on Twitter: When do corrections have an effect?Political Communication 35, 2 (2018), 196\u2013219.",
      "doi": ""
    },
    {
      "text": "Jaume Masip, Eugenio Garrido, and Carmen Herrero. 2004. Facial appearance and impressions of \u2018credibility\u2019: The effects of facial babyishness and age on person perception. International journal of psychology 39, 4 (2004), 276\u2013289.",
      "doi": ""
    },
    {
      "text": "Maria\u00a0D Molina and S\u00a0Shyam Sundar. 2022. Does distrust in humans predict greater trust in AI? Role of individual differences in user responses to content moderation. New Media & Society(2022), 14614448221103534.",
      "doi": ""
    },
    {
      "text": "Meredith\u00a0Ringel Morris, Scott Counts, Asta Roseway, Aaron Hoff, and Julia Schwarz. 2012. Tweeting is believing? Understanding microblog credibility perceptions. In Proceedings of the ACM 2012 conference on computer supported cooperative work. 441\u2013450.",
      "doi": "10.1145/2145204.2145274"
    },
    {
      "text": "Kathleen\u00a0L Mosier and Linda\u00a0J Skitka. 1999. Automation use and automation bias. In Proceedings of the human factors and ergonomics society annual meeting, Vol.\u00a043. SAGE Publications Sage CA: Los Angeles, CA, 344\u2013348.",
      "doi": ""
    },
    {
      "text": "Kathleen\u00a0L Mosier, Linda\u00a0J Skitka, Mark\u00a0D Burdick, and Susan\u00a0T Heers. 1996. Automation bias, accountability, and verification behaviors. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, Vol.\u00a040. SAGE Publications Sage CA: Los Angeles, CA, 204\u2013208.",
      "doi": ""
    },
    {
      "text": "Kathleen\u00a0L Mosier, Linda\u00a0J Skitka, Kristina\u00a0J Korte, M Mouloua, and R Parasuraman. 1994. Cognitive and social psychological issues in flight crew/automation interaction. Human performance in automated systems: Current research and trends (1994), 191\u2013197.",
      "doi": ""
    },
    {
      "text": "Mohsen Mosleh, Gordon Pennycook, Antonio\u00a0A Arechar, and David\u00a0G Rand. 2021. Cognitive reflection correlates with behavior on Twitter. Nature Communications 12, 1 (2021), 1\u201310.",
      "doi": ""
    },
    {
      "text": "Adam Mosseri. 2016. News feed fyi: Addressing hoaxes and fake news. Facebook newsroom 15(2016), 12.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook, Adam Bear, Evan\u00a0T Collins, and David\u00a0G Rand. 2020. The implied truth effect: Attaching warnings to a subset of fake news headlines increases perceived accuracy of headlines without warnings. Management Science 66, 11 (2020), 4944\u20134957.",
      "doi": "10.1287/mnsc.2019.3478"
    },
    {
      "text": "Gordon Pennycook, Ziv Epstein, Mohsen Mosleh, Antonio\u00a0A Arechar, Dean Eckles, and David\u00a0G Rand. 2021. Shifting attention to accuracy can reduce misinformation online. Nature 592, 7855 (2021), 590\u2013595.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook, Jonathon McPhetres, Yunhao Zhang, Jackson\u00a0G Lu, and David\u00a0G Rand. 2020. Fighting COVID-19 misinformation on social media: Experimental evidence for a scalable accuracy-nudge intervention. Psychological science 31, 7 (2020), 770\u2013780.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook and David\u00a0G Rand. 2019. Fighting misinformation on social media using crowdsourced judgments of news source quality. Proceedings of the National Academy of Sciences 116, 7 (2019), 2521\u20132526.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook and David\u00a0G Rand. 2019. Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition 188(2019), 39\u201350.",
      "doi": ""
    },
    {
      "text": "Sarah Perez. 2019. Facebook News Feed changes downrank misleading health info and dangerous \u2018cures\u2019. Retrieved August 25, 2022 from https://techcrunch.com/2019/07/02/facebook-news-feed-changes-downrank-misleading-health-info-and-dangerous-cures/",
      "doi": ""
    },
    {
      "text": "Emilee Rader and Rebecca Gray. 2015. Understanding user beliefs about algorithmic curation in the Facebook news feed. In Proceedings of the 33rd annual ACM conference on human factors in computing systems. 173\u2013182.",
      "doi": "10.1145/2702123.2702174"
    },
    {
      "text": "John Reed. 2018. Hate speech, atrocities and fake news: The crisis of democracy in Myanmar. Financial Times. Retrieved from https://www.ft.com/content/2003d54e-169a-11e8-9376-4a6390addb44(2018).",
      "doi": ""
    },
    {
      "text": "Emily Saltz, Claire\u00a0R Leibowicz, and Claire Wardle. 2021. Encounters with visual misinformation and labels across platforms: An interview and diary study to inform ecosystem approaches to misinformation interventions. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u20136.",
      "doi": "10.1145/3411763.3451807"
    },
    {
      "text": "David\u00a0O Sears and Jonathan\u00a0L Freedman. 1967. Selective exposure to information: A critical review. Public Opinion Quarterly 31, 2 (1967), 194\u2013213.",
      "doi": ""
    },
    {
      "text": "Haeseung Seo, Aiping Xiong, and Dongwon Lee. 2019. Trust it or not: Effects of machine-learning warnings in helping individuals mitigate misinformation. In Proceedings of the 10th ACM Conference on Web Science. 265\u2013274.",
      "doi": "10.1145/3292522.3326012"
    },
    {
      "text": "Emily\u00a0V Shaw, Mona Lynch, Sofia Laguna, and Steven\u00a0J Frenda. 2021. Race, witness credibility, and jury deliberation in a simulated drug trafficking trial.Law and human behavior 45, 3 (2021), 215.",
      "doi": ""
    },
    {
      "text": "Eyal Shnarch, Alon Halfon, Ariel Gera, Marina Danilevsky, Yannis Katsis, Leshem Choshen, Martin\u00a0Santillan Cooper, Dina Epelboim, Zheng Zhang, Dakuo Wang, Lucy Yip, Liat Ein-Dor, Lena Dankin, Ilya Shnayderman, Ranit Aharonov, Yunyao Li, Naftali Liberman, Philip\u00a0Levin Slesarev, Gwilym Newton, Shila Ofek-Koifman, Noam Slonim, and Yoav Katz. 2022. Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours. https://arxiv.org/abs/2208.01483",
      "doi": ""
    },
    {
      "text": "Robert Shrimsley. 2016. Facebook photos: snap judgments. Retrieved August 25, 2022 from https://www.ft.com/content/dbcdf744-7ac6-11e6-b837-eb4b4333ee43",
      "doi": ""
    },
    {
      "text": "Linda\u00a0J Skitka, Kathleen Mosier, and Mark\u00a0D Burdick. 2000. Accountability and automation bias. International Journal of Human-Computer Studies 52, 4 (2000), 701\u2013717.",
      "doi": "10.1006/ijhc.1999.0349"
    },
    {
      "text": "Brent Smith and Greg Linden. 2017. Two decades of recommender systems at Amazon. com. Ieee internet computing 21, 3 (2017), 12\u201318.",
      "doi": ""
    },
    {
      "text": "Alison Smith-Renner, Ron Fan, Melissa Birchfield, Tongshuang Wu, Jordan Boyd-Graber, Daniel\u00a0S Weld, and Leah Findlater. 2020. No explainability without accountability: An empirical study of explanations and feedback in interactive ml. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3313831.3376624"
    },
    {
      "text": "Dominic Spohr. 2017. Fake news and ideological polarization: Filter bubbles and selective exposure on social media. Business Information Review 34, 3 (2017), 150\u2013160.",
      "doi": ""
    },
    {
      "text": "Sara Spray. 2016. Facebook Is Embroiled In A Row With Activists Over \u201cCensorship\u201d. Retrieved August 25, 2022 from https://www.buzzfeed.com/saraspary/facebook-in-dispute-with-pro-kurdish-activists-over-deleted",
      "doi": ""
    },
    {
      "text": "Natalie\u00a0Jomini Stroud. 2010. Polarization and partisan selective exposure. Journal of communication 60, 3 (2010), 556\u2013576.",
      "doi": ""
    },
    {
      "text": "S\u00a0Shyam Sundar and Jinyoung Kim. 2019. Machine heuristic: When we trust computers more than humans with our personal information. In Proceedings of the 2019 CHI Conference on human factors in computing systems. 1\u20139.",
      "doi": "10.1145/3290605.3300768"
    },
    {
      "text": "Alan\u00a0R Wagner, Jason Borenstein, and Ayanna Howard. 2018. Overtrust in the robotic age. Commun. ACM 61, 9 (2018), 22\u201324.",
      "doi": "10.1145/3241365"
    },
    {
      "text": "Dakuo Wang and Gloria Mark. 2015. Internet censorship in China: Examining user awareness and attitudes. ACM Transactions on Computer-Human Interaction (TOCHI) 22, 6(2015), 1\u201322.",
      "doi": "10.1145/2818997"
    },
    {
      "text": "Dakuo Wang, Liuping Wang, Zhan Zhang, Ding Wang, Haiyi Zhu, Yvonne Gao, Xiangmin Fan, and Feng Tian. 2021. \u201cBrilliant AI doctor\u201d in rural clinics: Challenges in AI-powered clinical decision support system deployment. In Proceedings of the 2021 CHI conference on human factors in computing systems. 1\u201318.",
      "doi": "10.1145/3411764.3445432"
    },
    {
      "text": "Dakuo Wang, Justin\u00a0D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray. 2019. Human-AI collaboration in data science: Exploring data scientists\u2019 perceptions of automated AI. Proceedings of the ACM on human-computer interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359313"
    },
    {
      "text": "Jinping Wang, Maria\u00a0D Molina, and S\u00a0Shyam Sundar. 2020. When expert recommendation contradicts peer opinion: Relative social influence of valence, group identity and artificial intelligence. Computers in Human Behavior 107 (2020), 106278.",
      "doi": "10.1016/j.chb.2020.106278"
    },
    {
      "text": "Feiyu Xu, Hans Uszkoreit, Yangzhou Du, Wei Fan, Dongyan Zhao, and Jun Zhu. 2019. Explainable AI: A brief survey on history, research areas, approaches and challenges. In CCF international conference on natural language processing and Chinese computing. Springer, 563\u2013574.",
      "doi": "10.1007/978-3-030-32236-6_51"
    },
    {
      "text": "Waheeb Yaqub, Otari Kakhidze, Morgan\u00a0L Brockman, Nasir Memon, and Sameer Patil. 2020. Effects of credibility indicators on social media news sharing intent. In Proceedings of the 2020 chi conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3313831.3376213"
    },
    {
      "text": "Ming Yin, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2019. Understanding the effect of accuracy on trust in machine learning models. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201312.",
      "doi": "10.1145/3290605.3300509"
    },
    {
      "text": "Amy\u00a0X Zhang, Grant Hugh, and Michael\u00a0S Bernstein. 2020. PolicyKit: Building Governance in Online Communities. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology. 365\u2013378.",
      "doi": "10.1145/3379337.3415858"
    },
    {
      "text": "Amy\u00a0X Zhang, Aditya Ranganathan, Sarah\u00a0Emlen Metz, Scott Appling, Connie\u00a0Moon Sehat, Norman Gilmore, Nick\u00a0B Adams, Emmanuel Vincent, Jennifer Lee, Martin Robbins, 2018. A structured response to misinformation: Defining and annotating credibility indicators in news articles. In Companion Proceedings of the The Web Conference 2018. 603\u2013612.",
      "doi": "10.1145/3184558.3188731"
    },
    {
      "text": "Yunfeng Zhang, Q\u00a0Vera Liao, and Rachel\u00a0KE Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 295\u2013305.",
      "doi": "10.1145/3351095.3372852"
    }
  ]
}