{
  "doi": "10.1145/3544548.3581224",
  "title": "From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-16",
  "year": 2023,
  "badges": [],
  "abstract": "Consumer speech recognition systems do not work as well for many people with speech differences, such as stuttering, relative to the rest of the general population. However, what is not clear is the degree to which these systems do not work, how they can be improved, or how much people want to use them. In this paper, we first address these questions using results from a 61-person survey from people who stutter and find participants want to use speech recognition but are frequently cut off, misunderstood, or speech predictions do not represent intent. In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system. Through three technical investigations, we demonstrate how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.",
  "tags": [
    "dictation",
    "speech input",
    "accessibility",
    "stuttering",
    "voice assistants"
  ],
  "authors": [
    {
      "name": "Colin Lea",
      "institution": "Apple, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660782445",
      "orcid": "0000-0001-7068-3351"
    },
    {
      "name": "Zifang Huang",
      "institution": "Apple, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660782457",
      "orcid": "0000-0002-0564-0897"
    },
    {
      "name": "Jaya Narain",
      "institution": "Apple, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659528846",
      "orcid": "0000-0002-4395-3501"
    },
    {
      "name": "Lauren Tooley",
      "institution": "Apple, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660780822",
      "orcid": "0000-0002-3890-5636"
    },
    {
      "name": "Dianna Yee",
      "institution": "Apple, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660783258",
      "orcid": "0000-0002-2920-8732"
    },
    {
      "name": "Dung Tien Tran",
      "institution": "Apple Inc, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660782156",
      "orcid": "0000-0001-5647-0069"
    },
    {
      "name": "Panayiotis Georgiou",
      "institution": "Apple, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81318494236",
      "orcid": "0000-0002-0790-7161"
    },
    {
      "name": "Jeffrey P Bigham",
      "institution": "Apple, United States and Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81338487593",
      "orcid": "0000-0002-2072-0625"
    },
    {
      "name": "Leah Findlater",
      "institution": "Apple, United States and Human Centered Design and Engineering, University of Washington, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100170743",
      "orcid": "0000-0002-5619-4452"
    }
  ],
  "references": [
    {
      "text": "Ali Abdolrahmani, Ravi Kuber, and Stacy\u00a0M Branham. 2018. \u201cSiri Talks at You\u201d An Empirical Investigation of Voice-Activated Personal Assistant (VAPA) Usage by Individuals Who Are Blind. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility. 249\u2013258.",
      "doi": "10.1145/3234695.3236344"
    },
    {
      "text": "Sadeen Alharbi, Madina Hasan, Anthony\u00a0JH Simons, Shelagh Brumfitt, and Phil Green. 2018. A lightly supervised approach to detect stuttering in children\u2019s speech. In Interspeech 2018. ISCA, 3433\u20133437.",
      "doi": ""
    },
    {
      "text": "Sadeen Alharbi, Anthony J.\u00a0H. Simons, Shelagh Brumfitt, and Phil\u00a0D. Green. 2017. Automatic recognition of children\u2019s read speech for stuttering application. International Workshop on Child Computer Interaction WOCCI (2017).",
      "doi": ""
    },
    {
      "text": "Tawfiq Ammari, Jofish Kaye, Janice\u00a0Y. Tsai, and Frank Bentley. 2019. Music, Search, and IoT: How People (Really) Use Voice Assistants. ACM Transactions on Computer-Human Interaction. 26, 3, Article 17 (apr 2019), 28\u00a0pages.",
      "doi": "10.1145/3311956"
    },
    {
      "text": "Raviteja Anantha, Srinivas Chappidi, and Arash\u00a0W Dawoodi. 2020. Learning to Rank Intents in Voice Assistants. In Conversational Dialogue Systems for the Next Decade. Springer Singapore, Singapore, 87\u2013101.",
      "doi": ""
    },
    {
      "text": "Gavin Andrews and Mary Harris. 1964. The syndrome of stuttering.Spastics Society Medical Education(1964).",
      "doi": ""
    },
    {
      "text": "Apple. 2022. Speech Framework. https://developer.apple.com/documentation/speech.",
      "doi": ""
    },
    {
      "text": "KN Arjun, S Karthik, D Kamalnath, Pranavi Chanda, and Shikha Tripathi. 2020. Automatic Correction of Stutter in Disfluent Speech. CoCoNet (2020).",
      "doi": ""
    },
    {
      "text": "Fabio Ballati, Fulvio Corno, and Luigi De\u00a0Russis. 2018. Assessing virtual assistant capabilities with Italian dysarthric speech. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility. 93\u2013101.",
      "doi": "10.1145/3234695.3236354"
    },
    {
      "text": "Santosh Basapur, Shuang Xu, Mark Ahlenius, and Young\u00a0Seok Lee. 2007. User Expectations from Dictation on Mobile Devices. In Human-Computer Interaction. Interaction Platforms and Techniques, Julie\u00a0A. Jacko (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 217\u2013225.",
      "doi": ""
    },
    {
      "text": "Sebastian Bayerl, Florian H\u00f6nig, Joelle Reister, and Korbinian Riedhammer. 2020. Towards Automated Assessment of Stuttering and Stuttering Therapy. In International Conference on Text, Speech, and Dialogue.",
      "doi": ""
    },
    {
      "text": "Sebastian\u00a0P Bayerl, Alexander\u00a0Wolff von Gudenberg, Florian H\u00f6nig, Elmar N\u00f6th, and Korbinian Riedhammer. 2022. KSoF: The Kassel State of Fluency Dataset\u2013A Therapy Centered Dataset of Stuttering. arXiv preprint arXiv:2203.05383(2022).",
      "doi": ""
    },
    {
      "text": "Anna Bleakley, Daniel Rough, Abi Roper, Stephen Lindsay, Martin Porcheron, Minha Lee, Stuart Nicholson, Benjamin Cowan, and Leigh Clark. 2022. Exploring Smart Speaker User Experience for People Who Stammer. In Proceedings of the ACM SIGACCESS Conference on Computers & Accessibility.",
      "doi": "10.1145/3517428.3544823"
    },
    {
      "text": "Michael\u00a0P Cannito, Annette\u00a0Renee Burch, Christopher Watts, Patrick\u00a0W Rappold, Stephen\u00a0B Hood, and Kyla Sherrard. 1997. Disfluency in spasmodic dysphonia: A multivariate analysis. Journal of Speech, Language, and Hearing Research 40, 3 (1997), 627\u2013641.",
      "doi": ""
    },
    {
      "text": "William Chan, Navdeep Jaitly, Quoc\u00a0V Le, and Oriol Vinyals. 2015. Listen, attend and spell. arXiv preprint arXiv:1508.01211(2015).",
      "doi": ""
    },
    {
      "text": "Xi\u00a0C Chen, Adithya Sagar, Justine\u00a0T Kao, Tony\u00a0Y Li, Christopher Klein, Stephen Pulman, Ashish Garg, and Jason\u00a0D Williams. 2019. Active learning for domain classification in a commercial spoken personal assistant. Interspeech (2019).",
      "doi": ""
    },
    {
      "text": "Leigh Clark, Benjamin\u00a0R. Cowan, Abi Roper, Stephen Lindsay, and Owen Sheers. 2020. Speech Diversity and Speech Interfaces: Considering an Inclusive Future through Stammering. In Proceedings of the 2nd Conference on Conversational User Interfaces (Bilbao, Spain) (CUI \u201920). Association for Computing Machinery, New York, NY, USA, Article 24, 3\u00a0pages. https://doi.org/10.1145/3405755.3406139",
      "doi": "10.1145/3405755.3406139"
    },
    {
      "text": "Eric Corbett and Astrid Weber. 2016. What can I say? addressing user experience challenges of a mobile voice user interface for accessibility. In Proceedings of the 18th international conference on human-computer interaction with mobile devices and services. 72\u201382.",
      "doi": "10.1145/2935334.2935386"
    },
    {
      "text": "Moira Corcoran. 2018. When Alexa Can\u2019t Understand You. Slate (online).",
      "doi": ""
    },
    {
      "text": "Ashley Craig, Karen Hancock, Yvonne Tran, Magali Craig, and Karen Peters. 2002. Epidemiology of stuttering in the community across the entire life span. (2002).",
      "doi": ""
    },
    {
      "text": "Frederic\u00a0L Darley, Arnold\u00a0E Aronson, and Joe\u00a0R Brown. 1969. Differential diagnostic patterns of dysarthria. Journal of speech and hearing research 12, 2 (1969), 246\u2013269.",
      "doi": ""
    },
    {
      "text": "Arun Das, Jeffrey Mock, Henry Chacon, Farzan Irani, Edward Golob, and Peyman Najafirad. 2020. Stuttering Speech Disfluency Prediction using Explainable Attribution Vectors of Facial Muscle Movements. In arXiv.",
      "doi": ""
    },
    {
      "text": "Ankit Dash, Nikhil Subramani, Tejas Manjunath, Vishruti Yaragarala, and Shikha Tripathi. 2018. Speech Recognition and Correction of a Stuttered Speech. In 2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI). 1757\u20131760.",
      "doi": ""
    },
    {
      "text": "Katie Deighton. 2021. Tech Firms Train Voice Assistants to Understand Atypical Speech. Wall Street Journal (online).",
      "doi": ""
    },
    {
      "text": "Iva Demarin, Ljubica Leko, Maja \u0160krobo, Helena Germano, Patr\u00edcia Macedo, and Rui\u00a0Neves Madeira. 2015. The Impact of Stuttering; How Can a Mobile App Help?. In Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility. 399\u2013400.",
      "doi": "10.1145/2700648.2811389"
    },
    {
      "text": "Joseph\u00a0R Duffy. 2019. Motor speech disorders e-book: Substrates, differential diagnosis, and management. Elsevier Health Sciences.",
      "doi": ""
    },
    {
      "text": "William\u00a0S Evans, William\u00a0D Hula, Yina Quique, and Jeffrey\u00a0J Starns. 2020. How much time do people with aphasia need to respond during picture naming? Estimating optimal response time cutoffs using a multinomial ex-Gaussian approach. Journal of Speech, Language, and Hearing Research 63, 2 (2020), 599\u2013614.",
      "doi": ""
    },
    {
      "text": "Raymond Fok, Harmanpreet Kaur, Skanda Palani, Martez\u00a0E Mott, and Walter\u00a0S Lasecki. 2018. Towards more robust speech interactions for deaf and hard of hearing users. In Proceedings of the 20th international ACM SIGACCESS conference on computers and accessibility. 57\u201367.",
      "doi": "10.1145/3234695.3236343"
    },
    {
      "text": "Bhavya Ghai and Klaus Mueller. 2021. Fluent: An AI Augmented Writing Tool for People who Stutter. In The 23rd International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 1\u20138.",
      "doi": "10.1145/3441852.3471211"
    },
    {
      "text": "Alexander\u00a0M Goberman, Michael Blomgren, and Erika Metzger. 2010. Characteristics of speech disfluency in Parkinson disease. Journal of Neurolinguistics 23, 5 (2010), 470\u2013478.",
      "doi": ""
    },
    {
      "text": "Sashank Gondala, Lyan Verwimp, Ernest Pusateri, Manos Tsagkias, and Christophe Van\u00a0Gysel. 2021. Error-driven Pruning of Language Models for Virtual Assistants. arXiv preprint arXiv:2102.07219(2021).",
      "doi": ""
    },
    {
      "text": "Alex Graves. 2012. Sequence transduction with recurrent neural networks. arXiv preprint arXiv:1211.3711(2012).",
      "doi": ""
    },
    {
      "text": "Jordan\u00a0R Green, Robert\u00a0L MacDonald, Pan-Pan Jiang, Julie Cattiau, Rus Heywood, Richard Cave, Katie Seaver, Marilyn\u00a0A Ladewig, Jimmy Tobin, Michael\u00a0P Brenner, 2021. Automatic Speech Recognition of Disordered Speech: Personalized Models Outperforming Human Listeners on Short Phrases.. In Interspeech. 4778\u20134782.",
      "doi": ""
    },
    {
      "text": "Kenneth Heafield, Ivan Pouzyrevsky, Jonathan Clark, and Philipp Koehn. 2013. Scalable Modified Kneser-Ney Language Model Estimation. In In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 690\u2013696. Association for Computational Linguistics.",
      "doi": ""
    },
    {
      "text": "Peter\u00a0A Heeman, Rebecca Lunsford, Andy McMillin, and J\u00a0Scott Yaruss. 2016. Using Clinician Annotations to Improve Automatic Speech Recognition of Stuttered Speech. In Interspeech. 2651\u20132655.",
      "doi": ""
    },
    {
      "text": "Geoffrey Hinton, Li Deng, Dong Yu, George\u00a0E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara\u00a0N Sainath, 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal processing magazine 29, 6 (2012), 82\u201397.",
      "doi": ""
    },
    {
      "text": "Peter Howell, Stephen Davis, and Jon Bartrip. 2009. The UCLASS archive of stuttered speech. Journal of Speech Language and Hearing Research 52 (2009), 556.",
      "doi": ""
    },
    {
      "text": "Zhen Huang, Tim Ng, Leo Liu, Henry Mason, Xiaodan Zhuang, and Daben Liu. 2020. SNDCNN: Self-normalizing deep CNNs with scaled exponential linear units for speech recognition. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6854\u20136858.",
      "doi": ""
    },
    {
      "text": "Fabiola\u00a0Star\u00f3bole Juste, Fernanda\u00a0Chiarion Sassi, Julia\u00a0Biancalana Costa, and Claudia Regina\u00a0Furquim de Andrade. 2018. Frequency of speech disruptions in Parkinson\u2019s Disease and developmental stuttering: A comparison among speech tasks. Plos one 13, 6 (2018), e0199054.",
      "doi": ""
    },
    {
      "text": "Tedd Kourkounakis, Amirhossein Hajavi, and Ali Etemad. 2020. Detecting Multiple Speech Disfluencies Using a Deep Residual Network with Bidirectional Long Short-Term Memory. In ICASSP. IEEE.",
      "doi": ""
    },
    {
      "text": "Duc Le, Thilo Koehler, Christian Fuegen, and Michael\u00a0L. Seltzer. 2020. G2G: TTS-DRIVEN PRONUNCIATION LEARNING FOR GRAPHEMIC HYBRID ASR. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6869\u20136873.",
      "doi": ""
    },
    {
      "text": "Colin Lea, Vikramjit Mitra, Aparna Joshi, Sachin Kajarekar, and Jeffrey\u00a0P Bigham. 2021. SEP-28k: A Dataset for Stuttering Event Detection From Podcasts With People Who Stutter. arXiv preprint arXiv:2102.12394(2021).",
      "doi": ""
    },
    {
      "text": "Colin Lea, Vikramjit Mitra, Aparna Joshi, Sachin Kajarekar, and Jeffrey\u00a0P. Bigham. 2021. SEP-28k: A Dataset for Stuttering Event Detection From Podcasts With People Who Stutter. In ICASSP. IEEE.",
      "doi": ""
    },
    {
      "text": "Bo Li, Shuo-yiin Chang, Tara\u00a0N Sainath, Ruoming Pang, Yanzhang He, Trevor Strohman, and Yonghui Wu. 2020. Towards fast and accurate streaming end-to-end ASR. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6069\u20136073.",
      "doi": ""
    },
    {
      "text": "Roland Maas, Ariya Rastrow, Chengyuan Ma, Guitang Lan, Kyle Goehner, Gautam Tiwari, Shaun Joseph, and Bj\u00f6rn Hoffmeister. 2018. Combining Acoustic Embeddings and Decoding Features for End-of-Utterance Detection in Real-Time Far-Field Speech Recognition Systems. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 5544\u20135548.",
      "doi": ""
    },
    {
      "text": "Bob MacDonald, Pan-Pan Jiang, Julie Cattiau, Rus Heywood, Richard Cave, Katie Seaver, Marilyn Ladewig, Jimmy Tobin, Michael Brenner, Philip\u00a0Q Nelson, Jordan\u00a0R. Green, and Katrin Tomanek. 2021. Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia.",
      "doi": ""
    },
    {
      "text": "Rui\u00a0Neves Madeira, Patr\u00edcia Macedo, Pedro Pita, \u00cdris Bonan\u00e7a, and Helena Germano. 2013. Building on mobile towards better stuttering awareness to improve speech therapy. In Proceedings of International Conference on Advances in Mobile Computing & Multimedia. 551\u2013554.",
      "doi": "10.1145/2536853.2536911"
    },
    {
      "text": "P. Mahesha and D.S. Vinod. 2016. Gaussian Mixture Model Based Classification of Stuttering Dysfluencies. Journal of Intelligent Systems 25, 3 (2016), 387\u2013399.",
      "doi": ""
    },
    {
      "text": "Roisin McNaney, Christopher Bull, Lynne Mackie, Floriane Dahman, Helen Stringer, Dan Richardson, and Daniel Welsh. 2018. StammerApp: Designing a Mobile Application to Support Self-Reflection and Goal Setting for People Who Stammer. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 1\u201312.",
      "doi": "10.1145/3173574.3173841"
    },
    {
      "text": "Valentin Mendelev, Tina Raissi, Guglielmo Camporese, and Manuel Giollo. 2020. Improved Robustness to Disfluencies in RNN-Transducer Based Speech Recognition. In arXiv. arXiv:2012.06259\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "Vikramjit Mitra, Zifang Huang, Colin Lea, Lauren Tooley, Sarah Wu, Darren Botten, Ashwini Palekar, Shrinath Thelapurath, Panayiotis Georgiou, Sachin Kajarekar, 2021. Analysis and tuning of a voice assistant system for dysfluent speech. arXiv preprint arXiv:2106.11759(2021).",
      "doi": ""
    },
    {
      "text": "Thomas Murry. 2014. Spasmodic dysphonia: let\u2019s look at that again. Journal of Voice 28, 6 (2014), 694\u2013699.",
      "doi": ""
    },
    {
      "text": "National Public Media. 2022. NPR Smart Audio Report. https://www.nationalpublicmedia.com/insights/reports/smart-audio-report/.",
      "doi": ""
    },
    {
      "text": "Alisha Pradhan, Kanika Mehta, and Leah Findlater. 2018. \u201cAccessibility Came by Accident\u201d: Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities. In Proceedings of the 2018 CHI Conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3173574.3174033"
    },
    {
      "text": "Nan\u00a0Bernstein Ratnera and Brian MacWhinney. 2018. Fluency Bank: A new resource for fluency research and practice. Journal of Fluency Disorders(2018).",
      "doi": ""
    },
    {
      "text": "Rachid Riad, Anne-Catherine Bachoud-L\u00e9vi, Frank Rudzicz, and Emmanuel Dupoux. 2020. Identification of Primary and Collateral Tracks in Stuttered Speech. In LREC. European Language Resources Association.",
      "doi": ""
    },
    {
      "text": "Glyndon\u00a0D Riley. 2009. SSI-4 stuttering severity instrument fourth edition.",
      "doi": ""
    },
    {
      "text": "Abi Roper, Stephanie Wilson, Timothy Neate, and Jane Marshall. 2019. Speech and Language. In Web Accessibility. Springer, 121\u2013131.",
      "doi": ""
    },
    {
      "text": "Hasim Sak, Francoise Beaufays, Kaisuke Nakajima, and Cyril Allauzen. 2013. Language model verbalization for automatic speech recognition. In ICASSP 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE.",
      "doi": ""
    },
    {
      "text": "Eric\u00a0K Sander. 1963. Frequency of syllable repetition and \u2018stutterer\u2019judgments. Journal of Speech and Hearing Disorders 28, 1 (1963), 19\u201330.",
      "doi": ""
    },
    {
      "text": "Olabanji Shonibare, Xiaosu Tong, and Venkatesh Ravichandran. 2022. Enhancing ASR for Stuttered Speech with Limited Data Using Detect and Pass. arXiv preprint arXiv:2202.05396(2022).",
      "doi": ""
    },
    {
      "text": "Andreas Stolcke and Jasha Droppo. 2017. Comparing Human and Machine Errors in Conversational Speech Transcription. In Proc of INTERSPEECH 2017. IEEE, 137\u2013141.",
      "doi": ""
    },
    {
      "text": "Joanne\u00a0D Subtelny, Robert\u00a0L Whitehead, and Vincent\u00a0J Samar. 1992. Spectral study of deviant resonance in the speech of women who are deaf. Journal of Speech, Language, and Hearing Research 35, 3 (1992), 574\u2013579.",
      "doi": ""
    },
    {
      "text": "Seth\u00a0E Tichenor and J\u00a0Scott Yaruss. 2021. Variability of stuttering: Behavior and impact. American Journal of Speech-Language Pathology 30, 1 (2021), 75\u201388.",
      "doi": ""
    },
    {
      "text": "Jimmy Tobin and Katrin Tomanek. 2022. Personalized Automatic Speech Recognition Trained on Small Disordered Speech Datasets. In ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6637\u20136641.",
      "doi": ""
    },
    {
      "text": "David Ward and Kathleen\u00a0S Scott. 2011. Cluttering: A Handbook of Research. Intervention and Education(2011).",
      "doi": ""
    },
    {
      "text": "Kevin Wheeler. 2020. For people who stutter, the convenience of voice assistant technology remains out of reach. USA Today (online).",
      "doi": ""
    },
    {
      "text": "Wayne Xiong, Jasha Droppo, Xuedong Huang, Frank Seide, Mike Seltzer, Andreas Stolcke, Dong Yu, and Geoffrey Zweig. 2016. Achieving Human Parity in Conversational Speech Recognition. CoRR abs/1610.05256. arXiv:1610.05256",
      "doi": ""
    },
    {
      "text": "W. Xiong, L. Wu, F. Alleva, J. Droppo, X. Huang, and A. Stolcke. 2018. The Microsoft 2017 Conversational Speech Recognition System. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE.",
      "doi": ""
    },
    {
      "text": "J\u00a0Scott Yaruss and Robert\u00a0W Quesal. 2006. Overall Assessment of the Speaker\u2019s Experience of Stuttering (OASES): Documenting multiple outcomes in stuttering treatment. Journal of fluency disorders 31, 2 (2006), 90\u2013115.",
      "doi": ""
    },
    {
      "text": "Cheng Yi, Shiyu Zhou, and Bo Xu. 2021. Effciently fusing pretrained acoustic and linguistic encoders for low-resource speech recognition. In IEEE Signal Processing Letters, Vol.\u00a028. IEEE, 788\u2013792.",
      "doi": ""
    },
    {
      "text": "Yu Zhong, TV Raman, Casey Burkhardt, Fadi Biadsy, and Jeffrey\u00a0P Bigham. 2014. JustSpeak: enabling universal voice control on Android. In Proceedings of the 11th Web for All Conference. 1\u20134.",
      "doi": "10.1145/2596695.2596720"
    }
  ]
}