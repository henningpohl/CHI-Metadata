{
  "doi": "10.1145/3544548.3580810",
  "title": "Understanding and Enhancing The Role of Speechreading in Online d/DHH Communication Accessibility",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-17",
  "year": 2023,
  "badges": [],
  "abstract": "Speechreading is the art of using visual and contextual cues in the environment to support listening. Often used by d/Deaf and Hard-of-Hearing (d/DHH) individuals, it highlights nuances of rich communication. However, lived experiences of speechreaders are underdocumented in HCI literature, and the impact of online environments and interactions of captioning with speechreading has not been explored in depth. We bridge these gaps through a three-part study consisting of formative interviews, design probes, and design sessions with 12 d/DHH individuals who speechread. Our primary contribution is to understand the lived experience of speechreading in online communication, and thus to better understand the richness and variety of techniques d/DHH individuals use to provision access. We highlight technical, environmental and sociocultural factors that impact communication accessibility, explore the design space of speechreading supports and share considerations for the design future of speechreading technology.",
  "tags": [
    "Accessible Video Calls",
    "d/Deaf and Hard-of-Hearing",
    "Speechreading"
  ],
  "authors": [
    {
      "name": "Aashaka Desai",
      "institution": "Paul G. Allen School of Computer Science and Engineering, University of Washington, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660617195",
      "orcid": "0000-0003-4601-8137"
    },
    {
      "name": "Jennifer Mankoff",
      "institution": "Paul G. Allen School of Computer Science and Engineering, University of Washington, United States",
      "img": "/do/10.1145/contrib-81100650762/rel-imgonly/jenmankoff2.jpg",
      "acmid": "81100650762",
      "orcid": "0000-0001-9235-5324"
    },
    {
      "name": "Richard E. Ladner",
      "institution": "Paul G. Allen School of Computer Science & Engineering, University of Washington, United States",
      "img": "/do/10.1145/contrib-81100297556/rel-imgonly/ladner3.jpg",
      "acmid": "81100297556",
      "orcid": "0000-0001-9413-6774"
    }
  ],
  "references": [
    {
      "text": "2022. CDC Speechreading. https://www.cdc.gov/ncbddd/hearingloss/parentsguide/building/speech-reading.html.",
      "doi": ""
    },
    {
      "text": "Abdullah\u00a0Mefareh Almelhi. 2020. Understanding code-switching from a sociolinguistic perspective: A meta-analysis. International Journal of Language and Linguistics 8, 1(2020), 34\u201345.",
      "doi": ""
    },
    {
      "text": "Stefan Andrei, Lawrence Osborne, and Zanthia Smith. 2013. Designing an American Sign Language avatar for learning computer science concepts for deaf or hard-of-hearing students and deaf interpreters. Journal of Educational Multimedia and Hypermedia 22, 3(2013), 229\u2013242.",
      "doi": ""
    },
    {
      "text": "Jazz Rui\u00a0Xia Ang, Ping Liu, Emma\u00a0J. McDonnell, and Sarah Coppola. 2022. \u201cIn this online environment, we\u2019re limited\u201d: Exploring Inclusive Video Conferencing Design for Signers.. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3491102.3517488"
    },
    {
      "text": "Virginie Attina, Denis Beautemps, Marie-Agn\u00e8s Cathiard, and Matthias Odisio. 2004. A pilot study of temporal organization in Cued Speech production of French syllables: rules for a Cued Speech synthesizer. Speech Communication 44, 1-4 (2004), 197\u2013214.",
      "doi": ""
    },
    {
      "text": "Virginie Attina, Marie-Agn\u00e8s Cathiard, and Denis Beautemps. 2005. Temporal measures of hand and speech coordination during French Cued Speech production. In International Gesture Workshop. Springer, 13\u201324.",
      "doi": ""
    },
    {
      "text": "H-Dirksen\u00a0L Bauman. 2004. Audism: Exploring the metaphysics of oppression. Journal of deaf studies and deaf education 9, 2 (2004), 239\u2013246.",
      "doi": ""
    },
    {
      "text": "Cynthia\u00a0L Bennett, Erin Brady, and Stacy\u00a0M Branham. 2018. Interdependence as a frame for assistive technology research and design. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility. 161\u2013173.",
      "doi": "10.1145/3234695.3236348"
    },
    {
      "text": "Larwan Berke, Khaled Albusays, Matthew Seita, and Matt Huenerfauth. 2019. Preferred Appearance of Captions Generated by Automatic Speech Recognition for Deaf and Hard-of-Hearing Viewers. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI EA \u201919). Association for Computing Machinery, New York, NY, USA, 1\u20136. https://doi.org/10.1145/3290607.3312921",
      "doi": "10.1145/3290607.3312921"
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative research in psychology 3, 2 (2006), 77\u2013101.",
      "doi": ""
    },
    {
      "text": "Senthil Chandrasegaran, Chris Bryan, Hidekazu Shidara, Tung-Yen Chuang, and Kwan-Liu Ma. 2019. TalkTraces: Real-time capture and visualization of verbal content in meetings. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3290605.3300807"
    },
    {
      "text": "R\u00a0Orin Cornett. 1967. Cued speech. American annals of the deaf(1967), 3\u201313.",
      "doi": ""
    },
    {
      "text": "R\u00a0Orin Cornett. 1994. Adapting Cued Speech to additional languages. Cued Speech Journal 5(1994), 19\u201329.",
      "doi": ""
    },
    {
      "text": "Paul Duchnowski, David\u00a0S Lum, Jean\u00a0C Krause, Matthew\u00a0G Sexton, Maroula\u00a0S Bratakos, and Louis\u00a0D Braida. 2000. Development of speechreading supplements based on automatic speech recognition. IEEE transactions on biomedical engineering 47, 4 (2000), 487\u2013496.",
      "doi": ""
    },
    {
      "text": "Heather\u00a0A. Faucett, Matthew\u00a0L. Lee, and Scott Carter. 2017. I Should Listen More: Real-Time Sensing and Feedback of Non-Verbal Communication in Video Telehealth. 1, CSCW, Article 44 (dec 2017), 19\u00a0pages. https://doi.org/10.1145/3134679",
      "doi": "10.1145/3134679"
    },
    {
      "text": "Heather\u00a0A Faucett, Kate\u00a0E Ringland, Amanda\u00a0LL Cullen, and Gillian\u00a0R Hayes. 2017. (In) visibility in disability and assistive technology. ACM Transactions on Accessible Computing (TACCESS) 10, 4 (2017), 1\u201317.",
      "doi": "10.1145/3132040"
    },
    {
      "text": "Benjamin\u00a0M Gorman. 2016. Reducing viseme confusion in speech-reading. ACM SIGACCESS Accessibility and Computing114 (2016), 36\u201343.",
      "doi": ""
    },
    {
      "text": "Benjamin\u00a0M. Gorman. 2018. A Framework for Speechreading Acquisition Tools. University of Dundee. Ph.D. Dissertation.",
      "doi": ""
    },
    {
      "text": "Benjamin\u00a0M. Gorman and David\u00a0R. Flatla. 2017. A Framework for Speechreading Acquisition Tools(CHI \u201917). Association for Computing Machinery, New York, NY, USA, 12\u00a0pages. https://doi.org/10.1145/3025453.3025560",
      "doi": "10.1145/3025453.3025560"
    },
    {
      "text": "Benjamin\u00a0M Gorman and David\u00a0R Flatla. 2018. Mirrormirror: A mobile application to improve speechreading acquisition. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3173574.3173600"
    },
    {
      "text": "Michael Gower, Brent Shiver, Charu Pandhi, and Shari Trewin. 2018. Leveraging pauses to improve video captions. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility. 414\u2013416.",
      "doi": "10.1145/3234695.3241023"
    },
    {
      "text": "David\u00a0M. Grayson and Andrew\u00a0F. Monk. 2003. Are You Looking at Me? Eye Contact and Desktop Video Conferencing. ACM Trans. Comput.-Hum. Interact. 10, 3 (sep 2003), 221\u2013243. https://doi.org/10.1145/937549.937552",
      "doi": "10.1145/937549.937552"
    },
    {
      "text": "Beth\u00a0G Greene, David\u00a0B Pisoni, and Thomas\u00a0D Carrell. 1984. Recognition of speech spectrograms. The Journal of the Acoustical Society of America 76, 1 (1984), 32\u201343.",
      "doi": ""
    },
    {
      "text": "Rebecca\u00a0Perkins Harrington and Gregg\u00a0C Vanderheiden. 2013. Crowd caption correction (CCC). In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility. 1\u20132.",
      "doi": "10.1145/2513383.2513413"
    },
    {
      "text": "Jon Henner and Octavian Robinson. 2021. Unsettling Languages, Unruly Bodyminds: Imaging a Crip Linguistics. https://doi.org/10.31234/osf.io/7bzaw",
      "doi": ""
    },
    {
      "text": "Adeline\u00a0F Hillier, Claire\u00a0E Hillier, and David\u00a0A Hillier. 2018. A modified spectrogram with possible application as a visual hearing aid for the deaf. The Journal of the Acoustical Society of America 144, 3 (2018), 1517\u20131520.",
      "doi": ""
    },
    {
      "text": "Richang Hong, Meng Wang, Mengdi Xu, Shuicheng Yan, and Tat-Seng Chua. 2010. Dynamic captioning: video accessibility enhancement for hearing impairment. In Proceedings of the 18th ACM international conference on Multimedia. 421\u2013430.",
      "doi": "10.1145/1873951.1874013"
    },
    {
      "text": "Ryo Iijima, Akihisa Shitara, Sayan Sarcar, and Yoichi Ochiai. 2021. Word Cloud for Meeting: A Visualization System for DHH People in Online Meetings. In The 23rd International ACM SIGACCESS Conference on Computers and Accessibility(Virtual Event, USA) (ASSETS \u201921). Association for Computing Machinery, New York, NY, USA, Article 99, 4\u00a0pages. https://doi.org/10.1145/3441852.3476547",
      "doi": "10.1145/3441852.3476547"
    },
    {
      "text": "Dhruv Jain, Bonnie Chinh, Leah Findlater, Raja Kushalnagar, and Jon Froehlich. 2018. Exploring augmented reality approaches to real-time captioning: A preliminary autoethnographic study. In Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems. 7\u201311.",
      "doi": "10.1145/3197391.3205404"
    },
    {
      "text": "Dhruv Jain, Audrey Desjardins, Leah Findlater, and Jon\u00a0E Froehlich. 2019. Autoethnography of a hard of hearing traveler. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. 236\u2013248.",
      "doi": "10.1145/3308561.3353800"
    },
    {
      "text": "Dhruv Jain, Leah Findlater, Jamie Gilkeson, Benjamin Holland, Ramani Duraiswami, Dmitry Zotkin, Christian Vogler, and Jon\u00a0E Froehlich. 2015. Head-mounted display visualizations to support sound awareness for the deaf and hard of hearing. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 241\u2013250.",
      "doi": "10.1145/2702123.2702393"
    },
    {
      "text": "Sushant Kafle, Peter Yeung, and Matt Huenerfauth. 2019. Evaluating the Benefit of Highlighting Key Words in Captions for People Who Are Deaf or Hard of Hearing. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility (Pittsburgh, PA, USA) (ASSETS \u201919). Association for Computing Machinery, New York, NY, USA, 43\u201355. https://doi.org/10.1145/3308561.3353781",
      "doi": "10.1145/3308561.3353781"
    },
    {
      "text": "Harriet Kaplan. 1997. Speechreading. In Seminars in Hearing, Vol.\u00a018. Copyright\u00a9 1997 by Thieme Medical Publishers, Inc., 129\u2013138.",
      "doi": ""
    },
    {
      "text": "Saba Kawas, George Karalis, Tzu Wen, and Richard\u00a0E Ladner. 2016. Improving real-time captioning experiences for deaf and hard of hearing students. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility. 15\u201323.",
      "doi": "10.1145/2982142.2982164"
    },
    {
      "text": "Linda Kozma-Spytek, Paula Tucker, and Christian Vogler. 2013. Audio-visual speech understanding in simulated telephony applications by individuals with hearing loss. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility. 1\u20138.",
      "doi": "10.1145/2513383.2517032"
    },
    {
      "text": "Raja\u00a0S Kushalnagar, Gary\u00a0W Behm, Aaron\u00a0W Kelstone, and Shareef Ali. 2015. Tracked speech-to-text display: Enhancing accessibility and readability of real-time speech-to-text. In Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility. 223\u2013230.",
      "doi": "10.1145/2700648.2809843"
    },
    {
      "text": "Raja\u00a0S. Kushalnagar and Christian Vogler. 2020. Teleconference Accessibility and Guidelines for Deaf and Hard of Hearing Users. In The 22nd International ACM SIGACCESS Conference on Computers and Accessibility(Virtual Event, Greece) (ASSETS \u201920). Association for Computing Machinery, New York, NY, USA, Article 9, 6\u00a0pages. https://doi.org/10.1145/3373625.3417299",
      "doi": "10.1145/3373625.3417299"
    },
    {
      "text": "Harlan Lane. 1989. When the Mind Hears: A History of the Deaf. Knopf Doubleday Publishing Group, London.",
      "doi": ""
    },
    {
      "text": "Walter\u00a0S Lasecki, Christopher\u00a0D Miller, Raja Kushalnagar, and Jeffrey\u00a0P Bigham. 2013. Legion scribe: real-time captioning by the non-experts. In Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility. 1\u20132.",
      "doi": "10.1145/2461121.2461151"
    },
    {
      "text": "Gi-Bbeum Lee, Hyuckjin Jang, Hyundeok Jeong, and Woontack Woo. 2021. Designing a Multi-Modal Communication System for the Deaf and Hard-of-Hearing Users. In 2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct). 429\u2013434. https://doi.org/10.1109/ISMAR-Adjunct54149.2021.00097",
      "doi": ""
    },
    {
      "text": "Frank\u00a0R Lin, John\u00a0K Niparko, and Luigi Ferrucci. 2011. Hearing loss prevalence in the United States. Archives of internal medicine 171, 20 (2011), 1851\u20131853.",
      "doi": ""
    },
    {
      "text": "Bj\u00d6Rn Lyxell and Jerker R\u00f6nnberg. 1989. Information-processing skill and speech-reading. British Journal of Audiology 23, 4 (1989), 339\u2013347.",
      "doi": ""
    },
    {
      "text": "Kelly Mack, Emma\u00a0J. McDonnell, Venkatesh Potluri, Maggie Xu, Jailyn Zabala, Jeffery\u00a0P. Bigham, Jennifer Mankoff, and Cynthia\u00a0L. Bennett. 2022. Anticipate and Adjust: Cultivating Access in Human-Centered Methods. In CHI Conference on Human Factors in Computing Systems. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. 1\u201318.",
      "doi": ""
    },
    {
      "text": "Dominic\u00a0W Massaro, Miguel\u00a0\u00c1 Carreira-Perpi\u00f1\u00e1n, David\u00a0J Merrill, Cass Sterling, Stephanie Bigler, Elise Piazza, and Marcus Perlman. 2008. IGlasses: an automatic wearable speech supplementin face-to-face communication and classroom situations. In Proceedings of the 10th international conference on Multimodal interfaces. 197\u2013198.",
      "doi": "10.1145/1452392.1452432"
    },
    {
      "text": "Andrea\u00a0Britto Mattos and Dario Augusto\u00a0Borges Oliveira. 2018. Multi-view mouth renderization for assisting lip-reading. In Proceedings of the 15th International Web for All Conference. 1\u201310.",
      "doi": "10.1145/3192714.3192824"
    },
    {
      "text": "Emma\u00a0J. McDonnell, Ping Liu, Steven\u00a0M. Goodman, Raja Kushalnagar, Jon\u00a0E. Froehlich, and Leah Findlater. 2021. Social, Environmental, and Technical: Factors at Play in the Current Use and Future Design of Small-Group Captioning. Proc. ACM Hum.-Comput. Interact. 5, CSCW2, Article 434 (oct 2021), 25\u00a0pages. https://doi.org/10.1145/3479578",
      "doi": "10.1145/3479578"
    },
    {
      "text": "Ross\u00a0E Mitchell, Travas\u00a0A Young, Bellamie Bachelda, and Michael\u00a0A Karchmer. 2006. How many people use ASL in the United States? Why estimates need updating. Sign Language Studies 6, 3 (2006), 306\u2013335.",
      "doi": ""
    },
    {
      "text": "Gaye\u00a0H Nicholls and Daniel\u00a0Ling Mcgill. 1982. Cued Speech and the reception of spoken language. Journal of Speech, Language, and Hearing Research 25, 2 (1982), 262\u2013269.",
      "doi": ""
    },
    {
      "text": "Alex Olwal, Kevin Balke, Dmitrii Votintcev, Thad Starner, Paula Conn, Bonnie Chinh, and Benoit Corda. 2020. Wearable Subtitles: Augmenting Spoken Communication with Lightweight Eyewear for All-Day Captioning. Association for Computing Machinery, New York, NY, USA, 1108\u20131120. https://doi.org/10.1145/3379337.3415817",
      "doi": "10.1145/3379337.3415817"
    },
    {
      "text": "Kotaro Oomori, Akihisa Shitara, Tatsuya Minagawa, Sayan Sarcar, and Yoichi Ochiai. 2020. A Preliminary Study on Understanding Voice-Only Online Meetings Using Emoji-Based Captioning for Deaf or Hard of Hearing Users. In The 22nd International ACM SIGACCESS Conference on Computers and Accessibility (Virtual Event, Greece) (ASSETS \u201920). Association for Computing Machinery, New York, NY, USA, Article 54, 4\u00a0pages. https://doi.org/10.1145/3373625.3418032",
      "doi": "10.1145/3373625.3418032"
    },
    {
      "text": "Yi-Hao Peng, Ming-Wei Hsi, Paul Taele, Ting-Yu Lin, Po-En Lai, Leon Hsu, Tzu-chuan Chen, Te-Yen Wu, Yu-An Chen, Hsien-Hui Tang, 2018. Speechbubbles: Enhancing captioning experiences for deaf and hard-of-hearing people in group conversations. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1\u201310.",
      "doi": "10.1145/3173574.3173867"
    },
    {
      "text": "Mary Pietrowicz and Karrie Karahalios. 2013. Sonic shapes: Visualizing vocal expression. Georgia Institute of Technology.",
      "doi": ""
    },
    {
      "text": "Lorna Quandt. 2020. Teaching ASL signs using signing avatars and immersive learning in virtual reality. In The 22nd international ACM SIGACCESS conference on computers and accessibility. 1\u20134.",
      "doi": "10.1145/3373625.3418042"
    },
    {
      "text": "Kevin Rathbun, Larwan Berke, Christopher Caulfield, Michael Stinson, and Matt Huenerfauth. 2017. Eye movements of deaf and hard of hearing viewers of automatic captions. Journal on Technology and Persons with Disabilities 5 (2017).",
      "doi": ""
    },
    {
      "text": "Allison Saupp\u00e9 and Bilge Mutlu. 2014. How Social Cues Shape Task Coordination and Communication. In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing(Baltimore, Maryland, USA) (CSCW \u201914). Association for Computing Machinery, New York, NY, USA, 97\u2013108. https://doi.org/10.1145/2531602.2531610",
      "doi": "10.1145/2531602.2531610"
    },
    {
      "text": "Matthew Seita, Sarah Andrew, and Matt Huenerfauth. 2021. Deaf and Hard-of-Hearing Users\u2019 Preferences for Hearing Speakers\u2019 Behavior during Technology-Mediated in-Person and Remote Conversations. In Proceedings of the 18th International Web for All Conference (Ljubljana, Slovenia) (W4A \u201921). Association for Computing Machinery, New York, NY, USA, Article 25, 12\u00a0pages. https://doi.org/10.1145/3430263.3452430",
      "doi": "10.1145/3430263.3452430"
    },
    {
      "text": "Matthew Seita and Matt Huenerfauth. 2020. Deaf Individuals\u2019 Views on Speaking Behaviors of Hearing Peers when Using an Automatic Captioning App. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u20138.",
      "doi": "10.1145/3334480.3383083"
    },
    {
      "text": "Kalin Stefanov and Mayumi Bono. 2019. Towards Digitally-Mediated Sign Language Communication. In Proceedings of the 7th International Conference on Human-Agent Interaction. 286\u2013288.",
      "doi": "10.1145/3349537.3352794"
    },
    {
      "text": "Agnieszka Szarkowska, Izabela Krejtz, Zuzanna Klyszejko, and Anna Wieczorek. 2011. Verbatim, standard, or edited? Reading patterns of different captioning styles among deaf, hard of hearing, and hearing viewers. American annals of the deaf 156, 4 (2011), 363\u2013378.",
      "doi": ""
    },
    {
      "text": "Jessica\u00a0J. Tran, Ben Flowers, Eve\u00a0A. Risken, Richard\u00a0E. Ladner, and Jacob\u00a0O. Wobbrock. 2014. Analyzing the Intelligibility of Real-Time Mobile Sign Language Video Transmitted below Recommended Standards. In Proceedings of the 16th International ACM SIGACCESS Conference on Computers & Accessibility (Rochester, New York, USA) (ASSETS \u201914). Association for Computing Machinery, New York, NY, USA, 177\u2013184. https://doi.org/10.1145/2661334.2661358",
      "doi": "10.1145/2661334.2661358"
    },
    {
      "text": "M\u00e1t\u00e9\u00a0Akos T\u00fcndik, Gy\u00f6rgy Szasz\u00e1k, G\u00e1bor Gosztolya, and Andr\u00e1s Beke. 2018. User-centric evaluation of automatic punctuation in ASR closed captioning. (2018).",
      "doi": ""
    },
    {
      "text": "Mike Wald. 2006. Captioning for deaf and hard of hearing people by editing automatic speech recognition in real time. In International Conference on Computers for Handicapped Persons. Springer, 683\u2013690.",
      "doi": "10.1007/11788713_100"
    },
    {
      "text": "Emily\u00a0Q Wang and Anne\u00a0Marie Piper. 2018. Accessibility in action: Co-located collaboration among deaf and hearing professionals. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201325.",
      "doi": "10.1145/3274449"
    },
    {
      "text": "Xu Wang, Li-Fang Xue, and Dan Yang. 2007. Speech visualization based on wavelet transform for the hearing impaired. In 2007 International Conference on Wavelet Analysis and Pattern Recognition, Vol.\u00a04. IEEE, 1827\u20131830.",
      "doi": ""
    },
    {
      "text": "Akira Watanabe, Shingo Tomishige, and Masahiro Nakatake. 2000. Speech visualization by integrating features for the hearing impaired. IEEE transactions on speech and audio processing 8, 4 (2000), 454\u2013466.",
      "doi": ""
    },
    {
      "text": "Lei Xie, Yi Wang, and Zhi-Qiang Liu. 2006. Lip assistant: Visualize speech for hearing impaired people in multimedia services. In 2006 IEEE International Conference on Systems, Man and Cybernetics, Vol.\u00a05. IEEE, 4331\u20134336.",
      "doi": ""
    },
    {
      "text": "Victor Zue and Ronald Cole. 1979. Experiments on spectrogram reading. In ICASSP\u201979. IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol.\u00a04. IEEE, 116\u2013119.",
      "doi": ""
    }
  ]
}