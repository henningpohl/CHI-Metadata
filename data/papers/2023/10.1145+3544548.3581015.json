{
  "doi": "10.1145/3544548.3581015",
  "title": "Are Two Heads Better Than One in AI-Assisted Decision Making? Comparing the Behavior and Performance of Groups and Individuals in Human-AI Collaborative Recidivism Risk Assessment",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-18",
  "year": 2023,
  "badges": [],
  "abstract": "With the prevalence of AI assistance in decision making, a more relevant question to ask than the classical question of \u201care two heads better than one?\u2019\u2019 is how groups\u2019 behavior and performance in AI-assisted decision making compare with those of individuals\u2019. In this paper, we conduct a case study to compare groups and individuals in human-AI collaborative recidivism risk assessment along six aspects, including decision accuracy and confidence, appropriateness of reliance on AI, understanding of AI, decision-making fairness, and willingness to take accountability. Our results highlight that compared to individuals, groups rely on AI models more regardless of their correctness, but they are more confident when they overturn incorrect AI recommendations. We also find that groups make fairer decisions than individuals according to the accuracy equality criterion, and groups are willing to give AI more credit when they make correct decisions. We conclude by discussing the implications of our work.",
  "authors": [
    {
      "name": "Chun-Wei Chiang",
      "institution": "Computer Sciences, Purdue University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659243338",
      "orcid": "0000-0001-9635-3385"
    },
    {
      "name": "Zhuoran Lu",
      "institution": "Computer Science, Purdue University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659702293",
      "orcid": "0000-0002-1079-2043"
    },
    {
      "name": "Zhuoyan Li",
      "institution": "Purdue university, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660783365",
      "orcid": "0000-0001-7143-9262"
    },
    {
      "name": "Ming Yin",
      "institution": "Purdue University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81438595973",
      "orcid": "0000-0002-7364-139X"
    }
  ],
  "references": [
    {
      "text": "Abdullah Almaatouq, Mohammed Alsobay, Ming Yin, and Duncan\u00a0J Watts. 2021. Task complexity moderates group synergy. Proceedings of the National Academy of Sciences 118, 36(2021), e2101062118.",
      "doi": ""
    },
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine Bias. ProPublica (2016). URL: https://www. propublica. org/article/machine-bias-risk-asses sments-in-criminal-sentencing(2016).",
      "doi": ""
    },
    {
      "text": "Alejandro\u00a0Barredo Arrieta, Natalia D\u00edaz-Rodr\u00edguez, Javier Del\u00a0Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc\u00eda, Sergio Gil-L\u00f3pez, Daniel Molina, Richard Benjamins, 2020. Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information fusion 58(2020), 82\u2013115.",
      "doi": ""
    },
    {
      "text": "Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Narendra\u00a0Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin, Qian Pan, Christine\u00a0T Wolf, 2021. AI-Assisted Human Labeling: Batching for Efficiency without Overreliance. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201327.",
      "doi": "10.1145/3449163"
    },
    {
      "text": "Bahador Bahrami, Karsten Olsen, Peter\u00a0E Latham, Andreas Roepstorff, Geraint Rees, and Chris\u00a0D Frith. 2010. Optimally interacting minds. Science 329, 5995 (2010), 1081\u20131085.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Walter\u00a0S Lasecki, Daniel\u00a0S Weld, and Eric Horvitz. 2019. Beyond accuracy: The role of mental models in human-AI team performance. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 2\u201311.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Daniel\u00a0S Weld, Walter\u00a0S Lasecki, and Eric Horvitz. 2019. Updates in human-ai teams: Understanding and addressing the performance/compatibility tradeoff. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol.\u00a033. 2429\u20132437.",
      "doi": "10.1609/aaai.v33i01.33012429"
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel Weld. 2021. Does the whole exceed its parts? the effect of ai explanations on complementary team performance. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3411764.3445717"
    },
    {
      "text": "Solon Barocas, Moritz Hardt, and Arvind Narayanan. 2017. Fairness in machine learning. Nips tutorial 1(2017), 2.",
      "doi": ""
    },
    {
      "text": "Bernard Bass. 1982. Individual capability, team performance, and team productivity. Human Performance and Productivity. Vols 1, 2 (1982), 179\u2013222.",
      "doi": ""
    },
    {
      "text": "Suzanne\u00a0T Bell. 2007. Deep-level composition variables as predictors of team performance: a meta-analysis.Journal of applied psychology 92, 3 (2007), 595.",
      "doi": ""
    },
    {
      "text": "Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. 2021. Fairness in criminal justice risk assessments: The state of the art. Sociological Methods & Research 50, 1 (2021), 3\u201344.",
      "doi": ""
    },
    {
      "text": "Yochanan\u00a0E Bigman and Kurt Gray. 2018. People are averse to machines making moral decisions. Cognition 181(2018), 21\u201334.",
      "doi": ""
    },
    {
      "text": "Reuben Binns, Max Van\u00a0Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. \u2019It\u2019s Reducing a Human Being to a Percentage\u2019 Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 Chi conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3173574.3173951"
    },
    {
      "text": "Bruce\u00a0K Blaylock and Loren\u00a0P Rees. 1984. Cognitive style and the usefulness of information. Decision Sciences 15, 1 (1984), 74\u201391.",
      "doi": ""
    },
    {
      "text": "Jonathan\u00a0David Bobaljik and H\u00f6skuldur Thr\u00e1insson. 1998. Two heads aren\u2019t always better than one. Syntax 1, 1 (1998), 37\u201371.",
      "doi": ""
    },
    {
      "text": "Marcus\u00a0T Boccaccini, Darrel\u00a0B Turner, Daniel\u00a0C Murrie, Craig\u00a0E Henderson, and Caroline Chevalier. 2013. Do scores from risk measures matter to jurors?Psychology, Public Policy, and Law 19, 2 (2013), 259.",
      "doi": ""
    },
    {
      "text": "Tim Brennan, William Dieterich, and Beate Ehret. 2009. Evaluating the predictive validity of the COMPAS risk and needs assessment system. Criminal Justice and behavior 36, 1 (2009), 21\u201340.",
      "doi": ""
    },
    {
      "text": "Zana Bu\u00e7inca, Phoebe Lin, Krzysztof\u00a0Z Gajos, and Elena\u00a0L Glassman. 2020. Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems. In Proceedings of the 25th international conference on intelligent user interfaces. 454\u2013464.",
      "doi": "10.1145/3377325.3377498"
    },
    {
      "text": "Zana Bu\u00e7inca, Maja\u00a0Barbara Malaya, and Krzysztof\u00a0Z Gajos. 2021. To trust or to think: cognitive forcing functions can reduce overreliance on AI in AI-assisted decision-making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201321.",
      "doi": "10.1145/3449287"
    },
    {
      "text": "Madalina Busuioc. 2021. Accountable artificial intelligence: Holding algorithms to account. Public Administration Review 81, 5 (2021), 825\u2013836.",
      "doi": ""
    },
    {
      "text": "Carrie\u00a0J Cai, Samantha Winter, David Steiner, Lauren Wilcox, and Michael Terry. 2019. \" Hello AI\": uncovering the onboarding needs of medical practitioners for human-AI collaborative decision-making. Proceedings of the ACM on Human-computer Interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359206"
    },
    {
      "text": "Aylin Caliskan, Joanna\u00a0J Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science 356, 6334 (2017), 183\u2013186.",
      "doi": ""
    },
    {
      "text": "Samuel Carton, Qiaozhu Mei, and Paul Resnick. 2020. Feature-Based Explanations Don\u2019t Help People Detect Misclassifications of Online Toxicity. In Proceedings of the International AAAI Conference on Web and Social Media, Vol.\u00a014. 95\u2013106.",
      "doi": ""
    },
    {
      "text": "Hao-Fei Cheng, Ruotong Wang, Zheng Zhang, Fiona O\u2019Connell, Terrance Gray, F\u00a0Maxwell Harper, and Haiyi Zhu. 2019. Explaining decision-making algorithms through UI: Strategies to help non-expert stakeholders. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201312.",
      "doi": "10.1145/3290605.3300789"
    },
    {
      "text": "Chun-Wei Chiang and Ming Yin. 2021. You\u2019d better stop! Understanding human reliance on machine learning models under covariate shift. In 13th ACM Web Science Conference 2021. 120\u2013129.",
      "doi": "10.1145/3447535.3462487"
    },
    {
      "text": "Chun-Wei Chiang and Ming Yin. 2022. Exploring the Effects of Machine Learning Literacy Interventions on Laypeople\u2019s Reliance on Machine Learning Models. In 27th International Conference on Intelligent User Interfaces. 148\u2013161.",
      "doi": ""
    },
    {
      "text": "Leah Chong, Ayush Raina, Kosa Goucher-Lambert, Kenneth Kotovsky, and Jonathan Cagan. 2022. The Evolution and Impact of Human Confidence in Artificial Intelligence and in Themselves on AI-Assisted Decision-Making in Design. Journal of Mechanical Design(2022), 1\u201337.",
      "doi": ""
    },
    {
      "text": "Leah Chong, Guanglu Zhang, Kosa Goucher-Lambert, Kenneth Kotovsky, and Jonathan Cagan. 2022. Human confidence in artificial intelligence and in themselves: The evolution and impact of confidence on adoption of AI advice. Computers in Human Behavior 127 (2022), 107018.",
      "doi": "10.1016/j.chb.2021.107018"
    },
    {
      "text": "Nancy\u00a0J Cooke, Mustafa Demir, and Nathan McNeese. 2016. Synthetic teammates as team players: Coordination of human and synthetic teammates. Technical Report. Cognitive Engineering Research Institute Mesa United States.",
      "doi": ""
    },
    {
      "text": "Jeffrey Dastin. 2018. Amazon scraps secret AI recruiting tool that showed bias against women. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G",
      "doi": ""
    },
    {
      "text": "Bart\u00a0A De\u00a0Jong, Kurt\u00a0T Dirks, and Nicole Gillespie. 2016. Trust and team performance: A meta-analysis of main effects, moderators, and covariates.Journal of applied psychology 101, 8 (2016), 1134.",
      "doi": ""
    },
    {
      "text": "Marie Delacre, Dani\u00ebl Lakens, and Christophe Leys. 2017. Why psychologists should by default use Welch\u2019s t-test instead of Student\u2019s t-test. International Review of Social Psychology 30, 1 (2017).",
      "doi": ""
    },
    {
      "text": "Mustafa Demir, Nathan\u00a0J McNeese, and Nancy\u00a0J Cooke. 2016. Team communication behaviors of the human-automation teaming. In 2016 IEEE international multi-disciplinary conference on cognitive methods in situation awareness and decision support (CogSIMA). IEEE, 28\u201334.",
      "doi": ""
    },
    {
      "text": "Dennis\u00a0J Devine and Jennifer\u00a0L Philips. 2001. Do smarter teams do better: A meta-analysis of cognitive ability and team performance. Small group research 32, 5 (2001), 507\u2013532.",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J Dietvorst, Joseph\u00a0P Simmons, and Cade Massey. 2015. Algorithm aversion: people erroneously avoid algorithms after seeing them err.Journal of Experimental Psychology: General 144, 1 (2015), 114.",
      "doi": ""
    },
    {
      "text": "Jonathan Dodge, Q\u00a0Vera Liao, Yunfeng Zhang, Rachel\u00a0KE Bellamy, and Casey Dugan. 2019. Explaining models: an empirical study of how explanations impact fairness judgment. In Proceedings of the 24th international conference on intelligent user interfaces. 275\u2013285.",
      "doi": "10.1145/3301275.3302310"
    },
    {
      "text": "Julia Dressel and Hany Farid. 2018. The accuracy, fairness, and limits of predicting recidivism. Science advances 4, 1 (2018), eaao5580.",
      "doi": ""
    },
    {
      "text": "Xiaoni Duan, Chien-Ju Ho, and Ming Yin. 2022. The influences of task design on crowdsourced judgement: A case study of recidivism risk evaluation. In Proceedings of the ACM Web Conference 2022. 1685\u20131696.",
      "doi": "10.1145/3485447.3512239"
    },
    {
      "text": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference. 214\u2013226.",
      "doi": "10.1145/2090236.2090255"
    },
    {
      "text": "Ferda Erdem, Janset Ozen, and Nuray Atsan. 2003. The relationship between trust and team performance. Work study (2003).",
      "doi": ""
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto\u00a0A Novoa, Justin Ko, Susan\u00a0M Swetter, Helen\u00a0M Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. nature 542, 7639 (2017), 115\u2013118.",
      "doi": ""
    },
    {
      "text": "Northpointe\u00a0Institute for Public\u00a0Management.1996. COMPAS [Computer software].",
      "doi": ""
    },
    {
      "text": "Donelson\u00a0R Forsyth. 2018. Group dynamics. Cengage Learning.",
      "doi": ""
    },
    {
      "text": "Jorge Galindo and Pablo Tamayo. 2000. Credit risk assessment using statistical and machine learning: basic methodology and risk modeling applications. Computational economics 15, 1 (2000), 107\u2013143.",
      "doi": ""
    },
    {
      "text": "Yashesh Gaur, Walter\u00a0S Lasecki, Florian Metze, and Jeffrey\u00a0P Bigham. 2016. The effects of automatic speech recognition quality on human transcription latency. In Proceedings of the 13th International Web for All Conference. 1\u20138.",
      "doi": "10.1145/2899475.2899478"
    },
    {
      "text": "Meric\u00a0Altug Gemalmaz and Ming Yin. 2022. Understanding Decision Subjects\u2019 Fairness Perceptions and Retention in Repeated Interactions with AI-Based Decision Systems. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society. 295\u2013306.",
      "doi": "10.1145/3514094.3534201"
    },
    {
      "text": "Ella Glikson and Anita\u00a0Williams Woolley. 2020. Human trust in artificial intelligence: Review of empirical research. Academy of Management Annals 14, 2 (2020), 627\u2013660.",
      "doi": ""
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. Disparate interactions: An algorithm-in-the-loop analysis of fairness in risk assessments. In Proceedings of the conference on fairness, accountability, and transparency. 90\u201399.",
      "doi": "10.1145/3287560.3287563"
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. The principles and limits of algorithm-in-the-loop decision making. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359152"
    },
    {
      "text": "Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. Advances in neural information processing systems 29 (2016).",
      "doi": ""
    },
    {
      "text": "Randy\u00a0Y Hirokawa and Marshall\u00a0Scott Poole. 1996. Communication and group decision making. Sage Publications.",
      "doi": ""
    },
    {
      "text": "Fred Hohman, Andrew Head, Rich Caruana, Robert DeLine, and Steven\u00a0M Drucker. 2019. Gamut: A design probe to understand how data scientists understand machine learning models. In Proceedings of the 2019 CHI conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3290605.3300809"
    },
    {
      "text": "Lu Hong and Scott\u00a0E Page. 2004. Groups of diverse problem solvers can outperform groups of high-ability problem solvers. Proceedings of the National Academy of Sciences 101, 46(2004), 16385\u201316389.",
      "doi": ""
    },
    {
      "text": "Sujin\u00a0K Horwitz and Irwin\u00a0B Horwitz. 2007. The effects of team diversity on team outcomes: A meta-analytic review of team demography. Journal of management 33, 6 (2007), 987\u20131015.",
      "doi": ""
    },
    {
      "text": "Yoyo Tsung-Yu Hou and Malte\u00a0F Jung. 2021. Who is the expert? Reconciling algorithm aversion and algorithm appreciation in AI-supported decision making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201325.",
      "doi": ""
    },
    {
      "text": "George\u00a0P Huber and Kyle Lewis. 2010. Cross-understanding: Implications for group cognition and performance. Academy of Management review 35, 1 (2010), 6\u201326.",
      "doi": ""
    },
    {
      "text": "Raymond\u00a0G Hunt, Frank\u00a0J Krzystofiak, James\u00a0R Meindl, and Abdalla\u00a0M Yousry. 1989. Cognitive style and decision making. Organizational behavior and human decision processes 44, 3 (1989), 436\u2013453.",
      "doi": ""
    },
    {
      "text": "Niranjan\u00a0S Janardhanan, Kyle Lewis, Rhonda\u00a0K Reger, and Cynthia\u00a0K Stevens. 2020. Getting to know you: motivating cross-understanding for improved team and individual performance. Organization Science 31, 1 (2020), 103\u2013118.",
      "doi": "10.1287/orsc.2019.1324"
    },
    {
      "text": "Irving\u00a0Lester Janis. 1983. Groupthink. Houghton Mifflin Boston.",
      "doi": ""
    },
    {
      "text": "Karen\u00a0A Jehn, Gregory\u00a0B Northcraft, and Margaret\u00a0A Neale. 1999. Why differences make a difference: A field study of diversity, conflict and performance in workgroups. Administrative science quarterly 44, 4 (1999), 741\u2013763.",
      "doi": ""
    },
    {
      "text": "Ece Kamar. 2016. Directions in Hybrid Intelligence: Complementing AI Systems with Human Intelligence.. In IJCAI. 4070\u20134073.",
      "doi": ""
    },
    {
      "text": "Steven\u00a0J Karau and Kipling\u00a0D Williams. 1993. Social loafing: A meta-analytic review and theoretical integration.Journal of personality and social psychology 65, 4(1993), 681.",
      "doi": ""
    },
    {
      "text": "Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, and Jennifer Wortman\u00a0Vaughan. 2020. Interpreting Interpretability: Understanding Data Scientists\u2019 Use of Interpretability Tools for Machine Learning. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3313831.3376219"
    },
    {
      "text": "Norbert\u00a0L Kerr, R\u00a0Scott Tindale, 2004. Group performance and decision making. Annual review of psychology 55, 1 (2004), 623\u2013655.",
      "doi": ""
    },
    {
      "text": "Antino Kim, Mochen Yang, and Jingjng Zhang. 2020. When Algorithms Err: Differential Impact of Early vs. Late Errors on Users\u2019 Reliance on Algorithms. Late Errors on Users\u2019 Reliance on Algorithms (July 2020) (2020).",
      "doi": ""
    },
    {
      "text": "Young\u00a0Ji Kim, David Engel, Anita\u00a0Williams Woolley, Jeffrey Yu-Ting Lin, Naomi McArthur, and Thomas\u00a0W Malone. 2017. What makes a strong team? Using collective intelligence to predict team performance in League of Legends. In Proceedings of the 2017 ACM conference on computer supported cooperative work and social computing. 2316\u20132329.",
      "doi": ""
    },
    {
      "text": "Keith Kirkpatrick. 2017. It\u2019s not the algorithm, it\u2019s the data. Commun. ACM 60, 2 (2017), 21\u201323.",
      "doi": "10.1145/3022181"
    },
    {
      "text": "Asher Koriat. 2012. When are two heads better than one and why?Science 336, 6079 (2012), 360\u2013362.",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Chacha Chen, Q\u00a0Vera Liao, Alison Smith-Renner, and Chenhao Tan. 2021. Towards a science of human-ai decision making: a survey of empirical studies. arXiv preprint arXiv:2112.11471(2021).",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Han Liu, and Chenhao Tan. 2020. \" Why is\u2019 Chicago\u2019deceptive?\" Towards Building Model-Driven Tutorials for Humans. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3313831.3376873"
    },
    {
      "text": "Vivian Lai and Chenhao Tan. 2019. On human predictions with explanations and predictions of machine learning models: A case study on deception detection. In Proceedings of the conference on fairness, accountability, and transparency. 29\u201338.",
      "doi": "10.1145/3287560.3287590"
    },
    {
      "text": "Molly\u00a0K Land and Jay\u00a0D Aronson. 2020. Human rights and technology: new challenges for justice and accountability. Annual Review of Law and Social Science (Forthcoming) (2020).",
      "doi": ""
    },
    {
      "text": "Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. How we analyzed the COMPAS recidivism algorithm. ProPublica (5 2016) 9, 1 (2016), 3\u20133.",
      "doi": ""
    },
    {
      "text": "James\u00a0R Larson\u00a0Jr. 2013. In search of synergy in small group performance. Psychology Press.",
      "doi": ""
    },
    {
      "text": "James\u00a0R Larson\u00a0Jr, Pennie\u00a0G Foster-Fishman, and Timothy\u00a0M Franz. 1998. Leadership style and the discussion of shared and unshared information in decision-making groups. Personality and Social Psychology Bulletin 24, 5 (1998), 482\u2013495.",
      "doi": ""
    },
    {
      "text": "Patrick\u00a0R Laughlin and John Adamopoulos. 1980. Social combination processes and individual learning for six-person cooperative groups on an intellective task.Journal of Personality and Social Psychology 38, 6(1980), 941.",
      "doi": ""
    },
    {
      "text": "Patrick\u00a0R Laughlin, Bryan\u00a0L Bonner, and Andrew\u00a0G Miner. 2002. Groups perform better than the best individuals on letters-to-numbers problems. Organizational Behavior and Human Decision Processes 88, 2 (2002), 605\u2013620.",
      "doi": ""
    },
    {
      "text": "Daniel Levi and David\u00a0A Askay. 2020. Group dynamics for teams. Sage Publications.",
      "doi": ""
    },
    {
      "text": "Brian\u00a0Y Lim, Anind\u00a0K Dey, and Daniel Avrahami. 2009. Why and why not explanations improve the intelligibility of context-aware intelligent systems. In Proceedings of the SIGCHI conference on human factors in computing systems. 2119\u20132128.",
      "doi": "10.1145/1518701.1519023"
    },
    {
      "text": "Zachary\u00a0C Lipton. 2018. The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.Queue 16, 3 (2018), 31\u201357.",
      "doi": "10.1145/3236386.3241340"
    },
    {
      "text": "Han Liu, Vivian Lai, and Chenhao Tan. 2021. Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making. arXiv preprint arXiv:2101.05303(2021).",
      "doi": ""
    },
    {
      "text": "Jennifer\u00a0M Logg, Julia\u00a0A Minson, and Don\u00a0A Moore. 2019. Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes 151 (2019), 90\u2013103.",
      "doi": ""
    },
    {
      "text": "Zhuoran Lu and Ming Yin. 2021. Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems.",
      "doi": "10.1145/3411764.3445562"
    },
    {
      "text": "Pamela\u00a0J Ludford, Dan Cosley, Dan Frankowski, and Loren Terveen. 2004. Think different: increasing online community participation using uniqueness and group dissimilarity. In Proceedings of the SIGCHI conference on Human factors in computing systems. 631\u2013638.",
      "doi": "10.1145/985692.985772"
    },
    {
      "text": "Merce Mach, Simon Dolan, and Shay Tzafrir. 2010. The differential effect of team members\u2019 trust on team performance: The mediation role of team cohesion. Journal of Occupational and Organizational Psychology 83, 3(2010), 771\u2013794.",
      "doi": ""
    },
    {
      "text": "Andrew Mao, Winter Mason, Siddharth Suri, and Duncan\u00a0J Watts. 2016. An experimental study of team size and performance on a complex task. PloS one 11, 4 (2016), e0153048.",
      "doi": ""
    },
    {
      "text": "Winter Mason and Siddharth Suri. 2012. Conducting behavioral research on Amazon\u2019s Mechanical Turk. Behavior research methods 44, 1 (2012), 1\u201323.",
      "doi": ""
    },
    {
      "text": "Winter Mason and Duncan\u00a0J Watts. 2012. Collaborative learning in networks. Proceedings of the National Academy of Sciences 109, 3 (2012), 764\u2013769.",
      "doi": ""
    },
    {
      "text": "Nathan\u00a0J McNeese, Beau\u00a0G Schelble, Lorenzo\u00a0Barberis Canonico, and Mustafa Demir. 2021. Who/What Is My Teammate? Team Composition Considerations in Human\u2013AI Teaming. IEEE Transactions on Human-Machine Systems 51, 4 (2021), 288\u2013299.",
      "doi": ""
    },
    {
      "text": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A survey on bias and fairness in machine learning. ACM Computing Surveys (CSUR) 54, 6 (2021), 1\u201335.",
      "doi": "10.1145/3457607"
    },
    {
      "text": "Larry\u00a0K Michaelsen, Warren\u00a0E Watson, and Robert\u00a0H Black. 1989. A realistic test of individual versus group consensus decision making.Journal of applied psychology 74, 5 (1989), 834.",
      "doi": ""
    },
    {
      "text": "Dena\u00a0F Mujtaba and Nihar\u00a0R Mahapatra. 2019. Ethical considerations in AI-based recruitment. In 2019 IEEE International Symposium on Technology and Society (ISTAS). IEEE, 1\u20137.",
      "doi": ""
    },
    {
      "text": "Geoff Musick, Thomas\u00a0A O\u2019Neill, Beau\u00a0G Schelble, Nathan\u00a0J McNeese, and Jonn\u00a0B Henke. 2021. What Happens When Humans Believe Their Teammate is an AI? An Investigation into Humans Teaming with Autonomy. Computers in Human Behavior 122 (2021), 106852.",
      "doi": ""
    },
    {
      "text": "David\u00a0G Myers and Helmut Lamm. 1976. The group polarization phenomenon.Psychological bulletin 83, 4 (1976), 602.",
      "doi": ""
    },
    {
      "text": "Richard Nadeau, Edouard Cloutier, and J-H Guay. 1993. New evidence about the existence of a bandwagon effect in the opinion formation process. International Political Science Review 14, 2 (1993), 203\u2013213.",
      "doi": ""
    },
    {
      "text": "Lisa\u00a0Hope Pelled, Kathleen\u00a0M Eisenhardt, and Katherine\u00a0R Xin. 1999. Exploring the black box: An analysis of work group diversity, conflict and performance. Administrative science quarterly 44, 1 (1999), 1\u201328.",
      "doi": ""
    },
    {
      "text": "Ka\u015bka Porayska-Pomsta and Gnanathusharan Rajendran. 2019. Accountability in human and artificial intelligence decision-making as the basis for diversity and educational inclusion. In Artificial intelligence and inclusive education. Springer, 39\u201359.",
      "doi": ""
    },
    {
      "text": "Forough Poursabzi-Sangdeh, Daniel\u00a0G Goldstein, Jake\u00a0M Hofman, Jennifer\u00a0Wortman Wortman\u00a0Vaughan, and Hanna Wallach. 2021. Manipulating and measuring model interpretability. In Proceedings of the 2021 CHI conference on human factors in computing systems. 1\u201352.",
      "doi": "10.1145/3411764.3445315"
    },
    {
      "text": "Emilee Rader, Kelley Cotter, and Janghee Cho. 2018. Explanations as mechanisms for supporting algorithmic transparency. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3173574.3173677"
    },
    {
      "text": "Amy Rechkemmer and Ming Yin. 2022. When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models. In CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": ""
    },
    {
      "text": "Marco\u00a0Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \" Why should i trust you?\" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 1135\u20131144.",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Niloufar Salehi, Andrew McCabe, Melissa Valentine, and Michael Bernstein. 2017. Huddler: Convening stable and familiar crowd teams despite unpredictable availability. In Proceedings of the 2017 ACM conference on computer supported cooperative work and social computing. 1700\u20131713.",
      "doi": "10.1145/2998181.2998300"
    },
    {
      "text": "Julian Sanchez, Wendy\u00a0A Rogers, Arthur\u00a0D Fisk, and Ericka Rovira. 2014. Understanding reliance on automation: effects of error type, error distribution, age and experience. Theoretical issues in ergonomics science 15, 2 (2014), 134\u2013160.",
      "doi": ""
    },
    {
      "text": "Donghee Shin. 2020. User perceptions of algorithmic decisions in the personalized AI system: perceptual evaluation of fairness, accountability, transparency, and explainability. Journal of Broadcasting & Electronic Media 64, 4 (2020), 541\u2013565.",
      "doi": ""
    },
    {
      "text": "Ben Shneiderman. 2020. Human-centered artificial intelligence: Reliable, safe & trustworthy. International Journal of Human\u2013Computer Interaction 36, 6(2020), 495\u2013504.",
      "doi": ""
    },
    {
      "text": "Tony Simons, Lisa\u00a0Hope Pelled, and Ken\u00a0A Smith. 1999. Making use of difference: Diversity, debate, and decision comprehensiveness in top management teams. Academy of management journal 42, 6 (1999), 662\u2013673.",
      "doi": ""
    },
    {
      "text": "Joachim Stempfle and Petra Badke-Schaub. 2002. Thinking in design teams-an analysis of team communication. Design studies 23, 5 (2002), 473\u2013496.",
      "doi": ""
    },
    {
      "text": "Harini Suresh, Natalie Lao, and Ilaria Liccardi. 2020. Misplaced Trust: Measuring the Interference of Machine Learning in Human Decision-Making. In 12th ACM Conference on Web Science. 315\u2013324.",
      "doi": ""
    },
    {
      "text": "James Surowiecki. 2005. The wisdom of crowds. Anchor.",
      "doi": ""
    },
    {
      "text": "Suzanne Tolmeijer, Markus Christen, Serhiy Kandul, Markus Kneer, and Abraham Bernstein. 2022. Capable but Amoral? Comparing AI and Human Expert Collaboration in Ethical Decision Making. In CHI Conference on Human Factors in Computing Systems. 1\u201317.",
      "doi": ""
    },
    {
      "text": "Suzanne Tolmeijer, Ujwal Gadiraju, Ramya Ghantasala, Akshit Gupta, and Abraham Bernstein. 2021. Second Chance for a First Impression? Trust Development in Intelligent System Interaction. In Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization (UMAP 2021).",
      "doi": "10.1145/3450613.3456817"
    },
    {
      "text": "Ray Tsaih, Yenshan Hsu, and Charles\u00a0C Lai. 1998. Forecasting S&P 500 stock index futures with a hybrid AI system. Decision support systems 23, 2 (1998), 161\u2013174.",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van\u00a0Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in high-stakes public sector decision-making. In Proceedings of the 2018 chi conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "Oleksandra Vereschak, Gilles Bailly, and Baptiste Caramiaux. 2021. How to evaluate trust in AI-assisted decision making? A survey of empirical methodologies. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201339.",
      "doi": "10.1145/3476068"
    },
    {
      "text": "Victor\u00a0H Vroom. 2000. Leadership and the decision-making process. Organizational dynamics 28, 4 (2000), 82\u201394.",
      "doi": ""
    },
    {
      "text": "Daisuke Wakabayashi. 2018. Self-driving Uber car kills pedestrian in Arizona, where robots roam. The New York Times 19, 03 (2018).",
      "doi": ""
    },
    {
      "text": "Ruotong Wang, F\u00a0Maxwell Harper, and Haiyi Zhu. 2020. Factors influencing perceived fairness in algorithmic decision-making: Algorithm outcomes, development procedures, and individual differences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3313831.3376813"
    },
    {
      "text": "Xinru Wang, Zhuoran Lu, and Ming Yin. 2022. Will You Accept the AI Recommendation? Predicting Human Behavior in AI-Assisted Decision Making. In Proceedings of the ACM Web Conference 2022. 1697\u20131708.",
      "doi": "10.1145/3485447.3512240"
    },
    {
      "text": "Xinru Wang and Ming Yin. 2021. Are explanations helpful? a comparative study of the effects of explanations in ai-assisted decision-making. In 26th International Conference on Intelligent User Interfaces. 318\u2013328.",
      "doi": "10.1145/3397481.3450650"
    },
    {
      "text": "Xinru Wang and Ming Yin. 2022. Effects of Explanations in AI-Assisted Decision Making: Principles and Comparisons. ACM Transactions on Interactive Intelligent Systems (TiiS) (2022).",
      "doi": ""
    },
    {
      "text": "Jenny\u00a0S Wesche and Andreas Sonderegger. 2019. When computers take the lead: The automation of leadership. Computers in Human Behavior 101 (2019), 197\u2013209.",
      "doi": ""
    },
    {
      "text": "Anita\u00a0Williams Woolley, Christopher\u00a0F Chabris, Alex Pentland, Nada Hashmi, and Thomas\u00a0W Malone. 2010. Evidence for a collective intelligence factor in the performance of human groups. science 330, 6004 (2010), 686\u2013688.",
      "doi": ""
    },
    {
      "text": "Edward\u00a0F Wright and Gary\u00a0L Wells. 1985. Does group discussion attenuate the dispositional bias?Journal of Applied Social Psychology 15, 6 (1985), 531\u2013546.",
      "doi": ""
    },
    {
      "text": "Fumeng Yang, Zhuanyi Huang, Jean Scholtz, and Dustin\u00a0L Arendt. 2020. How do visual explanations foster end users\u2019 appropriate trust in machine learning?. In Proceedings of the 25th International Conference on Intelligent User Interfaces. 189\u2013201.",
      "doi": "10.1145/3377325.3377480"
    },
    {
      "text": "Michael Yeomans, Anuj Shah, Sendhil Mullainathan, and Jon Kleinberg. 2019. Making sense of recommendations. Journal of Behavioral Decision Making 32, 4 (2019), 403\u2013414.",
      "doi": ""
    },
    {
      "text": "Ming Yin, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2019. Understanding the effect of accuracy on trust in machine learning models. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201312.",
      "doi": "10.1145/3290605.3300509"
    },
    {
      "text": "Kun Yu, Shlomo Berkovsky, Ronnie Taib, Jianlong Zhou, and Fang Chen. 2019. Do I Trust My Machine Teammate? An Investigation from Perception to Decision. In Proceedings of the 24th International Conference on Intelligent User Interfaces (Marina del Ray, California) (IUI \u201919). Association for Computing Machinery, New York, NY, USA, 460\u2013468. https://doi.org/10.1145/3301275.3302277",
      "doi": "10.1145/3301275.3302277"
    },
    {
      "text": "Muhammad\u00a0Bilal Zafar, Isabel Valera, Manuel Gomez\u00a0Rodriguez, and Krishna\u00a0P Gummadi. 2017. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th international conference on world wide web. 1171\u20131180.",
      "doi": "10.1145/3038912.3052660"
    },
    {
      "text": "Rui Zhang, Nathan\u00a0J McNeese, Guo Freeman, and Geoff Musick. 2021. \" An Ideal Human\" Expectations of AI Teammates in Human-AI Teaming. Proceedings of the ACM on Human-Computer Interaction 4, CSCW3(2021), 1\u201325.",
      "doi": ""
    },
    {
      "text": "Yunfeng Zhang, Q\u00a0Vera Liao, and Rachel\u00a0KE Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 295\u2013305.",
      "doi": "10.1145/3351095.3372852"
    },
    {
      "text": "Zijian Zhang, Jaspreet Singh, Ujwal Gadiraju, and Avishek Anand. 2019. Dissonance between human and machine understanding. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201323.",
      "doi": "10.1145/3359158"
    },
    {
      "text": "Sharon Zhou, Melissa Valentine, and Michael\u00a0S Bernstein. 2018. In search of the dream team: Temporally constrained multi-armed bandits for identifying effective team structures. In Proceedings of the 2018 chi conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3173574.3173682"
    }
  ]
}