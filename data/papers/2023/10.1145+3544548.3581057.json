{
  "doi": "10.1145/3544548.3581057",
  "title": "ModSandbox: Facilitating Online Community Moderation Through Error Prediction and Improvement of Automated Rules",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-20",
  "year": 2023,
  "badges": [],
  "abstract": "Despite the common use of rule-based tools for online content moderation, human moderators still spend a lot of time monitoring them to ensure they work as intended. Based on surveys and interviews with Reddit moderators who use AutoModerator, we identified the main challenges in reducing false positives and false negatives of automated rules: not being able to estimate the actual effect of a rule in advance and having difficulty figuring out how the rules should be updated. To address these issues, we built ModSandbox, a novel virtual sandbox system that detects possible false positives and false negatives of a rule and visualizes which part of the rule is causing issues. We conducted a comparative, between-subject study with online content moderators to evaluate the effect of ModSandbox in improving automated rules. Results show that ModSandbox can support quickly finding possible false positives and false negatives of automated rules and guide moderators to improve them to reduce future errors.",
  "tags": [
    "automated moderation bots",
    "human-AI collaboration",
    "sociotechnical systems",
    "online communities",
    "virtual sandbox",
    "moderation"
  ],
  "authors": [
    {
      "name": "Jean Y. Song",
      "institution": "Electrical Engineering and Computer Science, DGIST, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659249417",
      "orcid": "0000-0003-4379-3971"
    },
    {
      "name": "Sangwook Lee",
      "institution": "School of Computing, KAIST, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660626593",
      "orcid": "0000-0002-2600-4769"
    },
    {
      "name": "Jisoo Lee",
      "institution": "Beeble, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660780868",
      "orcid": "0000-0003-3347-0706"
    },
    {
      "name": "Mina Kim",
      "institution": "Kakao Corp, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660778480",
      "orcid": "0000-0002-4461-4181"
    },
    {
      "name": "Juho Kim",
      "institution": "School of Computing, KAIST, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81484651506",
      "orcid": "0000-0001-6348-4127"
    }
  ],
  "references": [
    {
      "text": "S Abarna, JI Sheeba, S Jayasrilakshmi, and S\u00a0Pradeep Devaneyan. 2022. Identification of cyber harassment and intention of target users on social media platforms. Engineering applications of artificial intelligence 115 (2022), 105283.",
      "doi": ""
    },
    {
      "text": "Fernando Alfonso\u00a0III. 2014. Reddit strips r/technology from its homepage following moderator and censorship drama. https://www.dailydot.com/unclick/reddit-censorship-technology-drama-default/",
      "doi": ""
    },
    {
      "text": "Jie Cai and Donghee\u00a0Yvette Wohn. 2019. Categorizing Live Streaming Moderation Tools: An Analysis of Twitch. International Journal of Interactive Communication Systems and Technologies (IJICST) 9, 2 (2019), 36\u201350.",
      "doi": ""
    },
    {
      "text": "Twitter\u00a0Help Center. 2021. Hateful conduct policy. Retrieved 2021 from https://help.twitter.com/en/rules-and-policies/hateful-conduct-policy",
      "doi": ""
    },
    {
      "text": "Damon Centola. 2010. The spread of behavior in an online social network experiment. science 329, 5996 (2010), 1194\u20131197.",
      "doi": ""
    },
    {
      "text": "Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni\u00a0St John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, 2018. Universal sentence encoder for English. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 169\u2013174.",
      "doi": ""
    },
    {
      "text": "Stevie Chancellor, Yannis Kalantidis, Jessica\u00a0A Pater, Munmun De\u00a0Choudhury, and David\u00a0A Shamma. 2017. Multimodal classification of moderated online pro-eating disorder content. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 3213\u20133226.",
      "doi": "10.1145/3025453.3025985"
    },
    {
      "text": "Stevie Chancellor, Jessica\u00a0Annette Pater, Trustin Clear, Eric Gilbert, and Munmun De\u00a0Choudhury. 2016. #thyghgapp: Instagram content moderation and lexical variation in pro-eating disorder communities. In Proceedings of the 19th ACM conference on computer-supported cooperative work & social computing. 1201\u20131213.",
      "doi": "10.1145/2818048.2819963"
    },
    {
      "text": "Eshwar Chandrasekharan, Chaitrali Gandhi, Matthew\u00a0Wortley Mustelier, and Eric Gilbert. 2019. Crossmod: A cross-community learning-based system to assist reddit moderators. Proceedings of the ACM on human-computer interaction 3, CSCW(2019), 1\u201330.",
      "doi": "10.1145/3359276"
    },
    {
      "text": "Eshwar Chandrasekharan, Mattia Samory, Shagun Jhaver, Hunter Charvat, Amy Bruckman, Cliff Lampe, Jacob Eisenstein, and Eric Gilbert. 2018. The internet\u2019s hidden rules: An empirical study of Reddit norm violations at micro, meso, and macro Scales. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201325.",
      "doi": "10.1145/3274301"
    },
    {
      "text": "Eshwar Chandrasekharan, Mattia Samory, Anirudh Srinivasan, and Eric Gilbert. 2017. The bag of communities: Identifying abusive behavior online with preexisting internet data. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 3175\u20133187.",
      "doi": "10.1145/3025453.3026018"
    },
    {
      "text": "Kevin Collier. 2014. Reddit\u2019s r/technology has a secret list of about 50 words you can\u2019t use in headlines. The Daily Dot (Apr 2014). https://www.dailydot.com/unclick/reddit-technology-banned-words/",
      "doi": ""
    },
    {
      "text": "Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, and Antoine Bordes. 2017. Supervised learning of universal sentence representations from natural language inference data. arXiv preprint arXiv:1705.02364(2017).",
      "doi": ""
    },
    {
      "text": "Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detection and the problem of offensive language. In Proceedings of the international AAAI conference on web and social media, Vol.\u00a011. 512\u2013515.",
      "doi": ""
    },
    {
      "text": "Nicholas Diakopoulos. 2016. Accountability in algorithmic decision making. Commun. ACM 59, 2 (2016), 56\u201362.",
      "doi": "10.1145/2844110"
    },
    {
      "text": "Karthik Dinakar, Roi Reichart, and Henry Lieberman. 2011. Modeling the detection of textual cyberbullying. In Proceedings of the International AAAI Conference on Web and Social Media, Vol.\u00a05. 11\u201317.",
      "doi": ""
    },
    {
      "text": "Bryan Dosono and Bryan Semaan. 2019. Moderation practices as emotional labor in sustaining online communities: The case of AAPI identity work on Reddit. In Proceedings of the 2019 CHI conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3290605.3300372"
    },
    {
      "text": "Joseph\u00a0L Fleiss. 1971. Measuring nominal scale agreement among many raters.Psychological bulletin 76, 5 (1971), 378.",
      "doi": ""
    },
    {
      "text": "Robert Gorwa, Reuben Binns, and Christian Katzenbach. 2020. Algorithmic content moderation: Technical and political challenges in the automation of platform governance. Big Data & Society 7, 1 (2020), 2053951719897945.",
      "doi": ""
    },
    {
      "text": "James Grimmelmann. 2015. The virtues of moderation. Yale JL & Tech. 17(2015), 42.",
      "doi": ""
    },
    {
      "text": "Shagun Jhaver, Darren\u00a0Scott Appling, Eric Gilbert, and Amy Bruckman. 2019. \" Did You Suspect the Post Would be Removed?\" Understanding User Reactions to Content Removals on Reddit. Proceedings of the ACM on human-computer interaction 3, CSCW(2019), 1\u201333.",
      "doi": ""
    },
    {
      "text": "Shagun Jhaver, Iris Birman, Eric Gilbert, and Amy Bruckman. 2019. Human-machine collaboration for content regulation: The case of Reddit Automoderator. ACM Transactions on Computer-Human Interaction (TOCHI) 26, 5(2019), 1\u201335.",
      "doi": "10.1145/3338243"
    },
    {
      "text": "Shagun Jhaver, Quan\u00a0Ze Chen, Detlef Knauss, and Amy\u00a0X Zhang. 2022. Designing Word Filter Tools for Creator-led Comment Moderation. In CHI Conference on Human Factors in Computing Systems. 1\u201321.",
      "doi": ""
    },
    {
      "text": "Shagun Jhaver, Seth Frey, and Amy Zhang. 2021. Designing for Multiple Centers of Power: A Taxonomy of Multi-level Governance in Online Social Platforms. arXiv preprint arXiv:2108.12529(2021).",
      "doi": ""
    },
    {
      "text": "Jialun\u00a0Aaron Jiang, Charles Kiene, Skyler Middler, Jed\u00a0R Brubaker, and Casey Fiesler. 2019. Moderation challenges in voice-based online communities on discord. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201323.",
      "doi": "10.1145/3359157"
    },
    {
      "text": "Prerna Juneja, Deepika Rama\u00a0Subramanian, and Tanushree Mitra. 2020. Through the Looking Glass: Study of Transparency in Reddit\u2019s Moderation Practices. Proceedings of the ACM on Human-Computer Interaction 4, GROUP(2020), 1\u201335.",
      "doi": "10.1145/3375197"
    },
    {
      "text": "Charles Kiene and Benjamin\u00a0Mako Hill. 2020. Who uses bots? A statistical analysis of bot usage in moderation teams. In Extended abstracts of the 2020 CHI conference on human factors in computing systems. 1\u20138.",
      "doi": ""
    },
    {
      "text": "Charles Kiene, Jialun\u00a0Aaron Jiang, and Benjamin\u00a0Mako Hill. 2019. Technological frames and user innovation: Exploring technological change in community moderation teams. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201323.",
      "doi": "10.1145/3359146"
    },
    {
      "text": "Charles Kiene, Andr\u00e9s Monroy-Hern\u00e1ndez, and Benjamin\u00a0Mako Hill. 2016. Surviving an\" Eternal September\" How an Online Community Managed a Surge of Newcomers. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 1152\u20131156.",
      "doi": "10.1145/2858036.2858356"
    },
    {
      "text": "Josua Krause, Aritra Dasgupta, Jordan Swartz, Yindalon Aphinyanaphongs, and Enrico Bertini. 2017. A workflow for visual diagnostics of binary classifiers using instance-level explanations. In 2017 IEEE Conference on Visual Analytics Science and Technology (VAST). IEEE, 162\u2013172.",
      "doi": ""
    },
    {
      "text": "PJS Kumar, Polagani\u00a0Rama Devi, N\u00a0Raghavendra Sai, S\u00a0Sai Kumar, and Tharini Benarji. 2021. Battling Fake News: A Survey on Mitigation Techniques and Identification. In 2021 5th International Conference on Trends in Electronics and Informatics (ICOEI). IEEE, 829\u2013835.",
      "doi": ""
    },
    {
      "text": "Cheng\u00a0Hua Li and Jimmy\u00a0Xiangji Huang. 2012. Spam filtering using semantic similarity approach and adaptive BPNN. Neurocomputing 92(2012), 88\u201397.",
      "doi": "10.1016/j.neucom.2011.09.036"
    },
    {
      "text": "Daniel Loureiro, Francesco Barbieri, Leonardo Neves, Luis\u00a0Espinosa Anke, and Jose Camacho-Collados. 2022. Timelms: Diachronic language models from twitter. arXiv preprint arXiv:2202.03829(2022).",
      "doi": ""
    },
    {
      "text": "J\u00a0Nathan Matias. 2016. Going dark: Social factors in collective action against platform operators in the Reddit blackout. In Proceedings of the 2016 CHI conference on human factors in computing systems. 1138\u20131151.",
      "doi": "10.1145/2858036.2858391"
    },
    {
      "text": "Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781(2013).",
      "doi": ""
    },
    {
      "text": "Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive language detection in online user content. In Proceedings of the 25th international conference on world wide web. 145\u2013153.",
      "doi": "10.1145/2872427.2883062"
    },
    {
      "text": "Deokgun Park, Simranjit Sachar, Nicholas Diakopoulos, and Niklas Elmqvist. 2016. Supporting comment moderators in identifying high quality online news comments. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 1114\u20131125.",
      "doi": "10.1145/2858036.2858389"
    },
    {
      "text": "Joon\u00a0Sung Park, Lindsay Popowski, Carrie\u00a0J. Cai, Meredith\u00a0Ringel Morris, Percy Liang, and Michael\u00a0S. Bernstein. 2022. Social Simulacra: Creating Populated Prototypes for Social Computing Systems. In In the 35th Annual ACM Symposium on User Interface Software and Technology (UIST \u201922) (Bend, OR, USA) (UIST \u201922). Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3526113.3545616",
      "doi": "10.1145/3526113.3545616"
    },
    {
      "text": "Reddit. 2021. Transparency Report 2021. https://www.redditinc.com/policies/transparency-report-2021",
      "doi": ""
    },
    {
      "text": "Sarah\u00a0T Roberts. 2016. Commercial content moderation: Digital laborers\u2019 dirty work. (2016).",
      "doi": ""
    },
    {
      "text": "Sarah\u00a0T Roberts. 2019. Behind the screen. Yale University Press.",
      "doi": ""
    },
    {
      "text": "Mozhgan Saeidi, Samuel Bruno\u00a0da S\u00a0Sousa, Evangelos Milios, Norbert Zeh, and Lilian Berton. 2019. Categorizing online harassment on Twitter. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 283\u2013297.",
      "doi": ""
    },
    {
      "text": "Koustuv Saha, Eshwar Chandrasekharan, and Munmun De\u00a0Choudhury. 2019. Prevalence and psychological effects of hateful speech in online college communities. In Proceedings of the 10th ACM conference on web science. 255\u2013264.",
      "doi": "10.1145/3292522.3326032"
    },
    {
      "text": "Vlad Sandulescu and Martin Ester. 2015. Detecting singleton review spammers using semantic similarity. In Proceedings of the 24th international conference on World Wide Web. 971\u2013976.",
      "doi": "10.1145/2740908.2742570"
    },
    {
      "text": "Nathan Schneider, Primavera De\u00a0Filippi, Seth Frey, Joshua\u00a0Z Tan, and Amy\u00a0X Zhang. 2021. Modular Politics: Toward a Governance Layer for Online Communities. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201326.",
      "doi": "10.1145/3449090"
    },
    {
      "text": "Joseph Seering. 2020. Reconsidering Self-Moderation: the Role of Research in Supporting Community-Based Models for Online Content Moderation. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2(2020), 1\u201328.",
      "doi": "10.1145/3415178"
    },
    {
      "text": "Joseph Seering, Tony Wang, Jina Yoon, and Geoff Kaufman. 2019. Moderator engagement and community development in the age of algorithms. New Media & Society 21, 7 (2019), 1417\u20131443.",
      "doi": ""
    },
    {
      "text": "Monika Singh, Divya Bansal, and Sanjeev Sofat. 2016. Behavioral analysis and classification of spammers distributing pornographic content in social media. Social Network Analysis and Mining 6, 1 (2016), 1\u201318.",
      "doi": ""
    },
    {
      "text": "Sara Sood, Judd Antin, and Elizabeth Churchill. 2012. Profanity use in online communities. In Proceedings of the SIGCHI conference on human factors in computing systems. 1481\u20131490.",
      "doi": "10.1145/2207676.2208610"
    },
    {
      "text": "Sara\u00a0Owsley Sood, Elizabeth\u00a0F Churchill, and Judd Antin. 2012. Automatic identification of personal insults on social news sites. Journal of the American Society for Information Science and Technology 63, 2 (2012), 270\u2013285.",
      "doi": "10.1002/asi.21690"
    },
    {
      "text": "Top.gg. 2022. Mee6 discord bot: The #1 discord bot list. https://top.gg/bot/159985870458322944",
      "doi": ""
    },
    {
      "text": "Kristen Vaccaro, Christian Sandvig, and Karrie Karahalios. 2020. \" At the End of the Day Facebook Does What ItWants\" How Users Experience Contesting Algorithmic Content Moderation. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2(2020), 1\u201322.",
      "doi": ""
    },
    {
      "text": "James Vincent. 2020. Facebook is now using AI to sort content for quicker moderation. The Verge (Nov. 2020). https://www.theverge.com/2020/11/13/21562596/facebook-ai-moderation",
      "doi": ""
    },
    {
      "text": "Amy\u00a0X Zhang, Grant Hugh, and Michael\u00a0S Bernstein. 2020. PolicyKit: Building Governance in Online Communities. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology. 365\u2013378.",
      "doi": "10.1145/3379337.3415858"
    }
  ]
}