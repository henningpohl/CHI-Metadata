{
  "doi": "10.1145/3544548.3581287",
  "title": "Understanding tensions in music accessibility through song signing for and with d/Deaf and Non-d/Deaf persons",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-18",
  "year": 2023,
  "badges": [],
  "abstract": "Song signing is a method practiced by people who are d/Deaf and non-d/Deaf individuals to visually represent music and make music accessible through sign language and body movements. Although there is growing interest in song signing, there is a lack of understanding on what d/Deaf people value about song signing and how to make song signing productions that they would consider acceptable. We conducted semi-structured interviews with 12 d/Deaf participants to gain a deeper understanding of what they value in music and song signing. We then interviewed 14 song signers to understand their experiences and processes in creating song signing performances. From this study, we identify three complex, interrelated layers of the song signing creation process and discuss how they can be supported and completed to potentially bridge the cultural divide between the d/Deaf and non-d/Deaf audiences and guide more culturally responsive creation of music.",
  "authors": [
    {
      "name": "Suhyeon Yoo",
      "institution": "Computer Science, University of Toronto, Canada",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660782148",
      "orcid": "0000-0001-6098-9947"
    },
    {
      "name": "Georgianna Lin",
      "institution": "Computer Science, University of Toronto, Canada",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660783266",
      "orcid": "0000-0002-9993-2718"
    },
    {
      "name": "Hyeon Jeong Byeon",
      "institution": "Computer Science and Engineering, Ewha Womans University, Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659894443",
      "orcid": "0000-0002-0811-2504"
    },
    {
      "name": "Amy S. Hwang",
      "institution": "Computer Science, University of Toronto, Canada",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658704869",
      "orcid": "0000-0003-0217-6088"
    },
    {
      "name": "Khai Nhut Truong",
      "institution": "Computer Science, University of Toronto, Canada",
      "img": "/do/10.1145/contrib-81339532748/rel-imgonly/81339532748.jpg",
      "acmid": "81339532748",
      "orcid": "0000-0003-0774-5964"
    }
  ],
  "references": [
    {
      "text": "1993. Do you feel comfortable having hearing people signing songs to deaf audience?Deaf Life (Jul 1993), p. 60.",
      "doi": ""
    },
    {
      "text": "Kailyn Aaron\u00a0Lozano and H\u00a0Dirksen\u00a0L Bauman. 2022. Sign Language Music Videos: Language Preservation or Appropriation?In The Routledge Companion to Art and Disability.",
      "doi": ""
    },
    {
      "text": "Pawe\u0142 Aleksandrowicz. 2020. Can subtitles for the deaf and hard-of-hearing convey the emotions of film music? A reception study. Perspectives 28, 1 (2020), 58\u201372.",
      "doi": ""
    },
    {
      "text": "Felipe Alves\u00a0Araujo, Fabricio Lima\u00a0Brasil, Allison Candido Lima\u00a0Santos, Luzenildo de Sousa Batista\u00a0Junior, Savio Pereira Fonseca\u00a0Dutra, and Carlos Eduardo Coelho Freire\u00a0Batista. 2017. Auris system: providing vibrotactile feedback for hearing impaired population. BioMed research international 2017 (2017).",
      "doi": ""
    },
    {
      "text": "Shunya Ariga, Masataka Goto, and Koji Yatani. 2017. Strummer: An interactive guitar chord practice system. In 2017 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 1057\u20131062.",
      "doi": ""
    },
    {
      "text": "Ben Bahan. 2006. Face-to-face tradition in the American Deaf Community. Signing the body poetic(2006), 21\u201350.",
      "doi": ""
    },
    {
      "text": "Mathieu Barthet, Gy\u00f6rgy Fazekas, and Mark Sandler. 2012. Music emotion recognition: From content-to context-based models. In International symposium on computer music modeling and retrieval. Springer, 228\u2013252.",
      "doi": ""
    },
    {
      "text": "Beth\u00a0S Benedict and Marilyn Sass-Lehrer. 2007. Deaf and hearing partnerships: Ethical and communication considerations. American annals of the deaf 152, 3 (2007), 275\u2013282.",
      "doi": ""
    },
    {
      "text": "Tony Bergstrom, Karrie Karahalios, and John\u00a0C Hart. 2007. Isochords: visualizing structure in music. In Proceedings of Graphics Interface 2007. 297\u2013304.",
      "doi": "10.1145/1268517.1268565"
    },
    {
      "text": "Katelyn\u00a0E Best. 2015. \u201cWe still have a dream\u201d the deaf hip hop movement and the struggle against the socio-cultural marginalization of deaf people. Lied und popul\u00e4re Kultur/Song and Popular Culture 60 (2015), 61\u201386.",
      "doi": ""
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative research in psychology 3, 2 (2006), 77\u2013101.",
      "doi": ""
    },
    {
      "text": "Sylvain Br\u00e9t\u00e9ch\u00e9. 2019. The Deaf Musical Experience. In International Symposium on Computer Music Multidisciplinary Research. Springer, 422\u2013448.",
      "doi": ""
    },
    {
      "text": "Diane Brewer. 2002. West side silence: Producing West Side Story with deaf and hearing actors. Theatre Topics 12, 1 (2002), 17\u201334.",
      "doi": ""
    },
    {
      "text": "Noah Buchholz. 2018. Seeing music? An inquiry into the place of music in Deaf culture. Journal of American Sign Languages & Literatures (2018).",
      "doi": ""
    },
    {
      "text": "Doga Cavdir. 2022. Touch, Listen,(Re) Act: Co-designing Vibrotactile Wearable Instruments for Deaf and Hard of Hearing. In NIME 2022. PubPub.",
      "doi": ""
    },
    {
      "text": "James\u00a0I Charlton. 1998. Nothing about us without us. In Nothing About Us Without Us. University of California Press.",
      "doi": ""
    },
    {
      "text": "Kathy Charmaz. 2006. Constructing grounded theory: A practical guide through qualitative analysis. sage.",
      "doi": ""
    },
    {
      "text": "Jody Cripps. 2018. Ethnomusicology & signed music: A breakthrough. Journal of American Sign Languages & Literatures (2018).",
      "doi": ""
    },
    {
      "text": "Jody\u00a0H Cripps. 2017. Understanding Signed Music. Society for American Sign Language Journal 1 (2017).",
      "doi": ""
    },
    {
      "text": "Jody\u00a0H Cripps, Ely Rosenblum, Anita Small, and Samuel\u00a0J Supalla. 2017. A case study on signed music: The emergence of an inter-performance art. Liminalities 13, 2 (2017).",
      "doi": ""
    },
    {
      "text": "Robert Dale. 2021. GPT-3: What\u2019s it good for?Natural Language Engineering 27, 1 (2021), 113\u2013118.",
      "doi": ""
    },
    {
      "text": "Alice-Ann Darrow. 1987. Exploring the arts of sign and song. Music Educators Journal 74, 1 (1987), 32\u201335.",
      "doi": ""
    },
    {
      "text": "Alice-Ann Darrow. 1993. The role of music in deaf culture: Implications for music educators. Journal of Research in Music Education 41, 2 (1993), 93\u2013110.",
      "doi": ""
    },
    {
      "text": "Alice-Ann Darrow. 2006. Sounds in the silence: Research on music and deafness. Update: Applications of Research in Music Education 25, 1 (2006), 5\u201314.",
      "doi": ""
    },
    {
      "text": "Maartje De\u00a0Meulder. 2019. \u201cSo, why do you sign?\u201d Deaf and hearing new signers, their motivation, and revitalisation policies for sign languages. Applied Linguistics Review 10, 4 (2019), 705\u2013724.",
      "doi": ""
    },
    {
      "text": "Nicolas DeGuglielmo, Cesar Lobo, Edward\u00a0J Moriarty, Gloria Ma, and Douglas\u00a0E Dow. 2021. Haptic Vibrations for Hearing Impaired to Experience Aspects of Live Music. In International Conference on Bio-inspired Information and Communication Technologies. Springer, 71\u201386.",
      "doi": ""
    },
    {
      "text": "Jordan\u00a0Aiko Deja, Alexczar Dela\u00a0Torre, Hans\u00a0Joshua Lee, Jose\u00a0Florencio Ciriaco\u00a0IV, and Carlo\u00a0Miguel Eroles. 2020. Vitune: A visualizer tool to allow the deaf and hard of hearing to see music with their eyes. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u20138.",
      "doi": "10.1145/3334480.3383046"
    },
    {
      "text": "Becca Dingman, Garreth\u00a0W Tigwell, and Kristen Shinohara. 2021. Designing a Podcast Platform for Deaf and Hard of Hearing Users. In The 23rd International ACM SIGACCESS Conference on Computers and Accessibility. 1\u20134.",
      "doi": "10.1145/3441852.3476523"
    },
    {
      "text": "Daniel\u00a0PW Ellis. 2006. Extracting information from music audio. Commun. ACM 49, 8 (2006), 32\u201337.",
      "doi": "10.1145/1145287.1145310"
    },
    {
      "text": "Karla Enriquez, Melany Palacios, Daniel Pallo, and Graciela Guerrero. 2020. SENSE: Sensory component VR application for hearing impaired people to enhance the music experience. In 2020 15th Iberian Conference on Information Systems and Technologies (CISTI). IEEE, 1\u20136.",
      "doi": ""
    },
    {
      "text": "Citra Fadillah and RR\u00a0Ratna\u00a0Amalia Rahayu. 2019. Sound Visualization Using Typography Composition Based GIF. In 2019 International Conference on Sustainable Engineering and Creative Computing (ICSECC). IEEE, 309\u2013314.",
      "doi": ""
    },
    {
      "text": "Michael Fell. 2020. Natural language processing for music information retrieval: deep analysis of lyrics structure and content. Ph.\u00a0D. Dissertation. Universit\u00e9 C\u00f4te d\u2019Azur.",
      "doi": ""
    },
    {
      "text": "Jami\u00a0N Fisher, Gene Mirus, and Donna\u00a0Jo Napoli. 2019. Sticky: Taboo topics in deaf communities. (2019).",
      "doi": ""
    },
    {
      "text": "Vicky\u00a0J Fisher. 2021. Embodied Songs: Insights Into the Nature of Cross-Modal Meaning-Making Within Sign Language Informed, Embodied Interpretations of Vocal Music. Frontiers in psychology 12 (2021).",
      "doi": ""
    },
    {
      "text": "Luciano Floridi and Massimo Chiriatti. 2020. GPT-3: Its nature, scope, limits, and consequences. Minds and Machines 30, 4 (2020), 681\u2013694.",
      "doi": "10.1007/s11023-020-09548-1"
    },
    {
      "text": "David Fourney. 2012. Can computer representations of music enhance enjoyment for individuals who are hard of hearing?. In International Conference on Computers for Handicapped Persons. Springer, 535\u2013542.",
      "doi": "10.1007/978-3-642-31522-0_80"
    },
    {
      "text": "David\u00a0W Fourney and Deborah\u00a0I Fels. 2009. Creating access to music through visualization. In 2009 ieee toronto international conference science and technology for humanity (tic-sth). IEEE, 939\u2013944.",
      "doi": ""
    },
    {
      "text": "Hiromasa Fujihara, Masataka Goto, Jun Ogata, and Hiroshi\u00a0G Okuno. 2011. LyricSynchronizer: Automatic synchronization system between musical audio signals and lyrics. IEEE Journal of Selected Topics in Signal Processing 5, 6 (2011), 1252\u20131261.",
      "doi": ""
    },
    {
      "text": "Graham\u00a0R Gibbs. 2007. Thematic coding and categorizing. Analyzing qualitative data 703 (2007), 38\u201356.",
      "doi": ""
    },
    {
      "text": "Abraham Glasser, Fyodor Minakov, and Danielle Bragg. 2022. ASL Wiki: An Exploratory Interface for Crowdsourcing ASL Translations. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility. 1\u201313.",
      "doi": "10.1145/3517428.3544827"
    },
    {
      "text": "Satoshi Hashizume, Shinji Sakamoto, Kenta Suzuki, and Yoichi Ochiai. 2018. Livejacket: Wearable music experience device with multiple speakers. In International Conference on Distributed, Ambient, and Pervasive Interactions. Springer, 359\u2013371.",
      "doi": "10.1007/978-3-319-91125-0_30"
    },
    {
      "text": "Alice Haynes, Jonathan Lawry, Christopher Kent, and Jonathan Rossiter. 2021. FeelMusic: enriching our emotive experience of music through audio-tactile mappings. Multimodal Technologies and Interaction 5, 6 (2021), 29.",
      "doi": ""
    },
    {
      "text": "Gabrielle Hodge. 2020. The ideology of communication practices embedded in an Australian deaf/hearing dance collaboration. Sign Language Ideologies in Practice(2020), 59\u201382.",
      "doi": ""
    },
    {
      "text": "Jessica\u00a0A Holmes. 2017. Expert listening beyond the limits of hearing: Music and deafness. Journal of the American Musicological Society 70, 1 (2017), 171\u2013220.",
      "doi": ""
    },
    {
      "text": "Ryo Iijima, Akihisa Shitara, and Yoichi Ochiai. 2022. Designing Gestures for Digital Musical Instruments: Gesture Elicitation Study with Deaf and Hard of Hearing People. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility. 1\u20138.",
      "doi": "10.1145/3517428.3544828"
    },
    {
      "text": "Eric\u00a0J Isaacson. 2005. What You See Is What You Get: on Visualizing Music.. In ISMIR. 389\u2013395.",
      "doi": ""
    },
    {
      "text": "Robert Jack, Andrew McPherson, and Tony Stockman. 2015. Designing tactile musical devices with and for deaf users: a case study. In Proceedings of the International Conference on the Multimodal Experience of Music, Sheffield, UK. 23\u201325.",
      "doi": ""
    },
    {
      "text": "Haojian Jin, Yale Song, and Koji Yatani. 2017. Elasticplay: Interactive video summarization with dynamic time budgets. In Proceedings of the 25th ACM international conference on Multimedia. 1164\u20131172.",
      "doi": "10.1145/3123266.3123393"
    },
    {
      "text": "Junichi Kanebako, Fusako Kusunoki, Shigenori Inagaki, and Miki Namatame. 2015. Proposal for science learning materials using a\" VibGrip\". In Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology. 1\u20133.",
      "doi": "10.1145/2832932.2832935"
    },
    {
      "text": "Junichi Kanebako and Kouta Minamizawa. 2016. VibGrip++: haptic device allows feeling the music for hearing impaired people. In International AsiaHaptics conference. Springer, 449\u2013452.",
      "doi": ""
    },
    {
      "text": "Maria Karam, Carmen Branje, Gabe Nespoli, Norma Thompson, Frank\u00a0A Russo, and Deborah\u00a0I Fels. 2010. The emoti-chair: an interactive tactile music exhibit. In CHI\u201910 Extended Abstracts on Human Factors in Computing Systems. 3069\u20133074.",
      "doi": ""
    },
    {
      "text": "Maria Karam and Deborah\u00a0I Fels. 2008. Designing a model human cochlea: Issues and challenges in crossmodal audio-haptic displays. In Proceedings of the 2008 Ambi-Sys workshop on Haptic user interfaces in ambient media systems. 1\u20139.",
      "doi": ""
    },
    {
      "text": "Maria Karam, Gabe Nespoli, Frank Russo, and Deborah\u00a0I Fels. 2009. Modelling perceptual elements of music in a vibrotactile display for deaf users: A field study. In 2009 Second International Conferences on Advances in Computer-Human Interactions. IEEE, 249\u2013254.",
      "doi": "10.1109/ACHI.2009.64"
    },
    {
      "text": "Tanya Keshari and Suja Palaniswamy. 2019. Emotion recognition using feature-level fusion of facial expressions and body gestures. In 2019 International Conference on Communication and Electronics Systems (ICCES). IEEE, 1184\u20131189.",
      "doi": ""
    },
    {
      "text": "Michael Kipp, Alexis Heloir, and Quan Nguyen. 2011. Sign language avatars: Animation and comprehensibility. In International Workshop on Intelligent Virtual Agents. Springer, 113\u2013126.",
      "doi": ""
    },
    {
      "text": "Katri Kosonen and Roope Raisamo. 2006. Rhythm perception through different modalities. In Proc. EuroHaptics. 365\u2013370.",
      "doi": ""
    },
    {
      "text": "Daniel\u00a0G Lee, Deborah\u00a0I Fels, and John\u00a0Patrick Udo. 2007. Emotive captioning. Computers in Entertainment (CIE) 5, 2 (2007), 11.",
      "doi": "10.1145/1236224.1236242"
    },
    {
      "text": "Sang\u00a0Won Lee and Jeffrey Scott. 2017. Word level lyrics-audio synchronization using separated vocals. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 646\u2013650.",
      "doi": "10.1109/ICASSP.2017.7952235"
    },
    {
      "text": "Kelly Mack, Danielle Bragg, Meredith\u00a0Ringel Morris, Maarten\u00a0W Bos, Isabelle Albi, and Andr\u00e9s Monroy-Hern\u00e1ndez. 2020. Social app accessibility for deaf signers. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2(2020), 1\u201331.",
      "doi": "10.1145/3415196"
    },
    {
      "text": "Anabel Maler. 2013. Songs for hands: Analyzing interactions of sign language and music. Music theory online 19, 1 (2013).",
      "doi": ""
    },
    {
      "text": "Anabel Maler. 2015. Musical expression among deaf and hearing song signers. The Oxford handbook of music and disability studies (2015), 73\u201391.",
      "doi": ""
    },
    {
      "text": "Anabel Maler. 2022. Music and Deafness in the Nineteenth-Century US Imagination. Journal of the Society for American Music(2022), 1\u201322.",
      "doi": ""
    },
    {
      "text": "Anabel Maler and Robert Komaniecki. 2021. Rhythmic Techniques in Deaf Hip Hop. Music Theory Online 27, 1 (2021).",
      "doi": ""
    },
    {
      "text": "Heather\u00a0Harden Mangelsdorf, Jason Listman, and Anabel Maler. 2021. Perception of Musicality and Emotion in Signed Songs. Music Perception: An Interdisciplinary Journal 39, 2 (2021), 160\u2013180.",
      "doi": ""
    },
    {
      "text": "Jennifer Mankoff, Gillian\u00a0R Hayes, and Devva Kasnitz. 2010. Disability studies as a source of critical inquiry for the field of assistive technology. In Proceedings of the 12th international ACM SIGACCESS conference on Computers and accessibility. 3\u201310.",
      "doi": "10.1145/1878803.1878807"
    },
    {
      "text": "Antonella Mazzoni and Nick Bryan-Kinns. 2016. Mood glove: A haptic wearable prototype system to enhance mood music in film. Entertainment Computing 17 (2016), 9\u201317.",
      "doi": ""
    },
    {
      "text": "Thomas\u00a0Barlow McHugh, Abir Saha, David Bar-El, Marcelo Worsley, and Anne\u00a0Marie Piper. 2021. Towards Inclusive Streaming: Building Multimodal Music Experiences for the Deaf and Hard of Hearing. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u20137.",
      "doi": ""
    },
    {
      "text": "Sebastian Merchel and M\u00a0Ercan Altinsoy. 2014. The influence of vibrations on musical experience. Journal of the Audio Engineering Society 62, 4 (2014), 220\u2013234.",
      "doi": ""
    },
    {
      "text": "Jorge Mori and Deborah\u00a0I Fels. 2009. Seeing the music can animated lyrics provide access to the emotional content in music for people who are deaf or hard of hearing?. In 2009 IEEE Toronto International Conference Science and Technology for Humanity (TIC-STH). IEEE, 951\u2013956.",
      "doi": ""
    },
    {
      "text": "John\u00a0W Morley and Mark\u00a0J Rowe. 1990. Perceived pitch of vibrotactile stimuli: effects of vibration amplitude, and implications for vibration frequency coding.The Journal of physiology 431, 1 (1990), 403\u2013416.",
      "doi": ""
    },
    {
      "text": "Suranga Nanayakkara, Elizabeth Taylor, Lonce Wyse, and S\u00a0H Ong. 2009. An enhanced musical experience for the deaf: design and evaluation of a music display and a haptic chair. In Proceedings of the sigchi conference on human factors in computing systems. 337\u2013346.",
      "doi": "10.1145/1518701.1518756"
    },
    {
      "text": "Suranga\u00a0Chandima Nanayakkara, Elizabeth Taylor, Lonce Wyse, and SH Ong. 2007. Towards building an experiential music visualizer. In 2007 6th International Conference on Information, Communications & Signal Processing. IEEE, 1\u20135.",
      "doi": ""
    },
    {
      "text": "Suranga\u00a0Chandima Nanayakkara, Lonce Wyse, Sim\u00a0Heng Ong, and Elizabeth\u00a0A Taylor. 2013. Enhancing musical experience for the hearing-impaired using visual and haptic displays. Human\u2013Computer Interaction 28, 2 (2013), 115\u2013160.",
      "doi": ""
    },
    {
      "text": "Ashley\u00a0M Nassiri, Donna\u00a0L Sorkin, and Matthew\u00a0L Carlson. 2022. Current estimates of cochlear implant utilization in the United States. Otology & Neurotology 43, 5 (2022), e558\u2013e562.",
      "doi": ""
    },
    {
      "text": "NIH National Institute\u00a0of Health. 2021. Quick statistics about hearing. https://www.nidcd.nih.gov/health/statistics/quick-statistics-hearing",
      "doi": ""
    },
    {
      "text": "Kia Ng, Joanne Armitage, and Alex McLean. 2014. The colour of music: Real-time music visualisation with synaesthetic sound-colour mapping. Electronic Visualisation and the Arts (EVA 2014) (2014), 17\u201320.",
      "doi": ""
    },
    {
      "text": "Catherine O\u2019Brien, Crystal Kroner, and Peggy Placier. 2015. Deaf culture and academic culture: Cultivating understanding across cultural and linguistic boundaries.Journal of Diversity in Higher Education 8, 2 (2015), 104.",
      "doi": ""
    },
    {
      "text": "Keita Ohshiro and Mark Cartwright. 2022. How people who are deaf, Deaf, and hard of hearing use technology in creative sound activities. In Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility. 1\u20134.",
      "doi": "10.1145/3517428.3550396"
    },
    {
      "text": "Benjamin\u00a0I Outram. 2016. Synesthesia audio-visual interactive-sound and music visualization in virtual reality with orbital observation and navigation. In 2016 IEEE International Workshop on Mixed Reality Art (MRA). IEEE, 7\u20138.",
      "doi": ""
    },
    {
      "text": "Carol\u00a0A Padden and Tom Humphries. 1988. Deaf in America: Voices from a culture. Harvard University Press.",
      "doi": ""
    },
    {
      "text": "Soochul Park and Ben\u00a0Sangbae Chon. 2020. GSEP: A robust vocal and accompaniment separation system using gated CBHG module and loudness normalization. arXiv preprint arXiv:2010.12139(2020).",
      "doi": ""
    },
    {
      "text": "Joana\u00a0Mor\u00eado Pereira. 2021. Deaf on stage: the cultural impact of performing Signed Songs. University of London, University College London (United Kingdom).",
      "doi": ""
    },
    {
      "text": "Benjamin Petry, Thavishi Illandara, Don\u00a0Samitha Elvitigala, and Suranga Nanayakkara. 2018. Supporting rhythm activities of deaf children using music-sensory-substitution systems. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. 1\u201310.",
      "doi": "10.1145/3173574.3174060"
    },
    {
      "text": "Benjamin Petry, Thavishi Illandara, Juan\u00a0Pablo Forero, and Suranga Nanayakkara. 2016. Ad-hoc access to musical sound for deaf individuals. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility. 285\u2013286.",
      "doi": "10.1145/2982142.2982213"
    },
    {
      "text": "Benjamin Petry, Thavishi Illandara, and Suranga Nanayakkara. 2016. MuSS-bits: sensor-display blocks for deaf people to explore musical sounds. In Proceedings of the 28th Australian Conference on Computer-Human Interaction. 72\u201380.",
      "doi": "10.1145/3010915.3010939"
    },
    {
      "text": "Michael Pouris and Deborah\u00a0I Fels. 2012. Creating an entertaining and informative music visualization. In International Conference on Computers for Handicapped Persons. Springer, 451\u2013458.",
      "doi": "10.1007/978-3-642-31522-0_68"
    },
    {
      "text": "Konstantinos Pyrovolakis, Paraskevi Tzouveli, and George Stamou. 2021. Mood detection analyzing lyrics and audio signal based on deep learning architectures. In 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 9363\u20139370.",
      "doi": ""
    },
    {
      "text": "Raisa Rashid, Quoc Vy, Richard Hunt, and Deborah\u00a0I Fels. 2008. Dancing with words: Using animated text for captioning. Intl. Journal of Human\u2013Computer Interaction 24, 5(2008), 505\u2013519.",
      "doi": ""
    },
    {
      "text": "Pablo Revuelta, Tom\u00e1s Ortiz, Mar\u00eda\u00a0J Luc\u00eda, Bel\u00e9n Ruiz, and Jos\u00e9\u00a0Manuel S\u00e1nchez-Pena. 2020. Limitations of standard accessible captioning of sounds and music for deaf and hard of hearing people: An EEG study. Frontiers in integrative neuroscience(2020), 1.",
      "doi": ""
    },
    {
      "text": "Kelly Robinson. 2021. Knowing by DEAF-Listening: Epistemologies & Ontologies Revealed in Song-Signing. (2021).",
      "doi": ""
    },
    {
      "text": "WUD Rodrigo, HUW Ratnayake, and IA Premaratne. 2021. Identification of Music Instruments from a Music Audio File. In Proceedings of International Conference on Sustainable Expert Systems. Springer, 335\u2013352.",
      "doi": ""
    },
    {
      "text": "Martin Rothenberg, Ronald\u00a0T Verrillo, Stephen\u00a0A Zahorian, Michael\u00a0L Brachman, and Stanley\u00a0J Bolanowski\u00a0Jr. 1977. Vibrotactile frequency for encoding a speech parameter. The Journal of the Acoustical Society of America 62, 4 (1977), 1003\u20131012.",
      "doi": ""
    },
    {
      "text": "Joseph Rovan and Vincent Hayward. 2000. Typology of tactile sounds and their synthesis in gesture-driven computer music performance. Trends in gestural control of music(2000), 297\u2013320.",
      "doi": ""
    },
    {
      "text": "Frank\u00a0A Russo, Paolo Ammirante, and Deborah\u00a0I Fels. 2012. Vibrotactile discrimination of musical timbre.Journal of Experimental Psychology: Human Perception and Performance 38, 4(2012), 822.",
      "doi": ""
    },
    {
      "text": "Ioannis\u00a0Petros Samiotis, Sihang Qiu, Andrea Mauri, Cynthia\u00a0CS Liem, Christoph Lofi, and Alessandro Bozzon. 2020. Microtask Crowdsourcing for Music Score Transcriptions: An Experiment with Error Detection.. In ISMIR. 901\u2013907.",
      "doi": ""
    },
    {
      "text": "R Santhoshkumar and M\u00a0Kalaiselvi Geetha. 2019. Deep learning approach for emotion recognition from human body movements with feedforward deep convolution neural networks. Procedia Computer Science 152 (2019), 158\u2013165.",
      "doi": "10.1016/j.procs.2019.05.038"
    },
    {
      "text": "Pierre Schmitt. 2017. Representations of sign language, deaf people, and interpreters in the arts and the media. Sign Language Studies 18, 1 (2017), 130\u2013147.",
      "doi": ""
    },
    {
      "text": "Anastasia Schmitz, Catherine Holloway, and Youngjun Cho. 2020. Hearing through Vibrations: Perception of Musical Emotions by Profoundly Deaf People. arXiv preprint arXiv:2012.13265(2020).",
      "doi": ""
    },
    {
      "text": "Jerry\u00a0C Schnepp, Rosalee\u00a0J Wolfe, John\u00a0C McDonald, and Jorge\u00a0A Toro. 2012. Combining emotion and facial nonmanual signals in synthesized american sign language. In Proceedings of the 14th international ACM SIGACCESS conference on Computers and accessibility. 249\u2013250.",
      "doi": "10.1145/2384916.2384977"
    },
    {
      "text": "Andr\u00e9anne Sharp, BA Bacon, and F Champoux. 2020. Enhanced tactile identification of musical emotion in the deaf. Experimental brain research 238, 5 (2020), 1229\u20131236.",
      "doi": ""
    },
    {
      "text": "Miguel\u00a0Cuadrado Sierra, Jonas Brunskog, and Jeremy Marozeau. 2021. An audio-tactile artinstallation for hearing impaired people. In 2nd Nordic Sound and Music Conference.",
      "doi": ""
    },
    {
      "text": "Jason\u00a0M Silveira and Frank\u00a0M Diaz. 2014. The effect of subtitles on listeners\u2019 perceptions of expressivity. Psychology of music 42, 2 (2014), 233\u2013250.",
      "doi": ""
    },
    {
      "text": "Anita Small. 2021. Mentorship for Canadian Deaf Artists: Fostering Deaf Performance Arts Excellence. Canadian Cultural Society of the Deaf(2021).",
      "doi": ""
    },
    {
      "text": "Robert\u00a0G Smith and Brian Nolan. 2016. Emotional facial expressions in synthesised sign language avatars: a manual evaluation. Universal Access in the Information Society 15, 4 (2016), 567\u2013576.",
      "doi": "10.1007/s10209-015-0410-7"
    },
    {
      "text": "Ene\u00a0Alicia S\u00f8derberg, Rasmus\u00a0Emil Odgaard, Sarah Bitsch, Oliver H\u00f8eg-Jensen, Nikolaj\u00a0Schildt Christensen, S\u00f8ren\u00a0Dahl Poulsen, and Steven Gelineck. 2016. Music Aid: Towards a Collaborative Experience for Deaf and Hearing People in Creating Music. In New Interfaces for Musical Expression.",
      "doi": ""
    },
    {
      "text": "Nan Song, Hongwu Yang, and Peiwen Wu. 2018. A gesture-to-emotional speech conversion by combining gesture recognition and facial expression recognition. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia). IEEE, 1\u20136.",
      "doi": ""
    },
    {
      "text": "T Stark, SJ Brockmeier, P Nopp, M Vischer, WD Baumgartner, F Sch\u00f6n, J M\u00fcller, T Braunschweig, W Arnold, and DJ Allum. 2003. Correlation of speech and music appreciation in post-lingually deaf Combi 40/40+ cochlear implant users. Cochlear implants international 4, S1 (2003), 68\u201369.",
      "doi": ""
    },
    {
      "text": "Minhyang\u00a0(Mia) Suh, Emily Youngblom, Michael Terry, and Carrie\u00a0J Cai. 2021. AI as Social Glue: Uncovering the Roles of Deep Generative AI during Social Music Composition. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 582, 11\u00a0pages. https://doi.org/10.1145/3411764.3445219",
      "doi": "10.1145/3411764.3445219"
    },
    {
      "text": "Veronika Szucs, Beata Kovacs, and Balint Tasnadi. 2018. Music for seeing\u2013visualization of sounds. In 2018 9th IEEE International Conference on Cognitive Infocommunications (CogInfoCom). IEEE, 000123\u2013000128.",
      "doi": ""
    },
    {
      "text": "Pauline Tranchant, Martha\u00a0M Shiell, Marcello Giordano, Alexis Nadeau, Isabelle Peretz, and Robert\u00a0J Zatorre. 2017. Feeling the beat: Bouncing synchronization to vibrotactile music in hearing and early deaf people. Frontiers in neuroscience 11 (2017), 507.",
      "doi": ""
    },
    {
      "text": "Urvish Trivedi, Redwan Alqasemi, and Rajiv Dubey. 2019. Wearable musical haptic sleeves for people with hearing impairment. In Proceedings of the 12th ACM International Conference on Pervasive Technologies Related to Assistive Environments. 146\u2013151.",
      "doi": "10.1145/3316782.3316796"
    },
    {
      "text": "Tim Tse, Justin Salamon, Alex\u00a0C Williams, Helga Jiang, and Edith Law. 2016. Ensemble: A Hybrid Human-Machine System for Generating Melody Scores from Audio.. In ISMIR. 143\u2013149.",
      "doi": ""
    },
    {
      "text": "Luca Turchet, Travis West, and Marcelo\u00a0M Wanderley. 2021. Touching the audience: musical haptic wearables for augmented and participatory live music performances. Personal and Ubiquitous Computing 25, 4 (2021), 749\u2013769.",
      "doi": "10.1007/s00779-020-01395-2"
    },
    {
      "text": "Stefan Uhlich, Franck Giron, and Yuki Mitsufuji. 2015. Deep neural network based instrument extraction from music. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2135\u20132139.",
      "doi": ""
    },
    {
      "text": "Joy Victory. 2021. Hearing loss statistics at a glance. https://www.healthyhearing.com/report/52814-Hearing-loss-statistics-at-a-glance",
      "doi": ""
    },
    {
      "text": "Ulrich Von\u00a0Agris, J\u00f6rg Zieren, Ulrich Canzler, Britta Bauer, and Karl-Friedrich Kraiss. 2008. Recent developments in visual sign language recognition. Universal Access in the Information Society 6, 4 (2008), 323\u2013362.",
      "doi": "10.1007/s10209-007-0104-x"
    },
    {
      "text": "Quoc\u00a0V Vy, Jorge\u00a0A Mori, David\u00a0W Fourney, and Deborah\u00a0I Fels. 2008. EnACT: A software tool for creating animated text captions. In International Conference on Computers for Handicapped Persons. Springer, 609\u2013616.",
      "doi": "10.1007/978-3-540-70540-6_87"
    },
    {
      "text": "Amy Wilson and Nickson Kakiri. 2011. Best practices for collaborating with deaf communities in developing countries. Deaf around the world: The impact of language (2011), 271\u2013286.",
      "doi": ""
    },
    {
      "text": "Ju-Lee\u00a0A Wolsey, Kim\u00a0Misener Dunn, Scott\u00a0W Gentzke, Hannah\u00a0A Joharchi, M\u00a0Diane Clark, and CSEDL Team. 2017. Deaf/hearing research partnerships. American Annals of the Deaf 161, 5 (2017), 571\u2013582.",
      "doi": ""
    },
    {
      "text": "Yi-Hsuan Yang and Homer\u00a0H Chen. 2011. Music emotion recognition. CRC Press.",
      "doi": ""
    },
    {
      "text": "Yixiao Zhang, Junyan Jiang, Gus Xia, and Simon Dixon. 2022. Interpreting Song Lyrics with an Audio-Informed Pre-trained Language Model. arXiv preprint arXiv:2208.11671(2022).",
      "doi": ""
    },
    {
      "text": "Zhongyi Zhou, Anran Xu, and Koji Yatani. 2021. SyncUp: Vision-based Practice Support for Synchronized Dancing. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 3 (2021), 1\u201325.",
      "doi": "10.1145/3478120"
    }
  ]
}