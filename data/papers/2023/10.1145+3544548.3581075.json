{
  "doi": "10.1145/3544548.3581075",
  "title": "Ignore, Trust, or Negotiate: Understanding Clinician Acceptance of AI-Based Treatment Recommendations in Health Care",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-18",
  "year": 2023,
  "badges": [],
  "abstract": "Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term \u201cnegotiation.\u201d These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.",
  "authors": [
    {
      "name": "Venkatesh Sivaraman",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659857571",
      "orcid": "0000-0002-6965-3961"
    },
    {
      "name": "Leigh A Bukowski",
      "institution": "Department of Critical Care Medicine, University of Pittsburgh School of Medicine, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660780364",
      "orcid": "0000-0001-7889-3062"
    },
    {
      "name": "Joel Levin",
      "institution": "University of Pittsburgh, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660781450",
      "orcid": "0000-0002-4095-4840"
    },
    {
      "name": "Jeremy M. Kahn",
      "institution": "Department of Critical Care Medicine, University of Pittsburgh School of Medicine, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660779582",
      "orcid": "0000-0001-9688-5576"
    },
    {
      "name": "Adam Perer",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/do/10.1145/contrib-81100462318/rel-imgonly/adam_head.jpg",
      "acmid": "81100462318",
      "orcid": "0000-0002-8369-3847"
    }
  ],
  "references": [
    {
      "text": "Lamia Alam and Shane Mueller. 2021. Examining the effect of explanation on satisfaction and trust in AI diagnostic systems. BMC Medical Informatics and Decision Making 21, 1 (2021), 1\u201315. https://doi.org/10.1186/s12911-021-01542-6",
      "doi": ""
    },
    {
      "text": "Julia Amann, Dennis Vetter, Stig\u00a0Nikolaj Blomberg, Helle\u00a0Collatz Christensen, Megan Coffee, Sara Gerke, Thomas\u00a0K. Gilbert, Thilo Hagendorff, Sune Holm, Michelle Livne, Andy Spezzatti, Inga Str\u00fcmke, Roberto\u00a0V. Zicari, and Vince\u00a0Istvan Madai. 2022. To explain or not to explain?\u2014Artificial intelligence explainability in clinical decision support systems. PLOS Digital Health 1, 2 (2022), e0000016. https://doi.org/10.1371/journal.pdig.0000016",
      "doi": ""
    },
    {
      "text": "Laura Arbelaez Ossa, Georg Starke, Giorgia Lorenzini, Julia\u00a0E. Vogt, David\u00a0M. Shaw, and Bernice\u00a0Simone Elger. 2022. Re-focusing explainability in medicine. Digital Health 8(2022). https://doi.org/10.1177/20552076221074488",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Daniel\u00a0S. Weld, Walter\u00a0S. Lasecki, and Eric Horvitz. 2019. Updates in human-ai teams: Understanding and addressing the performance/compatibility tradeoff. 33rd AAAI Conference on Artificial Intelligence, AAAI 2019 (2019), 2429\u20132437. https://doi.org/10.1609/aaai.v33i01.33012429",
      "doi": "10.1609/aaai.v33i01.33012429"
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, F.\u00a0O.K. Raymond, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel\u00a0S. Weld. 2020. Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance. arXiv (2020). arxiv:2006.14779",
      "doi": ""
    },
    {
      "text": "Ian\u00a0J Barbash, Billie Davis, and Jeremy\u00a0M Kahn. 2019. National performance on the Medicare SEP-1 sepsis quality measure. Critical care medicine 47, 8 (2019), 1026.",
      "doi": ""
    },
    {
      "text": "Sarah Bayer, Henner Gimpel, and Moritz Markgraf. 2021. The role of domain expertise in trusting and following explainable AI decision support systems. Journal of Decision Systems 00, 00 (2021), 1\u201329. https://doi.org/10.1080/12460125.2021.1958505",
      "doi": ""
    },
    {
      "text": "Melissa Beauchemin, Meghan\u00a0T. Murray, Lillian Sung, Dawn\u00a0L. Hershman, Chunhua Weng, and Rebecca Schnall. 2019. Clinical decision support for therapeutic decision-making in cancer: A systematic review. Int J Med Inform (2019), 139\u2013148. https://doi.org/10.1016/j.ijmedinf.2019.07.019",
      "doi": ""
    },
    {
      "text": "Emma Beede, Elizabeth Baylor, Fred Hersch, Anna Iurchenko, Lauren Wilcox, Paisan Ruamviboonsuk, and Laura\u00a0M. Vardoulakis. 2020. A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy. Conference on Human Factors in Computing Systems - Proceedings (2020), 1\u201312. https://doi.org/10.1145/3313831.3376718",
      "doi": "10.1145/3313831.3376718"
    },
    {
      "text": "Timothy\u00a0G Buchman, Steven\u00a0Q Simpson, Kimberly\u00a0L Sciarretta, Kristen\u00a0P Finne, Nicole Sowers, Michael Collier, Saurabh Chavan, Ibijoke Oke, Meghan\u00a0E Pennini, Aathira Santhosh, 2020. Sepsis among medicare beneficiaries: 1. The burdens of sepsis, 2012\u20132018. Critical care medicine 48, 3 (2020), 276.",
      "doi": ""
    },
    {
      "text": "Zana Bu\u00e7inca, Maja\u00a0Barbara Malaya, and Krzysztof\u00a0Z. Gajos. 2021. To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making. 5, April (2021). https://doi.org/10.1145/3449287 arxiv:2102.09692",
      "doi": "10.1145/3449287"
    },
    {
      "text": "Adrian Bussone, Simone Stumpf, and Dympna O\u2019Sullivan. 2015. The role of explanations on trust and reliance in clinical decision support systems. Conference on Healthcare Informatics(2015). http://openaccess.city.ac.uk/1189/",
      "doi": "10.1109/ICHI.2015.26"
    },
    {
      "text": "Carrie\u00a0J. Cai, Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel Smilkov, Martin Wattenberg, Fernanda Viegas, Greg\u00a0S. Corrado, Martin\u00a0C. Stumpe, and Michael Terry. 2019. Human-centered tools for coping with imperfect algorithms during medical decision-making. Conference on Human Factors in Computing Systems - Proceedings (2019), 1\u201314. arxiv:1902.02960",
      "doi": "10.1145/3290605.3300234"
    },
    {
      "text": "Carrie\u00a0J. Cai, Samantha Winter, David Steiner, Lauren Wilcox, and Michael Terry. 2019. \u201cHello AI\u201d: Uncovering the onboarding needs of medical practitioners for human\u2013AI collaborative decision-making. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019). https://doi.org/10.1145/3359206",
      "doi": "10.1145/3359206"
    },
    {
      "text": "Francisco\u00a0Maria Calisto, Nuno Nunes, and Jacinto\u00a0C. Nascimento. 2022. Modeling adoption of intelligent agents in medical imaging. International Journal of Human Computer Studies 168, September(2022), 102922. https://doi.org/10.1016/j.ijhcs.2022.102922",
      "doi": ""
    },
    {
      "text": "Francisco\u00a0Maria Calisto, Carlos Santiago, Nuno Nunes, and Jacinto\u00a0C. Nascimento. 2021. Introduction of human-centric AI assistant to aid radiologists for multimodal breast image classification. International Journal of Human Computer Studies 150, August 2020(2021), 102607. https://doi.org/10.1016/j.ijhcs.2021.102607",
      "doi": ""
    },
    {
      "text": "Maurizio Cecconi, Laura Evans, Mitchell Levy, and Andrew Rhodes. 2018. Sepsis and septic shock. The Lancet 392, 10141 (July 2018), 75\u201387. https://doi.org/10.1016/S0140-6736(18)30696-2 Publisher: Elsevier.",
      "doi": ""
    },
    {
      "text": "Centers for Disease Control and Prevention. 2021. What is sepsis?",
      "doi": ""
    },
    {
      "text": "Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (San Francisco, California, USA) (KDD \u201916). ACM, New York, NY, USA, 785\u2013794. https://doi.org/10.1145/2939672.2939785",
      "doi": "10.1145/2939672.2939785"
    },
    {
      "text": "Michael Chromik, Malin Eiband, Felicitas Buchner, Adrian Kr\u00fcger, and Andreas Butz. 2021. I Think I Get Your Point, AI! The Illusion of Explanatory Depth in Explainable AI. International Conference on Intelligent User Interfaces, Proceedings IUI (2021), 307\u2013317. https://doi.org/10.1145/3397481.3450644",
      "doi": "10.1145/3397481.3450644"
    },
    {
      "text": "Claudia\u00a0Caroline Dobler, Allison\u00a0S. Morrow, and Celia\u00a0C. Kamath. 2019. Clinicians\u2019 cognitive biases: A potential barrier to implementation of evidence-based clinical practice. BMJ Evidence-Based Medicine 24, 4 (2019), 137\u2013140. https://doi.org/10.1136/bmjebm-2018-111074",
      "doi": ""
    },
    {
      "text": "Mark\u00a0H Ebell, Randi Sokol, Aaron Lee, Christopher Simons, and Jessica Early. 2017. How good is the evidence to support primary care practice?BMJ Evidence-Based Medicine(2017).",
      "doi": ""
    },
    {
      "text": "David\u00a0M. Eddy. 1984. Variations in Physician Practice: The Role of Uncertainty. Health Affairs 3, 2 (1984), 74\u201389. https://doi.org/10.1377/hlthaff.3.2.74 arXiv:https://doi.org/10.1377/hlthaff.3.2.74PMID: 6469198.",
      "doi": ""
    },
    {
      "text": "David\u00a0M Eddy. 1990. Clinical decision making: from theory to practice. Anatomy of a decision. Jama 263, 3 (1990), 441\u2013443.",
      "doi": ""
    },
    {
      "text": "Upol Ehsan, Samir Passi, Q.\u00a0Vera Liao, Larry Chan, I-Hsiang Lee, Michael Muller, and Mark\u00a0O. Riedl. 2021. The Who in Explainable AI: How AI Background Shapes Perceptions of AI Explanations. (2021). arxiv:2107.13509http://arxiv.org/abs/2107.13509",
      "doi": ""
    },
    {
      "text": "Upol Ehsan, Philipp Wintersberger, Q.\u00a0Vera Liao, Martina Mara, Marc Streit, Sandra Wachter, Andreas Riener, and Mark\u00a0O. Riedl. 2021. Operationalizing Human-Centered Perspectives in Explainable AI. Conference on Human Factors in Computing Systems - Proceedings (2021). https://doi.org/10.1145/3411763.3441342",
      "doi": "10.1145/3411763.3441342"
    },
    {
      "text": "Andre Esteva, Katherine Chou, Serena Yeung, Nikhil Naik, Ali Madani, Ali Mottaghi, Yun Liu, Eric Topol, Jeff Dean, and Richard Socher. 2021. Deep learning-enabled medical computer vision. npj Digital Medicine 4, 1 (2021), 1\u20139. https://doi.org/10.1038/s41746-020-00376-2",
      "doi": ""
    },
    {
      "text": "Laura Evans, Andrew Rhodes, Waleed Alhazzani, Massimo Antonelli, Craig\u00a0M. Coopersmith, Craig French, Fl\u00e1via\u00a0R. MacHado, Lauralyn McIntyre, Marlies Ostermann, Hallie\u00a0C. Prescott, Christa Schorr, Steven Simpson, W.\u00a0Joost Wiersinga, Fayez Alshamsi, Derek\u00a0C. Angus, Yaseen Arabi, Luciano Azevedo, Richard Beale, Gregory Beilman, Emilie Belley-Cote, Lisa Burry, Maurizio Cecconi, John Centofanti, Angel Coz Yataco, Jan De Waele, R.\u00a0Phillip Dellinger, Kent Doi, Bin Du, Elisa Estenssoro, Ricard Ferrer, Charles Gomersall, Carol Hodgson, Morten Hylander M\u00f8ller, Theodore Iwashyna, Shevin Jacob, Ruth Kleinpell, Michael Klompas, Younsuck Koh, Anand Kumar, Arthur Kwizera, Suzana Lobo, Henry Masur, Steven McGloughlin, Sangeeta Mehta, Yatin Mehta, Mervyn Mer, Mark Nunnally, Simon Oczkowski, Tiffany Osborn, Elizabeth Papathanassoglou, Anders Perner, Michael Puskarich, Jason Roberts, William Schweickert, Maureen Seckel, Jonathan Sevransky, Charles\u00a0L. Sprung, Tobias Welte, Janice Zimmerman, and Mitchell Levy. 2021. Surviving Sepsis Campaign: International Guidelines for Management of Sepsis and Septic Shock 2021. Vol.\u00a049. E1063\u2013E1143 pages. https://doi.org/10.1097/CCM.0000000000005337",
      "doi": ""
    },
    {
      "text": "Joseph Futoma, Anthony Lin, Mark Sendak, Armando Bedoya, Meredith Clement, Cara O\u2019Brien, and Katherine Heller. 2018. Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks. ICLR 2018 Conference Blind Submission2017 (2018), 1\u201310. https://openreview.net/pdf?id=SyxCqGbRZ",
      "doi": ""
    },
    {
      "text": "Joseph Futoma, Morgan Simons, Trishan Panch, Finale Doshi-Velez, and Leo\u00a0Anthony Celi. 2020. The myth of generalisability in clinical research and machine learning in health care. The Lancet Digital Health 2, 9 (2020), e489\u2013e492. https://doi.org/10.1016/S2589-7500(20)30186-2",
      "doi": ""
    },
    {
      "text": "Susanne Gaube, Harini Suresh, Martina Raue, Alexander Merritt, Seth\u00a0J. Berkowitz, Eva Lermer, Joseph\u00a0F. Coughlin, John\u00a0V. Guttag, Errol Colak, and Marzyeh Ghassemi. 2021. Do as AI say: susceptibility in deployment of clinical decision-aids. npj Digital Medicine 4, 1 (2021). https://doi.org/10.1038/s41746-021-00385-9",
      "doi": ""
    },
    {
      "text": "Marzyeh Ghassemi, Luke Oakden-Rayner, and Andrew\u00a0L. Beam. 2021. The false hope of current approaches to explainable artificial intelligence in health care. The Lancet Digital Health 3, 11 (2021), e745\u2013e750. https://doi.org/10.1016/S2589-7500(21)00208-9",
      "doi": ""
    },
    {
      "text": "Marzyeh Ghassemi, Mahima Pushkarna, James Wexler, Jesse Johnson, and Paul Varghese. 2018. ClinicalVis: Supporting Clinical Task-Focused Design Evaluation. (2018). arxiv:1810.05798http://arxiv.org/abs/1810.05798",
      "doi": ""
    },
    {
      "text": "Jennifer\u00a0C. Ginestra, Heather\u00a0M. Giannini, William\u00a0D. Schweickert, Laurie Meadows, Michael\u00a0J. Lynch, Kimberly Pavan, Corey\u00a0J. Chivers, Michael Draugelis, Patrick\u00a0J. Donnelly, Barry\u00a0D. Fuchs, and Craig\u00a0A. Umscheid. 2019. Clinician Perception of a Machine Learning-Based Early Warning System Designed to Predict Severe Sepsis and Septic Shock. Crit Care Med 47, 11 (2019), 1\u201318. https://doi.org/10.1097/CCM.0000000000003803",
      "doi": ""
    },
    {
      "text": "Katharine\u00a0E Henry, Rachel Korn, Anirudh Sridharan, Robert\u00a0C Linton, Catherine Groh, Tony Wang, and Albert Wu. 2022. Human \u2013 machine teaming is key to AI adoption : clinicians \u2019 experiences with a deployed machine learning system. (2022), 1\u20136. https://doi.org/10.1038/s41746-022-00597-7",
      "doi": ""
    },
    {
      "text": "Tina\u00a0B Hershey and Jeremy\u00a0M Kahn. 2017. State sepsis mandates-a new era for regulation of hospital quality. N Engl J Med 376, 24 (2017), 2311\u20132313.",
      "doi": ""
    },
    {
      "text": "Sungsoo\u00a0Ray Hong, Jessica Hullman, and Enrico Bertini. 2020. Human Factors in Model Interpretability: Industry Practices, Challenges, and Needs. Proceedings of the ACM on Human-Computer Interaction 4, CSCW1(2020), 1\u201326. https://doi.org/10.1145/3392878 arxiv:2004.11440",
      "doi": "10.1145/3392878"
    },
    {
      "text": "Michael\u00a0H Hooper, Lisa Weavind, Arthur\u00a0P Wheeler, Supriya\u00a0Srinivasa Gowda, Matthew\u00a0W Semler, Rachel\u00a0M Hayes, Daniel\u00a0W Albert, Norment\u00a0B Deane, Hui Nian, Janos\u00a0L Mathe, Andras Nadas, Janos Sztipanovits, Anne Miller, and Todd\u00a0W Rice. 2015. Randomized Trial of Automated, Electronic Monitoring to Facilitate Early Detection of Sepsis in the Intensive Care Unit Michael. Crit Care Med 40, 7 (2015), 2096\u20132101. https://doi.org/10.1097/CCM.0b013e318250a887.Randomized",
      "doi": ""
    },
    {
      "text": "Sheikh\u00a0Rabiul Islam, William Eberle, Sheikh\u00a0Khaled Ghafoor, and Mohiuddin Ahmed. 2021. Explainable Artificial Intelligence Approaches: A Survey. (2021), 1\u201314. arxiv:2101.09429http://arxiv.org/abs/2101.09429",
      "doi": ""
    },
    {
      "text": "Maia Jacobs, Melanie\u00a0F. Pradier, Thomas\u00a0H. McCoy, Roy\u00a0H. Perlis, Finale Doshi-Velez, and Krzysztof\u00a0Z. Gajos. 2021. How machine-learning recommendations influence clinician treatment selections: the example of the antidepressant selection. Translational Psychiatry 11, 1 (2021). https://doi.org/10.1038/s41398-021-01224-x",
      "doi": ""
    },
    {
      "text": "Russell Jeter, Christopher Josef, Supreeth Shashikumar, and Shamim Nemati. 2019. Does the \"Artificial Intelligence Clinician\" learn optimal treatment strategies for sepsis in intensive care?arXiv (nov 2019). https://doi.org/10.1038/s41591-018-0213-5 arxiv:1902.03271",
      "doi": ""
    },
    {
      "text": "A Johnson, L Bulgarelli, T Pollard, S Horng, L\u00a0A Celi, and R Mark. 2020. MIMIC-IV (version 1.0).",
      "doi": ""
    },
    {
      "text": "Barbara\u00a0E. Jones, Dave\u00a0S. Collingridge, Caroline\u00a0G. Vines, Herman Post, John Holmen, Todd\u00a0L. Allen, Peter Haug, Charlene\u00a0R. Weir, and Nathan\u00a0C. Dean. 2019. CDS in a learning health care system: Identifying physicians\u2019 reasons for rejection of best-practice recommendations in pneumonia through computerized clinical decision support. Applied Clinical Informatics 10, 1 (2019), 1\u20139. https://doi.org/10.1055/s-0038-1676587",
      "doi": ""
    },
    {
      "text": "Mathieu Jozwiak, Olfa Hamzaoui, Xavier Monnet, and Jean\u00a0Louis Teboul. 2018. Fluid resuscitation during early sepsis: A need for individualization. Minerva Anestesiologica 84, 8 (2018), 987\u2013992. https://doi.org/10.23736/S0375-9393.18.12422-9",
      "doi": ""
    },
    {
      "text": "Ekaterina Jussupow, Kai Spohrer, Armin Heinzl, and Joshua Gawlitza. 2020. Augmenting medical diagnosis decisions? An investigation into physicians\u2019 decision making process with artificial intelligence. Information Systems Research : ISR tba, March (2020).",
      "doi": ""
    },
    {
      "text": "Annika Kaltenhauser, Verena Rheinst\u00e4dter, Andreas Butz, and Dieter\u00a0P. Wallach. 2020. You Have to Piece the Puzzle Together\": Implications for designing decision support in intensive care. DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference (2020), 1509\u20131522. https://doi.org/10.1145/3357236.3395436",
      "doi": "10.1145/3357236.3395436"
    },
    {
      "text": "Anna Kawakami, Venkatesh Sivaraman, Hao-Fei Cheng, Logan Stapleton, Yanghuidi Cheng, Diana Qing, Adam Perer, Zhiwei\u00a0Steven Wu, Haiyi Zhu, and Kenneth Holstein. 2022. Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support. In Conference on Human Factors in Computing Systems - Proceedings. arxiv:2204.02310http://arxiv.org/abs/2204.02310",
      "doi": "10.1145/3491102.3517439"
    },
    {
      "text": "Saif Khairat, David Marc, William Crosby, and Ali Al Sanousi. 2018. Reasons for physicians not adopting clinical decision support systems: Critical analysis. JMIR Medical Informatics 20, 4 (2018). https://doi.org/10.2196/medinform.8912",
      "doi": ""
    },
    {
      "text": "Michael Klompas and Chanu Rhee. 2020. Current sepsis mandates are overly prescriptive, and some aspects may be harmful. Critical care medicine 48, 6 (2020), 890\u2013893.",
      "doi": ""
    },
    {
      "text": "Matthieu Komorowski, Leo\u00a0A. Celi, Omar Badawi, Anthony\u00a0C. Gordon, and A.\u00a0Aldo Faisal. 2018. The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care. Nature Medicine 24, 11 (2018), 1716\u20131720. https://doi.org/10.1038/s41591-018-0213-5 arxiv:1902.03271",
      "doi": ""
    },
    {
      "text": "Todd Kulesza, Simone Stumpf, Margaret Burnett, Sherry Yang, Irwin Kwan, and Weng\u00a0Keen Wong. 2013. Too much, too little, or just right? Ways explanations impact end users\u2019 mental models. Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC (2013), 3\u201310. https://doi.org/10.1109/VLHCC.2013.6645235",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Chacha Chen, Q.\u00a0Vera Liao, Alison Smith-Renner, and Chenhao Tan. 2021. Towards a Science of Human-AI Decision Making: A Survey of Empirical Studies. 1, 1 (2021). arxiv:2112.11471http://arxiv.org/abs/2112.11471",
      "doi": ""
    },
    {
      "text": "Min\u00a0Hun Lee, Daniel\u00a0P. Siewiorek, and Asim Smailagic. 2021. A human-ai collaborative approach for clinical decision making on rehabilitation assessment. In Conference on Human Factors in Computing Systems - Proceedings. Association for Computing Machinery. https://doi.org/10.1145/3411764.3445472",
      "doi": "10.1145/3411764.3445472"
    },
    {
      "text": "Scott\u00a0M. Lundberg and Su\u00a0In Lee. 2017. A unified approach to interpreting model predictions. Advances in Neural Information Processing Systems 2017-Decem, Section 2(2017), 4766\u20134775. arxiv:1705.07874",
      "doi": ""
    },
    {
      "text": "Prashan Madumal, Tim Miller, Liz Sonenberg, and Frank Vetere. 2020. Explainable reinforcement learning through a causal lens. AAAI 2020 - 34th AAAI Conference on Artificial Intelligence (2020), 2493\u20132500. https://doi.org/10.1609/aaai.v34i03.5631 arxiv:1905.10958",
      "doi": ""
    },
    {
      "text": "Jason\u00a0N Mansoori, Brendan\u00a0J Clark, Edward\u00a0P Havranek, and Ivor\u00a0S Douglas. 2022. The Impact of Choice Architecture on Sepsis Fluid Resuscitation Decisions: An Exploratory Survey-Based Study. MDM policy & practice 7, 1 (2022), 23814683221099454.",
      "doi": ""
    },
    {
      "text": "Aniek\u00a0F. Markus, Jan\u00a0A. Kors, and Peter\u00a0R. Rijnbeek. 2021. The role of explainability in creating trustworthy artificial intelligence for health care: A comprehensive survey of the terminology, design choices, and evaluation strategies. Journal of Biomedical Informatics 113, July 2020 (2021), 103655. https://doi.org/10.1016/j.jbi.2020.103655 arxiv:2007.15911",
      "doi": "10.1016/j.jbi.2020.103655"
    },
    {
      "text": "Michael Moor, Bastian Rieck, Max Horn, Catherine\u00a0R Jutzeler, and Karsten Borgwardt. 2021. Early prediction of sepsis in the ICU using machine learning: a systematic review. Frontiers in medicine 8(2021), 607952.",
      "doi": ""
    },
    {
      "text": "Trishan Panch, Heather Mattie, and Leo\u00a0Anthony Celi. 2019. The \u201cinconvenient truth\u201d about AI in healthcare. npj Digital Medicine 2, 1 (2019), 4\u20136. https://doi.org/10.1038/s41746-019-0155-4",
      "doi": ""
    },
    {
      "text": "Sonali Parbhoo, Shalmali Joshi, and Finale Doshi-Velez. 2022. Generalizing Off-Policy Evaluation From a Causal Perspective For Sequential Decision-Making. September (2022), 1\u201312. arxiv:2201.08262http://arxiv.org/abs/2201.08262",
      "doi": ""
    },
    {
      "text": "Xuefeng Peng, Yi Ding, David Wihl, Omer Gottesman, Matthieu Komorowski, Li\u00a0Wei\u00a0H. Lehman, Andrew Ross, Aldo Faisal, and Finale Doshi-Velez. 2018. Improving Sepsis Treatment Strategies by Combining Deep and Kernel-Based Reinforcement Learning. AMIA... Annual Symposium proceedings. AMIA Symposium 2018 (2018), 887\u2013896. arxiv:1901.04670",
      "doi": ""
    },
    {
      "text": "Erika Puiutta and Eric\u00a0M.S.P. Veith. 2020. Explainable Reinforcement Learning: A Survey. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 12279 LNCS (2020), 77\u201395. https://doi.org/10.1007/978-3-030-57321-8_5 arxiv:2005.06247",
      "doi": ""
    },
    {
      "text": "Gordon\u00a0D Rubenfeld. 2001. Understanding why we agree on the evidence but disagree on the medicine.Respiratory care 46, 12 (2001), 1442\u20131449.",
      "doi": ""
    },
    {
      "text": "Sudarsan Sadasivuni, Monjoy Saha, Neal Bhatia, Imon Banerjee, and Arindam Sanyal. 2022. Fusion of fully integrated analog machine learning classifier with electronic medical records for real-time prediction of sepsis onset. Scientific reports 12, 1 (2022), 1\u201311.",
      "doi": ""
    },
    {
      "text": "Mike Schaekermann, Graeme Beaton, Elaheh Sanoubari, Andrew Lim, Kate Larson, and Edith Law. 2020. Ambiguity-aware AI Assistants for Medical Data Analysis. (2020), 1\u201314. https://doi.org/10.1145/3313831.3376506",
      "doi": "10.1145/3313831.3376506"
    },
    {
      "text": "Nicolas Scharowski, Sebastian A.\u00a0C. Perrig, Nick von Felten, and Florian Br\u00fchlmann. 2022. Trust and Reliance in XAI \u2013 Distinguishing Between Attitudinal and Behavioral Measures. CHI 2022: Workshop on Trust and Reliance in AI-Human Teams 1, 1(2022), 1\u20136. arxiv:2203.12318http://arxiv.org/abs/2203.12318",
      "doi": ""
    },
    {
      "text": "Tjeerd\u00a0A.J. Schoonderwoerd, Wiard Jorritsma, Mark\u00a0A. Neerincx, and Karel van\u00a0den Bosch. 2021. Human-centered XAI: Developing design patterns for explanations of clinical decision support systems. International Journal of Human Computer Studies 154 (2021), 102684. https://doi.org/10.1016/j.ijhcs.2021.102684",
      "doi": "10.1016/j.ijhcs.2021.102684"
    },
    {
      "text": "Mark Sendak, Madeleine\u00a0Clare Elish, Michael Gao, Joseph Futoma, William Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, and Cara O\u2019Brien. 2020. \u201cThe human body is a black box\u201d: Supporting clinical decision-making with deep learning. FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency(2020), 99\u2013109. https://doi.org/10.1145/3351095.3372827 arxiv:1911.08089",
      "doi": "10.1145/3351095.3372827"
    },
    {
      "text": "Mark\u00a0P. Sendak, William Ratliff, Dina Sarro, Elizabeth Alderton, Joseph Futoma, Michael Gao, Marshall Nichols, Mike Revoir, Faraz Yashar, Corinne Miller, Kelly Kester, Sahil Sandhu, Kristin Corey, Nathan Brajer, Christelle Tan, Anthony Lin, Tres Brown, Susan Engelbosch, Kevin Anstrom, Madeleine\u00a0Clare Elish, Katherine Heller, Rebecca Donohoe, Jason Theiling, Eric Poon, Suresh Balu, Armando Bedoya, and Cara O\u2019Brien. 2020. Real-world integration of a sepsis deep learning technology into routine clinical care: Implementation study. JMIR Medical Informatics 8, 7 (2020), 1\u201316. https://doi.org/10.2196/15182",
      "doi": ""
    },
    {
      "text": "Nirav\u00a0R Shah and Thomas\u00a0H Lee. 2019. What AI means for doctors and doctoring. NEJM Catalyst 5, 5 (2019).",
      "doi": ""
    },
    {
      "text": "Manu Shankar-Hari, Gary\u00a0S. Phillips, Mitchell\u00a0L. Levy, Christopher\u00a0W. Seymour, Vincent\u00a0X. Liu, Clifford\u00a0S. Deutschman, Derek\u00a0C. Angus, Gordon\u00a0D. Rubenfeld, and Mervyn Singer. 2016. Developing a New Definition and Assessing New Clinical Criteria for Septic Shock. JAMA 315, 8 (2016), 775\u2013787. https://doi.org/10.1001/jama.2016.0289",
      "doi": ""
    },
    {
      "text": "Rui Shi, Olfa Hamzaoui, Nello De Vita, Xavier Monnet, and Jean-Louis Teboul. 2020. Vasopressors in septic shock: which, when, and how much?Annals of Translational Medicine 8, 12 (2020), 794\u2013794. https://doi.org/10.21037/atm.2020.04.24",
      "doi": ""
    },
    {
      "text": "Dylan Slack, Sophie Hilgard, Sameer Singh, and Himabindu Lakkaraju. 2021. Reliable Post hoc Explanations: Modeling Uncertainty in Explainability. Advances in Neural Information Processing Systems 12, NeurIPS(2021), 9391\u20139404. arxiv:2008.05030",
      "doi": ""
    },
    {
      "text": "Elizabeth\u00a0K Stevenson, Amanda\u00a0R Rubenstein, Gregory\u00a0T Radin, Renda\u00a0Soylemez Wiener, and Allan\u00a0J Walkey. 2014. Two decades of mortality trends among patients with severe sepsis: a comparative meta-analysis. Critical care medicine 42, 3 (2014), 625.",
      "doi": ""
    },
    {
      "text": "Lisa Stoneking, Kurt Denninghoff, Lawrence DeLuca, Samuel\u00a0M. Keim, and Benson Munger. 2011. Sepsis bundles and compliance with clinical guidelines. Journal of Intensive Care Medicine 26, 3 (2011), 172\u2013182. https://doi.org/10.1177/0885066610387988",
      "doi": ""
    },
    {
      "text": "Harini Suresh, Steven\u00a0R. Gomez, Kevin\u00a0K. Nam, and Arvind Satyanarayan. 2021. Beyond expertise and roles: A framework to characterize the stakeholders of interpretable machine learning and their needs. Conference on Human Factors in Computing Systems - Proceedings (2021). https://doi.org/10.1145/3411764.3445088 arxiv:2101.09824",
      "doi": "10.1145/3411764.3445088"
    },
    {
      "text": "Andrew\u00a0K Teng and Adam\u00a0B Wilcox. 2020. A review of predictive analytics solutions for sepsis patients. Applied clinical informatics 11, 03 (2020), 387\u2013398.",
      "doi": ""
    },
    {
      "text": "Sana Tonekaboni, Shalmali Joshi, Melissa\u00a0D. McCradden, and Anna Goldenberg. 2019. What clinicians want: Contextualizing explainable machine learning for clinical end use. arXivMl(2019), 1\u201321. arxiv:1905.05134",
      "doi": ""
    },
    {
      "text": "Eric\u00a0J. Topol. 2019. High-performance medicine: the convergence of human and artificial intelligence. Nature Medicine 25, 1 (2019), 44\u201356. https://doi.org/10.1038/s41591-018-0300-7",
      "doi": ""
    },
    {
      "text": "Philipp Tschandl, Christoph Rinner, Zoe Apalla, Giuseppe Argenziano, Noel Codella, Allan Halpern, Monika Janda, Aimilios Lallas, Caterina Longo, Josep Malvehy, John Paoli, Susana Puig, Cliff Rosendahl, H.\u00a0Peter Soyer, Iris Zalaudek, and Harald Kittler. 2020. Human\u2013computer collaboration for skin cancer recognition. Nature Medicine 26, 8 (2020), 1229\u20131234. https://doi.org/10.1038/s41591-020-0942-0",
      "doi": ""
    },
    {
      "text": "U.S. Food and Drug Administration. 2022. Clinical Decision Support Software. Technical Report. 1\u201326 pages. https://www.fda.gov/media/109618/download",
      "doi": ""
    },
    {
      "text": "Baptiste Vasey, Myura Nagendran, Bruce Campbell, David\u00a0A. Clifton, Gary\u00a0S. Collins, Spiros Denaxas, Alastair\u00a0K. Denniston, Livia Faes, Bart Geerts, Mudathir Ibrahim, Xiaoxuan Liu, Bilal\u00a0A. Mateen, Piyush Mathur, Melissa\u00a0D. McCradden, Lauren Morgan, Johan Ordish, Campbell Rogers, Suchi Saria, Daniel S.\u00a0W. Ting, Peter Watkinson, Wim Weber, Peter Wheatstone, Peter McCulloch, and DECIDE-AI Expert Group. 2022. Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI. Nature Medicine 28, May (2022), 924\u2013933. https://doi.org/10.1038/s41591-022-01772-9",
      "doi": ""
    },
    {
      "text": "Dakuo Wang, Liuping Wang, and Zhan Zhang. 2021. Brilliant ai doctor in rural clinics: Challenges in AI-powered clinical decision support system deployment. Conference on Human Factors in Computing Systems - Proceedings (2021). https://doi.org/10.1145/3411764.3445432",
      "doi": "10.1145/3411764.3445432"
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian\u00a0Y. Lim. 2019. Designing theory-driven user-centric explainable AI. In Conference on Human Factors in Computing Systems - Proceedings. Association for Computing Machinery. https://doi.org/10.1145/3290605.3300831",
      "doi": "10.1145/3290605.3300831"
    },
    {
      "text": "Xinru Wang and Ming Yin. 2020. Are explanations helpful? A comparative study of the Effects of Explanations in AI-assisted Decision Making. Intelligent User Interfaces, IUI \u201921, April 14\u201317, 2021, College Station, TX, USA (2020), 318\u2013328.",
      "doi": ""
    },
    {
      "text": "Kevin\u00a0C Wilson and Holger\u00a0J Sch\u00fcnemann. 2011. An appraisal of the evidence underlying performance measures for community-acquired pneumonia. American journal of respiratory and critical care medicine 183, 11(2011), 1454\u20131462.",
      "doi": ""
    },
    {
      "text": "Qian Yang, Aaron Steinfeld, and John Zimmerman. 2019. Unremarkable AI: Fitting intelligent decision support into critical, clinical decision-making processes. Conference on Human Factors in Computing Systems - Proceedings (2019). https://doi.org/10.1145/3290605.3300468 arxiv:1904.09612",
      "doi": "10.1145/3290605.3300468"
    },
    {
      "text": "Chao Yu, Jiming Liu, Shamim Nemati, and Guosheng Yin. 2023. Reinforcement Learning in Healthcare: A Survey. Comput. Surveys 55, 1 (2023), 1\u201336. https://doi.org/10.1145/3477600 arxiv:1908.08796",
      "doi": "10.1145/3477600"
    },
    {
      "text": "Chao Yu, Guoqi Ren, and Jiming Liu. 2019. Deep inverse reinforcement learning for sepsis treatment. 2019 IEEE International Conference on Healthcare Informatics, ICHI 2019 (2019), 31\u201333. https://doi.org/10.1109/ICHI.2019.8904645",
      "doi": ""
    },
    {
      "text": "Yunfeng Zhang, Q. Vera Liao, and Rachel\u00a0K.E. Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making. FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency(2020), 295\u2013305. https://doi.org/10.1145/3351095.3372852 arxiv:2001.02114",
      "doi": "10.1145/3351095.3372852"
    },
    {
      "text": "Alexandra Zytek, Dongyu Liu, Rhema Vaithianathan, and Kalyan Veeramachaneni. 2021. Sibyl: Understanding and Addressing the Usability Challenges of Machine Learning In High-Stakes Decision Making. Ml (2021). https://doi.org/10.1109/tvcg.2021.3114864 arxiv:2103.02071",
      "doi": "10.1109/tvcg.2021.3114864"
    }
  ]
}