{
  "doi": "10.1145/3544548.3581185",
  "title": "TmoTA: Simple, Highly Responsive Tool for Multiple Object Tracking Annotation",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-11",
  "year": 2023,
  "badges": [],
  "abstract": "Machine learning is applied in a multitude of sectors with very impressive results. This success is due to the availability of an ever-growing amount of data acquired by omnipresent sensor devices and platforms on the internet. But there is a scarcity of labeled data which is required for most ML methods. However, generation of labeled data requires much time and resources. In this paper, we propose a portable, Open Source, simple and responsive manual Tool for 2D multiple object Tracking Annotation (TmoTA). Besides responsiveness, our tool design provides several features like view centering and looped playback that speed up the annotation process. We evaluate our proposed tool by comparing TmoTA with the widely used manual labeling tools CVAT, Label Studio, and two semi-automated tools Supervisely and VATIC with respect to object labeling time and accuracy. The evaluation includes a user study and pre-case studies showing that the annotation time per object frame can be reduced by 20% to 40% over the first 20 annotated objects compared to the manual labeling tools.",
  "authors": [
    {
      "name": "Marzan Tasnim Oyshi",
      "institution": "Computer Graphics and Visualization Lab (CGV); TU Dresden, Institute of Software and Multimedia Technology, Germany and TU Dresden, Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI) Dresden/Leipzig, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660779166",
      "orcid": "0000-0001-9661-1591"
    },
    {
      "name": "Sebastian Vogt",
      "institution": "Computer Graphics and Visualization Lab (CGV); TU Dresden, Institute of Software and Multimedia Technology, Germany and TU Dresden, Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI) Dresden/Leipzig, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660782263",
      "orcid": "0000-0001-6329-6222"
    },
    {
      "name": "Stefan Gumhold",
      "institution": "Computer Graphics and Visualization Lab (CGV); TU Dresden, Institute of Software and Multimedia Technology, Germany and TU Dresden, Centre for Tactile Internet with Human-in-the-Loop (CeTI), Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100408275",
      "orcid": "0000-0003-2467-5734"
    }
  ],
  "references": [
    {
      "text": "K. Bernardin, A. Elbs, and R. Stiefelhagen. 2006. Multiple object tracking performance metrics and evaluation in a smart room environment. In Proceedings of the Sixth IEEE International Workshop on Visual Surveillance, VS 2006, Graz, Austria, 1. May 2006.",
      "doi": ""
    },
    {
      "text": "Keni Bernardin and Rainer Stiefelhagen. 2008. Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics. J. Image Video Process. 2008, Article 1 (jan 2008), 10\u00a0pages. https://doi.org/10.1155/2008/246309",
      "doi": ""
    },
    {
      "text": "P.K. Bhagat and P. Choudhary. 2018. Image annotation: Then and now. Image and Vision Computing 80 (2018), 1\u201323. https://doi.org/10.1016/j.imavis.2018.09.017",
      "doi": ""
    },
    {
      "text": "Dinesh Bolkensteyn. 2016. Vatic.js. https://github.com/dbolkensteyn/vatic.js. (Accessed on 12/08/2022).",
      "doi": ""
    },
    {
      "text": "cognilytica. 2021. Data Labeling Market: Research Snapshot Dec. 2021 - Cognilytica. https://www.cognilytica.com/document/data-labeling-market-research-snapshot-dec-2021/. (Accessed on 06/20/2022).",
      "doi": ""
    },
    {
      "text": "Carlos Cuevas, Eva\u00a0Mar\u00eda Y\u00e1\u00f1ez, and Narciso Garc\u00eda. 2015. Tool for Semiautomatic Labeling of Moving Objects in Video Sequences: TSLAB. Sensors 15, 7 (2015), 15159\u201315178. https://doi.org/10.3390/s150715159",
      "doi": ""
    },
    {
      "text": "Patrick Dendorfer, Hamid Rezatofighi, Anton Milan, Javen Shi, Daniel Cremers, Ian Reid, Stefan Roth, Konrad Schindler, and Laura Leal-Taix\u00e9. 2020. Mot20: A benchmark for multi object tracking in crowded scenes. arXiv preprint arXiv:2003.09003(2020).",
      "doi": ""
    },
    {
      "text": "Abhishek Dutta and Andrew Zisserman. 2019. The VIA Annotation Software for Images, Audio and Video. In Proceedings of the 27th ACM International Conference on Multimedia (Nice, France) (MM \u201919). Association for Computing Machinery, New York, NY, USA, 2276\u20132279. https://doi.org/10.1145/3343031.3350535",
      "doi": "10.1145/3343031.3350535"
    },
    {
      "text": "Heartex Inc.2022. Label Studio. https://labelstud.io/. (Accessed on 12/08/2022).",
      "doi": ""
    },
    {
      "text": "Arne\u00a0Hoffhues Jonathon\u00a0Luiten. 2020. TrackEval. https://github.com/JonathonLuiten/TrackEval.",
      "doi": ""
    },
    {
      "text": "Patrick\u00a0W. Jordan, Bruce Thomas, Bernard\u00a0A. Weerdmeester, and Ian\u00a0L. McClelland. 1996. Usability Evaluation In Industry - Google Books. https://rb.gy/juemzj. (Accessed on 12/09/2022).",
      "doi": ""
    },
    {
      "text": "Adrian Krenzer, Kevin Makowski, Amar Hekalo, Daniel Fitting, Joel Troya, Wolfram\u00a0G Zoller, Alexander Hann, and Frank Puppe. 2022. Fast machine learning annotation in the medical domain: a semi-automated video annotation tool for gastroenterologists. BioMedical Engineering OnLine 21, 1 (2022), 1\u201323.",
      "doi": ""
    },
    {
      "text": "Alina Kuznetsova, Aakrati Talati, Yiwen Luo, Keith Simmons, and Vittorio Ferrari. 2020. Efficient video annotation with visual interpolation and frame selection guidance. CoRR abs/2012.12554(2020). arXiv:2012.12554https://arxiv.org/abs/2012.12554",
      "doi": ""
    },
    {
      "text": "Jonathon Luiten, Aljosa Osep, Patrick Dendorfer, Philip Torr, Andreas Geiger, Laura Leal-Taix\u00e9, and Bastian Leibe. 2020. HOTA: A Higher Order Metric for Evaluating Multi-Object Tracking. International Journal of Computer Vision(2020), 1\u201331.",
      "doi": ""
    },
    {
      "text": "microsoft/VoTT. 2021. GitHub - microsoft/VoTT: Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.https://github.com/microsoft/VoTT#download-and-install-a-release-package-for-your-platform-recommended. (Accessed on 06/24/2022).",
      "doi": ""
    },
    {
      "text": "Supervisely O\u00dc. 2022. Supervisely. https://supervise.ly/. (Accessed on 12/08/2022).",
      "doi": ""
    },
    {
      "text": "Boris Sekachev, Andrey Zhavoronkov, and Nikita Manovich. 2019. Computer Vision Annotation Tool: A Universal Approach to Data Annotation. https://www.intel.com/content/www/us/en/developer/articles/technical/computer-vision-annotation-tool-a-universal-approach-to-data-annotation.html. (Accessed on 06/24/2022).",
      "doi": ""
    },
    {
      "text": "sgumhold/cgv. 2022. GitHub - sgumhold/cgv. https://github.com/sgumhold/cgv. (Accessed on 06/28/2022).",
      "doi": ""
    },
    {
      "text": "Dennis Stumpf, Stephan Krau\u00df, Gerd Reis, Oliver Wasenm\u00fcller, and Didier Stricker. 2021. SALT: A Semi-automatic Labeling Tool for RGB-D Video Sequences. CoRR abs/2102.10820(2021). arXiv:2102.10820https://arxiv.org/abs/2102.10820",
      "doi": ""
    },
    {
      "text": "tzutalin. 2021. GitHub - tzutalin/labelImg: LabelImg is a graphical image annotation tool and label object bounding boxes in images. https://github.com/tzutalin/labelImg. (Accessed on 06/24/2022).",
      "doi": ""
    },
    {
      "text": "Luis von Ahn and Laura Dabbish. 2004. Labeling Images with a Computer Game. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Vienna, Austria) (CHI \u201904). Association for Computing Machinery, New York, NY, USA, 319\u2013326. https://doi.org/10.1145/985692.985733",
      "doi": "10.1145/985692.985733"
    },
    {
      "text": "Luis von Ahn, Ruoran Liu, and Manuel Blum. 2006. Peekaboom: A Game for Locating Objects in Images. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Montr\u00e9al, Qu\u00e9bec, Canada) (CHI \u201906). Association for Computing Machinery, New York, NY, USA, 55\u201364. https://doi.org/10.1145/1124772.1124782",
      "doi": "10.1145/1124772.1124782"
    },
    {
      "text": "Carl Vondrick, Donald\u00a0J. Patterson, and Deva Ramanan. 2012. Efficiently Scaling up Crowdsourced Video Annotation. International Journal of Computer Vision 101 (2012), 184\u2013204. http://dx.doi.org/10.1007/s11263-012-0564-1",
      "doi": "10.1007/s11263-012-0564-1"
    },
    {
      "text": "Jenny Yuen, Bryan Russell, Ce Liu, and Antonio Torralba. 2009. LabelMe video: Building a video database with human annotations. In 2009 IEEE 12th International Conference on Computer Vision. 1451\u20131458. https://doi.org/10.1109/ICCV.2009.5459289",
      "doi": ""
    }
  ]
}