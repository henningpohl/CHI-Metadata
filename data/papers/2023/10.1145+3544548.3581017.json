{
  "doi": "10.1145/3544548.3581017",
  "title": "Transcending the \u201cMale Code\u201d: Implicit Masculine Biases in NLP Contexts",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-19",
  "year": 2023,
  "badges": [],
  "abstract": "Critical scholarship has elevated the problem of gender bias in data sets used to train virtual assistants (VAs). Most work has focused on explicit biases in language, especially against women, girls, femme-identifying people, and genderqueer folk; implicit associations through word embeddings; and limited models of gender and masculinities, especially toxic masculinities, conflation of sex and gender, and a sex/gender binary framing of the masculine as diametric to the feminine. Yet, we must also interrogate how masculinities are \u201ccoded\u201d into language and the assumption of \u201cmale\u201d as the linguistic default: implicit masculine biases. To this end, we examined two natural language processing (NLP) data sets. We found that when gendered language was present, so were gender biases and especially masculine biases. Moreover, these biases related in nuanced ways to the NLP context. We offer a new dictionary called AVA that covers ambiguous associations between gendered language and the language of VAs.",
  "tags": [
    "Gender bias",
    "Natural language processing",
    "Implicit gendered language",
    "Data sets",
    "Machine learning bias",
    "Feminist HCI",
    "Masculinities"
  ],
  "authors": [
    {
      "name": "Katie Seaborn",
      "institution": "Department of Industrial Engineering and Economics, Tokyo Institute of Technology, Japan",
      "img": "/do/10.1145/contrib-81460657397/rel-imgonly/uclic.png",
      "acmid": "81460657397",
      "orcid": "0000-0002-7812-9096"
    },
    {
      "name": "Shruti Chandra",
      "institution": "Social and Intelligent Robotics Research Laboratory, University of Waterloo, Canada",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659135237",
      "orcid": "0000-0003-2042-8875"
    },
    {
      "name": "Thibault Fabre",
      "institution": "The University of Tokyo, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660779754",
      "orcid": "0000-0003-1978-9374"
    }
  ],
  "references": [
    {
      "text": "Ashutosh Baheti, Maarten Sap, Alan Ritter, and Mark Riedl. 2021. Just say no: Analyzing the stance of neural dialogue generation in offensive contexts. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021), 4846-4862. https://doi.org/10.18653/v1/2021.emnlp-main.397",
      "doi": ""
    },
    {
      "text": "April H. Bailey, Marianne LaFrance, and John F. Dovidio. 2019. Is man the measure of all things? A social cognitive account of androcentrism. Personality and Social Psychology Review 23, 4, 307-331. https://doi.org/10.1177/1088868318782848",
      "doi": ""
    },
    {
      "text": "April H. Bailey, Adina Williams, and Andrei Cimpian. 2022. Based on billions of words on the internet, people = men. Science Advances 8, 13, eabm2463. https://doi.org/10.1126/sciadv.abm2463",
      "doi": ""
    },
    {
      "text": "Shaowen Bardzell. 2010. Feminist HCI: Taking stock and outlining an agenda for design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \u201910), 1301-1310. https://doi.org/10.1145/1753326.1753521",
      "doi": "10.1145/1753326.1753521"
    },
    {
      "text": "Shaowen Bardzell and Jeffrey Bardzell. 2011. Towards a feminist HCI methodology: Social science, feminism, and HCI. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \u201911), 675-684. https://doi.org/10.1145/1978942.1979041",
      "doi": "10.1145/1978942.1979041"
    },
    {
      "text": "Jennifer A. Bartz and John E. Lydon. 2004. Close relationships and the working self-concept: Implicit and explicit effects of priming attachment on agency and communion. Personality and Social Psychology Bulletin 30, 11, 1389-1401. https://doi.org/10.1177/0146167204264245",
      "doi": ""
    },
    {
      "text": "Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski, and Verena Rieser. 2020. SLURP: A Spoken Language Understanding Resource Package. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP-2020). https://doi.org/10.48550/arXiv.2011.13205",
      "doi": ""
    },
    {
      "text": "Simone de Beauvoir. 2011. The Second Sex. Vintage Books, New York, NY.",
      "doi": ""
    },
    {
      "text": "Rosanna Bellini, Angelika Strohmayer, Ebtisam Alabdulqader, Alex A. Ahmed, Katta Spiel, Shaowen Bardzell, and Madeline Balaam. 2018. Feminist HCI: Taking stock, moving forward, and engaging community. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems (CHI EA \u201918), 1-4. https://doi.org/10.1145/3170427.3185370",
      "doi": "10.1145/3170427.3185370"
    },
    {
      "text": "Sandra L. Bem. 1974. The measurement of psychological androgyny. Journal of Consulting and Clinical Psychology 42, 2, 155-162. https://doi.org/10.1037/h0036215",
      "doi": ""
    },
    {
      "text": "Sandra L. Bem. 1993. The Lenses of Gender: Transforming the Debate on Sexual Inequality. Yale University Press.",
      "doi": ""
    },
    {
      "text": "Emily M. Bender and Batya Friedman. 2018. Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics 6, 587-604. https://doi.org/10.1162/tacl_a_00041",
      "doi": ""
    },
    {
      "text": "Hilary Bergen. 2016. \u201cI'd blush if I could\u201d: Digital assistants, disembodied cyborgs and the problem of gender. Word and Text, A Journal of Literary Studies and Linguistics VI, 01, 95-113.",
      "doi": ""
    },
    {
      "text": "Su Lin Blodgett, Solon Barocas, Hal Daum\u00e9 III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey of \u201cbias\u201d in NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020), 5454-5476. https://doi.org/10.18653/v1/2020.acl-main.485",
      "doi": ""
    },
    {
      "text": "Su Lin Blodgett, Q. Vera Liao, Alexandra Olteanu, Rada Mihalcea, Michael Muller, Morgan Klaus Scheuerman, Chenhao Tan, and Qian Yang. 2022. Responsible language technologies: Foreseeing and mitigating harms. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA \u201922), 1-3. https://doi.org/10.1145/3491101.3516502",
      "doi": "10.1145/3491101.3516502"
    },
    {
      "text": "Su Lin Blodgett and Brendan O'Connor. 2017. Racial disparity in natural language processing: A case study of social media African-American english. In Proceedings of the 2017 Workshop on Fairness, Accountability, and Transparency in Machine Learning (FAT/ML 2017). https://doi.org/10.48550/arXiv.1707.00061",
      "doi": ""
    },
    {
      "text": "Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. In 30th Conference on Advances in Neural Information Processing Systems (NIPS 2016). Retrieved August 22, 2022 from https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html",
      "doi": ""
    },
    {
      "text": "Margaret M. Bradley and Peter J. Lang. 1999. Affective norms for English words (ANEW): Instruction manual and affective ratings. Technical report C-1, the center for research in psychophysiology\u00a0\u2026.",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency in Machine Learning Research (PMLR 2018), 77-91. Retrieved from http://proceedings.mlr.press/v81/buolamwini18a.html?mod=article_inline",
      "doi": ""
    },
    {
      "text": "Yang Trista Cao and Hal Daum\u00e9 III. 2021. Toward gender-inclusive coreference resolution: An analysis of gender and bias throughout the machine learning lifecycle. Computational Linguistics 47, 3, 615-661. https://doi.org/10.1162/coli_a_00413",
      "doi": ""
    },
    {
      "text": "Tommaso Caselli, Roberto Cibin, Costanza Conforti, Enrique Encinas, and Maurizio Teli. 2021. Guiding principles for participatory design-inspired natural language processing. In Proceedings of the 1st Workshop on NLP for Positive Impact (ACL-IJCNLP-NLP4PosImpact 2021), 27-35. https://doi.org/10.18653/v1/2021.nlp4posimpact-1.4",
      "doi": ""
    },
    {
      "text": "Jiawei Chen, Anbang Xu, Zhe Liu, Yufan Guo, Xiaotong Liu, Yingbei Tong, Rama Akkiraju, and John M. Carroll. 2020. A general methodology to quantify biases in natural language data. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920), 1-9. https://doi.org/10.1145/3334480.3382949",
      "doi": "10.1145/3334480.3382949"
    },
    {
      "text": "Yan Chen, Christopher Mahoney, Isabella Grasso, Esma Wali, Abigail Matthews, Thomas Middleton, Mariama Njie, and Jeanna Matthews. 2021. Gender bias and under-representation in natural language processing across human languages. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society (AIES \u201921), 24-34. https://doi.org/10.1145/3461702.3462530",
      "doi": "10.1145/3461702.3462530"
    },
    {
      "text": "Sapna Cheryan and Hazel Rose Markus. 2020. Masculine defaults: Identifying and mitigating hidden cultural biases. Psychological Review 127, 1022-1052. https://doi.org/10.1037/rev0000209",
      "doi": ""
    },
    {
      "text": "Shruthi Sai Chivukula and Colin M. Gray. 2020. Bardzell's \u201cFeminist HCI\u201d legacy: Analyzing citational patterns. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems (CHI EA \u201920), 1-8. https://doi.org/10.1145/3334480.3382936",
      "doi": "10.1145/3334480.3382936"
    },
    {
      "text": "K. R. Chowdhary. 2020. Natural Language Processing. In Fundamentals of Artificial Intelligence, K.R. Chowdhary (ed.). Springer India, New Delhi, 603-649. https://doi.org/10.1007/978-81-322-3972-7_19",
      "doi": ""
    },
    {
      "text": "Davide Cirillo, Hila Gonen, Enrico Santus, Alfonso Valencia, Marta R. Costa-juss\u00e0, and Marta Villegas. 2022. Chapter 6 - Sex and gender bias in natural language processing. In Sex and Gender Bias in Technology and Artificial Intelligence, Davide Cirillo, Silvina Catuara-Solarz and Emre Guney (eds.). Academic Press, 113-132. https://doi.org/10.1016/B978-0-12-821392-6.00009-1",
      "doi": ""
    },
    {
      "text": "Leigh Clark, Philip Doyle, Diego Garaialde, Emer Gilmartin, Stephan Schl\u00f6gl, Jens Edlund, Matthew Aylett, Jo\u00e3o Cabral, Cosmin Munteanu, Justin Edwards, and Benjamin R Cowan. 2019. The state of speech in HCI: Trends, themes and challenges. Interacting with Computers 31, 4, 349-371. https://doi.org/10.1093/iwc/iwz016",
      "doi": ""
    },
    {
      "text": "Cynthia Cockburn. 2003. The circuit of technology: Gender, identity and power. In Consuming Technologies: Media and Information in Domestic Spaces, Eric Hirsch and Roger Silverstone (eds.). Routledge, 33-42.",
      "doi": ""
    },
    {
      "text": "Anne Constantinople. 2005. \u201cMasculinity-femininity: An exception to a famous dictum?\u201d Feminism & Psychology 15, 4, 385-407. https://doi.org/10.1177/0959-353505057611",
      "doi": ""
    },
    {
      "text": "Jenna Cryan, Shiliang Tang, Xinyi Zhang, Miriam Metzger, Haitao Zheng, and Ben Y. Zhao. 2020. Detecting gender stereotypes: Lexicon vs. Supervised learning methods. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920), 1-11. https://doi.org/10.1145/3313831.3376488",
      "doi": "10.1145/3313831.3376488"
    },
    {
      "text": "Jenny L. Davis. 2019. Refusing (mis)recognition: Navigating multiple marginalization in the U.S. Two Spirit movement. Review of International American Studies 12, 1, 65-86.",
      "doi": ""
    },
    {
      "text": "Simon De Deyne, Danielle J. Navarro, Amy Perfors, Marc Brysbaert, and Gert Storms. 2019. The \u201cSmall World of Words\u201d English word association norms for over 12,000 cue words. Behavior Research Methods 51, 3, 987-1006. https://doi.org/10.3758/s13428-018-1115-7",
      "doi": ""
    },
    {
      "text": "Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff M. Phillips, and Kai-Wei Chang. 2021. Harms of gender exclusivity and challenges in non-binary representation in language technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021), 1968-1994. https://doi.org/10.18653/v1/2021.emnlp-main.150",
      "doi": ""
    },
    {
      "text": "Mark Diaz, Isaac Johnson, Amanda Lazar, Anne Marie Piper, and Darren Gergle. 2018. Addressing age-related bias in sentiment analysis. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI \u201918), 1-14. https://doi.org/10.1145/3173574.3173986",
      "doi": "10.1145/3173574.3173986"
    },
    {
      "text": "Emily Dinan, Angela Fan, Ledell Wu, Jason Weston, Douwe Kiela, and Adina Williams. 2020. Multi-dimensional gender bias classification. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (EMNLP 2020), 314-331. https://doi.org/10.18653/v1/2020.emnlp-main.23",
      "doi": ""
    },
    {
      "text": "Jad Doughman, Wael Khreich, Maya El Gharib, Maha Wiss, and Zahraa Berjawi. 2021. Gender bias in text: Origin, taxonomy, and implications. In Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing (ACL-GeBNLP-IJCNLP 2021), 34-44. https://doi.org/10.18653/v1/2021.gebnlp-1.5",
      "doi": ""
    },
    {
      "text": "Y. Du, K. Zhang, S. Ramabadran, and Y. Liu. 2021. \u201cAlexa, what is that sound?\u201d A video analysis of child-agent communication from two Amazon Alexa games. In Proceedings of the 2021 International Conference on Interaction Design and Children (IDC \u201921), 513-520. https://doi.org/10.1145/3459990.3465195",
      "doi": "10.1145/3459990.3465195"
    },
    {
      "text": "Nick C. Ellis. 2002. Frequency effects in language processing: A review with implications for theories of implicit and explicit language acquisition. Studies in Second Language Acquisition 24, 2, 143-188. https://doi.org/10.1017/S0272263102002024",
      "doi": ""
    },
    {
      "text": "Norman Fairclough. 1989. Language and Power. Longman, Essex, UK.",
      "doi": ""
    },
    {
      "text": "Norman Fairclough. 2013. Critical Discourse Analysis: The Critical Study of Language. Routledge.",
      "doi": ""
    },
    {
      "text": "Tracie Farrell, Miriam Fernandez, Jakub Novotny, and Harith Alani. 2019. Exploring misogyny across the manosphere in Reddit. In Proceedings of the 10th ACM Conference on Web Science (WebSci \u201919), 87-96. https://doi.org/10.1145/3292522.3326045",
      "doi": "10.1145/3292522.3326045"
    },
    {
      "text": "Christiane Fellbaum. 2005. WordNet and wordnets. In Encyclopedia of Language and Linguistics (2nd ed.), Keith Brown (ed.). Elsevier, Oxford, 665-670.",
      "doi": ""
    },
    {
      "text": "Leah Fessler. 2017. We tested bots like Siri and Alexa to see who would stand up to sexual harassment. Quartz. Retrieved November 21, 2019 from https://qz.com/911681/we-tested-apples-siri-amazon-echos-alexa-microsofts-cortana-and-googles-google-home-to-see-which-personal-assistant-bots-stand-up-for-themselves-in-the-face-of-sexual-harassment/",
      "doi": ""
    },
    {
      "text": "Anjalie Field and Yulia Tsvetkov. 2020. Unsupervised discovery of implicit gender bias. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (EMNLP 2020), 596-608. https://doi.org/10.18653/v1/2020.emnlp-main.44",
      "doi": ""
    },
    {
      "text": "Sophie Freud. 1994. The social construction of gender. Journal of Adult Development 1, 1, 37-45. https://doi.org/10.1007/BF02252981",
      "doi": ""
    },
    {
      "text": "Ismael Garrido-Mu\u00f1oz, Arturo Montejo-R\u00e1ez, Fernando Mart\u00ednez-Santiago, and L. Alfonso Ure\u00f1a-L\u00f3pez. 2021. A survey on bias in deep NLP. Applied Sciences 11, 7, 3184. https://doi.org/10.3390/app11073184",
      "doi": ""
    },
    {
      "text": "Danielle Gaucher, Justin Friesen, and Aaron C. Kay. 2011. Evidence that gendered wording in job advertisements exists and sustains gender inequality. Journal of Personality and Social Psychology 101, 1, 109-128. https://doi.org/10.1037/a0022530",
      "doi": ""
    },
    {
      "text": "Bhavya Ghai, Md Naimul Hoque, and Klaus Mueller. 2021. WordBias: An interactive visual tool for discovering intersectional biases encoded in word embeddings. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems (CHI \u201921), 1-7. https://doi.org/10.1145/3411763.3451587",
      "doi": "10.1145/3411763.3451587"
    },
    {
      "text": "Peter Glick and Susan T. Fiske. 2018. The Ambivalent Sexism Inventory: Differentiating hostile and benevolent sexism. In Social Cognition. Routledge.",
      "doi": ""
    },
    {
      "text": "Alessandra Gomes, Dennys Antonialli, and Thiago Oliva. 2019. Drag queens and Artificial Intelligence: should computers decide what is \u2018toxic\u2019 on the internet? InternetLab. Retrieved August 11, 2022 from https://internetlab.org.br/en/news/drag-queens-and-artificial-intelligence-should-computers-decide-what-is-toxic-on-the-internet/",
      "doi": ""
    },
    {
      "text": "Anthony G. Greenwald and Linda Hamilton Krieger. 2006. Implicit bias: Scientific foundations. California Law Review 94, 4, 945-967. https://doi.org/10.2307/20439056",
      "doi": ""
    },
    {
      "text": "Justin Grimmer and Brandon M. Stewart. 2013. Text as data: The promise and pitfalls of automatic content analysis methods for political texts. Political Analysis 21, 3, 267-297. https://doi.org/10.1093/pan/mps028",
      "doi": ""
    },
    {
      "text": "Mykol C. Hamilton. 1991. Masculine bias in the attribution of personhood: People= male, male= people. Psychology of Women Quarterly 15, 3, 393-402. https://doi.org/10.1111/j.1471-6402.1991.tb00415.x",
      "doi": ""
    },
    {
      "text": "Carol Harrington. 2021. What is \u201ctoxic masculinity\u201d and why does it matter? Men and Masculinities 24, 2, 345-352. https://doi.org/10.1177/1097184X20943254",
      "doi": ""
    },
    {
      "text": "Andrew F. Hayes and Klaus Krippendorff. 2007. Answering the call for a standard reliability measure for coding data. Communication Methods and Measures 1, 1, 77-89. https://doi.org/10.1080/19312450709336664",
      "doi": ""
    },
    {
      "text": "Daniel Hershcovich, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, Constanza Fierro, Katerina Margatina, Phillip Rust, and Anders S\u00f8gaard. 2022. Challenges and strategies in cross-cultural NLP. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL 2022), 6997-7013. https://doi.org/10.18653/v1/2022.acl-long.482",
      "doi": ""
    },
    {
      "text": "Curt Hoffman and Nancy Hurst. 1990. Gender stereotypes: Perception or rationalization? Journal of Personality and Social Psychology 58, 2, 197-208. https://doi.org/10.1037/0022-3514.58.2.197",
      "doi": ""
    },
    {
      "text": "Matthew B. Hoy. 2018. Alexa, Siri, Cortana, and more: An introduction to voice assistants. Medical Reference Services Quarterly 37, 1, 81-88. https://doi.org/10.1080/02763869.2018.1404391",
      "doi": ""
    },
    {
      "text": "Hsiu-Fang Hsieh and Sarah E. Shannon. 2005. Three approaches to qualitative content analysis. Qualitative Health Research 15, 9, 1277-1288. https://doi.org/10.1177/1049732305276687",
      "doi": ""
    },
    {
      "text": "Christoph Hube, Besnik Fetahu, and Ujwal Gadiraju. 2019. Understanding and mitigating worker biases in the crowdsourced collection of subjective judgments. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI \u201919), 1-12. https://doi.org/10.1145/3290605.3300637",
      "doi": "10.1145/3290605.3300637"
    },
    {
      "text": "Janet Shibley Hyde, Rebecca S. Bigler, Daphna Joel, Charlotte Chucky Tate, and Sari M. van Anders. 2019. The future of sex and gender in psychology: Five challenges to the gender binary. American Psychologist 74, 2, 171-193. https://doi.org/10.1037/amp0000307",
      "doi": ""
    },
    {
      "text": "Samantha Jaroszewski, Danielle Lottridge, Oliver L. Haimson, and Katie Quehl. 2018. \u201cGenderfluid\u201d or \u201cattack helicopter\u201d: Responsible HCI research practice with non-binary gender variation in online communities. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI \u201918), 1-15. https://doi.org/10.1145/3173574.3173881",
      "doi": "10.1145/3173574.3173881"
    },
    {
      "text": "Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020), 6282-6293. https://doi.org/10.18653/v1/2020.acl-main.560",
      "doi": ""
    },
    {
      "text": "Abby Kaplan. 2016. Women Talk More than Men ... and Other Myths about Language Explained. Cambridge University Press, Cambridge, UK.",
      "doi": ""
    },
    {
      "text": "Os Keyes, Chandler May, and Annabelle Carrell. 2021. You keep using that word: Ways of thinking about gender in computing research. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1, 39:1-39:23. https://doi.org/10.1145/3449113",
      "doi": "10.1145/3449113"
    },
    {
      "text": "Scott Kiesling. 2007. Men, masculinities, and language. Language and Linguistics Compass 1, 6, 653-673. https://doi.org/10.1111/j.1749-818X.2007.00035.x",
      "doi": ""
    },
    {
      "text": "Allison Koenecke, Andrew Nam, Emily Lake, Joe Nudell, Minnie Quartey, Zion Mengesha, Connor Toups, John R. Rickford, Dan Jurafsky, and Sharad Goel. 2020. Racial disparities in automated speech recognition. Proceedings of the National Academy of Sciences 117, 14, 7684-7689. https://doi.org/10.1073/pnas.1915768117",
      "doi": ""
    },
    {
      "text": "Ivar Krumpal. 2013. Determinants of social desirability bias in sensitive surveys: A literature review. Quality & Quantity 47, 4, 2025-2047. https://doi.org/10.1007/s11135-011-9640-9",
      "doi": ""
    },
    {
      "text": "Elizabeth Landau. Tech confronts Its use of the labels \u2018master\u2019 and \u2018slave.\u2019 Wired. Retrieved September 2, 2022 from https://www.wired.com/story/tech-confronts-use-labels-master-slave/",
      "doi": ""
    },
    {
      "text": "Anne Lauscher, Archie Crowley, and Dirk Hovy. 2022. Welcome to the modern world of pronouns: Identity-inclusive natural language processing beyond gender. In Proceedings of the 29th International Conference on Computational Linguistics (COLING 2022), 1221-1232. Retrieved November 23, 2022 from https://aclanthology.org/2022.coling-1.105",
      "doi": ""
    },
    {
      "text": "Susan Leavy, Gerardine Meaney, Karen Wade, and Derek Greene. 2020. Mitigating gender bias in machine learning data sets. In Bias and Social Aspects in Search and Recommendation (BIAS 2020), 12-26. https://doi.org/10.1007/978-3-030-52485-2_2",
      "doi": ""
    },
    {
      "text": "Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, and Chris Pal. 2018. Towards deep conversational recommendations. In Advances in Neural Information Processing Systems (NeurIPS \u201918). Retrieved August 11, 2022 from https://papers.nips.cc/paper/2018/hash/800de15c79c8d840f4e78d3af937d4d4-Abstract.html",
      "doi": ""
    },
    {
      "text": "Sebastian Linxen, Christian Sturm, Florian Br\u00fchlmann, Vincent Cassau, Klaus Opwis, and Katharina Reinecke. 2021. How WEIRD is CHI? In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI \u201921), 1-14. https://doi.org/10.1145/3411764.3445488",
      "doi": "10.1145/3411764.3445488"
    },
    {
      "text": "Heather Jean Macarthur. 2015. When Women are Called \u201cGirls\u201d: The Effect of Infantilizing Labels on Women's Self-perceptions. Penn State University, PA, US. Retrieved from https://etda.libraries.psu.edu/catalog/25797",
      "doi": ""
    },
    {
      "text": "Kate Manne. 2018. Down Girl: The Logic of Misogyny. Oxford University Press.",
      "doi": ""
    },
    {
      "text": "Thomas Manzini, Lim Yao Chong, Alan W Black, and Yulia Tsvetkov. 2019. Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (NAACL-HLT 2019), 615-621. https://doi.org/10.18653/v1/N19-1062",
      "doi": ""
    },
    {
      "text": "Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the Conference on Fairness, Accountability, and Transparency, 220-229. https://doi.org/10.1145/3287560.3287596",
      "doi": "10.1145/3287560.3287596"
    },
    {
      "text": "Christine Murad, Cosmin Munteanu, Benjamin R. Cowan, Leigh Clark, Martin Porcheron, Heloisa Candello, Stephan Schl\u00f6gl, Matthew P. Aylett, Jaisie Sin, Robert J. Moore, Grace Hughes, and Andrew Ku. 2021. Let's talk about CUIs: Putting conversational user interface design into practice. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems (CHI EA \u201921), 1-6. https://doi.org/10.1145/3411763.3441336",
      "doi": "10.1145/3411763.3441336"
    },
    {
      "text": "Gina Neff and Peter Nagy. 2016. Talking to bots: Symbiotic agency and the case of Tay. International Journal of Communication 10, 0, 17.",
      "doi": ""
    },
    {
      "text": "Ihudiya Finda Ogbonnaya-Ogburu, Angela D.R. Smith, Alexandra To, and Kentaro Toyama. 2020. Critical race theory for HCI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920), 1-16. https://doi.org/10.1145/3313831.3376392",
      "doi": "10.1145/3313831.3376392"
    },
    {
      "text": "Sven H. Pedersen and Leif A. Str\u00f6mwall. 2013. Victim blame, sexism and Just-world beliefs: A cross-cultural comparison. Psychiatry, Psychology and Law 20, 6, 932-941. https://doi.org/10.1080/13218719.2013.770715",
      "doi": ""
    },
    {
      "text": "Davor Petreski and Ibrahim C. Hashim. 2022. Word embeddings are biased. But whose bias are they reflecting? AI & SOCIETY. https://doi.org/10.1007/s00146-022-01443-w",
      "doi": "10.1007/s00146-022-01443-w"
    },
    {
      "text": "Liz Plank. 2019. For the Love of Men: From Toxic to a More Mindful Masculinity. St. Martin's Press.",
      "doi": ""
    },
    {
      "text": "Manoel Horta Ribeiro, Jeremy Blackburn, Barry Bradlyn, Emiliano De Cristofaro, Gianluca Stringhini, Summer Long, Stephanie Greenberg, and Savvas Zannettou. 2021. The evolution of the manosphere across the web. In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM 2021), 196-207. Retrieved August 8, 2022 from https://ojs.aaai.org/index.php/ICWSM/article/view/18053",
      "doi": ""
    },
    {
      "text": "Cami Rinc\u00f3n, Os Keyes, and Corinne Cath. 2021. Speaking from experience: Trans/non-binary requirements for voice-activated AI. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1, 132:1-132:27. https://doi.org/10.1145/3449206",
      "doi": "10.1145/3449206"
    },
    {
      "text": "Damon C. Roberts and Stephen M. Utych. 2020. Linking gender, language, and partisanship: Developing a database of masculine and feminine words. Political Research Quarterly 73, 1, 40-50. https://doi.org/10.1177/1065912919874883",
      "doi": ""
    },
    {
      "text": "Jennifer A. Rode. 2011. Reflexivity in digital anthropology. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \u201911), 123-132. https://doi.org/10.1145/1978942.1978961",
      "doi": "10.1145/1978942.1978961"
    },
    {
      "text": "Laurie A. Rudman and Stephen E. Kilianski. 2000. Implicit and explicit attitudes toward female authority. Personality and Social Psychology Bulletin 26, 11, 1315-1328. https://doi.org/10.1177/0146167200263001",
      "doi": ""
    },
    {
      "text": "Niloofar Safi Samghabadi, Parth Patwa, Srinivas PYKL, Prerana Mukherjee, Amitava Das, and Thamar Solorio. 2020. Aggression and misogyny detection using BERT: A multi-task approach. In Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying (LREC 2020), 126-131. Retrieved August 30, 2022 from https://aclanthology.org/2020.trac-1.20",
      "doi": ""
    },
    {
      "text": "Londa Schiebinger. 2000. Has feminism changed science? Signs: Journal of Women in Culture and Society 25, 4, 1171-1175. https://doi.org/10.1086/495540",
      "doi": ""
    },
    {
      "text": "Ari Schlesinger, Kenton P. O'Hara, and Alex S. Taylor. 2018. Let's talk about race: Identity, chatbots, and AI. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI \u201918), 1-14. https://doi.org/10.1145/3173574.3173889",
      "doi": "10.1145/3173574.3173889"
    },
    {
      "text": "Stephen A. Schullo and Burton L. Alperson. 1984. Interpersonal phenomenology as a function of sexual orientation, sex, sentiment, and trait categories in long-term dyadic relationships. Journal of Personality and Social Psychology 47, 5, 983-1002. https://doi.org/10.1037/0022-3514.47.5.983",
      "doi": ""
    },
    {
      "text": "Katie Seaborn and Alexa Frank. 2022. What pronouns for Pepper? A critical review of gender/ing in research. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI \u201922), 1-15. https://doi.org/10.1145/3491102.3501996",
      "doi": "10.1145/3491102.3501996"
    },
    {
      "text": "Katie Seaborn, Norihisa Paul Miyake, Peter Pennefather, and Mihoko Otake-Matsuura. 2022. Voice in human-agent interaction: A survey. ACM Computing Surveys (CSUR) 54, 4, Article No. 81. https://doi.org/10.1145/3386867",
      "doi": "10.1145/3386867"
    },
    {
      "text": "James A. Serpell. 2000. Domestication and history of the cat. In The Domestic Cat: The Biology of its Behaviour (2nd ed.), Dennis C. Turner and Patrick Bateson (eds.). Cambridge University Press, Cambridge, UK, 180-192.",
      "doi": ""
    },
    {
      "text": "Dale Spender. 1985. Man Made Language. Routledge.",
      "doi": ""
    },
    {
      "text": "Katta Spiel, Os Keyes, and P\u0131nar Barlas. 2019. Patching gender: Non-binary utopias in HCI. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA \u201919), 1-11. https://doi.org/10.1145/3290607.3310425",
      "doi": "10.1145/3290607.3310425"
    },
    {
      "text": "Damiano Spina, Johanne R. Trippas, Paul Thomas, Hideo Joho, Katriina Bystr\u00f6m, Leigh Clark, Nick Craswell, Mary Czerwinski, David Elsweiler, Alexander Frummet, Souvick Ghosh, Johannes Kiesel, Irene Lopatovska, Daniel McDuff, Selina Meyer, Ahmed Mourad, Paul Owoicho, Sachin Pathiyan Cherumanal, Daniel Russell, and Laurianne Sitbon. 2021. Report on the future conversations workshop at CHIIR 2021. ACM SIGIR Forum 55, 1, 6:1-6:22. https://doi.org/10.1145/3476415.3476421",
      "doi": "10.1145/3476415.3476421"
    },
    {
      "text": "Yolande Strengers and Jenny Kennedy. 2021. The Smart Wife: Why Siri, Alexa, and Other Smart Home Devices Need a Feminist Reboot. MIT Press.",
      "doi": ""
    },
    {
      "text": "Yolande Strengers, Lizhen Qu, Qiongkai Xu, and Jarrod Knibbe. 2020. Adhering, steering, and queering: Treatment of gender in natural language generation. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920), 1-14. https://doi.org/10.1145/3313831.3376315",
      "doi": "10.1145/3313831.3376315"
    },
    {
      "text": "Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, and William Yang Wang. 2019. Mitigating gender bias in natural language processing: Literature review. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019), 1630-1640. https://doi.org/10.18653/v1/P19-1159",
      "doi": ""
    },
    {
      "text": "Rachael Tatman. 2017. Gender and dialect bias in YouTube's automatic captions. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (EthNLP 2017), 53-59. https://doi.org/10.18653/v1/W17-1606",
      "doi": ""
    },
    {
      "text": "Margaret Urban and Stephen Mailey. 2019. Conversation Design: Principles, Strategies, and Practical Application. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems, 1-3. https://doi.org/10.1145/3290607.3298821",
      "doi": "10.1145/3290607.3298821"
    },
    {
      "text": "Sarah Theres V\u00f6lkel, Daniel Buschek, Malin Eiband, Benjamin R. Cowan, and Heinrich Hussmann. 2021. Eliciting and analysing users\u2019 envisioned dialogues with perfect voice assistants. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI \u201921), 1-15. https://doi.org/10.1145/3411764.3445536",
      "doi": "10.1145/3411764.3445536"
    },
    {
      "text": "Mihaela Vorvoreanu, Lingyi Zhang, Yun-Han Huang, Claudia Hilderbrand, Zoe Steine-Hanson, and Margaret Burnett. 2019. From gender biases to gender-inclusive design: An empirical investigation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI \u201919), 1-14. https://doi.org/10.1145/3290605.3300283",
      "doi": "10.1145/3290605.3300283"
    },
    {
      "text": "Judy Wajcman. 1991. Technology as masculine culture. In Feminism confronts technology. Penn State University Press, Pennsylvania.",
      "doi": ""
    },
    {
      "text": "Kasper Welbers, Wouter van Atteveldt, and Kenneth Benoit. 2017. Text analysis in R. Communication Methods and Measures 11, 4, 245-265. https://doi.org/10.1080/19312458.2017.1387238",
      "doi": ""
    },
    {
      "text": "Mark West, Rebecca Kraut, and Chew Han Ei. 2019. I'd blush if I could: Closing gender divides in digital skills through education. EQUALS, France. Retrieved from https://unesdoc.unesco.org/ark:/48223/pf0000367416.page=1",
      "doi": ""
    },
    {
      "text": "Makeba Parramore Wilbourn and Daniel W. Kee. 2010. Henry the nurse is a doctor too: Implicitly examining children's gender stereotypes for male and female occupational roles. Sex Roles 62, 9, 670-683. https://doi.org/10.1007/s11199-010-9773-7",
      "doi": ""
    },
    {
      "text": "Steven Wilson, Rada Mihalcea, Ryan Boyd, and James Pennebaker. 2016. Disentangling topic models: A cross-cultural analysis of personal values through words. In Proceedings of the First Workshop on NLP and Computational Social Science (NLP+CSS \u201916), 143-152. https://doi.org/10.18653/v1/W16-5619",
      "doi": ""
    },
    {
      "text": "Georgia Zellou, Michelle Cohn, and Bruno Ferenc Segedin. 2021. Age- and gender-related differences in speech alignment toward humans and voice-AI. Frontiers in Communication 5. Retrieved May 4, 2022 from https://www.frontiersin.org/article/10.3389/fcomm.2020.600361",
      "doi": ""
    }
  ]
}