{
  "doi": "10.1145/3544548.3580727",
  "title": "Generating Haptic Motion Effects for Multiple Articulated Bodies for Improved 4D Experiences: A Camera Space Approach",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-17",
  "year": 2023,
  "badges": [],
  "abstract": "Motion effects are indispensable for improving 4D experiences in highly interactive applications, such as amusement parks, 4D theaters, and virtual reality games. Their recent emergence calls for effective algorithms generating motion effects synchronized with audiovisual content. This paper presents an automatic algorithm for synthesizing the object-based motion effects that express the movements of multiple articulated bodies inclusively when the objects\u2019 motion trajectories are available in the 3D camera space. By taking the visual velocities and sizes of all object parts, our method computes a motion proxy that represents the objects\u2019 movements by one point and converts the motion proxy to a motion command through a motion cueing algorithm. The motion proxy is determined by linearly combining the velocities, and its best combination was selected from several candidates by user studies. The results of user studies indicate that our algorithm can produce compelling object-based motion effects that enhance the multisensory experience.",
  "tags": [
    "synthesis",
    "motion cueing",
    "multiple sensorial media",
    "haptics",
    "virtual reality",
    "automatic generation",
    "articulated body",
    "4D",
    "mulsemedia",
    "vestibular sense",
    "motion effects"
  ],
  "authors": [
    {
      "name": "Sangyoon Han",
      "institution": "Computer Science and Engineering / Interaction Laboratory, Pohang University of Science and Technology (POSTECH), Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659261398",
      "orcid": "0000-0003-1969-0235"
    },
    {
      "name": "Jaejun Park",
      "institution": "Computer Science and Engineering / Interaction Laboratory, Pohang University of Science and Technology (POSTECH), Korea, Republic of",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659917764",
      "orcid": "0000-0002-9929-5130"
    },
    {
      "name": "Seungmoon Choi",
      "institution": "Computer Science and Engineering / Interaction Laboratory, Pohang University of Science and Technology (POSTECH), Korea, Republic of",
      "img": "/do/10.1145/contrib-81100480604/rel-imgonly/bio_seungmoonchoi.jpg",
      "acmid": "81100480604",
      "orcid": "0000-0002-5889-1083"
    }
  ],
  "references": [
    {
      "text": "Raphael Abreu, Douglas Mattos, Joel A. F.\u00a0dos Santos, and D\u00e9bora\u00a0C. Muchaluat-Saade. 2019. Semi-automatic synchronization of sensory effects in mulsemedia authoring tools. In Proceedings of the 25th Brazillian Symposium on Multimedia and the Web. ACM, 201\u2013208. https://doi.org/10.1145/3323503.3360302",
      "doi": "10.1145/3323503.3360302"
    },
    {
      "text": "Jake\u00a0K. Aggarwal and Qin Cai. 1999. Human motion analysis: A review. Computer Vision and Image Understanding 73, 3 (1999), 428\u2013440. https://doi.org/10.1006/cviu.1998.0744",
      "doi": "10.1006/cviu.1998.0744"
    },
    {
      "text": "Thiemo Alldieck, Gerard Pons-Moll, Christian Theobalt, and Marcus Magnor. 2019. Tex2Shape: Detailed full human body geometry from a single image. In 2019 IEEE/CVF International Conference on Computer Vision. IEEE, 2293\u20132303. https://doi.org/10.1109/ICCV.2019.00238",
      "doi": ""
    },
    {
      "text": "Tomohiro Amemiya, Michiteru Kitazaki, and Yasushi Ikei. 2020. Pseudo-sensation of walking generated by passive whole-body motions in heave and yaw directions. IEEE Transactions on Haptics 13, 1 (2020), 80\u201386. https://doi.org/10.1109/TOH.2020.2965937",
      "doi": "10.1109/TOH.2020.2965937"
    },
    {
      "text": "Jas Brooks, Pedro Lopes, Judith Amores, Emanuela Maggioni, Haruka Matsukura, Marianna Obrist, Roshan Lalintha\u00a0Peiris, and Nimesha Ranasinghe. 2021. Smell, taste, and temperature interfaces. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. ACM, Article 76, 6\u00a0pages. https://doi.org/10.1145/3411763.3441317",
      "doi": "10.1145/3411763.3441317"
    },
    {
      "text": "Eduardo\u00a0F. Camacho and Carlos\u00a0Bordons Alba. 2013. Model predictive control. Springer Science & Business Media.",
      "doi": ""
    },
    {
      "text": "Julie Chang and Gordon Wetzstein. 2019. Deep optics for monocular depth estimation and 3D object detection. In 2019 IEEE/CVF International Conference on Computer Vision. IEEE, 10192\u201310201. https://doi.org/10.1109/ICCV.2019.01029",
      "doi": ""
    },
    {
      "text": "Lung-Pan Cheng, Patrick L\u00fchne, Pedro Lopes, Christoph Sterz, and Patrick Baudisch. 2014. Haptic turk: A motion platform based on people. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3463\u20133472. https://doi.org/10.1145/2556288.2557101",
      "doi": "10.1145/2556288.2557101"
    },
    {
      "text": "Seungmoon Choi and Katherine\u00a0J. Kuchenbecker. 2012. Vibrotactile display: Perception, technology, and applications. Proc. IEEE 101, 9 (2012), 2093\u20132104. https://doi.org/10.1109/JPROC.2012.2221071",
      "doi": ""
    },
    {
      "text": "Chien-Hsing Chou, Yu-Sheng Su, Che-Ju Hsu, Kong-Chang Lee, and Ping-Hsuan Han. 2020. Design of desktop audiovisual entertainment system with deep learning and haptic sensations. Symmetry 12, 10, Article 1718(2020), 14\u00a0pages. https://doi.org/10.3390/sym12101718",
      "doi": ""
    },
    {
      "text": "CMU. 2003. Carnegie-Mellon mocap database. http://mocap.cs.cmu.edu/",
      "doi": ""
    },
    {
      "text": "Stelian Coros, Andrej Karpathy, Ben Jones, Lionel Reveret, and Michiel van\u00a0de Panne. 2011. Locomotion skills for simulated quadrupeds. ACM Transactions on Graphics 30, 4, Article 59(2011), 12\u00a0pages. https://doi.org/10.1145/2010324.1964954",
      "doi": "10.1145/2010324.1964954"
    },
    {
      "text": "Alexandra Covaci, Longhao Zou, Irina Tal, Gabriel-Miro Muntean, and Gheorghita Ghinea. 2018. Is multimedia multisensorial?-A review of mulsemedia systems. Comput. Surveys 51, 5, Article 91 (2018), 35\u00a0pages. https://doi.org/10.1145/3233774",
      "doi": "10.1145/3233774"
    },
    {
      "text": "Fabien Danieau, J\u00e9r\u00e9mie Bernon, Julien Fleureau, Philippe Guillotel, Nicolas Mollet, Marc Christie, and Anatole L\u00e9cuyer. 2013. H-Studio: An authoring tool for adding haptic and motion effects to audiovisual content. In Proceedings of the Adjunct Publication of the 26th Annual ACM Symposium on User Interface Software and Technology. ACM, 83\u201384. https://doi.org/10.1145/2508468.2514721",
      "doi": "10.1145/2508468.2514721"
    },
    {
      "text": "Fabien Danieau, Julien Fleureau, Philippe Guillotel, Nicolas Mollet, Anatole L\u00e9cuyer, and Marc Christie. 2012. HapSeat: Producing motion sensation with multiple force-feedback devices embedded in a seat. In Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology. ACM, 69\u201376. https://doi.org/10.1145/2407336.2407350",
      "doi": "10.1145/2407336.2407350"
    },
    {
      "text": "Fabien Danieau, Anatole L\u00e9cuyer, Philippe Guillotel, Julien Fleureau, Nicolas Mollet, and Marc Christie. 2012. Enhancing audiovisual experience with haptic feedback: A survey on HAV. IEEE Transactions on Haptics 6, 2 (2012), 193\u2013205. https://doi.org/10.1109/TOH.2012.70",
      "doi": "10.1109/TOH.2012.70"
    },
    {
      "text": "Raphael\u00a0Silva de Abreu, Douglas Mattos, Joel dos Santos, Gheorghita Ghinea, and D\u00e9bora\u00a0Christina Muchaluat-Saade. 2020. Toward content-driven intelligent authoring of mulsemedia applications. IEEE MultiMedia 28, 1 (2020), 7\u201316. https://doi.org/10.1109/MMUL.2020.3011383",
      "doi": ""
    },
    {
      "text": "Eunsu Goh, Daeyeol Kim, Suyeong Oh, and Chae-Bong Sohn. 2020. Automatic effect generation method for 4D films. International Journal of Computing and Digital Systems 9, 2(2020), 281\u2013288. https://doi.org/10.12785/ijcds/090213",
      "doi": ""
    },
    {
      "text": "Jan Gugenheimer, Dennis Wolf, Eythor\u00a0R. Eiriksson, Pattie Maes, and Enrico Rukzio. 2016. GyroVR: Simulating inertia in virtual reality using head worn flywheels. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. ACM, 227\u2013232. https://doi.org/10.1145/2984511.2984535",
      "doi": "10.1145/2984511.2984535"
    },
    {
      "text": "Jan Gugenheimer, Dennis Wolf, Gabriel Haas, Sebastian Krebs, and Enrico Rukzio. 2016. SwiVRChair: A motorized swivel chair to nudge users\u2019 orientation for 360 degree storytelling in virtual reality. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 1996\u20132000. https://doi.org/10.1145/2858036.2858040",
      "doi": "10.1145/2858036.2858040"
    },
    {
      "text": "Sangyoon Han, Jiwan Lee, Gyeore Yun, Sung\u00a0H. Han, and Seungmoon Choi. 2022. Motion effects: Perceptual space and synthesis for specific perceptual properties. IEEE Transactions on Haptics(2022), 12\u00a0pages. https://doi.org/10.1109/toh.2022.3196950 On-Line Access.",
      "doi": "10.1109/toh.2022.3196950"
    },
    {
      "text": "Sangyoon Han, Gyeore Yun, and Seungmoon Choi. 2021. Camera space synthesis of motion effects emphasizing a moving object in 4D films. In 2021 IEEE Virtual Reality and 3D User Interfaces. IEEE, 670\u2013678. https://doi.org/10.1109/VR50410.2021.00093",
      "doi": ""
    },
    {
      "text": "Koichi Hirota, Seichiro Ebisawa, Tomohiro Amemiya, and Yasushi Ikei. 2011. A system for creating the content for a multi-sensory theater. In Proceedings of the International Conference on Virtual and Mixed Reality. Springer, 151\u2013157. https://doi.org/10.1007/978-3-642-22024-1_17",
      "doi": ""
    },
    {
      "text": "Koichi Hirota, Seichiro Ebisawa, Tomohiro Amemiya, and Yasushi Ikei. 2011. A theater for viewing and editing multi-sensory content. In 2011 IEEE International Symposium on VR Innovation. IEEE, 239\u2013244. https://doi.org/10.1109/ISVRI.2011.5759643",
      "doi": ""
    },
    {
      "text": "Junhwa Hur and Stefan Roth. 2021. Self-supervised multi-frame monocular scene flow. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2684\u20132694.",
      "doi": ""
    },
    {
      "text": "Yasushi Ikei, Shunki Kato, Kohei Komase, Shogo Imao, Sho Sakurai, Tomohiro Amemiya, Michiteru Kitazaki, and Koichi Hirota. 2016. Vestibulohaptic passive stimulation for a walking sensation. In Proceedings of the IEEE Virtual Reality. IEEE, 185\u2013186. https://doi.org/10.1109/VR.2016.7504715",
      "doi": ""
    },
    {
      "text": "Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, and Thomas Brox. 2017. Flownet 2.0: Evolution of optical flow estimation with deep networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2462\u20132470.",
      "doi": ""
    },
    {
      "text": "Ali Israr and Ivan Poupyrev. 2011. Tactile brush: Drawing on skin with a tactile grid display. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2019\u20132028. https://doi.org/10.1145/1978942.1979235",
      "doi": "10.1145/1978942.1979235"
    },
    {
      "text": "Ali Israr, Siyan Zhao, Kaitlyn Schwalje, Roberta Klatzky, and Jill Lehman. 2014. Feel effects: Enriching storytelling with haptic feedback. ACM Transactions on Applied Perception 11, 3, Article 11(2014), 17\u00a0pages. https://doi.org/10.1145/2641570",
      "doi": "10.1145/2641570"
    },
    {
      "text": "Laurent Itti, Christof Koch, and Ernst Niebur. 1998. A model of saliency-based visual attention for rapid scene analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence 20, 11(1998), 1254\u20131259. https://doi.org/10.1109/34.730558",
      "doi": "10.1109/34.730558"
    },
    {
      "text": "Dhruv Jain, Misha Sra, Jingru Guo, Rodrigo Marques, Raymond Wu, Justin Chiu, and Chris Schmandt. 2016. Immersive terrestrial scuba diving using virtual reality. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 1563\u20131569. https://doi.org/10.1145/2851581.2892503",
      "doi": "10.1145/2851581.2892503"
    },
    {
      "text": "Eunjung Ju, Jungdam Won, Jehee Lee, Byungkuk Choi, Junyong Noh, and Min\u00a0Gyu Choi. 2013. Data-driven control of flapping flight. ACM Transactions on Graphics 32, 5, Article 151(2013), 12\u00a0pages. https://doi.org/10.1145/2516971.2516976",
      "doi": "10.1145/2516971.2516976"
    },
    {
      "text": "Takayuki Kameoka, Yuki Kon, Takuto Nakamura, and Hiroyuki Kajimoto. 2018. Haptopus: Haptic VR experience using suction mechanism embedded in head-mounted display. In The 31st Annual ACM Symposium on User Interface Software and Technology Adjunct Proceedings. ACM, 154\u2013156. https://doi.org/10.1145/3266037.3271634",
      "doi": "10.1145/3266037.3271634"
    },
    {
      "text": "Jaeha Kim, Chang-Gyu Lee, Yeongmi Kim, and Jeha Ryu. 2013. Construction of a haptic-enabled broadcasting system based on the MPEG-V standard. Signal Processing: Image Communication 28, 2 (2013), 151\u2013161. https://doi.org/10.1016/j.image.2012.10.010",
      "doi": "10.1016/j.image.2012.10.010"
    },
    {
      "text": "Sang-Kyun Kim. 2013. Authoring multisensorial content. Signal Processing: Image Communication 28, 2 (2013), 162\u2013167. https://doi.org/10.1016/j.image.2012.10.011",
      "doi": "10.1016/j.image.2012.10.011"
    },
    {
      "text": "Yeongmi Kim, Jongeun Cha, Jeha Ryu, and Ian Oakley. 2010. A tactile glove design and authoring system for immersive multimedia. IEEE MultiMedia 17, 3 (2010), 34\u201345. https://doi.org/10.1109/MMUL.2010.5692181",
      "doi": ""
    },
    {
      "text": "Bernd Kitt, Andreas Geiger, and Henning Lategahn. 2010. Visual odometry based on stereo image sequences with RANSAC-based outlier rejection scheme. In 2010 IEEE Intelligent Vehicles Symposium. IEEE, 486\u2013492. https://doi.org/10.1109/IVS.2010.5548123",
      "doi": ""
    },
    {
      "text": "Yuki Kon, Takuto Nakamura, and Hiroyuki Kajimoto. 2017. HangerOVER: HMD-embedded haptics display with hanger reflex. In ACM SIGGRAPH 2017 Emerging Technologies. ACM, Article 11, 2\u00a0pages. https://doi.org/10.1145/3084822.3084842",
      "doi": "10.1145/3084822.3084842"
    },
    {
      "text": "Hyoseung Lee, Seungjae Oh, and Seungmoon Choi. 2022. Data-driven rendering of motion effects for walking sensations in different gaits. IEEE Transactions on Haptics(2022), 13\u00a0pages. https://doi.org/10.1109/TOH.2022.3176964 On-Line Access.",
      "doi": "10.1109/TOH.2022.3176964"
    },
    {
      "text": "Jaebong Lee and Seungmoon Choi. 2013. Real-time perception-level translation from audio signals to vibrotactile effects. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2567\u20132576. https://doi.org/10.1145/2470654.2481354",
      "doi": "10.1145/2470654.2481354"
    },
    {
      "text": "Jaebong Lee, Bohyung Han, and Seungmoon Choi. 2015. Motion effects synthesis for 4D films. IEEE Transactions on Visualization and Computer Graphics 22, 10(2015), 2300\u20132314. https://doi.org/10.1109/TVCG.2015.2507591",
      "doi": "10.1109/TVCG.2015.2507591"
    },
    {
      "text": "Jaebong Lee, Bohyung Han, and Seungmoon Choi. 2016. Interactive motion effects design for a moving object in 4D films. In Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology. ACM, 219\u2013228. https://doi.org/10.1145/2993369.2993389",
      "doi": "10.1145/2993369.2993389"
    },
    {
      "text": "Sungkil Lee, Gerard\u00a0Jounghyun Kim, and Seungmoon Choi. 2008. Real-time tracking of visually attended objects in virtual environments and its application to LOD. IEEE Transactions on Visualization and Computer Graphics 15, 1(2008), 6\u201319. https://doi.org/10.1109/TVCG.2008.82",
      "doi": "10.1109/TVCG.2008.82"
    },
    {
      "text": "Yoonsang Lee, Sungeun Kim, and Jehee Lee. 2010. Data-driven biped control. In ACM SIGGRAPH 2010 Papers. ACM, Article 129, 8\u00a0pages. https://doi.org/10.1145/1833349.1781155",
      "doi": "10.1145/1833349.1781155"
    },
    {
      "text": "Yaxuan Li, Yongjae Yoo, Antoine Weill-Duflos, and Jeremy Cooperstock. 2021. Towards context-aware automatic haptic effect heneration for home theatre environments. In Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology. ACM, Article 13, 11\u00a0pages. https://doi.org/10.1145/3489849.3489887",
      "doi": "10.1145/3489849.3489887"
    },
    {
      "text": "Beomsu Lim, Sangyoon Han, and Seungmoon Choi. 2021. Image-based texture styling for motion effect rendering. In Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology. ACM, Article 20, 10\u00a0pages. https://doi.org/10.1145/3489849.3489854",
      "doi": "10.1145/3489849.3489854"
    },
    {
      "text": "Daniel Marfil, Fernando Boronat, Juan Gonz\u00e1lez, and Almanzor Sapena. 2022. Integration of multi-sensorial effects in synchronised immersive hybrid TV scenarios. IEEE Access 10(2022), 79071\u201379089. https://doi.org/10.1109/ACCESS.2022.3194170",
      "doi": ""
    },
    {
      "text": "Douglas Paulo\u00a0De Mattos, D\u00e9bora\u00a0C. Muchaluat-Saade, and Gheorghita Ghinea. 2021. Beyond multimedia authoring: On the need for mulsemedia authoring tools. Comput. Surveys 54, 7, Article 150 (2021), 31\u00a0pages. https://doi.org/10.1145/3464422",
      "doi": "10.1145/3464422"
    },
    {
      "text": "Dushyant Mehta, Oleksandr Sotnychenko, Franziska Mueller, Weipeng Xu, Mohamed Elgharib, Pascal Fua, Hans-Peter Seidel, Helge Rhodin, Gerard Pons-Moll, and Christian Theobalt. 2020. XNect: Real-time multi-person 3D motion capture with a single RGB camera. Acm Transactions On Graphics 39, 4, Article 82(2020), 17\u00a0pages. https://doi.org/10.1145/3386569.3392410",
      "doi": "10.1145/3386569.3392410"
    },
    {
      "text": "Miguel Melo, Guilherme Gon\u00e7alves, Pedro Monteiro, Hugo Coelho, Jos\u00e9 Vasconcelos-Raposo, and Maximino Bessa. 2020. Do multisensory stimuli benefit the virtual reality experience? A systematic review. IEEE Transactions on Visualization and Computer Graphics 28, 2(2020), 1428\u20131442. https://doi.org/10.1109/TVCG.2020.3010088",
      "doi": "10.1109/TVCG.2020.3010088"
    },
    {
      "text": "Meta. 2022. Meta: Social Metaverse Company. https://about.facebook.com/",
      "doi": ""
    },
    {
      "text": "Thomas\u00a0B. Moeslund, Adrian Hilton, and Volker Kr\u00fcger. 2006. A survey of advances in vision-based human motion capture and analysis. Computer Vision and Image Understanding 104, 2 (2006), 90\u2013126. https://doi.org/10.1016/j.cviu.2006.08.002",
      "doi": "10.1016/j.cviu.2006.08.002"
    },
    {
      "text": "Taeyong Moon and Gerard\u00a0J. Kim. 2004. Design and evaluation of a wind display for virtual reality. In Proceedings of the ACM Symposium on Virtual Reality Software and Technology. ACM, 122\u2013128. https://doi.org/10.1145/1077534.1077558",
      "doi": "10.1145/1077534.1077558"
    },
    {
      "text": "Allen\u00a0L Nagy and Robert\u00a0R Sanchez. 1990. Critical color differences determined with a visual search task. Journal of the Optical Society of America A 7, 7 (1990), 1209\u20131217.",
      "doi": ""
    },
    {
      "text": "Meyer\u00a0A. Nahon and Lloyd\u00a0D. Reid. 1990. Simulator motion-drive algorithms-A designer\u2019s perspective. Journal of Guidance, Control, and Dynamics 13, 2 (1990), 356\u2013362. https://doi.org/10.2514/3.20557",
      "doi": ""
    },
    {
      "text": "Takamichi Nakamoto and Hai Pham\u00a0Dinh Minh. 2007. Improvement of olfactory display using solenoid valves. In 2007 IEEE Virtual Reality Conference. IEEE, 179\u2013186. https://doi.org/10.1109/VR.2007.352479",
      "doi": ""
    },
    {
      "text": "Michael Ortega, Stephane Redon, and Sabine Coquillart. 2007. A six degree-of-freedom god-object method for haptic display of rigid bodies with surface properties. IEEE Transactions on Visualization and Computer Graphics 13, 3(2007), 458\u2013469. https://doi.org/10.1109/TVCG.2007.1028",
      "doi": "10.1109/TVCG.2007.1028"
    },
    {
      "text": "Roshan\u00a0Lalintha Peiris, Wei Peng, Zikun Chen, Liwei Chan, and Kouta Minamizawa. 2017. ThermoVR: Exploring integrated thermal haptic feedback with head mounted displays. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 5452\u20135456. https://doi.org/10.1145/3025453.3025824",
      "doi": "10.1145/3025453.3025824"
    },
    {
      "text": "Nimesha Ranasinghe, Pravar Jain, Nguyen Thi Ngoc\u00a0Tram, Koon Chuan\u00a0Raymond Koh, David Tolley, Shienny Karwita, Lin Lien-Ya, Yan Liangkun, Kala Shamaiah, Chow Eason Wai\u00a0Tung, Ching\u00a0Chiuan Yen, and Ellen Yi-Luen Do. 2018. Season Traveller: Multisensory narration for enhancing the virtual reality experience. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, Article 577, 13\u00a0pages. https://doi.org/10.1145/3173574.3174151 577.",
      "doi": "10.1145/3173574.3174151"
    },
    {
      "text": "Eduardo\u00a0C. Rodrigues, Estevao\u00a0B. Saleme, and Celso A.\u00a0S. Santos. 2021. A haptic system for switching wind temperatures based on ultrasonic vibrations, peltier elements, and electrical resistances for multisensory applications. In Proceedings of the Brazilian Symposium on Multimedia and the Web. ACM, 73\u201380. https://doi.org/10.1145/3470482.3479638",
      "doi": "10.1145/3470482.3479638"
    },
    {
      "text": "Diego\u00a0C. Ruspini, Krasimir Kolarov, and Oussama Khatib. 1997. The haptic display of complex graphical environments. In Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques. ACM, 345\u2013352. https://doi.org/10.1145/258734.258878",
      "doi": "10.1145/258734.258878"
    },
    {
      "text": "Celso A.\u00a0Saibel Santos, Almerindo N.\u00a0Rehem Neto, and Estevao\u00a0B. Saleme. 2015. An event-driven approach for integrating multi-sensory effects to interactive environments. In 2015 IEEE International Conference on Systems, Man, and Cybernetics. IEEE, 981\u2013986. https://doi.org/10.1109/SMC.2015.178",
      "doi": "10.1109/SMC.2015.178"
    },
    {
      "text": "Jo\u00e3o D.\u00a0P. Sardo, Jo\u00e3o A.\u00a0R. Pereira, Ricardo J.\u00a0M. Veiga, Jorge Semi\u00e3o, Pedro J.\u00a0S. Cardoso, and Jo\u00e3o M.\u00a0F. Rodrigues. 2018. Multisensorial portable device for augmented reality experiences in museums. International Journal of Education and Learning Systems 3 (2018), 60\u201369.",
      "doi": ""
    },
    {
      "text": "Jo\u00e3o D.\u00a0P. Sardo, Jo\u00e3o D.\u00a0P. Pereira, Ricardo J.\u00a0M. Veiga, Jorge Semi\u00e3o, Pedro J.\u00a0S. Cardoso, and Jo\u00e3o M.\u00a0F. Rodrigues. 2018. A portable device for five sense augmented reality experiences in museums. WSEAS Transactions on Environment and Development 14 (2018), 347\u2013362.",
      "doi": ""
    },
    {
      "text": "Hasti Seifi, Kailun Zhang, and Karon\u00a0E. MacLean. 2015. VibViz: Organizing, visualizing and navigating vibration libraries. In Proceedings of the IEEE World Haptics Conference. IEEE, 254\u2013259. https://doi.org/10.1109/whc.2015.7177722",
      "doi": ""
    },
    {
      "text": "Jongman Seo, Sunung Mun, Jaebong Lee, and Seungmoon Choi. 2018. Substituting motion effects with vibrotactile effects for 4D experiences. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, Article 428, 6\u00a0pages. https://doi.org/10.1145/3173574.3174002",
      "doi": "10.1145/3173574.3174002"
    },
    {
      "text": "Koichi Shimizu, Vibol Yem, Kentaro Yamaoka, Gaku Sueta, Tomohiro Amemiya, Michiteru Kitazaki, and Yasushi Ikei. 2019. Rendering of virtual walking sensation by a vestibular display. In Human Interface and the Management of Information. Information in Intelligent Systems, Vol.\u00a011570. Springer, 36\u201346. https://doi.org/10.1007/978-3-030-22649-7_4",
      "doi": ""
    },
    {
      "text": "Suchul Shin, Byounghyun Yoo, and Soonhung Han. 2014. A framework for automatic creation of motion effects from theatrical motion pictures. Multimedia Systems 20, 3 (2014), 327\u2013346. https://doi.org/10.1007/s00530-013-0322-4",
      "doi": "10.1007/s00530-013-0322-4"
    },
    {
      "text": "Thomhert\u00a0S. Siadari, Mikyong Han, and Hyunjin Yoon. 2017. 4D effect video classification with shot-aware frame selection and deep neural networks. In 2017 IEEE International Conference on Computer Vision Workshops. IEEE, 1148\u20131155. https://doi.org/10.1109/ICCVW.2017.139",
      "doi": ""
    },
    {
      "text": "Misha Sra, Abhinandan Jain, and Pattie Maes. 2019. Adding proprioceptive feedback to virtual reality experiences using galvanic vestibular stimulation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 14\u00a0pages. https://doi.org/10.1145/3290605.3300905 675.",
      "doi": "10.1145/3290605.3300905"
    },
    {
      "text": "Anne\u00a0M Treisman and Garry Gelade. 1980. A feature-integration theory of attention. Cognitive psychology 12, 1 (1980), 97\u2013136.",
      "doi": ""
    },
    {
      "text": "VIVE. 2022. VR headsets, games, and metaverse life: United States. https://www.vive.com/us/",
      "doi": ""
    },
    {
      "text": "Markus Waltl, Benjamin Rainer, Christian Timmerer, and Hermann Hellwagner. 2013. An end-to-end tool chain for sensory experience based on MPEG-V. Signal Processing: Image Communication 28, 2 (2013), 136\u2013150. https://doi.org/10.1016/j.image.2012.10.009",
      "doi": "10.1016/j.image.2012.10.009"
    },
    {
      "text": "Chi Wang, Da-Yuan Huang, Shuo-wen Hsu, Chu-En Hou, Yeu-Luen Chiu, Ruei-Che Chang, Jo-Yu Lo, and Bing-Yu Chen. 2019. Masque: Exploring lateral skin stretch feedback on the face with head-mounted displays. In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology. ACM, 439\u2013451. https://doi.org/10.1145/3332165.3347898",
      "doi": "10.1145/3332165.3347898"
    },
    {
      "text": "Wikipedia contributors. 2022. 4D Film \u2014 Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/4D_film [Online; accessed 1-September-2022].",
      "doi": ""
    },
    {
      "text": "Wikipedia contributors. 2022. Sensorama \u2014 Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/Sensorama [Online; accessed 1-September-2022].",
      "doi": ""
    },
    {
      "text": "Wikipedia contributors. 2022. Sim racing \u2014 Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/Sim_racing [Online; accessed 1-September-2022].",
      "doi": ""
    },
    {
      "text": "Jikuang Yang, Per L\u00f6vsund, Claude Cavallero, and Jean Bonnoit. 2000. A human-body 3D mathematical model for simulation of car-pedestrian impacts. Traffic Injury Prevention 2, 2 (2000), 131\u2013149. https://doi.org/10.1080/10286580008902559",
      "doi": ""
    },
    {
      "text": "Byounghyun Yoo, Moohyun Cha, and Soonhung Han. 2005. A framework for a multi-sensory VR effect system with motional display. In 2005 International Conference on Cyberworlds. IEEE, 237\u2013244. https://doi.org/10.1109/CW.2005.5",
      "doi": "10.1109/CW.2005.5"
    },
    {
      "text": "Gyeore Yun, Hyoseung Lee, Sangyoon Han, and Seungmoon Choi. 2021. Improving viewing experiences of first-person shooter gameplays with automatically-generated motion effects. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. ACM, Article 320, 14\u00a0pages. https://doi.org/10.1145/3411764.3445358",
      "doi": "10.1145/3411764.3445358"
    },
    {
      "text": "Dingwen Zhang, Huazhu Fu, Junwei Han, Ali Borji, and Xuelong Li. 2018. A review of co-saliency detection algorithms: Fundamentals, applications, and challenges. ACM Transactions on Intelligent Systems and Technology 9, 4, Article 38 (2018), 31\u00a0pages. https://doi.org/10.1145/3158674",
      "doi": "10.1145/3158674"
    },
    {
      "text": "Guangxin Zhao, Zhaobo Wang, Xiaoming Chen, Zhicheng Lu, Yuk\u00a0Ying Chung, and Li Haisheng. 2022. Video2Force: Experiencing object motion in video with dynamic force feedback based on bio-inspired sensing and processing. In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops. IEEE, 858\u2013859. https://doi.org/10.1109/VRW55335.2022.00280",
      "doi": ""
    },
    {
      "text": "Yuhao Zhoul, Makarand Tapaswi, and Sanja Fidler. 2018. Now You Shake Me: Towards automatic 4D cinema. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE, 7425\u20137434. https://doi.org/10.1109/CVPR.2018.00775",
      "doi": ""
    },
    {
      "text": "Silvia Zuffi, Angjoo Kanazawa, and Michael\u00a0J. Black. 2018. Lions and tigers and bears: Capturing non-rigid, 3D, articulated shape from images. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, 3955\u20133963. https://doi.org/10.1109/CVPR.2018.00416",
      "doi": ""
    }
  ]
}