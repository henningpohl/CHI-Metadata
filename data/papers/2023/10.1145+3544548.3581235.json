{
  "doi": "10.1145/3544548.3581235",
  "title": "ExpresSense: Exploring a Standalone Smartphone to Sense Engagement of Users from Facial Expressions Using Acoustic Sensing",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-18",
  "year": 2023,
  "badges": [],
  "abstract": "Facial expressions have been considered a metric reflecting a person\u2019s engagement with a task. While the evolution of expression detection methods is consequential, the foundation remains mostly on image processing techniques that suffer from occlusion, ambient light, and privacy concerns. In this paper, we propose ExpresSense, a lightweight application for standalone smartphones that relies on near-ultrasound acoustic signals for detecting users\u2019 facial expressions. ExpresSense has been tested on different users in lab-scaled and large-scale studies for both posed as well as natural expressions. By achieving a classification accuracy of over various basic expressions, we discuss the potential of a standalone smartphone to sense expressions through acoustic sensing.",
  "tags": [
    "smartphone",
    "Acoustic sensing",
    "assistive system",
    "engagement",
    "expressions"
  ],
  "authors": [
    {
      "name": "Pragma Kar",
      "institution": "Information Technology, Jadavpur University, India",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659096430",
      "orcid": "0000-0003-3366-0171"
    },
    {
      "name": "Shyamvanshikumar Singh",
      "institution": "Electronics and Electrical Comm. Engg., IIT Kharagpur, India",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660782428",
      "orcid": "0000-0003-0314-2103"
    },
    {
      "name": "Avijit Mandal",
      "institution": "Computer Science and Engineering, IIT Kharagpur, India",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660778496",
      "orcid": "0000-0001-7504-3556"
    },
    {
      "name": "Samiran Chattopadhyay",
      "institution": "Information Technology, Jadavpur University, India and Institute for Advancing Intelligence, TCG CREST, India",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100090601",
      "orcid": "0000-0002-8929-9605"
    },
    {
      "name": "Sandip Chakraborty",
      "institution": "CSE, IIT Kharagpur, India",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81490677640",
      "orcid": "0000-0003-3531-968X"
    }
  ],
  "references": [
    {
      "text": "Rebecca Adaimi, Howard Yong, and Edison Thomaz. 2021. Ok Google, What Am I Doing? Acoustic Activity Recognition Bounded by Conversational Assistant Interactions. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 1, Article 2 (mar 2021), 24\u00a0pages. https://doi.org/10.1145/3448090",
      "doi": "10.1145/3448090"
    },
    {
      "text": "Leandro\u00a0M Almeida, Diego P\u00a0da Silva, Daieny\u00a0P Theod\u00f3rio, Wolley\u00a0W Silva, Silvia Cristina\u00a0M Rodrigues, Terigi\u00a0A Scardovelli, Alessandro P\u00a0da Silva, and Marcia Aparecida\u00a0S Bissaco. 2019. ALTRIRAS: A computer game for training children with autism spectrum disorder in the recognition of basic emotions. International Journal of Computer Games Technology 2019 (2019), 1\u201316.",
      "doi": "10.1155/2019/4384896"
    },
    {
      "text": "Xianye Ben, Yi Ren, Junping Zhang, Su-Jing Wang, Kidiyo Kpalma, Weixiao Meng, and Yong-Jin Liu. 2022. Video-Based Facial Micro-Expression Analysis: A Survey of Datasets, Features and Algorithms. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 9(2022), 5826\u20135846. https://doi.org/10.1109/TPAMI.2021.3067464",
      "doi": ""
    },
    {
      "text": "Nigel Bosch, Sidney\u00a0K D\u2019mello, Jaclyn Ocumpaugh, Ryan\u00a0S Baker, and Valerie Shute. 2016. Using video to automatically detect learner affect in computer-enabled classrooms. ACM Transactions on Interactive Intelligent Systems (TiiS) 6, 2(2016), 1\u201326.",
      "doi": "10.1145/2946837"
    },
    {
      "text": "John Brooke 1996. SUS-A quick and dirty usability scale. Usability evaluation in industry 189, 194 (1996), 4\u20137.",
      "doi": ""
    },
    {
      "text": "Chao Cai, Zhe Chen, Henglin Pu, Liyuan Ye, Menglan Hu, and Jun Luo. 2020. AcuTe: Acoustic Thermometer Empowered by a Single Smartphone. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys \u201920). Association for Computing Machinery, New York, NY, USA, 28\u201341. https://doi.org/10.1145/3384419.3430714",
      "doi": "10.1145/3384419.3430714"
    },
    {
      "text": "Chao Cai, Henglin Pu, Peng Wang, Zhe Chen, and Jun Luo. 2021. We Hear Your PACE: Passive Acoustic Localization of Multiple Walking Persons. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 2 (2021), 1\u201324.",
      "doi": "10.1145/3479554"
    },
    {
      "text": "Gaoshuai Cao, Kuang Yuan, Jie Xiong, Panlong Yang, Yubo Yan, Hao Zhou, and Xiang-Yang Li. 2020. EarphoneTrack: Involving Earphones into the Ecosystem of Acoustic Motion Tracking. Association for Computing Machinery, New York, NY, USA, 95\u2013108. https://doi.org/10.1145/3384419.3430730",
      "doi": "10.1145/3384419.3430730"
    },
    {
      "text": "Mengqi Chen, Jiawei Lin, Yongpan Zou, Rukhsana Ruby, and Kaishun Wu. 2020. SilentSign: Device-free Handwritten Signature Verification through Acoustic Sensing. In 2020 IEEE International Conference on Pervasive Computing and Communications (PerCom). IEEE Computer Society, Los Alamitos, CA, USA, 1\u201310. https://doi.org/10.1109/PerCom45495.2020.9127372",
      "doi": ""
    },
    {
      "text": "Yongliang Chen, Tao Ni, Weitao Xu, and Tao Gu. 2022. SwipePass: Acoustic-Based Second-Factor User Authentication for Smartphones. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 6, 3, Article 106 (sep 2022), 25\u00a0pages. https://doi.org/10.1145/3550292",
      "doi": "10.1145/3550292"
    },
    {
      "text": "Yen-Liang Chen, Chia-Ling Chang, and Chin-Sheng Yeh. 2017. Emotion classification of YouTube videos. Decision Support Systems 101 (2017), 40\u201350.",
      "doi": "10.1016/j.dss.2017.05.014"
    },
    {
      "text": "Abhilash Dubbaka and Anandha Gopalan. 2020. Detecting Learner Engagement in MOOCs using Automatic Facial Expression Recognition. In 2020 IEEE Global Engineering Education Conference (EDUCON). IEEE, USA, 447\u2013456. https://doi.org/10.1109/EDUCON45650.2020.9125149",
      "doi": ""
    },
    {
      "text": "Yang Gao, Yincheng Jin, Seokmin Choi, Jiyang Li, Junjie Pan, Lin Shu, Chi Zhou, and Zhanpeng Jin. 2021. SonicFace: Tracking Facial Expressions Using a Commodity Microphone Array. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 4 (2021), 1\u201333.",
      "doi": "10.1145/3494988"
    },
    {
      "text": "Yang Gao, Yincheng Jin, Jiyang Li, Seokmin Choi, and Zhanpeng Jin. 2020. EchoWhisper: Exploring an Acoustic-Based Silent Speech Interface for Smartphone Users. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 3, Article 80 (sep 2020), 27\u00a0pages. https://doi.org/10.1145/3411830",
      "doi": "10.1145/3411830"
    },
    {
      "text": "Nakul Garg, Yang Bai, and Nirupam Roy. 2021. Owlet: Enabling Spatial Information in Ubiquitous Acoustic Devices. In Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services (Virtual Event, Wisconsin) (MobiSys \u201921). Association for Computing Machinery, New York, NY, USA, 255\u2013268. https://doi.org/10.1145/3458864.3467880",
      "doi": "10.1145/3458864.3467880"
    },
    {
      "text": "Peter Gerstoft, Yihan Hu, Michael\u00a0J. Bianco, Chaitanya Patil, Ardel Alegre, Yoav Freund, and Fran\u00e7ois Grondin. 2022. Audio Scene Monitoring Using Redundant Ad Hoc Microphone Array Networks. IEEE Internet of Things Journal 9, 6 (2022), 4259\u20134268. https://doi.org/10.1109/JIOT.2021.3103523",
      "doi": ""
    },
    {
      "text": "Mariah\u00a0T Hawes, Aline\u00a0K Szenczy, Daniel\u00a0N Klein, Greg Hajcak, and Brady\u00a0D Nelson. 2022. Increases in depression and anxiety symptoms in adolescents and young adults during the COVID-19 pandemic. Psychological medicine 52, 14 (2022), 3222\u20133230.",
      "doi": ""
    },
    {
      "text": "Yasha Iravantchi, Mayank Goel, and Chris Harrison. 2019. BeamBand: Hand Gesture Sensing with Ultrasonic Beamforming. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI \u201919). Association for Computing Machinery, New York, NY, USA, 1\u201310. https://doi.org/10.1145/3290605.3300245",
      "doi": "10.1145/3290605.3300245"
    },
    {
      "text": "Bashima Islam, Md\u00a0Mahbubur Rahman, Tousif Ahmed, Mohsin\u00a0Yusuf Ahmed, Md\u00a0Mehedi Hasan, Viswam Nathan, Korosh Vatanparvar, Ebrahim Nemati, Jilong Kuang, and Jun\u00a0Alex Gao. 2021. BreathTrack: Detecting Regular Breathing Phases from Unannotated Acoustic Data Captured by a Smartphone. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 3, Article 124 (sep 2021), 22\u00a0pages. https://doi.org/10.1145/3478123",
      "doi": "10.1145/3478123"
    },
    {
      "text": "Kaito Isobe and Kazuya Murao. 2021. Person-Identification Methodusing Active Acoustic Sensing Applied to Nose. In 2021 International Symposium on Wearable Computers (Virtual, USA) (ISWC \u201921). Association for Computing Machinery, New York, NY, USA, 138\u2013140. https://doi.org/10.1145/3460421.3480425",
      "doi": "10.1145/3460421.3480425"
    },
    {
      "text": "Kenichi Ito, Chew\u00a0Wei Ong, and Ryo Kitada. 2019. Emotional tears communicate sadness but not excessive emotions without other contextual knowledge. Frontiers in Psychology 10 (2019), 878.",
      "doi": ""
    },
    {
      "text": "Rachael\u00a0E Jack, Wei Sun, Ioannis Delis, Oliver\u00a0GB Garrod, and Philippe\u00a0G Schyns. 2016. Four not six: Revealing culturally common facial expressions of emotion.Journal of Experimental Psychology: General 145, 6 (2016), 708.",
      "doi": ""
    },
    {
      "text": "Wenqiang Jin, Srinivasan Murali, Youngtak Cho, Huadi Zhu, Tianhao Li, Rachael\u00a0Thompson Panik, Anika Rimu, Shuchisnigdha Deb, Kari Watkins, Xu Yuan, and Ming Li. 2022. CycleGuard: A Smartphone-Based Assistive Tool for Cyclist Safety Using Acoustic Ranging. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 4, Article 163 (dec 2022), 30\u00a0pages. https://doi.org/10.1145/3494992",
      "doi": "10.1145/3494992"
    },
    {
      "text": "Yincheng Jin, Yang Gao, Yanjun Zhu, Wei Wang, Jiyang Li, Seokmin Choi, Zhangyu Li, Jagmohan Chauhan, Anind\u00a0K Dey, and Zhanpeng Jin. 2021. Sonicasl: An acoustic-based sign language gesture recognizer using earphones. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 2 (2021), 1\u201330.",
      "doi": "10.1145/3463519"
    },
    {
      "text": "Mathias Johansson. 1999. The hilbert transform. Mathematics Master\u2019s Thesis. V\u00e4xj\u00f6 University, Suecia. Disponible en internet: http://w3. msi. vxu. se/exarb/mj_ex. pdf, consultado el 19(1999).",
      "doi": ""
    },
    {
      "text": "Hideo Joho, Jacopo Staiano, Nicu Sebe, and Joemon\u00a0M Jose. 2011. Looking at the viewer: analysing facial activity to detect personal highlights of multimedia contents. Multimedia Tools and Applications 51, 2 (2011), 505\u2013523.",
      "doi": "10.1007/s11042-010-0632-x"
    },
    {
      "text": "Pragma Kar, Samiran Chattopadhyay, and Sandip Chakraborty. 2022. Bifurcating Cognitive Attention from Visual Concentration: Utilizing Cooperative Audiovisual Sensing for Demarcating Inattentive Online Meeting Participants. Proc. ACM Hum.-Comput. Interact. 6, CSCW2, Article 498 (nov 2022), 34\u00a0pages. https://doi.org/10.1145/3555656",
      "doi": "10.1145/3555656"
    },
    {
      "text": "M. Ko, J. Li, and C. Lee. 2019. Learning Minimal Intra-Genre Multimodal Embedding from Trailer Content and Reactor Expressions for Box Office Prediction. In 2019 IEEE International Conference on Multimedia and Expo (ICME). IEEE Computer Society, Los Alamitos, CA, USA, 1804\u20131809. https://doi.org/10.1109/ICME.2019.00310",
      "doi": ""
    },
    {
      "text": "Chenqi Kong, Kexin Zheng, Shiqi Wang, Anderson Rocha, and Haoliang Li. 2022. Beyond the Pixel World: A Novel Acoustic-Based Face Anti-Spoofing System for Smartphones. IEEE Transactions on Information Forensics and Security 17 (2022), 3238\u20133253. https://doi.org/10.1109/TIFS.2022.3202115",
      "doi": ""
    },
    {
      "text": "Chei\u00a0Sian Lee. 2012. Exploring emotional expressions on YouTube through the lens of media system dependency theory. New media & society 14, 3 (2012), 457\u2013475.",
      "doi": ""
    },
    {
      "text": "Eun Lee, Jee\u00a0In Kang, Il\u00a0Ho Park, Jae-Jin Kim, and Suk\u00a0Kyoon An. 2008. Is a neutral face really evaluated as being emotionally neutral?Psychiatry research 157, 1-3 (2008), 77\u201385.",
      "doi": ""
    },
    {
      "text": "Dong Li, Jialin Liu, Sunghoon\u00a0Ivan Lee, and Jie Xiong. 2020. FM-Track: Pushing the Limits of Contactless Multi-Target Tracking Using Acoustic Signals. Association for Computing Machinery, New York, NY, USA, 150\u2013163. https://doi.org/10.1145/3384419.3430780",
      "doi": "10.1145/3384419.3430780"
    },
    {
      "text": "Ke Li, Ruidong Zhang, Bo Liang, Fran\u00e7ois Guimbreti\u00e8re, and Cheng Zhang. 2022. EarIO: A low-power acoustic sensing earable for continuously tracking detailed facial movements. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 6, 2 (2022), 1\u201324.",
      "doi": "10.1145/3555195"
    },
    {
      "text": "Ke Li, Ruidong Zhang, Bo Liang, Fran\u00e7ois Guimbreti\u00e8re, and Cheng Zhang. 2022. EarIO: A Low-Power Acoustic Sensing Earable for Continuously Tracking Detailed Facial Movements. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 6, 2, Article 62 (jul 2022), 24\u00a0pages. https://doi.org/10.1145/3534621",
      "doi": "10.1145/3534621"
    },
    {
      "text": "Jie Lian, Jiadong Lou, Li Chen, and Xu Yuan. 2021. EchoSpot: Spotting Your Locations via Acoustic Sensing. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 3 (2021), 1\u201321.",
      "doi": "10.1145/3478094"
    },
    {
      "text": "Jie Lian, Xu Yuan, Ming Li, and Nian-Feng Tzeng. 2021. Fall Detection via Inaudible Acoustic Sensing. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 3 (2021), 1\u201321.",
      "doi": "10.1145/3478095"
    },
    {
      "text": "Rebecca Lietz, Meaghan Harraghy, Diane Calderon, James Brady, Eric Becker, and Fillia Makedon. 2019. Survey of Mood Detection through Various Input Modes. In Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments (Rhodes, Greece) (PETRA \u201919). Association for Computing Machinery, New York, NY, USA, 28\u201331. https://doi.org/10.1145/3316782.3321543",
      "doi": "10.1145/3316782.3321543"
    },
    {
      "text": "Christine\u00a0L Lisetti and Diane\u00a0J Schiano. 2000. Automatic facial expression interpretation: Where human-computer interaction, artificial intelligence and cognitive science intersect. Pragmatics & cognition 8, 1 (2000), 185\u2013235.",
      "doi": ""
    },
    {
      "text": "Jialin Liu, Dong Li, Lei Wang, and Jie Xiong. 2021. BlinkListener: \"Listen\" to Your Eye Blink Using Your Smartphone. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 2, Article 73 (jun 2021), 27\u00a0pages. https://doi.org/10.1145/3463521",
      "doi": "10.1145/3463521"
    },
    {
      "text": "Yu Miao, Haiwei Dong, Jihad Mohamad\u00a0Al Jaam, and Abdulmotaleb\u00a0El Saddik. 2019. A deep learning system for recognizing facial expression in real-time. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) 15, 2 (2019), 1\u201320.",
      "doi": "10.1145/3311747"
    },
    {
      "text": "Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern recognition. IEEE, USA, 4510\u20134520.",
      "doi": ""
    },
    {
      "text": "Phakhawat Sarakit, Thanaruk Theeramunkong, Choochart Haruechaiyasak, and Manabu Okumura. 2015. Classifying emotion in Thai youtube comments. In 2015 6th International Conference of Information and Communication Technology for Embedded Systems (IC-ICTES). IEEE, USA, 1\u20135.",
      "doi": ""
    },
    {
      "text": "Julio Savigny and Ayu Purwarianti. 2017. Emotion classification on youtube comments using word embedding. In 2017 international conference on advanced informatics, concepts, theory, and applications (ICAICTA). IEEE, USA, 1\u20135.",
      "doi": ""
    },
    {
      "text": "Rijurekha Sen, Pankaj Siriah, and Bhaskaran Raman. 2011. Roadsoundsense: Acoustic sensing based road congestion monitoring in developing regions. In 2011 8th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks. IEEE, USA, 125\u2013133.",
      "doi": ""
    },
    {
      "text": "Kshitij Sharma, Evangelos Niforatos, Michail Giannakos, and Vassilis Kostakos. 2020. Assessing cognitive performance using physiological and facial features: Generalizing across contexts. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 3 (2020), 1\u201341.",
      "doi": "10.1145/3411811"
    },
    {
      "text": "Xingzhe Song, Kai Huang, and Wei Gao. 2022. FaceListener: Recognizing Human Facial Expressions via Acoustic Sensing on Commodity Headphones. In 2022 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN). IEEE, USA, 145\u2013157. https://doi.org/10.1109/IPSN54338.2022.00019",
      "doi": ""
    },
    {
      "text": "Xingzhe Song, Boyuan Yang, Ge Yang, Ruirong Chen, Erick Forno, Wei Chen, and Wei Gao. 2020. SpiroSonic: Monitoring Human Lung Function via Acoustic Sensing on Commodity Smartphones. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking (London, United Kingdom) (MobiCom \u201920). Association for Computing Machinery, New York, NY, USA, Article 52, 14\u00a0pages. https://doi.org/10.1145/3372224.3419209",
      "doi": "10.1145/3372224.3419209"
    },
    {
      "text": "Haoran Wan, Shuyu Shi, Wenyu Cao, Wei Wang, and Guihai Chen. 2021. RespTracker: Multi-User Room-Scale Respiration Tracking with Commercial Acoustic Devices. In IEEE INFOCOM 2021 - IEEE Conference on Computer Communications (Vancouver, BC, Canada). IEEE Press, USA, 1\u201310. https://doi.org/10.1109/INFOCOM42981.2021.9488881",
      "doi": "10.1109/INFOCOM42981.2021.9488881"
    },
    {
      "text": "Meng Wang and Yuecheng Shao. 2010. The Google Challenge: Video Genre Classification. Citeseer.",
      "doi": ""
    },
    {
      "text": "Weiguo Wang, Jinming Li, Yuan He, and Yunhao Liu. 2020. Symphony: Localizing Multiple Acoustic Sources with a Single Microphone Array. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (Virtual Event, Japan) (SenSys \u201920). Association for Computing Machinery, New York, NY, USA, 82\u201394. https://doi.org/10.1145/3384419.3430724",
      "doi": "10.1145/3384419.3430724"
    },
    {
      "text": "Yajie Wang, Song Zhao, Zhijie Zhang, and Wenfeng Feng. 2018. Sad Facial Expressions Increase Choice Blindness. Frontiers in Psychology 8 (2018), 2300.",
      "doi": ""
    },
    {
      "text": "Wentao Xie, Qian Zhang, and Jin Zhang. 2021. Acoustic-Based Upper Facial Action Recognition for Smart Eyewear. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 2, Article 41 (jun 2021), 28\u00a0pages. https://doi.org/10.1145/3448105",
      "doi": "10.1145/3448105"
    },
    {
      "text": "Qian Zhang, Dong Wang, Run Zhao, Yinggang Yu, and Junjie Shen. 2021. Sensing to hear: Speech enhancement for mobile devices using acoustic signals. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 3 (2021), 1\u201330.",
      "doi": "10.1145/3449235"
    },
    {
      "text": "Zengqun Zhao, Qingshan Liu, and Feng Zhou. 2021. Robust Lightweight Facial Expression Recognition Network with Label Distribution Training. Proceedings of the AAAI Conference on Artificial Intelligence 35, 4 (May 2021), 3510\u20133519. https://doi.org/10.1609/aaai.v35i4.16465",
      "doi": ""
    },
    {
      "text": "Yuan Zong, Wenming Zheng, Xiaopeng Hong, Chuangao Tang, Zhen Cui, and Guoying Zhao. 2019. Cross-Database Micro-Expression Recognition: A Benchmark. In Proceedings of the 2019 on International Conference on Multimedia Retrieval (Ottawa ON, Canada) (ICMR \u201919). Association for Computing Machinery, New York, NY, USA, 354\u2013363. https://doi.org/10.1145/3323873.3326590",
      "doi": "10.1145/3323873.3326590"
    }
  ]
}