{
  "doi": "10.1145/3544548.3580672",
  "title": "Don\u2019t Just Tell Me, Ask Me: AI Systems that Intelligently Frame Explanations as Questions Improve Human Logical Discernment Accuracy over Causal AI explanations",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2023,
  "badges": [],
  "abstract": "Critical thinking is an essential human skill. Despite the importance of critical thinking, research reveals that our reasoning ability suffers from personal biases and cognitive resource limitations, leading to potentially dangerous outcomes. This paper presents the novel idea of AI-framed Questioning that turns information relevant to the AI classification into questions to actively engage users\u2019 thinking and scaffold their reasoning process. We conducted a study with 204 participants comparing the effects of AI-framed Questioning on a critical thinking task; discernment of logical validity of socially divisive statements. Our results show that compared to no feedback and even causal AI explanations of an always correct system, AI-framed Questioning significantly increase human discernment of logically flawed statements. Our experiment exemplifies a future style of Human-AI co-reasoning system, where the AI becomes a critical thinking stimulator rather than an information teller.",
  "tags": [
    "AI Explanation",
    "Explainable AI",
    "Human-AI Interaction",
    "Language Model",
    "Logic",
    "Reasoning",
    "AI"
  ],
  "authors": [
    {
      "name": "Valdemar Danry",
      "institution": "MIT Media Lab, Massachusetts Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659538820",
      "orcid": "0000-0001-5225-0077"
    },
    {
      "name": "Pat Pataranutaporn",
      "institution": "MIT Media Lab, Massachusetts Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659198696",
      "orcid": "0000-0002-1879-7340"
    },
    {
      "name": "Yaoli Mao",
      "institution": "Human Development, Columbia University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659487073",
      "orcid": "0000-0002-2059-3734"
    },
    {
      "name": "Pattie Maes",
      "institution": "MIT Media Lab, Massachusetts Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659319638",
      "orcid": "0000-0002-7722-6038"
    }
  ],
  "references": [
    {
      "text": "Tariq Alhindi, Savvas Petridis, and Smaranda Muresan. 2018. Where is your Evidence: Improving Fact-checking by Justification Modeling. In Proceedings of the First Workshop on Fact Extraction and VERification (FEVER). 85\u201390.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel Weld. 2021. Does the whole exceed its parts? the effect of ai explanations on complementary team performance. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3411764.3445717"
    },
    {
      "text": "John\u00a0A Bargh. 1994. The four horsemen of automaticity: Intention, awareness, efficiency, and control as separate issues. (1994).",
      "doi": ""
    },
    {
      "text": "Oscar Barrera, Sergei Guriev, Emeric Henry, and Ekaterina Zhuravskaya. 2020. Facts, alternative facts, and fact checking in times of post-truth politics. Journal of public economics 182 (2020), 104123.",
      "doi": ""
    },
    {
      "text": "Richard\u00a0E Boyatzis. 1998. Transforming qualitative information: Thematic analysis and code development. sage.",
      "doi": ""
    },
    {
      "text": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared\u00a0D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877\u20131901.",
      "doi": ""
    },
    {
      "text": "Zana Bu\u00e7inca, Maja\u00a0Barbara Malaya, and Krzysztof\u00a0Z Gajos. 2021. To trust or to think: cognitive forcing functions can reduce overreliance on AI in AI-assisted decision-making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201321.",
      "doi": "10.1145/3449287"
    },
    {
      "text": "Michelene\u00a0TH Chi, Nicholas De\u00a0Leeuw, Mei-Hung Chiu, and Christian LaVancher. 1994. Eliciting self-explanations improves understanding. Cognitive science 18, 3 (1994), 439\u2013477.",
      "doi": ""
    },
    {
      "text": "Roberto Confalonieri, Tarek\u00a0R Besold, Tillman Weyde, Kathleen Creel, Tania Lombrozo, Shane Mueller, and Patrick Shafto. 2019. What makes a good explanation? Cognitive dimensions of explaining intelligent machines. CogSci 2019: Creativity+ Cognition+ Computation (2019).",
      "doi": ""
    },
    {
      "text": "John\u00a0W Creswell and J\u00a0David Creswell. 2017. Research design: Qualitative, quantitative, and mixed methods approaches. Sage publications.",
      "doi": ""
    },
    {
      "text": "Valdemar Danry, Pat Pataranutaporn, Yaoli Mao, and Pattie Maes. 2020. Wearable Reasoner: towards enhanced human rationality through a wearable device with an explainable AI assistant. In Proceedings of the Augmented Humans International Conference. 1\u201312.",
      "doi": "10.1145/3384657.3384799"
    },
    {
      "text": "Ziv Epstein, Nicolo Foppiani, Sophie Hilgard, Sanjana Sharma, Elena Glassman, and David Rand. 2022. Do explanations increase the effectiveness of AI-crowd generated fake news warnings?. In Proceedings of the International AAAI Conference on Web and Social Media, Vol.\u00a016. 183\u2013193.",
      "doi": ""
    },
    {
      "text": "Shane Frederick. 2005. Cognitive reflection and decision making. Journal of Economic perspectives 19, 4 (2005), 25\u201342.",
      "doi": ""
    },
    {
      "text": "Artur\u00a0d\u2019Avila Garcez and Luis\u00a0C Lamb. 2020. Neurosymbolic AI: The 3rd Wave. arXiv preprint arXiv:2012.05876(2020).",
      "doi": ""
    },
    {
      "text": "Gerd Gigerenzer and Reinhard Selten. 2002. Bounded rationality: The adaptive toolbox. MIT press.",
      "doi": ""
    },
    {
      "text": "Edward\u00a0M Glaser. 1985. Educating for responsible citizenship in a democracy. In National Forum, Vol.\u00a065. Honor Society of Phi Kappa Phi, 24.",
      "doi": ""
    },
    {
      "text": "Matthew Groh, Ziv Epstein, Chaz Firestone, and Rosalind Picard. 2022. Deepfake detection by human crowds, machines, and machine-informed crowds. Proceedings of the National Academy of Sciences 119, 1 (2022), e2110013119.",
      "doi": ""
    },
    {
      "text": "Matthew Groh, Aruna Sankaranarayanan, and Rosalind Picard. 2022. Human detection of political deepfakes across transcripts, audio, and video. arXiv preprint arXiv:2202.12883(2022).",
      "doi": ""
    },
    {
      "text": "Ivan Habernal, Raffael Hannemann, Christian Pollak, Christopher Klamm, Patrick Pauli, and Iryna Gurevych. 2017. Argotario: Computational argumentation meets serious games. arXiv preprint arXiv:1707.06002(2017).",
      "doi": ""
    },
    {
      "text": "Jonathan Haidt. 2001. The emotional dog and its rational tail: a social intuitionist approach to moral judgment.Psychological review 108, 4 (2001), 814.",
      "doi": ""
    },
    {
      "text": "Steven\u00a0R Haynes, Mark\u00a0A Cohen, and Frank\u00a0E Ritter. 2009. Designs for explaining intelligent agents. International Journal of Human-Computer Studies 67, 1 (2009), 90\u2013110.",
      "doi": "10.1016/j.ijhcs.2008.09.008"
    },
    {
      "text": "Jonathan Howard. 2019. Hasty Generalization, Survival Bias, Special Pleading, and Burden of Proof. In Cognitive Errors and Diagnostic Mistakes. Springer, 211\u2013246.",
      "doi": ""
    },
    {
      "text": "Eyke H\u00fcllermeier. 2020. Towards analogy-based explanations in machine learning. In International Conference on Modeling Decisions for Artificial Intelligence. Springer, 205\u2013217.",
      "doi": "10.1007/978-3-030-57524-3_17"
    },
    {
      "text": "Daniel Kahneman. 2011. Thinking, fast and slow. Macmillan.",
      "doi": ""
    },
    {
      "text": "Daniel Kahneman, Stewart\u00a0Paul Slovic, Paul Slovic, and Amos Tversky. 1982. Judgment under uncertainty: Heuristics and biases. Cambridge university press.",
      "doi": ""
    },
    {
      "text": "Mark\u00a0T Keane and Barry Smyth. 2020. Good counterfactuals and where to find them: A case-based technique for generating counterfactuals for explainable ai (xai). In International Conference on Case-Based Reasoning. Springer, 163\u2013178.",
      "doi": "10.1007/978-3-030-58342-2_11"
    },
    {
      "text": "Emily\u00a0R Lai. 2011. Critical thinking: A literature review. Pearson\u2019s Research Reports 6, 1 (2011), 40\u201341.",
      "doi": ""
    },
    {
      "text": "Vivian Lai and Chenhao Tan. 2019. On human predictions with explanations and predictions of machine learning models: A case study on deception detection. In Proceedings of the conference on fairness, accountability, and transparency. 29\u201338.",
      "doi": "10.1145/3287560.3287590"
    },
    {
      "text": "Himabindu Lakkaraju and Osbert Bastani. 2020. \" How do I fool you?\" Manipulating User Trust via Misleading Black Box Explanations. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 79\u201385.",
      "doi": "10.1145/3375627.3375833"
    },
    {
      "text": "David\u00a0MJ Lazer, Matthew\u00a0A Baum, Yochai Benkler, Adam\u00a0J Berinsky, Kelly\u00a0M Greenhill, Filippo Menczer, Miriam\u00a0J Metzger, Brendan Nyhan, Gordon Pennycook, David Rothschild, Michael Schudson, Steven\u00a0A. Sloman, Cass\u00a0R. Sunstein, Emily\u00a0A. Thorson, Duncan\u00a0J. Watts, and Jonathan\u00a0L. Zittrain. 2018. The science of fake news. Science 359, 6380 (2018), 1094\u20131096.",
      "doi": ""
    },
    {
      "text": "Nguyen-Thinh Le and Laura Wartschinski. 2018. A cognitive assistant for improving human reasoning skills. International Journal of Human-Computer Studies 117 (2018), 45\u201354.",
      "doi": ""
    },
    {
      "text": "Jennifer\u00a0S Lerner and Philip\u00a0E Tetlock. 1999. Accounting for the effects of accountability.Psychological bulletin 125, 2 (1999), 255.",
      "doi": ""
    },
    {
      "text": "Q\u00a0Vera Liao, Daniel Gruen, and Sarah Miller. 2020. Questioning the AI: informing design practices for explainable AI user experiences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201315.",
      "doi": "10.1145/3313831.3376590"
    },
    {
      "text": "Matthew\u00a0D Lieberman. 2000. Intuition: a social cognitive neuroscience approach.Psychological bulletin 126, 1 (2000), 109.",
      "doi": ""
    },
    {
      "text": "Matthew\u00a0D Lieberman, Ruth Gaunt, Daniel\u00a0T Gilbert, and Yaacov Trope. 2002. Reflexion and reflection: a social cognitive neuroscience approach to attributional inference.(2002).",
      "doi": ""
    },
    {
      "text": "Tania Lombrozo. 2016. Explanatory preferences shape learning and inference. Trends in Cognitive Sciences 20, 10 (2016), 748\u2013759.",
      "doi": ""
    },
    {
      "text": "Zilin Ma and Krzysztof\u00a0Z Gajos. 2022. Not Just a Preference: Reducing Biased Decision-making on Dating Websites. In CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3491102.3517587"
    },
    {
      "text": "Prashan Madumal, Tim Miller, Frank Vetere, and Liz Sonenberg. 2018. Towards a grounded dialog model for explainable artificial intelligence. arXiv preprint arXiv:1806.08055(2018).",
      "doi": ""
    },
    {
      "text": "Scott\u00a0E Maxwell, Harold\u00a0D Delaney, and Ken Kelley. 2017. Designing experiments and analyzing data: A model comparison perspective. Routledge.",
      "doi": ""
    },
    {
      "text": "Roger\u00a0C Mayer, James\u00a0H Davis, and F\u00a0David Schoorman. 1995. An integrative model of organizational trust. Academy of management review 20, 3 (1995), 709\u2013734.",
      "doi": ""
    },
    {
      "text": "Mark McCaffrey, Paige Hayes, Jason Wagner, and Matt Hobbs. 2018. Consumer Intelligence Series: Prepare for the voice revolution. pwc. com (2018).",
      "doi": ""
    },
    {
      "text": "Divyam Mehta, Aniket Dwivedi, Arunabha Patra, and M Anand\u00a0Kumar. 2021. A transformer-based architecture for fake news classification. Social network analysis and mining 11, 1 (2021), 1\u201312.",
      "doi": ""
    },
    {
      "text": "Shane\u00a0T Mueller, Robert\u00a0R Hoffman, William Clancey, Abigail Emrey, and Gary Klein. 2019. Explanation in human-AI systems: A literature meta-review, synopsis of key ideas and publications, and bibliography for explainable AI. arXiv preprint arXiv:1902.01876(2019).",
      "doi": ""
    },
    {
      "text": "R Paul and L Elder. 2006. The art of socratic questioning. Dillon beach, CA: foundation for critical thinking. Psychology, Monograph Series II 3 (2006), 107\u2013127.",
      "doi": ""
    },
    {
      "text": "Richard Paul and Linda Elder. 2007. Critical thinking: The art of Socratic questioning. Journal of developmental education 31, 1 (2007), 36.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook, Ziv Epstein, Mohsen Mosleh, Antonio\u00a0A Arechar, Dean Eckles, and David\u00a0G Rand. 2021. Shifting attention to accuracy can reduce misinformation online. Nature 592, 7855 (2021), 590\u2013595.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook and David\u00a0G Rand. 2019. Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition 188(2019), 39\u201350.",
      "doi": ""
    },
    {
      "text": "Gordon Pennycook and David\u00a0G Rand. 2020. Who falls for fake news? The roles of bullshit receptivity, overclaiming, familiarity, and analytic thinking. Journal of personality 88, 2 (2020), 185\u2013200.",
      "doi": ""
    },
    {
      "text": "Ruty Rinott, Lena Dankin, Carlos Alzate\u00a0Perez, Mitesh\u00a0M. Khapra, Ehud Aharoni, and Noam Slonim. 2015. Show Me Your Evidence - an Automatic Method for Context Dependent Evidence Detection. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Lisbon, Portugal, 440\u2013450. https://doi.org/10.18653/v1/D15-1050",
      "doi": ""
    },
    {
      "text": "Herbert\u00a0A Simon. 1956. Rational choice and the structure of the environment.Psychological review 63, 2 (1956), 129.",
      "doi": ""
    },
    {
      "text": "Herbert\u00a0Alexander Simon. 1997. Models of bounded rationality: Empirically grounded economic reason. Vol.\u00a03. MIT press.",
      "doi": ""
    },
    {
      "text": "Dominik Stammbach and Elliott Ash. 2020. e-fever: Explanations and summaries for automated fact checking. Proceedings of the 2020 Truth and Trust Online (TTO 2020) (2020), 32\u201343.",
      "doi": ""
    },
    {
      "text": "Keith\u00a0E Stanovich and Richard\u00a0F West. 2008. On the failure of cognitive ability to predict myside and one-sided thinking biases. Thinking & Reasoning 14, 2 (2008), 129\u2013167.",
      "doi": ""
    },
    {
      "text": "Keith\u00a0E Stanovich, Richard\u00a0F West, and Maggie\u00a0E Toplak. 2016. The rationality quotient: Toward a test of rational thinking. MIT press.",
      "doi": ""
    },
    {
      "text": "Maggie\u00a0E Toplak, Richard\u00a0F West, and Keith\u00a0E Stanovich. 2014. Assessing miserly information processing: An expansion of the Cognitive Reflection Test. Thinking & Reasoning 20, 2 (2014), 147\u2013168.",
      "doi": ""
    },
    {
      "text": "Jay\u00a0J Van\u00a0Bavel and Andrea Pereira. 2018. The partisan brain: An Identity-based model of political belief. Trends in cognitive sciences 22, 3 (2018), 213\u2013224.",
      "doi": ""
    },
    {
      "text": "Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. science 359, 6380 (2018), 1146\u20131151.",
      "doi": ""
    },
    {
      "text": "Nathan Walter, Jonathan Cohen, R\u00a0Lance Holbert, and Yasmin Morag. 2020. Fact-checking: A meta-analysis of what works and for whom. Political Communication 37, 3 (2020), 350\u2013375.",
      "doi": ""
    },
    {
      "text": "Darrell\u00a0M West. 2018. The future of work: Robots, AI, and automation. Brookings Institution Press.",
      "doi": ""
    },
    {
      "text": "Joachim\u00a0S Wiewiura and Vincent\u00a0F Hendricks. 2018. Informational pathologies and interest bubbles: Exploring the structural mobilization of knowledge, ignorance, and slack. New Media & Society 20, 3 (2018), 1123\u20131138.",
      "doi": ""
    },
    {
      "text": "Cassandra Xia. 2014. A game-based intervention for the reduction of statistical cognitive biases. Ph.\u00a0D. Dissertation. Massachusetts Institute of Technology.",
      "doi": ""
    },
    {
      "text": "Yifan Xu. 2022. Dialogue Explanation With Reasoning for AI. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society. 918\u2013918.",
      "doi": "10.1145/3514094.3539522"
    },
    {
      "text": "Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. 2019. Defending against neural fake news. Advances in neural information processing systems 32 (2019).",
      "doi": ""
    },
    {
      "text": "Xia Zeng, Amani\u00a0S Abumansour, and Arkaitz Zubiaga. 2021. Automated fact-checking: A survey. Language and Linguistics Compass 15, 10 (2021), e12438.",
      "doi": ""
    },
    {
      "text": "Qiaoning Zhang, Matthew\u00a0L Lee, and Scott Carter. 2022. You Complete Me: Human-AI Teams and Complementary Expertise. In CHI Conference on Human Factors in Computing Systems. 1\u201328.",
      "doi": ""
    }
  ]
}