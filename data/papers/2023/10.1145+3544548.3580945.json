{
  "doi": "10.1145/3544548.3580945",
  "title": "Contextualizing User Perceptions about Biases for Human-Centered Explainable Artificial Intelligence",
  "published": "2023-04-19",
  "proctitle": "CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-15",
  "year": 2023,
  "badges": [],
  "abstract": "Biases in Artificial Intelligence (AI) systems or their results are one important issue that demands AI explainability. Despite the prevalence of AI applications, the general public are not necessarily equipped with the ability to understand how the black-box algorithms work and how to deal with biases. To inform designs for explainable AI (XAI), we conducted in-depth interviews with major stakeholders, both end-users (n = 24) and engineers (n = 15), to investigate how they made sense of AI applications and the associated biases according to situations of high and low stakes. We discussed users\u2019 perceptions and attributions about AI biases and their desired levels and types of explainability. We found that personal relevance and boundaries as well as the level of stake are two major dimensions for developing user trust especially during biased situations and informing XAI designs.",
  "tags": [
    "Artificial Intelligence",
    "Human-Computer Interaction (HCI)",
    "Transparency",
    "AI bias",
    "Explainable AI (XAI)",
    "Human-Centered Computing",
    "Explainability"
  ],
  "authors": [
    {
      "name": "Chien Wen (Tina) Yuan",
      "institution": "D-School, National Taiwan University, Taiwan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81553594456",
      "orcid": "0000-0003-0807-2714"
    },
    {
      "name": "Nanyi Bi",
      "institution": "Department of Information Management, National Taiwan University, Taiwan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81502641340",
      "orcid": "0000-0003-1530-4464"
    },
    {
      "name": "Ya-Fang Lin",
      "institution": "Collaboration & Innovation Lab, College of Information Science of Technology, Penn State University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660783490",
      "orcid": "0000-0003-3689-5910"
    },
    {
      "name": "Yuen-Hsien Tseng",
      "institution": "Graduate Institute of Library and Information Studies, National Taiwan Normal University, Taiwan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100582986",
      "orcid": "0000-0001-8904-7902"
    }
  ],
  "references": [
    {
      "text": "Samira Abbasgholizadeh\u00a0Rahimi, Michelle Cwintal, Yuhui Huang, Pooria Ghadiri, Roland Grad, Dan Poenaru, Genevieve Gore, Herv\u00e9 Tchala\u00a0Vignon Zomahoun, France L\u00e9gar\u00e9, and Pierre Pluye. 2022. Application of artificial intelligence in shared decision making: scoping review. JMIR Medical Informatics 10, 8 (2022), e36199.",
      "doi": ""
    },
    {
      "text": "Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian\u00a0Y Lim, and Mohan Kankanhalli. [n. d.]. Trends and trajectories for explainable, accountable and intelligible systems: An hci research agenda. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1\u201318.",
      "doi": ""
    },
    {
      "text": "Amina Adadi and Mohammed Berrada. 2018. Peeking inside the black-box: A survey on Explainable Artificial Intelligence (XAI). IEEE Access 6(2018), 52138\u201352160.",
      "doi": ""
    },
    {
      "text": "Chelsea Barabas, Madars Virza, Karthik Dinakar, Joichi Ito, and Jonathan Zittrain. 2018. Interventions over predictions: Reframing the ethical debate for actuarial risk assessment. In Conference on Fairness, Accountability and Transparency. PMLR, 62\u201376.",
      "doi": ""
    },
    {
      "text": "Andrea Brennen. 2020. What Do People Really Want When They Say They Want\" Explainable AI?\" We Asked 60 Stakeholders.. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u20137.",
      "doi": "10.1145/3334480.3383047"
    },
    {
      "text": "Francesco Camastra and Alessandro Vinciarelli. 2015. Machine learning for audio, image and video analysis: theory and applications. Springer.",
      "doi": ""
    },
    {
      "text": "Maartje\u00a0MA De\u00a0Graaf and Bertram\u00a0F Malle. 2017. How people explain action (and autonomous intelligent systems should too). In 2017 AAAI Fall Symposium Series.",
      "doi": ""
    },
    {
      "text": "Ashley Deeks. 2019. The Judicial Demand for Explainable Artificial Intelligence. Columbia Law Review 119, 7 (2019), 1829\u20131850.",
      "doi": ""
    },
    {
      "text": "Jonathan Dodge, Q\u00a0Vera Liao, Yunfeng Zhang, Rachel\u00a0KE Bellamy, and Casey Dugan. 2019. Explaining models: an empirical study of how explanations impact fairness judgment. In Proceedings of the 24th international conference on intelligent user interfaces. 275\u2013285.",
      "doi": "10.1145/3301275.3302310"
    },
    {
      "text": "John Fox, David Glasspool, Dan Grecu, Sanjay Modgil, Matthew South, and Vivek Patkar. 2007. Argumentation-based inference and decision making\u2013A medical perspective. IEEE intelligent systems 22, 6 (2007), 34\u201341.",
      "doi": "10.1109/MIS.2007.102"
    },
    {
      "text": "Batya Friedman. 1996. Value-sensitive design. interactions 3, 6 (1996), 16\u201323.",
      "doi": ""
    },
    {
      "text": "Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer\u00a0Wortman Vaughan, Hanna Wallach, Hal Daum\u00e9\u00a0III, and Kate Crawford. 2018. Datasheets for datasets. arXiv preprint arXiv:1803.09010(2018).",
      "doi": ""
    },
    {
      "text": "Katy\u00a0Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan, James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David\u00a0R Millen, Murray Campbell, 2020. Mental Models of AI Agents in a Cooperative Game Setting. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3313831.3376316"
    },
    {
      "text": "Riccardo Guidotti, Anna Monreale, Dino Pedreschi, and Fosca Giannotti. 2021. Principles of explainable artificial intelligence. In Explainable AI within the digital transformation and cyber physical systems. Springer, 9\u201331.",
      "doi": ""
    },
    {
      "text": "David Gunning. 2017. Explainable artificial intelligence (xai). Defense Advanced Research Projects Agency (DARPA), nd Web 2, 2(2017).",
      "doi": ""
    },
    {
      "text": "Jess Hohenstein and Malte Jung. 2020. AI as a moral crumple zone: The effects of AI-mediated communication on attribution and trust. Computers in Human Behavior 106 (2020), 106190.",
      "doi": "10.1016/j.chb.2019.106190"
    },
    {
      "text": "Anna Jobin, Marcello Ienca, and Effy Vayena. 2019. The global landscape of AI ethics guidelines. Nature Machine Intelligence 1, 9 (2019), 389\u2013399.",
      "doi": ""
    },
    {
      "text": "Fabrice Jotterand and Clara Bosco. 2020. Keeping the \u201chuman in the loop\u201d in the age of artificial intelligence. Science and Engineering Ethics 26, 5 (2020), 2455\u20132460.",
      "doi": ""
    },
    {
      "text": "Harold\u00a0H Kelley. 1967. Attribution theory in social psychology.. In Nebraska symposium on motivation. University of Nebraska Press.",
      "doi": ""
    },
    {
      "text": "Jean-Baptiste Lamy, Boomadevi Sekar, Gilles Guezennec, Jacques Bouaud, and Brigitte S\u00e9roussi. 2019. Explainable artificial intelligence for breast cancer: A visual case-based reasoning approach. Artificial Intelligence in Medicine 94 (2019), 42\u201353.",
      "doi": "10.1016/j.artmed.2019.01.001"
    },
    {
      "text": "Q\u00a0Vera Liao, Daniel Gruen, and Sarah Miller. 2020. Questioning the AI: informing design practices for explainable AI user experiences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201315.",
      "doi": "10.1145/3313831.3376590"
    },
    {
      "text": "Duri Long and Brian Magerko. 2020. What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3313831.3376727"
    },
    {
      "text": "Michael\u00a0A Madaio, Luke Stark, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2020. Co-designing checklists to understand organizational challenges and opportunities around fairness in ai. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3313831.3376445"
    },
    {
      "text": "Prashan Madumal, Tim Miller, Liz Sonenberg, and Frank Vetere. 2019. A grounded interaction protocol for explainable artificial intelligence. arXiv preprint arXiv:1903.02409(2019).",
      "doi": ""
    },
    {
      "text": "Sherin\u00a0Mary Mathews. 2019. Explainable artificial intelligence applications in NLP, biomedical, and malware classification: a literature review. In Intelligent Computing-Proceedings of the Computing Conference. Springer, 1269\u20131292.",
      "doi": ""
    },
    {
      "text": "Christian Meske, Enrico Bunde, Johannes Schneider, and Martin Gersch. 2022. Explainable artificial intelligence: objectives, stakeholders, and future research opportunities. Information Systems Management 39, 1 (2022), 53\u201363.",
      "doi": ""
    },
    {
      "text": "Tim Miller. 2019. \" But why?\" Understanding explainable artificial intelligence. XRDS: Crossroads, The ACM Magazine for Students 25, 3 (2019), 20\u201325.",
      "doi": "10.1145/3313107"
    },
    {
      "text": "Tim Miller. 2019. Explanation in artificial intelligence: Insights from the social sciences. Artificial intelligence 267 (2019), 1\u201338.",
      "doi": ""
    },
    {
      "text": "Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa\u00a0Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency. 220\u2013229.",
      "doi": "10.1145/3287560.3287596"
    },
    {
      "text": "Brent Mittelstadt. 2019. Principles alone cannot guarantee ethical AI. Nature Machine Intelligence 1, 11 (2019), 501\u2013507.",
      "doi": ""
    },
    {
      "text": "Joseph\u00a0Happy Okoh. 2022. 10 Impacts of Artificial Intelligence on Our Everyday Life.",
      "doi": ""
    },
    {
      "text": "Franziska Pilling, Haider\u00a0Ali Akmal, Joseph Lindley, Adrian Gradinar, and Paul Coulton. 2022. Making AI Infused Products and Services more Legible. Leonardo (Oct 2022), 1\u201311. https://doi.org/gq9nf8",
      "doi": ""
    },
    {
      "text": "Inioluwa\u00a0Deborah Raji, Peggy Xu, Colleen Honigsberg, and Daniel Ho. 2022. Outsider oversight: Designing a third party audit ecosystem for ai governance. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society. 557\u2013571.",
      "doi": "10.1145/3514094.3534181"
    },
    {
      "text": "Marco\u00a0Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \" Why should i trust you?\" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 1135\u20131144.",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Justus Robertson, Athanasios\u00a0Vasileios Kokkinakis, Jonathan Hook, Ben Kirman, Florian Block, Marian\u00a0F Ursu, Sagarika Patra, Simon Demediuk, Anders Drachen, and Oluseyi Olarewaju. 2021. Wait, but why?: assessing behavior explanation strategies for real-time strategy games. In 26th International Conference on Intelligent User Interfaces. 32\u201342.",
      "doi": "10.1145/3397481.3450699"
    },
    {
      "text": "Stuart Russell and Peter Norvig. 2002. Artificial intelligence: a modern approach. (2002).",
      "doi": ""
    },
    {
      "text": "Wojciech Samek, Thomas Wiegand, and Klaus-Robert M\u00fcller. 2017. Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models. arXiv preprint arXiv:1708.08296(2017).",
      "doi": ""
    },
    {
      "text": "Andrew\u00a0D Selbst, Danah Boyd, Sorelle\u00a0A Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and abstraction in sociotechnical systems. In Proceedings of the conference on fairness, accountability, and transparency. 59\u201368.",
      "doi": "10.1145/3287560.3287598"
    },
    {
      "text": "Kacper Sokol. 2019. Fairness, accountability and transparency in artificial intelligence: A case study of logical predictive models. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 541\u2013542.",
      "doi": "10.1145/3306618.3314316"
    },
    {
      "text": "Harini Suresh and John\u00a0V Guttag. 2019. A framework for understanding unintended consequences of machine learning. arXiv preprint arXiv:1901.10002(2019).",
      "doi": ""
    },
    {
      "text": "Maxwell Szymanski, Martijn Millecamp, and Katrien Verbert. 2021. Visual, textual or hybrid: the effect of user expertise on different explanations. In 26th International Conference on Intelligent User Interfaces. 109\u2013119.",
      "doi": "10.1145/3397481.3450662"
    },
    {
      "text": "Prasanna Tambe, Peter Cappelli, and Valery Yakubovich. 2019. Artificial intelligence in human resources management: Challenges and a path forward. California Management Review 61, 4 (2019), 15\u201342.",
      "doi": ""
    },
    {
      "text": "Erico Tjoa and Cuntai Guan. 2020. A survey on explainable artificial intelligence (xai): Toward medical xai. IEEE Transactions on Neural Networks and Learning Systems (2020).",
      "doi": ""
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian\u00a0Y Lim. 2019. Designing theory-driven user-centric explainable AI. In Proceedings of the 2019 CHI conference on human factors in computing systems. 1\u201315.",
      "doi": "10.1145/3290605.3300831"
    },
    {
      "text": "Fabio\u00a0Massimo Zanzotto. 2019. Human-in-the-loop Artificial Intelligence. Journal of Artificial Intelligence Research 64 (2019), 243\u2013252.",
      "doi": "10.1613/jair.1.11345"
    },
    {
      "text": "Brahim Zarouali, Tom Dobber, Guy De\u00a0Pauw, and Claes de Vreese. 2020. Using a Personality-Profiling Algorithm to Investigate Political Microtargeting: Assessing the Persuasion Effects of Personality-Tailored Ads on Social Media. Communication Research(2020), 009365022096196.",
      "doi": ""
    },
    {
      "text": "Tal Zarsky. 2016. The trouble with algorithmic decisions: An analytic road map to examine efficiency and fairness in automated and opaque decision making. Science, Technology, & Human Values 41, 1 (2016), 118\u2013132.",
      "doi": ""
    },
    {
      "text": "Carlos Zednik. 2019. Solving the black box problem: a normative framework for explainable artificial intelligence. Philosophy & Technology(2019), 1\u201324.",
      "doi": ""
    }
  ]
}