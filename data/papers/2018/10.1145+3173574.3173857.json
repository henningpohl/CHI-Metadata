{
  "doi": "10.1145/3173574.3173857",
  "title": "Voicesetting: Voice Authoring UIs for Improved Expressivity in Augmentative Communication",
  "published": "2018-04-21",
  "proctitle": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2018,
  "badges": [],
  "abstract": "Alternative and augmentative communication (AAC) systems used by people with speech disabilities rely on text-to-speech (TTS) engines for synthesizing speech. Advances in TTS systems allowing for the rendering of speech with a range of emotions have yet to be incorporated into AAC systems, leaving AAC users with speech that is mostly devoid of emotion and expressivity. In this work, we describe voicesetting as the process of authoring the speech properties of text. We present the design and evaluation of two voicesetting user interfaces: the Expressive Keyboard, designed for rapid addition of expressivity to speech, and the Voicesetting Editor, designed for more careful crafting of the way text should be spoken. We evaluated the perceived output quality, requisite effort, and usability of both interfaces; the concept of voicesetting and our interfaces were highly valued by end-users as an enhancement to communication quality. We close by discussing design insights from our evaluations.",
  "tags": [
    "aac",
    "amyotrophic lateral sclerosis",
    "als",
    "tts"
  ],
  "authors": [
    {
      "name": "Alexander J. Fiannaca",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/do/10.1145/contrib-83058889957/rel-imgonly/professionalphoto.jpg",
      "acmid": "83058889957",
      "orcid": "missing"
    },
    {
      "name": "Ann Paradiso",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81545822456",
      "orcid": "0000-0002-5092-8603"
    },
    {
      "name": "Jon Campbell",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659130980",
      "orcid": "missing"
    },
    {
      "name": "Meredith Ringel Morris",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/do/10.1145/contrib-81452607037/rel-imgonly/merriesquare.jpg",
      "acmid": "81452607037",
      "orcid": "0000-0003-1436-9223"
    }
  ],
  "references": [
    {
      "text": "Matthew P. Aylett, Graham Pullin, David A. Braude, Blaise Potard, Shannon Hennig, and Marilia Antunes Ferreira. 2016. Don't Say Yes, Say Yes: Interacting with Synthetic Speech Using Tonetable. In Proceedings of CHI EA '16. ACM, 3643--3646.  ",
      "doi": "10.1145/2851581.2890245"
    },
    {
      "text": "Daniel C. Burnett, Mark R. Walker, and Andrew Hunt. 2004. Speech Synthesis Markup Language (SSML) Version 1.0. W3C. Retrieved September 9, 2016 from http://www.w3.org/TR/speech-synthesis/",
      "doi": ""
    },
    {
      "text": "Nick Campbell. 2007. Approaches to conversational speech rhythm: Speech activity in two-person telephone dialogues. In Proceedings of the 16th International Congress of the Phonetic Sciences, Saarbrucken, Germany, pp. 343--348.",
      "doi": ""
    },
    {
      "text": "CereVoice Engine Text-to-Speech SDK. 2016. CereProc. Retrieved September 9, 2016 from https://www.cereproc.com/en/products/sdk",
      "doi": ""
    },
    {
      "text": "Marcela Charfuelan and Ingmar Steiner. 2013. Expressive Speech Synthesis in MARY TTS Using Audiobook Data and EmotionML. In Proceedings of Interspeech 2013. ISCA.",
      "doi": ""
    },
    {
      "text": "Paul Ekman, E. Richard Sorenson, and Wallace V. Friesen. 1969. Pan-cultural elements in facial displays of emotion. In Science 164.3875: 86--88.",
      "doi": ""
    },
    {
      "text": "Susan Goldin-Meadow. 1999. The role of gesture in communication and thinking. In Trends in Cognitive Sciences, 3(11), 419--429.",
      "doi": ""
    },
    {
      "text": "John P. Hansen, Anders S. Johansen, Michael Donegan, David J.C. MacKay, Phil Cowans, Michael K\u00fchn, Richard Bates, P\u00e4ivi Majaranta, and Kari-Jouko R\u00e4ih\u00e4, K. J. (2005). D4. 1 Design Specifications and guidelines for COGAIN eye-typing systems. Retrieved September 9, 2016 from http://wiki.cogain.org/images/a/a7/COGAIN-D4.1.pdf",
      "doi": ""
    },
    {
      "text": "D. Jeffery Higginbotham. 2010. Humanizing Vox Artificialis: The Role of Speech Synthesis in Augmentative and Alternative Communication. In Computer Synthesized Speech Technologies: Tools for Aiding Impairment, 50.",
      "doi": ""
    },
    {
      "text": "Matt Huenerfauth, Pengfei Lu, and Andrew Rosenberg. 2011. Evaluating Importance of Facial Expression in American Sign Language and Pidgin Signed English Animations. In Proceedings of ASSETS '11, 99--106.  ",
      "doi": "10.1145/2049536.2049556"
    },
    {
      "text": "Shaun K. Kane, Meredith Ringel Morris, Ann Paradiso, and Jon Campbell. 2017. \"At times avuncular and cantankerous, with the reflexes of a mongoose\": Understanding Self-Expression through Augmentative and Alternative Communication Devices. In Proceedings of CSCW '17.  ",
      "doi": "10.1145/2998181.2998284"
    },
    {
      "text": "Light, Janice, Rebecca Page, Jennifer Curran, and Laura Pitkin. 2007. Children's ideas for the design of AAC assistive technologies for young children with complex communication needs. In Augmentative and Alternative Communication. 23, 4: 274--287.",
      "doi": ""
    },
    {
      "text": "P\u00e4ivi Majaranta and Kari-Jouko R\u00e4ih\u00e4. 2002. Twenty years of eye typing. In Proceedings of ETRA '02, ACM Press, 15.  ",
      "doi": "10.1145/507072.507076"
    },
    {
      "text": "Mary Text-To-Speech. Retrieved September 13, 2016 from http://mary.dfki.de/",
      "doi": ""
    },
    {
      "text": "Hiroshi Mitsumoto. 2009. Amyotrophic lateral sclerosis: a guide for patients and families. Demos Medical Publishing.",
      "doi": ""
    },
    {
      "text": "Martez E. Mott, Shane Williams, Jacob O. Wobbrock, and Meredith Ringel Morris. 2017. Improving DwellBased Gaze Typing with Dynamic, Cascading Dwell Times. In Proceedings of CHI '17.  ",
      "doi": "10.1145/3025453.3025517"
    },
    {
      "text": "Esther Nathanson. 2016. Native voice, self-concept and the moral case for personalized voice technology. In Disability and Rehabilitation. 1--9.",
      "doi": ""
    },
    {
      "text": "Nuance Loquendo. 2016. Nuance. Retrieved September 9, 2016 from http://www.nuance.com/forbusiness/by-solution/customer-servicesolutions/solutions-services/inboundsolutions/loquendo-small-business-bundle/ttsdemo/english/index.htm",
      "doi": ""
    },
    {
      "text": "Sandra Pauletto, Bruce Balentine, Chris Pidcock, Kevin Jones, Leonardo Bottaci, Maria Aretoulaki, Jez Wells, Darren P. Mundy, and James Balentine. 2013. Exploring Expressivity and Emotion with Artificial Voice and Speech Technologies.\" In Logopedics Phoniatrics Vocology 38, 3: 115--125.",
      "doi": ""
    },
    {
      "text": "John F. Pitrelli, Raimo Bakis, Ellen M. Eide, Raul Fernandez, Wael Hamza, and Michael A. Picheny. 2006. The IBM expressive text-to-speech synthesis system for American English. In IEEE Transactions on Audio, Speech, and Language Processing 14, no. 4: 1099--1108.  ",
      "doi": "10.1109/TASL.2006.876123"
    },
    {
      "text": "Colin Portnuff. 2006. Augmentative and Alternative Communication: A Users Perspective. Lecture delivered at the OHSU, August 18, 2006. http://aacrerc.psu.edu/index-8121.php.html",
      "doi": ""
    },
    {
      "text": "Graham Pullin and Shannon Hennig. 2015. 17 Ways to Say Yes: Toward Nuanced Tone of Voice in AAC and Speech Technology. In Augmentative and Alternative Communication, 31(2), 170--180.",
      "doi": ""
    },
    {
      "text": "Klaus R. Scherer and Heiner Ellgring, 2007. Multimodal Expression of Emotion: Affect Programs or Componential Appraisal Patterns? In Emotion, vol. 7, pp. 158--71.",
      "doi": ""
    },
    {
      "text": "Marc Schr\u00f6der. 2009. Expressive speech synthesis: Past, present, and possible futures. In Affective Information Processing, pp. 111--126. Springer.",
      "doi": ""
    },
    {
      "text": "Kiley Sobel, Alexander Fiannaca, Jon Campbell, Harish Kulkarni, Ann Paradiso, Ed Cutrell, Meredith Ringel Morris. 2017. Exploring the Design Space of AAC Awareness Displays. In Proceedings of CHI '17.  ",
      "doi": "10.1145/3025453.3025610"
    },
    {
      "text": "System Usability Scale. Retrieved September 11, 2016 from https://www.usability.gov/how-to-andtools/methods/system-usability-scale.html",
      "doi": ""
    },
    {
      "text": "\u00c9va Sz\u00e9kely, Zeeshan Ahmed, Jo\u00e3o P. Cabral, and Julie Carson-Berndsen. 2012. WinkTalk: a demonstration of a multimodal speech synthesis platform linking facial expressions to expressive synthetic voices. In Proceedings of SLPAT '12. 5--8. ",
      "doi": "10.5555/2392855.2392857"
    },
    {
      "text": "Watson Text-To-Speech. 2016 IBM. Retrieved September 9, 2016 from http://www.ibm.com/watson/developercloud/text-tospeech.html",
      "doi": ""
    },
    {
      "text": "Sheida White. 1989. Backchannels across cultures: A study of Americans and Japanese. Language in society. 18, 01: 59--76.",
      "doi": ""
    },
    {
      "text": "Xiaoyi Zhang, Harish Kulkarni, and Meredith Ringel Morris. 2017. Smartphone-Based Gaze Gesture Communication for People with Motor Disabilities. To appear in Proceedings of CHI '17.  ",
      "doi": "10.1145/3025453.3025790"
    }
  ]
}