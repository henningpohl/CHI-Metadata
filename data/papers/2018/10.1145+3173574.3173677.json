{
  "doi": "10.1145/3173574.3173677",
  "title": "Explanations as Mechanisms for Supporting Algorithmic Transparency",
  "published": "2018-04-19",
  "proctitle": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2018,
  "badges": [],
  "abstract": "Transparency can empower users to make informed choices about how they use an algorithmic decision-making system and judge its potential consequences. However, transparency is often conceptualized by the outcomes it is intended to bring about, not the specifics of mechanisms to achieve those outcomes. We conducted an online experiment focusing on how different ways of explaining Facebook's News Feed algorithm might affect participants' beliefs and judgments about the News Feed. We found that all explanations caused participants to become more aware of how the system works, and helped them to determine whether the system is biased and if they can control what they see. The explanations were less effective for helping participants evaluate the correctness of the system's output, and form opinions about how sensible and consistent its behavior is. We present implications for the design of transparency mechanisms in algorithmic decision-making systems based on these results.",
  "authors": [
    {
      "name": "Emilee Rader",
      "institution": "Michigan State University, East Lansing, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81328489766",
      "orcid": "missing"
    },
    {
      "name": "Kelley Cotter",
      "institution": "Michigan State University, East Lansing, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659161335",
      "orcid": "missing"
    },
    {
      "name": "Janghee Cho",
      "institution": "Michigan State University, East Lansing , MI, USA",
      "img": "/do/10.1145/contrib-99659162324/rel-imgonly/janghee_zoom.png",
      "acmid": "99659162324",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Mike Ananny and Kate Crawford. 2017. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. New Media & Society 33, 4 (2017), 1--17.",
      "doi": ""
    },
    {
      "text": "Association for Computing Machinery U.S. Public Policy Council. 2017. Statement on algorithmic transparency and accountability. (2017). https://www.acm.org/binaries/content/assets/publicpolicy/2017_usacm_statement_algorithms.pdf",
      "doi": ""
    },
    {
      "text": "Shlomo Berkovsky, Ronnie Taib, and Dan Conway. 2017. How to recommend? User trust factors in movie recommender systems. In International Conference on Intelligent User Interfaces. 287--300.  ",
      "doi": "10.1145/3025171.3025209"
    },
    {
      "text": "Anol Bhattacherjee. 2001. Understanding information systems continuance: An expectation-confirmation model. MIS Quarterly 25, 3 (2001), 351--370.  ",
      "doi": "10.2307/3250921"
    },
    {
      "text": "Mustafa Bilgic and Raymond J Mooney. 2005. Explaining recommendations: Satisfaction vs. promotion. In Beyond Personalization Workshop, IUI, Vol. 5. 153.",
      "doi": ""
    },
    {
      "text": "Engin Bozdag and Jeroen van den Hoven. 2015. Breaking the filter bubble: Democracy and design. Ethics and Information Technology 17, 4 (2015), 249--265.  ",
      "doi": "10.1007/s10676-015-9380-y"
    },
    {
      "text": "Jenna Burrell. 2016. How the machine 'thinks': Understanding opacity in machine learning algorithms. Big Data & Society 3, 1 (2016), 1--12.",
      "doi": ""
    },
    {
      "text": "Federal Trade Commission. 2016. Big Data: A tool for inclusion or exclusion? Understanding the issues. (2016). https://www.ftc.gov/system/files/documents/reports/ big-data-tool-inclusion-or-exclusion-understandingissues/160106big-data-rpt.pdf",
      "doi": ""
    },
    {
      "text": "Kelley Cotter, Janghee Cho, and Emilee Rader. 2017. Explaining the news feed algorithm: An analysis of the News Feed FYI blog. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems. 1553--1560.  ",
      "doi": "10.1145/3027063.3053114"
    },
    {
      "text": "Henriette Cramer, Vanessa Evers, Satyan Ramlal, Maarten van Someren, Lloyd Rutledge, Natalia Stash, Lora Aroyo, and Bob Wielinga. 2008. The effects of transparency on trust in and acceptance of a content-based art recommender. User Modeling and User-Adapted Interaction 18, 5 (2008), 455--496.  ",
      "doi": "10.1007/s11257-008-9051-3"
    },
    {
      "text": "Michael A. DeVito, Darren Gergle, and Jeremy Birnholtz. 2017. \"Algorithms ruin everything\": #RIPTwitter, Folk Theories, and Resistance to Algorithmic Change in Social Media. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 3163--3174.  ",
      "doi": "10.1145/3025453.3025659"
    },
    {
      "text": "Nicholas Diakopoulos. 2016. Accountability in algorithmic decision making. Commun. ACM 59, 2 (2016), 56--62.  ",
      "doi": "10.1145/2844110"
    },
    {
      "text": "Nicholas Diakopoulos. 2017. Enabling Accountability of Algorithmic Media: Transparency as a Constructive and Critical Lens. In Transparent Data Mining for Big and Small Data, Tania Cerquitelli, Daniele Quercia, and Frank Pasquale (Eds.). Vol. 32. Springer International Publishing, Cham, Switzerland, 25--43.",
      "doi": ""
    },
    {
      "text": "Nicholas Diakopoulos and Michael Koliska. 2016. Algorithmic transparency in the news media. Digital Journalism 5, 7 (2016), 809--828.",
      "doi": ""
    },
    {
      "text": "Nicole B. Ellison, Charles Steinfield, and Cliff Lampe. 2007. The benefits of Facebook \"friends:\" Social capital and college students' use of online social network sites. Journal of Computer-Mediated Communication 12, 4 (2007), 1143--1168.",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy Vuong, Karrie Karahalios, Kevin Hamilton, and Christian Sandvig. 2015. I always assumed that I wasn't really that close to {her}\": Reasoning about invisible algorithms in News Feeds. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 153--162.  ",
      "doi": "10.1145/2702123.2702556"
    },
    {
      "text": "Motahhare Eslami, Kristen Vaccaro, Karrie Karahalios, and Kevin Hamilton. 2017. Be careful; things can be worse than they appear\": Understanding biased algorithms and users' behavior around them in rating platforms. In The International AAAI Conference on Web and Social Media. 62--71.",
      "doi": ""
    },
    {
      "text": "Kenneth R. Fleischmann and William A. Wallace. 2005. A covenant with transparency: Opening the black box of models. Commun. ACM 48, 5 (2005), 93--97.  ",
      "doi": "10.1145/1060710.1060715"
    },
    {
      "text": "Mikkel Flyverbom. 2016. Transparency: Mediation and the Management of Visibilities. International Journal of Communication 10 (2016), 1--13.",
      "doi": ""
    },
    {
      "text": "Gerhard Friedrich and Markus Zanker. 2011. A taxonomy for generating explanations in recommender systems. AI Magazine 32, 3 (2011), 90--98.",
      "doi": ""
    },
    {
      "text": "Fatih Gedikli, Dietmar Jannach, and Mouzhi Ge. 2014. How should I explain? A comparison of different explanation types for recommender systems. International Journal of Human-Computer Studies 72, 4 (2014), 367--382.  ",
      "doi": "10.1016/j.ijhcs.2013.12.007"
    },
    {
      "text": "Justin Scott Giboney, Susan A. Brown, Paul Benjamin Lowry, and Jay F. Nunamaker. 2015. User acceptance of knowledge-based system recommendations: Explanations, arguments, and fit. Decision Support Systems 72 (2015), 1--10.  ",
      "doi": "10.1016/j.dss.2015.02.005"
    },
    {
      "text": "Tarleton Gillespie. 2014. The relevance of algorithms. In Media Technologies: Essays on Communication, Materiality, and Society, Tarleton Gillespie, Pablo J. Boczkowski, and Kirsten A. Foot (Eds.). The MIT Press, Cambridge, Mass., 167--194.",
      "doi": ""
    },
    {
      "text": "Shirley Gregor and Izak Benbasat. 1999. Explanations from intelligent systems: Theoretical foundations and implications for practice. 23, 4 (1999), 497--530.  ",
      "doi": "10.2307/249487"
    },
    {
      "text": "Eszter Hargittai and Yuli Patrick Hsieh. 2011. Succinct survey measures of web-use skills. Social Science Computer Review 30, 1 (2011), 95--107.  ",
      "doi": "10.1177/0894439310397146"
    },
    {
      "text": "Bernie Hogan. 2015. From invisible algorithms to interactive affordances: Data after the ideology of machine learning. In Roles, Trust, and Reputation in Social Media Knowledge Markets: Theory and Methods, Elisa Bertino and Sorin Adam Matei (Eds.). Springer International Publishing, 103--117.",
      "doi": ""
    },
    {
      "text": "Lucas D. Introna. 2016. Algorithms, Governance, and Governmentality: On Governing Academic Writing. Science, Technology, & Human Values 41, 1 (2016), 17--49.",
      "doi": ""
    },
    {
      "text": "Dietmar Jannach, Paul Resnick, Alexander Tuzhilin, and Markus Zanker. 2016. Recommender systems: Beyond matrix completion. Commun. ACM 59, 11 (2016), 94--102.  ",
      "doi": "10.1145/2891406"
    },
    {
      "text": "Joseph A Konstan and John Riedl. 2012. Recommender systems: from algorithms to user experience. User Modeling and User-Adapted Interaction 22, 1--2 (2012), 101--123.  ",
      "doi": "10.1007/s11257-011-9112-x"
    },
    {
      "text": "Joshua A. Kroll, Joanna Huey, Solon Barocas, Edward W. Felten, Joel R. Reidenberg, David G. Robinson, and Harlan Yu. 2016. Accountable algorithms. University of Pennsylvania Law Review 165, 3 (2016).",
      "doi": ""
    },
    {
      "text": "Todd Kulesza, Simone Stumpf, Margaret Burnett, Sherry Yang, Irwin Kwan, and Weng-Keen Wong. 2013. Too much, too little, or just right? Ways explanations impact end users' mental models. In 2013 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, 3--10.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee, Daniel Kusbit, Evan Metsky, and Laura Dabbish. 2015. Working with machines: The impact of algorithmic and data-driven management on human workers. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 1603--1612.  ",
      "doi": "10.1145/2702123.2702548"
    },
    {
      "text": "Xin Li, Traci J Hess, and Joseph S Valacich. 2008. Why do we trust new technology? A study of initial trust formation with organizational information systems. The Journal of Strategic Information Systems 17, 1 (2008), 39--71.  ",
      "doi": "10.1016/j.jsis.2008.01.001"
    },
    {
      "text": "Brian Y. Lim and Anind K. Dey. 2009. Assessing demand for intelligibility in context-aware applications. In Proceedings of the 11th International Conference on Ubiquitous Computing. 195--204.  ",
      "doi": "10.1145/1620545.1620576"
    },
    {
      "text": "Zachary C Lipton. 2016. The mythos of model interpretability. In 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016). 96--100.",
      "doi": ""
    },
    {
      "text": "Claudia Marino, Livio Finos, Alessio Vieno, Michela Lenzi, and Marcantonio M. Spada. 2017. Objective Facebook behaviour: Differences between problematic and non-problematic users. Computers in Human Behavior 73 (2017), 541--546.  ",
      "doi": "10.1016/j.chb.2017.04.015"
    },
    {
      "text": "Joseph E. Mercado, Michael A. Rupp, Jessie Y. C. Chen, Michael J. Barnes, Daniel Barber, and Katelyn Procci. 2016. Intelligent agent transparency in human-agent teaming for multi-UxV management. Human Factors: The Journal of the Human Factors and Ergonomics Society 58, 3 (2016), 401--415.",
      "doi": ""
    },
    {
      "text": "Brent Mittelstadt. 2016. Automation, algorithms, and politics: Auditing for transparency in content personalization systems. International Journal of Communication 10 (2016), 4991--5002.",
      "doi": ""
    },
    {
      "text": "Sayooran Nagulendra and Julita Vassileva. 2016. Providing awareness, explanation and control of personalized filtering in a social networking site. Information Systems Frontiers 18, 1 (2016), 145--158.  ",
      "doi": "10.1007/s10796-015-9577-y"
    },
    {
      "text": "Kenya Freeman Oduor and Eric N. Wiebe. 2008. The effects of automated decision algorithm modality and transparency on reported trust and task performance. Proceedings of the Human Factors and Ergonomics Society Annual Meeting 52, 4 (2008), 302--306.",
      "doi": ""
    },
    {
      "text": "Julian A. Oldmeadow, Sally Quinn, and Rachel Kowert. 2013. Attachment style, social skills, and Facebook use amongst adults. Computers in Human Behavior 29, 3 (2013), 1142--1149.  ",
      "doi": "10.1016/j.chb.2012.10.006"
    },
    {
      "text": "Alexis Papadimitriou, Panagiotis Symeonidis, and Yannis Manolopoulos. 2012. A generalized taxonomy of explanations styles for traditional and social recommender systems. Data Mining and Knowledge Discovery 24, 3 (2012), 555--583.  ",
      "doi": "10.1007/s10618-011-0215-0"
    },
    {
      "text": "Frank Pasquale. 2015. The black box society: the secret algorithms that control money and information. Harvard University Press, Cambridge, MA. ",
      "doi": "10.5555/2717112"
    },
    {
      "text": "John D. Podesta, Penny Pritzker, Ernest J. Moniz, John P. Holdren, and Jeffrey D. Zients. 2014. Big data: Seizing opportunities, preserving values. (2014). https://obamawhitehouse.archives.gov/sites/default/ files/docs/big_data_privacy_report_may_1_2014.pdf",
      "doi": ""
    },
    {
      "text": "Emilee Rader. 2017. Examining user surprise as a symptom of algorithmic filtering. International Journal of Human Computer Studies 98 (2017), 72--88.  ",
      "doi": "10.1016/j.ijhcs.2016.10.005"
    },
    {
      "text": "Emilee Rader and Rebecca Gray. 2015. Understanding user beliefs about algorithmic curation in the Facebook News Feed. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 173--182.  ",
      "doi": "10.1145/2702123.2702174"
    },
    {
      "text": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \"Why should I trust you?\" Explaining the Predictions of Any Classifier. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1135--1144.  ",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Christian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric Langbort. 2014. Auditing algorithms: Research methods for detecting discrimination on internet platforms. Data and discrimination: converting critical concerns into productive inquiry (2014).",
      "doi": ""
    },
    {
      "text": "Rashmi Sinha and Kirsten Swearingen. 2002. The role of transparency in recommender systems. In Proceedings of the 2002 CHI Conference Extended Abstracts on Human Factors in Computing Systems. 830--831.  ",
      "doi": "10.1145/506443.506619"
    },
    {
      "text": "Nava Tintarev and Judith Masthoff. 2007. A survey of explanations in recommender systems. In Proceedings of the 2007 IEEE 23rd International Conference on Data Engineering Workshop. 801--810.  ",
      "doi": "10.1109/ICDEW.2007.4401070"
    },
    {
      "text": "Nava Tintarev and Judith Masthoff. 2011. Designing and Evaluating Explanations for Recommender Systems. In Recommender Systems Handbook, Francesco Ricci, Lior Rokach, Bracha Shapira, and Paul B. Kantor (Eds.). Springer-Verlag, New York, New York, 479--510.",
      "doi": ""
    },
    {
      "text": "Nava Tintarev and Judith Masthoff. 2012. Evaluating the effectiveness of explanations for recommender systems. User Modeling and User-Adapted Interaction 22, 4--5 (2012), 399--439.  ",
      "doi": "10.1007/s11257-011-9117-5"
    },
    {
      "text": "Viswanath Venkatesh, James Y. L. Thong, Frank K. Y. Chan, Paul Jen-Hwa Hu, and Susan A. Brown. 2011. Extending the two-stage information systems continuance model: incorporating UTAUT predictors and the role of context. Information Systems Journal 21, 6 (2011), 527--555.",
      "doi": ""
    },
    {
      "text": "Weiquan Wang and Izak Benbasat. 2007. Recommendation agents for electronic commerce: Effects of explanation facilities on trusting beliefs. Journal of Management Information Systems 23, 4 (2007), 217--246.  ",
      "doi": "10.2753/MIS0742-1222230410"
    },
    {
      "text": "Markus Zanker and Daniel Ninaus. 2010. Knowledgeable explanations for recommender systems. In Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, Vol. 1. 657--660.  ",
      "doi": "10.1109/WI-IAT.2010.131"
    },
    {
      "text": "Tal Zarsky. 2016. The trouble with algorithmic decisions: An analytic road map to examine efficiency and fairness in automated and opaque decision making. Science, Technology, & Human Values 41, 1 (2016), 118--132.",
      "doi": ""
    }
  ]
}