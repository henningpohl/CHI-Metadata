{
  "doi": "10.1145/3173574.3173681",
  "title": "GestureWiz: A Human-Powered Gesture Design Environment for User Interface Prototypes",
  "published": "2018-04-19",
  "proctitle": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-11",
  "year": 2018,
  "badges": [],
  "abstract": "Designers and researchers often rely on simple gesture recognizers like Wobbrock et al.'s $1 for rapid user interface prototypes. However, most existing recognizers are limited to a particular input modality and/or pre-trained set of gestures, and cannot be easily combined with other recognizers. In particular, creating prototypes that employ advanced touch and mid-air gestures still requires significant technical experience and programming skill. Inspired by $1's easy, cheap, and flexible design, we present the GestureWiz prototyping environment that provides designers with an integrated solution for gesture definition, conflict checking, and real-time recognition by employing human recognizers in a Wizard of Oz manner. We present a series of experiments with designers and crowds to show that GestureWiz can perform with reasonable accuracy and latency. We demonstrate advantages of GestureWiz when recreating gesture-based interfaces from the literature and conducting a study with 12 interaction designers that prototyped a multimodal interface with support for a wide range of novel gestures in about 45 minutes.",
  "authors": [
    {
      "name": "Maximilian Speicher",
      "institution": "University of Michigan, Ann Arbor, MI, USA",
      "img": "/do/10.1145/contrib-81558253056/rel-imgonly/fb_profile_pic_455x455.jpg",
      "acmid": "81558253056",
      "orcid": "missing"
    },
    {
      "name": "Michael Nebeling",
      "institution": "University of Michigan, Ann Arbor, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81484640607",
      "orcid": "0000-0003-3743-2387"
    }
  ],
  "references": [
    {
      "text": "Amini, S., and Li, Y. CrowdLearner: Rapidly Creating Mobile Recognizers using Crowdsourcing. In Proc. UIST (2013).  ",
      "doi": "10.1145/2501988.2502029"
    },
    {
      "text": "Ashbrook, D., and Starner, T. MAGIC: A Motion Gesture Design Tool. In Proc. CHI (2010).  ",
      "doi": "10.1145/1753326.1753653"
    },
    {
      "text": "Bernstein, M. S., Brandt, J., Miller, R. C., and Karger, D. R. Crowds in Two Seconds: Enabling Realtime Crowd-Powered Interfaces. In Proc. UIST (2011).  ",
      "doi": "10.1145/2047196.2047201"
    },
    {
      "text": "Bigham, J. P., Jayant, C., Ji, H., Little, G., Miller, A., Miller, R. C., Miller, R., Tatarowicz, A., White, B., White, S., and Yeh, T. VizWiz: Nearly Real-time Answers to Visual Questions. In Proc. UIST (2010).  ",
      "doi": "10.1145/1866029.1866080"
    },
    {
      "text": "Chen, X. A., Grossman, T., Wigdor, D. J., and Fitzmaurice, G. W. Duet: Exploring Joint Interactions on a Smart Phone and a Smart Watch. In Proc. CHI (2014).  ",
      "doi": "10.1145/2556288.2556955"
    },
    {
      "text": "Dow, S., Lee, J., Oezbek, C., MacIntyre, B., Bolter, J. D., and Gandy, M. Wizard of oz interfaces for mixed reality applications. In Proc. CHI Extended Abstracts (2005), 1339--1342.  ",
      "doi": "10.1145/1056808.1056911"
    },
    {
      "text": "Dow, S., MacIntyre, B., Lee, J., Oezbek, C., Bolter, J. D., and Gandy, M. Wizard of oz support throughout an iterative design process. IEEE Pervasive Computing 4, 4 (2005), 18--26.  ",
      "doi": "10.1109/MPRV.2005.93"
    },
    {
      "text": "Jang, S., Elmqvist, N., and Ramani, K. GestureAnalyzer: Visual Analytics for Pattern Analysis of Mid-Air Hand Gestures. In Proc. SUI (2014).  ",
      "doi": "10.1145/2659766.2659772"
    },
    {
      "text": "Kato, J., McDirmid, S., and Cao, X. DejaVu: Integrated Support for Developing Interactive Camera-Based Programs. In Proc. UIST (2012).  ",
      "doi": "10.1145/2380116.2380142"
    },
    {
      "text": "Kittur, A., Smus, B., Khamkar, S., and Kraut, R. E. Crowdforge: Crowdsourcing complex work. In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology, UIST '11, ACM (2011), 43--52.  ",
      "doi": "10.1145/2047196.2047202"
    },
    {
      "text": "Kulkarni, A., Can, M., and Hartmann, B. Collaboratively crowdsourcing workflows with turkomatic. In Proc. CSCW (2012).  ",
      "doi": "10.1145/2145204.2145354"
    },
    {
      "text": "Laput, G., Lasecki, W. S., Wiese, J., Xiao, R., Bigham, J. P., and Harrison, C. Zensors: Adaptive, rapidly deployable, human-intelligent sensor feeds. In Proc. CHI (2015).  ",
      "doi": "10.1145/2702123.2702416"
    },
    {
      "text": "Lasecki, W. S., Gordon, M., Koutra, D., Jung, M. F., Dow, S. P., and Bigham, J. P. Glance: Rapidly Coding Behavioral Video with the Crowd. In Proc. UIST (2014).  ",
      "doi": "10.1145/2642918.2647367"
    },
    {
      "text": "Lasecki, W. S., Kim, J., Rafter, N., Sen, O., Bigham, J. P., and Bernstein, M. S. Apparition: Crowdsourced User Interfaces that Come to Life as You Sketch Them. In Proc. CHI (2015).  ",
      "doi": "10.1145/2702123.2702565"
    },
    {
      "text": "Lasecki, W. S., Murray, K. I., White, S., Miller, R. C., and Bigham, J. P. Real-time crowd control of existing interfaces. In Proc. UIST (2011), 23--32.  ",
      "doi": "10.1145/2047196.2047200"
    },
    {
      "text": "Lee, S.-S., Chae, J., Kim, H., Lim, Y.-K., and Lee, K.-P. Towards more Natural Digital Content Manipulation via User Freehand Gestural Interaction in a Living Room. In Proc. UbiComp (2013).  ",
      "doi": "10.1145/2493432.2493480"
    },
    {
      "text": "L\u00a8 u, H., and Li, Y. Gesture Coder: A Tool for Programming Multi-touch Gestures By Demonstration. In Proc. CHI (2012).  ",
      "doi": "10.1145/2207676.2208693"
    },
    {
      "text": "L\u00a8 u, H., and Li, Y. Gesture Studio: Authoring Multi-touch Interactions through Demonstration and Declaration. In Proc. CHI (2013).  ",
      "doi": "10.1145/2470654.2470690"
    },
    {
      "text": "MacIntyre, B., Gandy, M., Dow, S., and Bolter, J. D. DART: a toolkit for rapid design exploration of augmented reality experiences. In Proc. UIST (2004).  ",
      "doi": "10.1145/1029632.1029669"
    },
    {
      "text": "Morris, M. R. Web on the Wall: Insights from a Multimodal Interaction Elicitation Study. In Proc. ITS (2012).  ",
      "doi": "10.1145/2396636.2396651"
    },
    {
      "text": "Morris, M. R., Danielescu, A., Drucker, S. M., Fisher, D., Lee, B., m. c. schraefel, and Wobbrock, J. O. Reducing Legacy Bias in Gesture Elicitation Studies. Interactions 21, 3 (2014).  ",
      "doi": "10.1145/2591689"
    },
    {
      "text": "Morris, M. R., Wobbrock, J. O., and Wilson, A. D. Understanding Users' Preferences for Surface Gestures. In Proc. GI (2010). ",
      "doi": "10.5555/1839214.1839260"
    },
    {
      "text": "Nacenta, M. A., Kamber, Y., Qiang, Y., and Kristensson, P. O. Memorability of Pre-designed and User-defined Gesture Sets. In Proc. CHI (2013).  ",
      "doi": "10.1145/2470654.2466142"
    },
    {
      "text": "Nebeling, M., and Dey, A. K. XDBrowser: User-Defined Cross-Device Web Page Designs. In Proc. CHI (2016).  ",
      "doi": "10.1145/2858036.2858048"
    },
    {
      "text": "Nebeling, M., Huber, A., Ott, D., and Norrie, M. C. Web on the Wall Reloaded: Implementation, Replication and Refinement of User-Defined Interaction Sets. In Proc. ITS (2014).  ",
      "doi": "10.1145/2669485.2669497"
    },
    {
      "text": "Oh, U., and Findlater, L. The Challenges and Potential of End-User Gesture Customization. In Proc. CHI (2013).  ",
      "doi": "10.1145/2470654.2466145"
    },
    {
      "text": "Ouyang, T., and Li, Y. Bootstrapping personal gesture shortcuts with the wisdom of the crowd and handwriting recognition. In Proc. CHI (2012).  ",
      "doi": "10.1145/2207676.2208695"
    },
    {
      "text": "Piumsomboon, T., Clark, A. J., Billinghurst, M., and Cockburn, A. User-defined gestures for augmented reality. In Proc. INTERACT (2013).",
      "doi": "10.1145/2468356.2468527"
    },
    {
      "text": "Song, J., S\u00a8 or\u00a8 os, G., Pece, F., Fanello, S. R., Izadi, S., Keskin, C., and Hilliges, O. In-air gestures around unmodified mobile devices. In Proc. UIST (2014).  ",
      "doi": "10.1145/2642918.2647373"
    },
    {
      "text": "Taranta II, E. M., Samiei, A., Maghoumi, M., Khaloo, P., Pittman, C. R., and LaViola Jr., J. J. Jackknife: A reliable recognizer with few samples and many modalities. In Proc. CHI (2017).  ",
      "doi": "10.1145/3025453.3026002"
    },
    {
      "text": "Vatavu, R. User-Defined Gestures for Free-Hand TV Control. In Proc. EuroITV (2012).  ",
      "doi": "10.1145/2325616.2325626"
    },
    {
      "text": "Wobbrock, J. O., Morris, M. R., and Wilson, A. D. User-Defined Gestures for Surface Computing. In Proc. CHI (2009).  ",
      "doi": "10.1145/1518701.1518866"
    },
    {
      "text": "Wobbrock, J. O., Wilson, A. D., and Li, Y. Gestures without Libraries, Toolkits or Training: A $1 Recognizer for User Interface Prototypes. In Proc. UIST (2007).  ",
      "doi": "10.1145/1294211.1294238"
    }
  ]
}