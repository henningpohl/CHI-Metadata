{
  "doi": "10.1145/3173574.3174198",
  "title": "Training Person-Specific Gaze Estimators from User Interactions with Multiple Devices",
  "published": "2018-04-21",
  "proctitle": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2018,
  "badges": [],
  "abstract": "Learning-based gaze estimation has significant potential to enable attentive user interfaces and gaze-based interaction on the billions of camera-equipped handheld devices and ambient displays. While training accurate person- and device-independent gaze estimators remains challenging, person-specific training is feasible but requires tedious data collection for each target device. To address these limitations, we present the first method to train person-specific gaze estimators across multiple devices. At the core of our method is a single convolutional neural network with shared feature extraction layers and device-specific branches that we train from face images and corresponding on-screen gaze locations. Detailed evaluations on a new dataset of interactions with five common devices (mobile phone, tablet, laptop, desktop computer, smart TV) and three common applications (mobile game, text editing, media center) demonstrate the significant potential of cross-device training. We further explore training with gaze locations derived from natural interactions, such as mouse or touch input.",
  "tags": [
    "appearance-based gaze estimation",
    "multi-devices"
  ],
  "authors": [
    {
      "name": "Xucong Zhang",
      "institution": "Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbr\u00fccken, Germany",
      "img": "/do/10.1145/contrib-99658989536/rel-imgonly/xuocngzhang3.png",
      "acmid": "99658989536",
      "orcid": "missing"
    },
    {
      "name": "Michael Xuelin Huang",
      "institution": "Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbr\u00fccken, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81502641295",
      "orcid": "missing"
    },
    {
      "name": "Yusuke Sugano",
      "institution": "Osaka University, Osaka, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81387606826",
      "orcid": "missing"
    },
    {
      "name": "Andreas Bulling",
      "institution": "Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbr\u00fccken, Germany",
      "img": "/do/10.1145/contrib-81372593219/rel-imgonly/portraet_cut.jpg",
      "acmid": "81372593219",
      "orcid": "0000-0001-6317-7303"
    }
  ],
  "references": [
    {
      "text": "Yusuke Sugano, Yasuyuki Matsushita, and Yoichi Sato. Learning-by-synthesis for appearance-based 3d gaze estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1821--1828, 2014.  ",
      "doi": "10.1109/CVPR.2014.235"
    },
    {
      "text": "Kenneth Alberto Funes Mora, Florent Monay, and Jean-Marc Odobez. Eyediap: A database for the development and evaluation of gaze estimation algorithms from rgb and rgb-d cameras. In Proceedings of the Symposium on Eye Tracking Research and Applications, pages 255--258. ACM, 2014.  ",
      "doi": "10.1145/2578153.2578190"
    },
    {
      "text": "Xucong Zhang, Yusuke Sugano, Mario Fritz, and Andreas Bulling. Appearance-based gaze estimation in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4511--4520, 2015.",
      "doi": ""
    },
    {
      "text": "Kyle Krafka, Aditya Khosla, Petr Kellnhofer, Harini Kannan, Suchendra Bhandarkar, Wojciech Matusik, and Antonio Torralba. Eye tracking for everyone. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2176--2184, 2016.",
      "doi": ""
    },
    {
      "text": "Xucong Zhang, Yusuke Sugano, Mario Fritz, and Andreas Bulling. It's written all over your face: Full-face appearance-based gaze estimation. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on, pages 2299--2308. IEEE, 2017.",
      "doi": ""
    },
    {
      "text": "Andreas Bulling. Pervasive attentive user interfaces. IEEE Computer, 49(1):94--98, 2016.  ",
      "doi": "10.1109/MC.2016.32"
    },
    {
      "text": "Christin Seifert, Annett Mitschick, J\u00f6rg Schl\u00f6tterer, and Raimund Dachselt. Focus paragraph detection for online zero-effort queries: Lessons learned from eye-tracking data. In Proceedings of the 2017 Conference on Conference Human Information Interaction and Retrieval, pages 301--304. ACM, 2017.  ",
      "doi": "10.1145/3020165.3022138"
    },
    {
      "text": "Michael Xuelin Huang, Jiajia Li, Grace Ngai, and Hong Va Leong. Stressclick: Sensing stress from gaze-click patterns. In Proceedings of the 2016 ACM on Multimedia Conference, pages 1395--1404. ACM, 2016.  ",
      "doi": "10.1145/2964284.2964318"
    },
    {
      "text": "Per Ola Kristensson and Keith Vertanen. The potential of dwell-free eye-typing for fast assistive gaze communication. In Proceedings of the Symposium on Eye Tracking Research and Applications, pages 241--244. ACM, 2012.  ",
      "doi": "10.1145/2168556.2168605"
    },
    {
      "text": "Yusuke Sugano, Xucong Zhang, and Andreas Bulling. Aggregaze: Collective estimation of audience attention on public displays. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology, pages 821--831. ACM, 2016.  ",
      "doi": "10.1145/2984511.2984536"
    },
    {
      "text": "Xucong Zhang, Yusuke Sugano, and Andreas Bulling. Everyday eye contact detection using unsupervised gaze target discovery. In 30th Annual Symposium on User Interface Software and Technology. ACM, 2017.  ",
      "doi": "10.1145/3126594.3126614"
    },
    {
      "text": "Pierre Weill-Tessier and Hans Gellersen. Touch input and gaze correlation on tablets. In International Conference on Intelligent Decision Technologies, pages 287--296. Springer, 2017.",
      "doi": ""
    },
    {
      "text": "Yusuke Sugano, Yasuyuki Matsushita, Yoichi Sato, and Hideki Koike. An incremental learning method for unconstrained gaze estimation. Computer Vision--ECCV 2008, pages 656--667, 2008.  ",
      "doi": "10.1007/978-3-540-88690-7_49"
    },
    {
      "text": "Michael Xuelin Huang, Tiffany CK Kwok, Grace Ngai, Stephen CF Chan, and Hong Va Leong. Building a personalized, auto-calibrating eye tracker from user interactions. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pages 5169--5179. ACM, 2016.  ",
      "doi": "10.1145/2858036.2858404"
    },
    {
      "text": "Jixu Chen and Qiang Ji. 3d gaze estimation with a single camera without ir illumination. In Pattern Recognition, 2008. ICPR 2008. 19th International Conference on, pages 1--4. IEEE, 2008.",
      "doi": ""
    },
    {
      "text": "Roberto Valenti, Nicu Sebe, and Theo Gevers. Combining head pose and eye location information for gaze estimation. IEEE Transactions on Image Processing, 21(2):802--815, 2012.  ",
      "doi": "10.1109/TIP.2011.2162740"
    },
    {
      "text": "Erroll Wood and Andreas Bulling. Eyetab: Model-based gaze estimation on unmodified tablet computers. In Proceedings of the Symposium on Eye Tracking Research and Applications, pages 207--210. ACM, 2014.  ",
      "doi": "10.1145/2578153.2578185"
    },
    {
      "text": "Kar-Han Tan, David J Kriegman, and Narendra Ahuja. Appearance-based eye gaze estimation. In Applications of Computer Vision, 2002.(WACV 2002). Proceedings. Sixth IEEE Workshop on, pages 191--195. IEEE, 2002. ",
      "doi": "10.5555/832302.836853"
    },
    {
      "text": "Oliver Williams, Andrew Blake, and Roberto Cipolla. Sparse and semi-supervised visual mapping with the \u015d3gp. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, volume 1, pages 230--237. IEEE, 2006.  ",
      "doi": "10.1109/CVPR.2006.285"
    },
    {
      "text": "Feng Lu, Takahiro Okabe, Yusuke Sugano, and Yoichi Sato. Learning gaze biases with head motion for head pose-free gaze estimation. Image and Vision Computing, 32(3):169--179, 2014.  ",
      "doi": "10.1016/j.imavis.2014.01.005"
    },
    {
      "text": "Kenneth A Funes-Mora and Jean-Marc Odobez. Gaze estimation in the 3d space using rgb-d sensors. International Journal of Computer Vision, 118(2):194--216, 2016.  ",
      "doi": "10.1007/s11263-015-0863-4"
    },
    {
      "text": "Erroll Wood, Tadas Baltrusaitis, Xucong Zhang, Yusuke Sugano, Peter Robinson, and Andreas Bulling. Rendering of eyes for eye-shape registration and gaze estimation. In Proceedings of the IEEE International Conference on Computer Vision, pages 3756--3764, 2015.  ",
      "doi": "10.1109/ICCV.2015.428"
    },
    {
      "text": "Erroll Wood, Tadas Baltru\u015daitis, Louis-Philippe Morency, Peter Robinson, and Andreas Bulling. Learning an appearance-based gaze estimator from one million synthesised images. In Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications, pages 131--138. ACM, 2016.  ",
      "doi": "10.1145/2857491.2857492"
    },
    {
      "text": "Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh Susskind, Wenda Wang, and Russ Webb. Learning from simulated and unsupervised images through adversarial training. 2017.",
      "doi": ""
    },
    {
      "text": "Qiong Huang, Ashok Veeraraghavan, and Ashutosh Sabharwal. Tabletgaze: unconstrained appearance-based gaze estimation in mobile tablets. arXiv preprint arXiv:1508.01244, 2015.",
      "doi": ""
    },
    {
      "text": "Jixu Chen and Qiang Ji. Probabilistic gaze estimation without active personal calibration. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 609--616. IEEE, 2011.  ",
      "doi": "10.1109/CVPR.2011.5995675"
    },
    {
      "text": "Yusuke Sugano, Yasuyuki Matsushita, and Yoichi Sato. Appearance-based gaze estimation using visual saliency. IEEE transactions on pattern analysis and machine intelligence, 35(2):329--341, 2013.  ",
      "doi": "10.1109/TPAMI.2012.101"
    },
    {
      "text": "Yusuke Sugano and Andreas Bulling. Self-calibrating head-mounted eye trackers using egocentric visual saliency. In Proc. ACM Symposium on User Interface Software and Technology (UIST), pages 363--372, 2015.  ",
      "doi": "10.1145/2807442.2807445"
    },
    {
      "text": "Kang Wang, Shen Wang, and Qiang Ji. Deep eye fixation map learning for calibration-free eye gaze tracking. In Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research & Applications, pages 47--55. ACM, 2016.  ",
      "doi": "10.1145/2857491.2857515"
    },
    {
      "text": "Jeff Huang, Ryen White, and Georg Buscher. User see, user point: gaze and cursor alignment in web search. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1341--1350. ACM, 2012.  ",
      "doi": "10.1145/2207676.2208591"
    },
    {
      "text": "Yusuke Sugano, Yasuyuki Matsushita, Yoichi Sato, and Hideki Koike. Appearance-based gaze estimation with online calibration from mouse operations. IEEE Transactions on Human-Machine Systems, 45(6):750--760, 2015.",
      "doi": ""
    },
    {
      "text": "Alexandra Papoutsaki, Patsorn Sangkloy, James Laskey, Nediyana Daskalova, Jeff Huang, and James Hays. Webgazer: Scalable webcam ' tracking using user interactions. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence-IJCAI 2016, 2016. ",
      "doi": "10.5555/3061053.3061156"
    },
    {
      "text": "Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160--167. ACM, 2008.  ",
      "doi": "10.1145/1390156.1390177"
    },
    {
      "text": "Li Deng, Geoffrey Hinton, and Brian Kingsbury. New types of deep neural network learning for speech recognition and related applications: An overview. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pages 8599--8603. IEEE, 2013.",
      "doi": ""
    },
    {
      "text": "Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang. Facial landmark detection by deep multi-task learning. In European Conference on Computer Vision, pages 94--108. Springer, 2014.",
      "doi": ""
    },
    {
      "text": "Jixu Chen, Xiaoming Liu, Peter Tu, and Amy Aragones. Learning person-specific models for facial expression and action unit recognition. Pattern Recognition Letters, 34(15):1964--1970, 2013.  ",
      "doi": "10.1016/j.patrec.2013.02.002"
    },
    {
      "text": "Lukasz Kaiser, Aidan N Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, and Jakob Uszkoreit. One model to learn them all. arXiv preprint arXiv:1706.05137, 2017.",
      "doi": ""
    },
    {
      "text": "Hyeonseob Nam and Bohyung Han. Learning multi-domain convolutional neural networks for visual tracking. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4293--4302, 2016.",
      "doi": ""
    },
    {
      "text": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097--1105, 2012. ",
      "doi": "10.5555/2999134.2999257"
    },
    {
      "text": "Davis E. King. Dlib-ml: A machine learning toolkit. Journal of Machine Learning Research, 10:1755--1758, 2009. ",
      "doi": "10.5555/1577069.1755843"
    },
    {
      "text": "Tadas Baltrusaitis, Peter Robinson, and Louis-Philippe Morency. Constrained local neural fields for robust facial landmark detection in the wild. In Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 354--361, 2013.  ",
      "doi": "10.1109/ICCVW.2013.54"
    },
    {
      "text": "Soonhwa Seok and Boaventura DaCosta. Predicting video game behavior: An investigation of the relationship between personality and mobile game play. Games and Culture, 10(5):481--501, 2015.",
      "doi": ""
    },
    {
      "text": "Katy E Pearce and Ronald E Rice. Digital divides from access to activities: Comparing mobile and personal computer internet users. Journal of Communication, 63(4):721--744, 2013.",
      "doi": ""
    },
    {
      "text": "Grace P Szeto and Raymond Lee. An ergonomic evaluation comparing desktop, notebook, and subnotebook computers. Archives of physical medicine and rehabilitation, 83(4):527--532, 2002.",
      "doi": ""
    },
    {
      "text": "Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. In Proceedings of the 22nd ACM international conference on Multimedia, pages 675--678. ACM, 2014.  ",
      "doi": "10.1145/2647868.2654889"
    },
    {
      "text": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248--255. IEEE, 2009.",
      "doi": ""
    },
    {
      "text": "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. International Conference for Learning Representations, 2015.",
      "doi": ""
    }
  ]
}