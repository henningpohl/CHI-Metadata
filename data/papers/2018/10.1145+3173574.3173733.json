{
  "doi": "10.1145/3173574.3173733",
  "title": "Conceptualizing Disagreement in Qualitative Coding",
  "published": "2018-04-19",
  "proctitle": "CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-11",
  "year": 2018,
  "badges": [],
  "abstract": "Collaborative qualitative coding often involves coders assign- ing different labels to the same instance, leading to ambiguity. We refer to such an instance of ambiguity as disagreement in coding. Analyzing reasons for such a disagreement is essential-- both for purposes of bolstering user understanding gained from coding and reinterpreting the data collaboratively, and for negotiating user-assigned labels for building effective machine learning models. We propose a conceptual definition of collective disagreement using diversity and divergence within the coding distributions. This perspective of disagreement translates to diverse coding contexts and groups of coders irrespective of discipline. We introduce two tree-based ranking metrics as standardized ways of comparing disagreements in how data instances have been coded. We empirically validate that, of the two tree-based metrics, coders' perceptions of dis- agreement match more closely with the n-ary tree metric than with the post-traversal tree metric.",
  "tags": [
    "theory",
    "qualitative coding",
    "disagreement",
    "ambiguity"
  ],
  "authors": [
    {
      "name": "Himanshu Zade",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87958668557",
      "orcid": "0000-0003-1755-7780"
    },
    {
      "name": "Margaret Drouhard",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658976741",
      "orcid": "missing"
    },
    {
      "name": "Bonnie Chinh",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659261848",
      "orcid": "missing"
    },
    {
      "name": "Lu Gan",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659261417",
      "orcid": "missing"
    },
    {
      "name": "Cecilia Aragon",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/do/10.1145/contrib-81502659190/rel-imgonly/cecilia_aragon_feb_2020_110x110.jpg",
      "acmid": "81502659190",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "David Armstrong, Ann Gosling, John Weinman, and Theresa Marteau. 1997. The place of inter-rater reliability in qualitative research: an empirical study. Sociology 31, 3 (1997), 597--606.",
      "doi": ""
    },
    {
      "text": "Lora Aroyo and Chris Welty. 2015. Truth is a lie: Crowd truth and the seven myths of human annotation. AI Magazine 36, 1 (2015), 15--24.",
      "doi": ""
    },
    {
      "text": "Laila Burla, Birte Knierim, Jurgen Barth, Katharina Liewald, Margreet Duetz, and Thomas Abel. 2008. From text to codings: intercoder reliability assessment in qualitative content analysis. Nursing research 57, 2 (2008), 113--117.",
      "doi": ""
    },
    {
      "text": "John L Campbell, Charles Quincy, Jordan Osserman, and Ove K Pedersen. 2013. Coding in-depth semistructured interviews: Problems of unitization and intercoder reliability and agreement. Sociological Methods & Research 42, 3 (2013), 294--320.",
      "doi": ""
    },
    {
      "text": "Joseph Chee Chang, Saleema Amershi, and Ece Kamar. 2017. Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets. In CHI 2017.",
      "doi": ""
    },
    {
      "text": "Jacob Cohen. 1960. A Coefficient of Agreement for Nominal Scales. Educational and Psychological Measurement 20, 1 (1960), 37--46.",
      "doi": ""
    },
    {
      "text": "David M Corey, William P Dunlap, and Michael J Burke. 1998. Averaging correlations: Expected values and bias in combined Pearson rs and Fisher's z transformations. The Journal of general psychology 125, 3 (1998), 245--261.",
      "doi": ""
    },
    {
      "text": "Benedetto De Martino, Dharshan Kumaran, Ben Seymour, and Raymond J. Dolan. 2006. Frames, Biases, and Rational Decision-Making in the Human Brain. Science 313, 5787 (2006), 684--687. http://science.sciencemag.org/content/313/5787/684",
      "doi": ""
    },
    {
      "text": "Ryan Drapeau, Lydia B Chilton, Jonathan Bragg, and Daniel S Weld. 2016. Microtalk: Using argumentation to improve crowdsourcing accuracy. In Fourth AAAI Conference on Human Computation and Crowdsourcing.",
      "doi": ""
    },
    {
      "text": "M. Drouhard, N. C. Chen, J. Suh, R. Kocielnik, V. Pena-Araya, K. Cen, Xiangyi Zheng, and C. R. Aragon. 2017. Aeonium: Visual analytics to support collaborative qualitative coding. In 2017 IEEE Pacific Visualization Symposium (PacificVis). 220--229.",
      "doi": ""
    },
    {
      "text": "Anca Dumitrache. 2015. Crowdsourcing Disagreement for Collecting Semantic Annotation. In European Semantic Web Conference. Springer, 701--710.  ",
      "doi": "10.1007/978-3-319-18818-8_43"
    },
    {
      "text": "Nicholas Epley and Thomas Gilovich. 2006. The anchoring-and-adjustment heuristic Why the adjustments are insufficient. Psychological science 17, 4 (2006), 311--318.",
      "doi": ""
    },
    {
      "text": "Frank Fischer, Johannes Bruhn, Cornelia Gr\u00e4sel, and Heinz Mandl. 2002. Fostering collaborative knowledge construction with visualization tools. Learning and Instruction 12, 2 (2002), 213--232.",
      "doi": ""
    },
    {
      "text": "Ronald A Fisher. 1915. Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population. Biometrika 10, 4 (1915), 507--521.",
      "doi": ""
    },
    {
      "text": "Ronald A Fisher. 1921. On the probable error of a coefficient of correlation deduced from a small sample. Metron 1 (1921), 3--32.",
      "doi": ""
    },
    {
      "text": "D Randy Garrison, Martha Cleveland-Innes, Marguerite Koole, and James Kappelman. 2006. Revisiting methodological issues in transcript analysis: Negotiated coding and reliability. The Internet and Higher Education 9, 1 (2006), 1--8.",
      "doi": ""
    },
    {
      "text": "Richard L Gorsuch and Curtis S Lehmann. 2010. Correlation coefficients: Mean bias and confidence interval distortions. Journal of Methods and Measurement in the Social Sciences 1, 2 (2010), 52--65.",
      "doi": ""
    },
    {
      "text": "Kilem Li Gwet. 2008. Computing inter-rater reliability and its variance in the presence of high agreement. Brit. J. Math. Statist. Psych. 61, 1 (2008), 29--48.",
      "doi": ""
    },
    {
      "text": "Kevin A Hallgren. 2012. Computing inter-rater reliability for observational data: an overview and tutorial. Tutorials in quantitative methods for psychology 8, 1 (2012), 23.",
      "doi": ""
    },
    {
      "text": "Daniel J Hruschka, Deborah Schwartz, Daphne Cobb St John, Erin Picone-Decaro, Richard A Jenkins, and James W Carey. 2004. Reliability in coding open-ended data: Lessons learned from HIV behavioral research. Field Methods 16, 3 (2004), 307--331.",
      "doi": ""
    },
    {
      "text": "Sanjay Kairam and Jeffrey Heer. 2016. Parting Crowds: Characterizing Divergent Interpretations in Crowdsourced Annotation Tasks. In CSCW 2016.  ",
      "doi": "10.1145/2818048.2820016"
    },
    {
      "text": "Katie Kuksenok, Michael Brooks, John J Robinson, Daniel Perry, Megan K Torkildson, and Cecilia Aragon. 2012. Automating large-scale annotation for analysis of social media content. In IEEE Workshop on Interactive Visual Text Analytics for Analysis of Social Media.",
      "doi": ""
    },
    {
      "text": "Walter S Lasecki, Mitchell Gordon, Danai Koutra, Malte F Jung, Steven P Dow, and Jeffrey P Bigham. 2014. Glance: Rapidly coding behavioral video with the crowd. In UIST 2014.  ",
      "doi": "10.1145/2642918.2647367"
    },
    {
      "text": "Margaret D LeCompte. 2000. Analyzing Qualitative Data. Theory into practice 39, 3 (2000), 146--154.",
      "doi": ""
    },
    {
      "text": "Mary L McHugh. 2012. Interrater reliability: the kappa statistic. Biochemia medica 22, 3 (2012), 276--282.",
      "doi": ""
    },
    {
      "text": "Slava Mikhaylov, Michael Laver, and Kenneth R Benoit. 2012. Coder reliability and misclassification in the human coding of party manifestos. Political Analysis 20, 1 (2012), 78--91.",
      "doi": ""
    },
    {
      "text": "Dan J Putka, Huy Le, Rodney A McCloy, and Tirso Diaz. 2008. Ill-structured measurement designs in organizational research: Implications for estimating interrater reliability. Journal of Applied Psychology 93, 5 (2008), 959.",
      "doi": ""
    },
    {
      "text": "Johnny Salda\u00f1a. 2015. The Coding Manual for Qualitative Researchers. Sage.",
      "doi": ""
    },
    {
      "text": "Anselm L Strauss. 1987. Qualitative Analysis for Social Scientists. Cambridge University Press.",
      "doi": ""
    },
    {
      "text": "Jasy Liew Suet Yan, Nancy McCracken, Shichun Zhou, and Kevin Crowston. 2014. Optimizing features in active machine learning for complex qualitative content analysis. ACL 2014 44 (2014).",
      "doi": ""
    }
  ]
}