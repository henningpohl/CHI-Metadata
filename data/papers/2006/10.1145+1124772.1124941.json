{
  "doi": "10.1145/1124772.1124941",
  "title": "Feeling what you hear: tactile feedback for navigation of audio graphs",
  "published": "2006-04-22",
  "proctitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "1123-1132",
  "year": 2006,
  "badges": [],
  "abstract": "Access to digitally stored numerical data is currently very limited for sight impaired people. Graphs and visualizations are often used to analyze relationships between numerical data, but the current methods of accessing them are highly visually mediated. Representing data using audio feedback is a common method of making data more accessible, but methods of navigating and accessing the data are often serial in nature and laborious. Tactile or haptic displays could be used to provide additional feedback to support a point-and-click type interaction for the visually impaired. A requirements capture conducted with sight impaired computer users produced a review of current accessibility technologies, and guidelines were extracted for using tactile feedback to aid navigation. The results of a qualitative evaluation with a prototype interface are also presented. Providing an absolute position input device and tactile feedback allowed the users to explore the graph using tactile and proprioceptive cues in a manner analogous to point-and-click techniques.",
  "tags": [
    "audio",
    "blind",
    "graph",
    "navigation",
    "tactile",
    "guidelines",
    "multimodal",
    "accessibility"
  ],
  "authors": [
    {
      "name": "Steven Wall",
      "institution": "University of Glasgow, Glasgow, UK",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100438904",
      "orcid": "missing"
    },
    {
      "name": "Stephen Brewster",
      "institution": "University of Glasgow, Glasgow, UK",
      "img": "/do/10.1145/contrib-81100359199/rel-imgonly/img_5764.jpg",
      "acmid": "81100359199",
      "orcid": "0000-0001-9720-3899"
    }
  ],
  "references": [
    {
      "text": "Kramer, G. An introduction to auditory display In Kramer, G. (Ed.) Auditory display. Addison-Wesley, 1994, 1--78.]]",
      "doi": ""
    },
    {
      "text": "Brown, L. M., Brewster, S., Ramloll, R., Yu, W. and Riedel, B. Browsing modes for sonified line graphs In Vol. II Proceedings of British HCI 2002, (2002), 2--5.]]",
      "doi": ""
    },
    {
      "text": "Ramloll, R. and Brewster, S. A. An environment for studying the impact of spatialising sonified graphs on data comprehension In Information Visualisation 2002, IEEE (2002), 167--174.]]",
      "doi": ""
    },
    {
      "text": "Zhao, H., Plaisant, C., Shneiderman, B. and Duraiswami, R. Sonification of geo-referenced data for auditory information seeking: Design principle and pilot study In Proceedings of the International Conference on Auditory Display (ICAD), (2004).]]",
      "doi": ""
    },
    {
      "text": "Shneiderman, B. The eyes have it: A task by data type taxonomy for information visualization In Proceedings of the IEEE Symposium on Visual Languages, (1996), 336--343.]] ",
      "doi": "10.5555/832277.834354"
    },
    {
      "text": "Fritz, J. P. and Barner, K. Design of a haptic graphing system In 19th RESNA Conference, (1996).]]",
      "doi": ""
    },
    {
      "text": "Wall, S. and Brewster, S. Providing external memory aids in haptic visualisations for blind computer users In The Fifth International Conference on Disability, Virtual Reality and Associated Technologies, School of Systems Engineering, University of Reading, UK (2004).]]",
      "doi": ""
    },
    {
      "text": "Yu, W. and Brewster, S. Comparing two haptic interfaces for multimodal graph rendering In IEEE VR2002, 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, (2002).]] ",
      "doi": "10.5555/795682.797511"
    },
    {
      "text": "Vanderheiden, G. C. Nonvisual alternative display techniques for output from graphics-based computers. Journal of Visual Impairment and Blindness 83, 8 (1989), 383--390.]]",
      "doi": ""
    },
    {
      "text": "Craig, J. C. and Sherrick, C. E. Dynamic tactile displays In Schiff, W. and Foulke, E. (Ed.) Tactual perception: A sourcebook. Cambridge University Press, 1982, 209--233.]]",
      "doi": ""
    },
    {
      "text": "Curcio, F. R. Comprehension of mathematical relationships expressed in graphs. journal for research in mathematics education 18, 5 (1987), 382--393.]]",
      "doi": ""
    },
    {
      "text": "Challis, B. P. and Edwards, A. D. N. Design principles for tactile interaction In Brewster, S. and Murray-Smith, R. (Ed.) Haptic hci 200. Springer-Verlag, 2001, 17--24.]] ",
      "doi": "10.5555/645443.652690"
    },
    {
      "text": "Wells, L. R. and Landau, S. Merging of tactile sensory input and audio data by means of the talking tactile tablet In Eurohaptics 2003, Media Lab Europe (2003), 414--418.]]",
      "doi": ""
    },
    {
      "text": "Parkes, D. \"\"nomad\"\": An audio-tactile tool for the acquisition, use and management of spatially distributed information by visually impaired people In Proceedings of the Second International Symposium on Maps and Graphics for Visually Impaired People, (1988), 24--29.]]",
      "doi": ""
    },
    {
      "text": "Sjostrom, C. Using haptics in computer interfaces for blind people In CHI 2001, ACM Press Addison-Wesley, pp 155-156 (2001), 245--246.]]  ",
      "doi": "10.1145/634067.634213"
    }
  ]
}