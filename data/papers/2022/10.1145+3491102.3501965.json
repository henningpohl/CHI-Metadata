{
  "doi": "10.1145/3491102.3501965",
  "title": "Shared Interest: Measuring Human-AI Alignment to Identify Recurring Patterns in Model Behavior",
  "published": "2022-04-28",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-17",
  "year": 2022,
  "badges": [],
  "abstract": "Saliency methods\u00a0\u2014\u00a0techniques to identify the importance of input features on a model\u2019s output\u00a0\u2014\u00a0are a common step in understanding neural network behavior. However, interpreting saliency requires tedious manual inspection to identify and aggregate patterns in model behavior, resulting in ad hoc or cherry-picked analysis. To address these concerns, we present Shared Interest: metrics for comparing model reasoning (via saliency) to human reasoning (via ground truth annotations). By providing quantitative descriptors, Shared Interest enables ranking, sorting, and aggregating inputs, thereby facilitating large-scale systematic analysis of model behavior. We use Shared Interest to identify eight recurring patterns in model behavior, such as cases where contextual features or a subset of ground truth features are most important to the model. Working with representative real-world users, we show how Shared Interest can be used to decide if a model is trustworthy, uncover issues missed in manual analyses, and enable interactive probing.",
  "authors": [
    {
      "name": "Angie Boggust",
      "institution": "CSAIL, Massachusetts Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660050170",
      "orcid": "missing"
    },
    {
      "name": "Benjamin Hoover",
      "institution": "IBM Research, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659693002",
      "orcid": "0000-0001-5218-3185"
    },
    {
      "name": "Arvind Satyanarayan",
      "institution": "CSAIL, Massachusetts Institute of Technology, United States",
      "img": "/do/10.1145/contrib-81500663321/rel-imgonly/arvind-satyanarayan.jpg",
      "acmid": "81500663321",
      "orcid": "0000-0001-5564-635X"
    },
    {
      "name": "Hendrik Strobelt",
      "institution": "IBM Research, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81444607610",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Julius Adebayo, Justin Gilmer, Michael Muelly, Ian\u00a0J. Goodfellow, Moritz Hardt, and Been Kim. 2018. Sanity Checks for Saliency Maps. In Proceedings of the Conference on Neural Information Processing Systems (NeurIPS). Montr\u00e9al, Canada, 9525\u20139536.",
      "doi": ""
    },
    {
      "text": "Julius Adebayo, Michael Muelly, Ilaria Liccardi, and Been Kim. 2020. Debugging Tests for Model Explanations. arXiv preprint arXiv:2011.05429(2020).",
      "doi": ""
    },
    {
      "text": "David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. 2017. Network Dissection: Quantifying Interpretability of Deep Visual Representations. In Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, Honolulu, USA, 3319\u20133327.",
      "doi": ""
    },
    {
      "text": "Lucas Beyer, Olivier\u00a0J. H\u00e9naff, Alexander Kolesnikov, Xiaohua Zhai, and A\u00e4ron van\u00a0den Oord. 2020. Are we done with ImageNet?arxiv:2006.07159\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Abeba Birhane and Vinay\u00a0Uday Prabhu. 2021. Large image datasets: A pyrrhic win for computer vision?. In Proceedings of the Winter Conference on Applications of Computer Vision (WACV). IEEE, Waikoloa, USA, 1536\u20131546.",
      "doi": ""
    },
    {
      "text": "Brandon Carter, Siddhartha Jain, Jonas Mueller, and David Gifford. 2021. Overinterpretation reveals image classification model pathologies. In Proceedings of the Conference on Neural Information Processing Systems (NeurIPS). Virtual Event.",
      "doi": ""
    },
    {
      "text": "Brandon Carter, Jonas Mueller, Siddhartha Jain, and David\u00a0K. Gifford. 2019. What made you do this? Understanding black-box decisions with sufficient input subsets. In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS). PMLR, Naha, Japan, 567\u2013576.",
      "doi": ""
    },
    {
      "text": "Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah. 2019. Activation Atlas. Distill (2019). https://doi.org/10.23915/distill.00015 https://distill.pub/2019/activation-atlas.",
      "doi": ""
    },
    {
      "text": "Noel Codella, Veronica Rotemberg, Philipp Tschandl, M.\u00a0Emre Celebi, Stephen Dusza, David Gutman, Brian Helba, Aadi Kalloo, Konstantinos Liopyris, Michael Marchetti, Harald Kittler, and Allan Halpern. 2019. Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC). arxiv:1902.03368\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. ImageNet: A large-scale hierarchical image database. In Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, Miami, USA, 248\u2013255.",
      "doi": ""
    },
    {
      "text": "Finale Doshi-Velez and Been Kim. 2017. Towards A Rigorous Science of Interpretable Machine Learning. arxiv:1702.08608\u00a0[stat.ML]",
      "doi": ""
    },
    {
      "text": "Dumitru Erhan, Y. Bengio, Aaron Courville, and Pascal Vincent. 2009. Visualizing Higher-Layer Features of a Deep Network. Technical Report, Univerist\u00e9 de Montr\u00e9al(2009).",
      "doi": ""
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto\u00a0A. Novoa, Justin Ko, Susan\u00a0M. Swetter, Helen\u00a0M. Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 7639 (2017), 115\u2013118.",
      "doi": ""
    },
    {
      "text": "David Gutman, Noel C.\u00a0F. Codella, Emre Celebi, Brian Helba, Michael Marchetti, Nabin Mishra, and Allan Halpern. 2016. Skin Lesion Analysis toward Melanoma Detection: A Challenge at the International Symposium on Biomedical Imaging (ISBI) 2016, hosted by the International Skin Imaging Collaboration (ISIC). arxiv:1605.01397\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, Las Vegas, USA, 770\u2013778.",
      "doi": ""
    },
    {
      "text": "Fred Hohman, Minsuk Kahng, Robert Pienta, and Duen\u00a0Horng Chau. 2019. Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers. IEEE Transactions on Visualization and Computer Graphics 25, 8(2019), 2674\u20132693.",
      "doi": "10.1109/TVCG.2018.2843369"
    },
    {
      "text": "Fred Hohman, Haekyu Park, Caleb Robinson, and Duen Horng\u00a0(Polo) Chau. 2020. Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations. IEEE Transactions on Visualization and Computer Graphics 26, 1(2020), 1096\u20131106.",
      "doi": "10.1109/TVCG.2019.2934659"
    },
    {
      "text": "Benjamin Hoover, Hendrik Strobelt, and Sebastian Gehrmann. 2020. exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models. In Proceedings of the Annual Meeting of the Association for Computational Linguistics: System Demonstrations (ACL). ACL, Virtual Event, 187\u2013196.",
      "doi": ""
    },
    {
      "text": "Minsuk Kahng, Pierre\u00a0Y. Andrews, Aditya Kalro, and Duen Horng\u00a0(Polo) Chau. 2018. ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models. IEEE Transactions on Visualization and Computer Graphics 24, 1(2018), 88\u201397.",
      "doi": ""
    },
    {
      "text": "Minsuk Kahng, Nikhil Thorat, Duen Horng\u00a0(Polo) Chau, Fernanda\u00a0B. Vi\u00e9gas, and Martin Wattenberg. 2019. GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation. IEEE Transactions on Visualization and Computer Graphics 25, 1(2019), 310\u2013320.",
      "doi": "10.1109/TVCG.2018.2864500"
    },
    {
      "text": "Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, and Rory Sayres. 2018. Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV). In Proceedings of the International Conference on Machine Learning (ICML). PMLR, Stockholm, Sweden, 2668\u20132677.",
      "doi": ""
    },
    {
      "text": "Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof\u00a0T. Sch\u00fctt, Sven D\u00e4hne, Dumitru Erhan, and Been Kim. 2019. The (Un)reliability of Saliency Methods. In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Vol.\u00a011700. Springer, 267\u2013280.",
      "doi": ""
    },
    {
      "text": "Diederik\u00a0P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In Proceedings of the International Conference on Learning Representations (ICLR). San Diego, USA.",
      "doi": ""
    },
    {
      "text": "Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal Alsallakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos Araya, Siqi Yan, and Orion Reblitz-Richardson. 2020. Captum: A unified and generic model interpretability library for PyTorch. arxiv:2009.07896\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Tao Lei, Regina Barzilay, and Tommi\u00a0S. Jaakkola. 2016. Rationalizing Neural Predictions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). ACL, Austin, USA, 107\u2013117.",
      "doi": ""
    },
    {
      "text": "Scott\u00a0M. Lundberg and Su-In Lee. 2017. A Unified Approach to Interpreting Model Predictions. In Proceedings of the Conference on Neural Information Processing Systems (NIPS). Long Beach, USA, 4765\u20134774.",
      "doi": ""
    },
    {
      "text": "Julian\u00a0J. McAuley, Jure Leskovec, and Dan Jurafsky. 2012. Learning Attitudes and Attributes from Multi-aspect Reviews. In Proceedings of the International Conference on Data Mining (ICDM). IEEE, Brussels, Belgium, 1020\u20131025.",
      "doi": "10.1109/ICDM.2012.110"
    },
    {
      "text": "Christopher Meek. 2016. A Characterization of Prediction Errors. arxiv:1611.05955\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. Comput. Surveys 54, 6 (2021), 115:1\u2013115:35.",
      "doi": "10.1145/3457607"
    },
    {
      "text": "Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, and Alexander Mordvintsev. 2018. The Building Blocks of Interpretability. Distill (2018). https://doi.org/10.23915/distill.00010 https://distill.pub/2018/building-blocks.",
      "doi": ""
    },
    {
      "text": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward\u00a0Z. Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Proceedings of the Conference on Neural Information Processing Systems (NeurIPS). Vancouver, Canada, 8024\u20138035.",
      "doi": ""
    },
    {
      "text": "Arun Rai. 2020. Explainable AI: From black box to glass box. Journal of the Academy of Marketing Science 48, 1 (2020), 137\u2013141.",
      "doi": ""
    },
    {
      "text": "Donghao Ren, Saleema Amershi, Bongshin Lee, Jina Suh, and Jason\u00a0D. Williams. 2017. Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers. IEEE Transactions on Visualization and Computer Graphics 23, 1(2017), 61\u201370.",
      "doi": "10.1109/TVCG.2016.2598828"
    },
    {
      "text": "Marco\u00a0Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \u201dWhy Should I Trust You?\u201d: Explaining the Predictions of Any Classifier. In Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD). ACM, San Francisco, USA, 1135\u20131144.",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Ramprasaath\u00a0R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization. In Proceedings of the International Conference on Computer Vision (ICCV). IEEE, Venice, Italy, 618\u2013626.",
      "doi": ""
    },
    {
      "text": "Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. In Proceedings of the International Conference on Learning Representations (ICLR), Workshop Track. Banff, Canada.",
      "doi": ""
    },
    {
      "text": "Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda\u00a0B. Vi\u00e9gas, and Martin Wattenberg. 2017. SmoothGrad: removing noise by adding noise. arxiv:1706.03825\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Jost\u00a0Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin\u00a0A. Riedmiller. 2015. Striving for Simplicity: The All Convolutional Net. In Proceedings of the International Conference on Learning Representations (ICLR), Workshop Track, Yoshua Bengio and Yann LeCun (Eds.). San Diego, USA.",
      "doi": ""
    },
    {
      "text": "Hendrik Strobelt, Sebastian Gehrmann, Hanspeter Pfister, and Alexander\u00a0M. Rush. 2018. LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks. IEEE Transactions on Visualization and Computer Graphics 24, 1(2018), 667\u2013676.",
      "doi": ""
    },
    {
      "text": "Pascal Sturmfels, Scott Lundberg, and Su-In Lee. 2020. Visualizing the Impact of Feature Attribution Baselines. Distill (2020). https://doi.org/10.23915/distill.00022 https://distill.pub/2020/attribution-baselines.",
      "doi": ""
    },
    {
      "text": "Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic Attribution for Deep Networks. In Proceedings of the International Conference on Machine Learning (ICML). PMLR, Sydney, Australia, 3319\u20133328.",
      "doi": ""
    },
    {
      "text": "Richard Tomsett, Dan Harborne, Supriyo Chakraborty, Prudhvi Gurram, and Alun\u00a0D. Preece. 2020. Sanity Checks for Saliency Metrics. In Proceedings of the Conference on Artificial Intelligence. AAAI, New York, USA, 6021\u20136029.",
      "doi": ""
    },
    {
      "text": "Philipp Tschandl, Cliff Rosendahl, and Harald Kittler. 2018. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Scientific Data 5, 1 (2018).",
      "doi": ""
    },
    {
      "text": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Andrew Ilyas, and Aleksander Madry. 2020. From ImageNet to Image Classification: Contextualizing Progress on Benchmarks. In Proceedings of the International Conference on Machine Learning (ICML), Vol.\u00a0119. PMLR, Virtual Event, 9625\u20139635.",
      "doi": ""
    },
    {
      "text": "Andrea Vedaldi and Stefano Soatto. 2008. Quick Shift and Kernel Methods for Mode Seeking. In Proceedings of the European Conference on Computer Vision (ECCV), David\u00a0A. Forsyth, Philip H.\u00a0S. Torr, and Andrew Zisserman (Eds.). Vol.\u00a05305. Springer, Marseille, France, 705\u2013718.",
      "doi": ""
    },
    {
      "text": "James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda\u00a0B. Vi\u00e9gas, and Jimbo Wilson. 2020. The What-If Tool: Interactive Probing of Machine Learning Models. IEEE Transactions on Visualization and Computer Graphics 26, 1(2020), 56\u201365.",
      "doi": ""
    },
    {
      "text": "Kanit Wongsuphasawat, Daniel Smilkov, James Wexler, Jimbo Wilson, Dandelion Man\u00e9, Doug Fritz, Dilip Krishnan, Fernanda\u00a0B. Vi\u00e9gas, and Martin Wattenberg. 2018. Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow. IEEE Transactions on Visualization and Computer Graphics 24, 1(2018), 1\u201312.",
      "doi": ""
    },
    {
      "text": "Kai\u00a0Yuanqing Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry. 2021. Noise or Signal: The Role of Image Backgrounds in Object Recognition. In Proceedings of the International Conference on Learning Representations (ICLR). OpenReview.net, Virtual Event.",
      "doi": ""
    },
    {
      "text": "Mengjiao Yang and Been Kim. 2019. Benchmarking Attribution Methods with Relative Feature Importance. arxiv:1907.09701\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Matthew\u00a0D. Zeiler and Rob Fergus. 2014. Visualizing and Understanding Convolutional Networks. In Proceedings of the European Conference on Computer Vision (ECCV), Vol.\u00a08689. Springer, Zurich, Switzerland, 818\u2013833.",
      "doi": ""
    }
  ]
}