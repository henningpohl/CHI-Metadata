{
  "doi": "10.1145/3491102.3501987",
  "title": "Analyzing Deaf and Hard-of-Hearing Users\u2019 Behavior, Usage, and Interaction with a Personal Assistant Device that Understands Sign-Language Input",
  "published": "2022-04-29",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2022,
  "badges": [],
  "abstract": "As voice-based personal assistant technologies proliferate, e.g., smart speakers in homes, and more generally as voice-control of technology becomes increasingly ubiquitous, new accessibility barriers are emerging for many Deaf and Hard of Hearing (DHH) users. Progress in sign-language recognition may enable devices to respond to sign-language commands and potentially mitigate these barriers, but research is needed to understand how DHH users would interact with these devices and what commands they would issue. In this work, we directly engage with the DHH community, using a Wizard-of-Oz prototype that appears to understand American Sign Language (ASL) commands. Our analysis of video recordings of DHH participants revealed how they woke-up the device to initiate commands, structured commands in ASL, and responded to device errors, providing guidance to future designers and researchers. We share our dataset of over 1400 commands, which may be of interest to sign-language-recognition researchers.",
  "authors": [
    {
      "name": "Abraham Glasser",
      "institution": "Computing and Information Sciences, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-99659181806/rel-imgonly/abraham_glasser.jpg",
      "acmid": "99659181806",
      "orcid": "missing"
    },
    {
      "name": "Matthew Watkins",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660237368",
      "orcid": "0000-0003-3133-8664"
    },
    {
      "name": "Kira Hart",
      "institution": "National Technical Institute for the Deaf, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660239464",
      "orcid": "missing"
    },
    {
      "name": "Sooyeon Lee",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659135375",
      "orcid": "0000-0002-4971-2004"
    },
    {
      "name": "Matt Huenerfauth",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-81100240888/rel-imgonly/huenerfauth-matt-headshot-1.jpg",
      "acmid": "81100240888",
      "orcid": "0000-0001-6290-2681"
    }
  ],
  "references": [
    {
      "text": "Charlotte Baker-Shenk and Dennis Cokley. 2002. American Sign Language: A Teachers Resource Text on Grammar and Culture. Gallaudet University Press.",
      "doi": ""
    },
    {
      "text": "Danielle Bragg, Naomi Caselli, Julie\u00a0A. Hochgesang, Matt Huenerfauth, Leah Katz-Hernandez, Oscar Koller, Raja Kushalnagar, Christian Vogler, and Richard\u00a0E. Ladner. 2021. The FATE Landscape of Sign Language AI Datasets: An Interdisciplinary Perspective. ACM Trans. Access. Comput. 14, 2, Article 7 (July 2021), 45\u00a0pages. https://doi.org/10.1145/3436996",
      "doi": "10.1145/3436996"
    },
    {
      "text": "Danielle Bragg, Oscar Koller, Mary Bellard, Larwan Berke, Patrick Boudreault, Annelies Braffort, Naomi Caselli, Matt Huenerfauth, Hernisa Kacorri, Tessa Verhoef, Christian Vogler, and Meredith Ringel\u00a0Morris. 2019. Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility (Pittsburgh, PA, USA) (ASSETS \u201919). Association for Computing Machinery, New York, NY, USA, 16\u201331. https://doi.org/10.1145/3308561.3353774",
      "doi": "10.1145/3308561.3353774"
    },
    {
      "text": "Convo. 2021. Convo VRS. https://www.convorelay.com/",
      "doi": ""
    },
    {
      "text": "Michael Erard. 2017. Why Sign-Language Gloves Don\u2019t Help Deaf People. https://www.theatlantic.com/technology/archive/2017/11/why-sign-language-gloves-dont-help-deaf-people/545441/",
      "doi": ""
    },
    {
      "text": "Abraham Glasser. 2019. Automatic Speech Recognition Services: Deaf and Hard-of-Hearing Usability. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI EA \u201919). Association for Computing Machinery, New York, NY, USA, 1\u20136. https://doi.org/10.1145/3290607.3308461",
      "doi": "10.1145/3290607.3308461"
    },
    {
      "text": "Abraham Glasser, Vaishnavi Mande, and Matt Huenerfauth. 2021. Understanding Deaf and Hard-of-Hearing Users\u2019 Interest in Sign-Language Interaction with Personal-Assistant Devices. Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3430263.3452428",
      "doi": ""
    },
    {
      "text": "Google. 2021. Use gestures on your Pixel phone. https://support.google.com/pixelphone/answer/7443425?hl=en",
      "doi": ""
    },
    {
      "text": "Maarten Grootendorst. 2020. BERTopic: Leveraging BERT and c-TF-IDF to create easily interpretable topics.https://doi.org/10.5281/zenodo.4381785",
      "doi": ""
    },
    {
      "text": "Matthew\u00a0B. Hoy. 2018. Alexa, Siri, Cortana, and More: An Introduction to Voice Assistants. Medical Reference Services Quarterly 37, 1 (2018), 81\u201388. https://doi.org/10.1080/02763869.2018.1404391",
      "doi": ""
    },
    {
      "text": "Xuedong Huang. 2017. Microsoft researchers achieve new conversational speech recognition milestone. https://www.microsoft.com/en-us/research/blog/microsoft-researchers-achieve-new-conversational-speech-recognition-milestone/",
      "doi": ""
    },
    {
      "text": "IBM. 2017. Reaching new records in speech recognition. https://www.ibm.com/blogs/watson/2017/03/reaching-new-records-in-speech-recognition/",
      "doi": ""
    },
    {
      "text": "Sushant Kafle, Abraham Glasser, Sedeeq Al-khazraji, Larwan Berke, Matthew Seita, and Matt Huenerfauth. 2020. Artificial Intelligence Fairness in the Context of Accessibility Research on Intelligent Systems for People Who Are Deaf or Hard of Hearing. SIGACCESS Access. Comput.125, Article 4 (March 2020), 1\u00a0pages. https://doi.org/10.1145/3386296.3386300",
      "doi": ""
    },
    {
      "text": "Svetlana Kouznetsova. 2016. Why the Signing Gloves Hype Needs to Stop. https://audio-accessibility.com/news/2016/05/signing-gloves-hype-needs-stop/",
      "doi": ""
    },
    {
      "text": "Abner Li. 2020. \u2018Hey Google\u2019 hotword training updated to boost Voice Match accuracy. https://9to5google.com/2020/04/23/hey-google-voice-match/",
      "doi": ""
    },
    {
      "text": "Ceil Lucas and Clayton Valli. 1992. Language Contact in the American Deaf Community. Brill.",
      "doi": ""
    },
    {
      "text": "Vaishnavi Mande, Abraham Glasser, Becca Dingman, and Matt Huenerfauth. 2021. Deaf Users\u2019 Preferences Among Wake-Up Approaches during Sign-Language Interaction with Personal Assistant Devices. Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3411763.3451592",
      "doi": ""
    },
    {
      "text": "Richard Meier. 1990. Person deixis in American sign language. Theoretical issues in sign language research 1 (1990), 175\u2013190.",
      "doi": ""
    },
    {
      "text": "Chelsea\u00a0M. Myers, Luis\u00a0Fernando Laris\u00a0Pardo, Ana Acosta-Ruiz, Alessandro Canossa, and Jichen Zhu. 2021. \u201cTry, Try, Try Again:\u201d Sequence Analysis of User Interaction Data with a Voice User Interface. In CUI 2021 - 3rd Conference on Conversational User Interfaces (Bilbao (online), Spain) (CUI \u201921). Association for Computing Machinery, New York, NY, USA, Article 18, 8\u00a0pages. https://doi.org/10.1145/3469595.3469613",
      "doi": "10.1145/3469595.3469613"
    },
    {
      "text": "Carol Neidle, Judy Kegl, Dawn MacLaughlin, Benjamin Bahan, and Robert\u00a0G. Lee. 2008. The Syntax of American Sign Language: Functional Categories and Hierarchical Structure. MIT Press.",
      "doi": ""
    },
    {
      "text": "Carol Neidle, Ashwin Thangali, and Stan Sclaroff. 2012. Challenges in development of the American Sign Language Lexicon Video Dataset (ASLLVD) corpus. In 5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon(LREC 2012). http://www.bu.edu/linguistics/UG/LREC2012/LREC-asllvd-final.pdf",
      "doi": ""
    },
    {
      "text": "Christi Olson and Kelli Kemery. 2019. 2019 Microsoft Voice report. https://about.ads.microsoft.com/en-us/insights/2019-voice-report",
      "doi": ""
    },
    {
      "text": "Alisha Pradhan, Kanika Mehta, and Leah Findlater. 2018. \u201dAccessibility Came by Accident\u201d: Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI \u201918). Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3173574.3174033",
      "doi": "10.1145/3173574.3174033"
    },
    {
      "text": "Jason Rodolitz, Evan Gambill, Brittany Willis, Christian Vogler, and Raja Kushalnagar. 2019. Accessibility of Voice-Activated Agents for People who are Deaf or Hard of Hearing. Journal on Technology and Persons with Disabilities 7 (2019), 144\u2013156. http://hdl.handle.net/10211.3/210397",
      "doi": ""
    },
    {
      "text": "John Shinal. 2017. Making sense of Google CEO Sundar Pichai\u2019s plan to move every direction at once. https://www.cnbc.com/2017/05/18/google-ceo-sundar-pichai-machine-learning-big-data.html",
      "doi": ""
    },
    {
      "text": "SignGenius. 2020. Do\u2019s & Don\u2019ts - Getting Attention in the Deaf Community. https://www.signgenius.com/info-dos&donts.html",
      "doi": ""
    },
    {
      "text": "Greg Sterling. 2018. Study: Google Assistant most accurate, Alexa most improved virtual assistant. https://searchengineland.com/study-google-assistant-most-accurate-alexa-most-improved-virtual-assistant-296936",
      "doi": ""
    },
    {
      "text": "Xuchen Yao, Guoguo Chen, and Yuan Cao. 2017. Developing Your Own Wake Word Engine Just Like \u2019Alexa\u2019 and \u2019OK Google\u2019. https://gputechconf2017.smarteventscloud.com/connect/sessionDetail.ww?SESSION_ID=112905",
      "doi": ""
    },
    {
      "text": "Sihan Yuan, Birgit Br\u00fcggemeier, Stefan Hillmann, and Thilo Michael. 2020. User Preference and Categories for Error Responses in Conversational User Interfaces. In Proceedings of the 2nd Conference on Conversational User Interfaces (Bilbao, Spain) (CUI \u201920). Association for Computing Machinery, New York, NY, USA, Article 5, 8\u00a0pages. https://doi.org/10.1145/3405755.3406126",
      "doi": "10.1145/3405755.3406126"
    }
  ]
}