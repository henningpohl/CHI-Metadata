{
  "doi": "10.1145/3491102.3517606",
  "title": "What\u2019s the Appeal? Perceptions of Review Processes for Algorithmic Decisions",
  "published": "2022-04-29",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-15",
  "year": 2022,
  "badges": [],
  "abstract": "If you were significantly impacted by an algorithmic decision, how would you want the decision to be reviewed? In this study, we explore perceptions of review processes for algorithmic decisions that differ across three dimensions: the reviewer, how the review is conducted, and how long the review takes. Using a choice-based conjoint analysis we find that people prefer review processes that provide for human review, the ability to participate in the review process, and a timely outcome. Using a survey, we find that people also see human review that provides for participation to be the fairest review process. Our qualitative analysis indicates that the fairest review process provides the greatest likelihood of a favourable outcome, an opportunity for the decision subject and their situation to be fully and accurately understood, human involvement, and dignity. These findings have implications for the design of contestation procedures and also the design of algorithmic decision-making processes.",
  "authors": [
    {
      "name": "Henrietta Lyons",
      "institution": "School of Computing and Information Systems, University of Melbourne, Australia",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659698407",
      "orcid": "missing"
    },
    {
      "name": "Senuri Wijenayake",
      "institution": "School of Architecture, Design and Planning, The University of Sydney, Australia",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659320986",
      "orcid": "missing"
    },
    {
      "name": "Tim Miller",
      "institution": "School of Computing and Information Systems, Universtity of Melbourne, Australia",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81407592901",
      "orcid": "missing"
    },
    {
      "name": "Eduardo Velloso",
      "institution": "School of Computing and Information Systems, University of Melbourne, Australia",
      "img": "/do/10.1145/contrib-81488669445/rel-imgonly/profilepic.jpg",
      "acmid": "81488669445",
      "orcid": "0000-0003-4414-2249"
    }
  ],
  "references": [
    {
      "text": "J\u00a0Stacy Adams. 1965. Inequity in Social Exchange. In Advances in Experimental Social Psychology. Vol.\u00a02. Elsevier, 267\u2013299.",
      "doi": ""
    },
    {
      "text": "Richard Adams and Heather Stewart. 2020. Ofqual \u2018blindsided\u2019 government by revoking A-level appeals process. Retrieved May 4, 2021 from https://www.theguardian.com/education/2020/aug/16/ofqual-blindsided-government-by-revoking-a-level-appeals-process.",
      "doi": ""
    },
    {
      "text": "Sheldon Alexander and Marian Ruderman. 1987. The role of procedural and distributive justice in organizational behavior. Social Justice Research 1, 2 (1987), 177\u2013198.",
      "doi": ""
    },
    {
      "text": "Marco Almada. 2019. Human Intervention in Automated Decision-making: Toward the Construction of Contestable Systems. In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law(ICAIL \u201919). 2\u201311.",
      "doi": "10.1145/3322640.3326699"
    },
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine Bias. Retrieved 24 July 2020 from https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.",
      "doi": ""
    },
    {
      "text": "Theo Araujo, Natali Helberger, Sanne Kruikemeier, and Claes\u00a0H De\u00a0Vreese. 2020. In AI we trust? Perceptions about automated decision-making by artificial intelligence. AI & Society (2020), 1\u201313.",
      "doi": ""
    },
    {
      "text": "Judith Bannister, Anna Olijnyk, and Stephen McDonald. 2018. Government accountability: Australian administrative law (2nd. ed.). Cambridge University Press, Port Melbourne, Vic.",
      "doi": ""
    },
    {
      "text": "Emre Bayaml\u0131o\u011flu. 2021. The right to contest automated decisions under the General Data Protection Regulation: Beyond the so-called \u201cright to explanation\u201d. Regulation & Governance(2021).",
      "doi": ""
    },
    {
      "text": "Reuben Binns, Max Van\u00a0Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. \u201cIt\u2019s Reducing a Human Being to a Percentage\u201d: Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI \u201918). ACM, 1\u201314. https://doi.org/10.1145/3173574.3173951",
      "doi": "10.1145/3173574.3173951"
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative Research in Psychology 3 (2006), 77\u2013101.",
      "doi": "10.1191/1478088706QP063OA"
    },
    {
      "text": "Kiel Brennan-Marquez and Stephen Henderson. 2019. Artificial Intelligence and Role-Reversible Judgment. Journal of Criminal Law and Criminology 109, 1, Article 2(2019), 27\u00a0pages.",
      "doi": ""
    },
    {
      "text": "Maja Brkan. 2019. Do algorithms rule the world? Algorithmic decision-making and data protection in the framework of the GDPR and beyond. International Journal of Law and Information Technology 27, 2(2019), 91\u2013121.",
      "doi": ""
    },
    {
      "text": "Noah Castelo, Maarten\u00a0W Bos, and Donald\u00a0R Lehmann. 2019. Task-dependent algorithm aversion. Journal of Marketing Research 56, 5 (2019), 809\u2013825.",
      "doi": ""
    },
    {
      "text": "Danielle\u00a0Keats Citron and Frank Pasquale. 2014. The scored society: Due process for automated predictions. Wash. L. Rev. 89(2014), 1.",
      "doi": ""
    },
    {
      "text": "Ludovik Coba, Laurens Rook, Markus Zanker, and Panagiotis Symeonidis. 2019. Decision making strategies differ in the presence of collaborative explanations: two conjoint studies. In Proceedings of the 24th International Conference on Intelligent User Interfaces. 291\u2013302.",
      "doi": "10.1145/3301275.3302304"
    },
    {
      "text": "Jason\u00a0A Colquitt, Donald\u00a0E Conlon, Michael\u00a0J Wesson, Christopher\u00a0OLH Porter, and K\u00a0Yee Ng. 2001. Justice at the Millennium: A Meta-Analytic Review of 25 Years of Organizational Justice Research.Journal of Applied Psychology 86, 3 (2001), 425.",
      "doi": ""
    },
    {
      "text": "Jason\u00a0A Colquitt and Jessica\u00a0B Rodell. 2015. Measuring justice and fairness. In The Oxford Handbook of Justice in the Workplace, Russell\u00a0S. Cropanzano and Maureen\u00a0L. Ambrose (Eds.). Oxford University Press.",
      "doi": ""
    },
    {
      "text": "Donald\u00a0E Conlon. 1993. Some tests of the self-interest and group-value models of procedural justice: Evidence from an organizational appeal procedure. Academy of Management Journal 36, 5 (1993), 1109\u20131124.",
      "doi": ""
    },
    {
      "text": "Courts and Tribunals Judiciary\u00a0(United Kingdom). 2020. The right to appeal. Retrieved on 31 March 2020 from https://www.judiciary.uk/about-the-judiciary/the-judiciary-the-government-and-the-constitution/jud-acc-ind/right-2-appeal/.",
      "doi": ""
    },
    {
      "text": "Yves Croissant. 2012. Estimation of multinomial logit models in R: The mlogit Packages. R package version 0.2-2. URL: http://cran. r-project. org/web/packages/mlogit/vignettes/mlogit.pdf(2012).",
      "doi": ""
    },
    {
      "text": "Yves Croissant. 2020. Estimation of Random Utility Models in R: The mlogit Package. Journal of Statistical Software 95, 11 (2020), 1\u201341.",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J Dietvorst, Joseph\u00a0P Simmons, and Cade Massey. 2015. Algorithm aversion: People erroneously avoid algorithms after seeing them err.Journal of Experimental Psychology: General 144, 1 (2015), 114.",
      "doi": ""
    },
    {
      "text": "Felix Eggers, John\u00a0R Hauser, and Matthew Selove. 2016. The Effects of Incentive Alignment, Realistic Images, Video Instructions, and Ceteris Paribus Instructions on Willingness to Pay and Price Equilibria. In Proceedings of the Sawtooth Software Conference.",
      "doi": ""
    },
    {
      "text": "Felix Eggers, Henrik Sattler, Thorsten Teichert, and Franziska V\u00f6lckner. 2018. Choice-Based Conjoint Analysis. In Handbook of Market Research. Springer.",
      "doi": ""
    },
    {
      "text": "Theodoros Evgeniou, David\u00a0R. Hardoon, and Anton Ovchinnikov. 2020. What Happens When AI is Used to Set Grades?Retrieved May 4, 2021 from https://hbr.org/2020/08/what-happens-when-ai-is-used-to-set-grades.",
      "doi": ""
    },
    {
      "text": "Sophie Farthing, John Howell, Katerina Lecchi, Zoe Paleologos, Phoebe Saintilan, and Edward Santow. 2021. Human Rights and Technology (Australian Human Rights Commission). https://humanrights.gov.au/our-work/rights-and-freedoms/publications/human-rights-and-technology-final-report-2021.",
      "doi": ""
    },
    {
      "text": "Jerald Greenberg. 1986. Determinants of perceived fairness of performance evaluations.Journal of Applied Psychology 71, 2 (1986), 340.",
      "doi": ""
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Christoph Engel, and Krishna\u00a0P. Gummadi. 2019. Human Decision Making with Machine Advice: An Experiment on Bailing and Jailing. Proceedings of ACM Hum.-Comput. Interact. 3, CSCW, Article 178(2019), 25\u00a0pages.",
      "doi": ""
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Elissa\u00a0M. Redmiles, Krishna\u00a0P. Gummadi, and Adrian Weller. 2018. Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction. In Proceedings of the 2018 World Wide Web Conference(WWW \u201918). 903\u2013912. https://doi.org/10.1145/3178876.3186138",
      "doi": "10.1145/3178876.3186138"
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Muhammad\u00a0Bilal Zafar, Krishna\u00a0P. Gummadi, and Adrian Weller. 2018. Beyond Distributive Fairness in Algorithmic Decision Making: Feature Selection for Procedurally Fair Learning. In Proceedings of Thirty-Second AAAI Conference on Artificial Intelligence(AAAI-18). 51\u201360.",
      "doi": ""
    },
    {
      "text": "A\u00a0Brett Hauber, Juan\u00a0Marcos Gonz\u00e1lez, Catharina\u00a0GM Groothuis-Oudshoorn, Thomas Prior, Deborah\u00a0A Marshall, Charles Cunningham, Maarten\u00a0J IJzerman, and John\u00a0FP Bridges. 2016. Statistical methods for the analysis of discrete choice experiments: a report of the ISPOR conjoint analysis good research practices task force. Value in Health 19, 4 (2016), 300\u2013315.",
      "doi": ""
    },
    {
      "text": "Mireille Hildebrandt. 2019. Privacy as protection of the incomputable self: From agnostic to agonistic machine learning. Theoretical Inquiries in Law 20, 1 (2019), 83\u2013121.",
      "doi": ""
    },
    {
      "text": "Tad Hirsch, Kritzia Merced, Shrikanth Narayanan, Zac\u00a0E. Imel, and David\u00a0C. Atkins. 2017. Designing Contestability: Interaction Design, Machine Learning, and Mental Health. In Proceedings of the 2017 Conference on Designing Interactive Systems. 95\u201399.",
      "doi": "10.1145/3064663.3064703"
    },
    {
      "text": "Yoyo Tsung-Yu Hou and Malte\u00a0F Jung. 2021. Who is the expert? Reconciling algorithm aversion and algorithm appreciation in AI-supported decision making. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201325.",
      "doi": ""
    },
    {
      "text": "AI\u00a0Now Institute. 2018. Litigating Algorithms: Challenging Government Use of Algorithmic Decision Systems. Retrieved 15 December 2019 from https://ainowinstitute.org/litigatingalgorithms.pdf.",
      "doi": ""
    },
    {
      "text": "Alon Jacovi, Ana Marasovi\u0107, Tim Miller, and Yoav Goldberg. 2021. Formalizing trust in artificial intelligence: Prerequisites, causes and goals of human trust in ai. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. 624\u2013635.",
      "doi": "10.1145/3442188.3445923"
    },
    {
      "text": "Anna Jobin, Marcello Ienca, and Effy Vayena. 2019. The global landscape of AI ethics guidelines. Nature Machine Intelligence 1 (2019), 389\u2013399.",
      "doi": ""
    },
    {
      "text": "Ekaterina Jussupow, Izak Benbasat, and Armin Heinzl. 2020. Why are we averse towards algorithms? A comprehensive literature review on Algorithm aversion. In Twenty-Eighth European Conference on Information Systems (ECIS2020).",
      "doi": ""
    },
    {
      "text": "Margot Kaminski. 2019. Binary Governance: Lessons from the GDPR\u2019s Approach to Algorithmic Accountability. Southern California Law Review 92, 6 (2019), 1529\u20131616.",
      "doi": ""
    },
    {
      "text": "Margot\u00a0E Kaminski and Jennifer\u00a0M Urban. 2021. The Right to Contest AI. Columbia Law Review 121, 7 (2021).",
      "doi": ""
    },
    {
      "text": "Daniel Kluttz and Deirdre\u00a0K Mulligan. 2020. Automated decision support technologies and the legal profession. Berkeley Technology Law Journal 34, 3 (2020).",
      "doi": ""
    },
    {
      "text": "Max\u00a0F. Kramer, Jana Schaich\u00a0Borg, Vincent Conitzer, and Walter Sinnott-Armstrong. 2018. When Do People Want AI to Make Decisions?. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society (New Orleans, LA, USA) (AIES \u201918). 204\u2013209. https://doi.org/10.1145/3278721.3278752",
      "doi": "10.1145/3278721.3278752"
    },
    {
      "text": "David\u00a0A Kravitz, Eugene\u00a0F Stone-Romero, and Jeffrey\u00a0A Ryer. 1997. Student evaluations of grade appeal procedures: The importance of procedural justice. Research in Higher Education 38, 6 (1997), 699\u2013726.",
      "doi": ""
    },
    {
      "text": "Markus Langer, Tim Hunsicker, Tina Feldkamp, Cornelius\u00a0J K\u00f6nig, and Nina Grgi\u0107-Hla\u010da. 2021. \u201d Look! It\u2019s a Computer Program! It\u2019s an Algorithm! It\u2019s AI!\u201d: Does Terminology Affect Human Perceptions and Evaluations of Intelligent Systems?arXiv preprint arXiv:2108.11486(2021).",
      "doi": ""
    },
    {
      "text": "Markus Langer, Cornelius\u00a0J K\u00f6nig, and Victoria Hemsing. 2020. Is anybody listening? The impact of automatically evaluated job interviews on impression management and applicant reactions. Journal of Managerial Psychology(2020).",
      "doi": ""
    },
    {
      "text": "Min\u00a0Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 1\u201316.",
      "doi": ""
    },
    {
      "text": "Min\u00a0Kyung Lee, Anuraag Jain, Hea\u00a0Jin Cha, Shashank Ojha, and Daniel Kusbit. 2019. Procedural Justice in Algorithmic Fairness: Leveraging Transparency and Outcome Control for Fair Algorithmic Mediation. Proceedings ACM Hum.-Comput. Interact. 3, CSCW, Article 182 (Nov. 2019), 26\u00a0pages. https://doi.org/10.1145/3359284",
      "doi": "10.1145/3359284"
    },
    {
      "text": "Gerald Leventhal. 1980. What Should Be Done With Equity Theory? New Approaches to the Study of Fairness in Social Relationships. In Social Exchange, Kenneth\u00a0J Gergen, Martin\u00a0S Greenberg, and Richard Hartley (Eds.). Plenum Press.",
      "doi": ""
    },
    {
      "text": "E.\u00a0Allan Lind and Christiane Arndt. 2016. Perceived Fairness and Regulatory Policy: A Behavioural Science Perspective on Government-Citizen Interactions. OECD Regulatory Policy Working Papers\u00a06. OECD Publishing. https://doi.org/10.1787/1629d397-en",
      "doi": ""
    },
    {
      "text": "E\u00a0Allan Lind, Ruth Kanfer, and P\u00a0Christopher Earley. 1990. Voice, control, and procedural justice: Instrumental and noninstrumental concerns in fairness judgments.Journal of Personality and Social Psychology 59, 5(1990), 952.",
      "doi": ""
    },
    {
      "text": "E\u00a0Allan Lind, Robert\u00a0J MacCoun, Patricia\u00a0A Ebener, William\u00a0LF Felstiner, Deborah\u00a0R Hensler, Judith Resnik, and Tom\u00a0R Tyler. 1990. In the eye of the beholder: Tort litigants\u2019 evaluations of their experiences in the civil justice system. Law and Society Review 24, 4 (1990), 953\u2013996.",
      "doi": ""
    },
    {
      "text": "E\u00a0Allan Lind and Tom\u00a0R Tyler. 1988. The social psychology of procedural justice. Springer US.",
      "doi": ""
    },
    {
      "text": "Jennifer\u00a0M Logg, Julia\u00a0A Minson, and Don\u00a0A Moore. 2019. Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes 151 (2019), 90\u2013103.",
      "doi": ""
    },
    {
      "text": "Chiara Longoni, Andrea Bonezzi, and Carey\u00a0K Morewedge. 2019. Resistance to medical artificial intelligence. Journal of Consumer Research 46, 4 (2019), 629\u2013650.",
      "doi": ""
    },
    {
      "text": "Henrietta Lyons, Eduardo Velloso, and Tim Miller. 2021. Conceptualising Contestability: Perspectives on Contesting Algorithmic Decisions. Proceedings of the ACM on Human-Computer Interaction 5, CSCW1(2021), 1\u201325.",
      "doi": "10.1145/3449180"
    },
    {
      "text": "Frank Marcinkowski, Kimon Kieslich, Christopher Starke, and Marco L\u00fcnich. 2020. Implications of AI (Un-)Fairness in Higher Education Admissions: The Effects of Perceived AI (Un-)Fairness on Exit, Voice and Organizational Reputation. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (Barcelona, Spain) (FAT* \u201920). 122\u2013130. https://doi.org/10.1145/3351095.3372867",
      "doi": "10.1145/3351095.3372867"
    },
    {
      "text": "Daniel McFadden. 1973. Conditional logit analysis of qualitative choice behavior. In Frontiers in Econometrics, P.\u00a0Zarembka (Ed.). Academic Press: New York, 105\u2013142.",
      "doi": ""
    },
    {
      "text": "Daniel McFadden. 1974. The measurement of urban travel demand. Journal of Public Economics 3, 4 (1974), 303\u2013328.",
      "doi": ""
    },
    {
      "text": "Daniel McFadden. 1977. Quantitative methods for analyzing travel behavior of individuals: some recent developments. In Behavioural Travel Modelling, David\u00a0A Hensher and Peter\u00a0R Stopher (Eds.). Vol.\u00a0474. Croom Helm London:London, 279\u2013318.",
      "doi": ""
    },
    {
      "text": "Isak Mendoza and Lee\u00a0A. Bygrave. 2017. The Right not to be Subject to Automated Decisions based on Profiling. In EU Internet Law, Tatiani Synodinou, Philippe Jougleux, Christiana Markou, and Thalia Prastitou (Eds.). Springer.",
      "doi": ""
    },
    {
      "text": "Deirdre\u00a0K. Mulligan, Daniel Kluttz, and Nitin Kohli. 2020. Shaping Our Tools: Contestability as a Means to Promote Responsible Algorithmic Decision Making in the Professions. In After the Digital Tornado: Networks, Algorithms, Humanity, Kevin Werbach (Ed.). New York: Cambridge University Press.",
      "doi": ""
    },
    {
      "text": "Sarah Myers\u00a0West. 2018. Censored, suspended, shadowbanned: User interpretations of content moderation on social media platforms. New Media & Society 2, 11 (2018), 4366\u20134383.",
      "doi": ""
    },
    {
      "text": "Rosanna Nagtegaal. 2021. The impact of using algorithms for managerial decisions on public employees\u2019 procedural justice. Government Information Quarterly 38, 1 (2021), 101536.",
      "doi": ""
    },
    {
      "text": "Reserve\u00a0Bank of Australia. Undated. The Global Financial Crisis. Retrieved December 21, 2021 from https://www.rba.gov.au/education/resources/explainers/the-global-financial-crisis.html.",
      "doi": ""
    },
    {
      "text": "Australian Government\u00a0Department of Industry\u00a0Innovation and Science. 2019. AI Ethics Framework. Retrieved on 6 December 2019 from https://www.industry.gov.au/data-and-publications/building-australias-artificial-intelligence-capability/ai-ethics-framework/ai-ethics-principles.",
      "doi": ""
    },
    {
      "text": "Independent High-Level Expert\u00a0Group on Artificial\u00a0Intelligence. 2019. Ethics Guidelines for Trustworthy AI. Retrieved 24 February 2020 from https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai.",
      "doi": ""
    },
    {
      "text": "Sonja\u00a0K \u00d6tting and G\u00fcnter\u00a0W Maier. 2018. The importance of procedural justice in human\u2013machine interactions: Intelligent systems as new decision agents in organizations. Computers in Human Behavior 89 (2018), 27\u201339.",
      "doi": "10.1016/j.chb.2018.07.022"
    },
    {
      "text": "Eyal Peer, Joachim Vosgerau, and Alessandro Acquisti. 2014. Reputation as a sufficient condition for data quality on Amazon Mechanical Turk. Behavior Research Methods 46, 4 (2014), 1023\u20131031.",
      "doi": ""
    },
    {
      "text": "Rashida Richardson, Jason\u00a0M. Schultz, and Vincent\u00a0M. Southerland. 2019. Litigating Algorithms 2019 US Report: New Challenges to Government Use of Algorithmic Decision Systems. Retrieved 20 December 2019 from https://ainowinstitute.org/litigatingalgorithms-2019-us.pdf.",
      "doi": ""
    },
    {
      "text": "Judy Robertson and Maurits Kaptein. 2016. Modern statistical methods for HCI. Springer.",
      "doi": "10.5555/2927492"
    },
    {
      "text": "Mandy Ryan and Shelley Farrar. 2000. Using conjoint analysis to elicit preferences for health care. BMJ 320, 7248 (2000), 1530\u20131533.",
      "doi": ""
    },
    {
      "text": "Claudio Sarra. 2020. Put Dialectics into the Machine: Protection against Automatic-decision-making through a Deeper Understanding of Contestability by Design. Global Jurist 20, 3 (2020).",
      "doi": ""
    },
    {
      "text": "Nripsuta\u00a0Ani Saxena, Karen Huang, Evan DeFilippis, Goran Radanovic, David\u00a0C. Parkes, and Yang Liu. 2019. How Do Fairness Definitions Fare? Examining Public Attitudes Towards Algorithmic Definitions of Fairness. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society (Honolulu, HI, USA) (AIES \u201919). 99\u2013106. https://doi.org/10.1145/3306618.3314248",
      "doi": "10.1145/3306618.3314248"
    },
    {
      "text": "Ayelet Sela. 2018. Can Computers Be Fair: How Automated and Human-Powered Online Dispute Resolution Affect Procedural Justice in Mediation and Arbitration. Ohio St. J. on Disp. Resol. 33 (2018), 91.",
      "doi": ""
    },
    {
      "text": "Steven Shavell. 1995. The appeals process as a means of error correction. The Journal of Legal Studies 24, 2 (1995), 379\u2013426.",
      "doi": ""
    },
    {
      "text": "Blair\u00a0H Sheppard. 1985. Justice is no simple matter: Case for elaborating our model of procedural fairness.Journal of Personality and Social Psychology 49, 4(1985), 953.",
      "doi": ""
    },
    {
      "text": "John Thibaut and Laurens Walker. 1975. Procedural Justice: A Psychological Analysis. Lawrence Erlbaum Associates, Hillsdale, NJ.",
      "doi": ""
    },
    {
      "text": "Tom\u00a0R Tyler. 1988. What is procedural justice-criteria used by citizens to assess the fairness of legal procedures. Law & Soc\u2019y Rev. 22(1988), 103.",
      "doi": ""
    },
    {
      "text": "United States District Court 2017. Houston Federation of Teachers, Local 2415, et al v Houston Independent School District, 251 F.Supp.3d 116. leagle.com/decision/infdco20170530802.",
      "doi": ""
    },
    {
      "text": "Kristen Vaccaro, Christian Sandvig, and Karrie Karahalios. 2020. \u201dAt the End of the Day Facebook Does What It Wants\u201d How Users Experience Contesting Algorithmic Content Moderation. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2(2020), 1\u201322.",
      "doi": ""
    },
    {
      "text": "Kristen Vaccaro, Ziang Xiao, Kevin Hamilton, and Karrie Karahalios. 2021. Contestability For Content Moderation. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2(2021), 1\u201328.",
      "doi": "10.1145/3476059"
    },
    {
      "text": "Annukka Valkeap\u00e4\u00e4 and Tuija Sepp\u00e4l\u00e4. 2014. Speed of decision-making as a procedural justice principle. Social Justice Research 27, 3 (2014), 305\u2013321.",
      "doi": ""
    },
    {
      "text": "Niels van Berkel, Jorge Goncalves, Danula Hettiachchi, Senuri Wijenayake, Ryan\u00a0M. Kelly, and Vassilis Kostakos. 2019. Crowdsourcing Perceptions of Fair Predictors for Machine Learning: A Recidivism Case Study. Proc. ACM Hum.-Comput. Interact. 3, 28 (2019), 21\u00a0pages. https://doi.org/10.1145/3359130",
      "doi": "10.1145/3359130"
    },
    {
      "text": "Sandra Wachter, Brent Mittelstadt, and Chris Russell. 2018. Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR. Harvard Journal of Law and Technology 31, 2 (2018), 841\u2013887.",
      "doi": ""
    },
    {
      "text": "Ruotong Wang, F.\u00a0Maxwell Harper, and Haiyi Zhu. 2020. Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences. In Proceedings of the 2020 Conference on Human Factors in Computing Systems (Honolulu, HI, USA). 1\u201314. https://doi.org/10.1145/3313831.3376813",
      "doi": "10.1145/3313831.3376813"
    },
    {
      "text": "Jacob\u00a0O. Wobbrock, Leah Findlater, Darren Gergle, and James\u00a0J. Higgins. 2011. The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only Anova Procedures. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI \u201911). 143\u2013146. https://doi.org/10.1145/1978942.1978963",
      "doi": "10.1145/1978942.1978963"
    },
    {
      "text": "Sarah Woods, Michael Walters, Kheng\u00a0Lee Koay, and Kerstin Dautenhahn. 2006. Comparing human robot interaction scenarios using live and video based methods: towards a novel methodological approach. In 9th IEEE International Workshop on Advanced Motion Control, 2006. IEEE,..., 750\u2013755.",
      "doi": ""
    },
    {
      "text": "John Zerilli, Alistair Knott, James Maclaurin, and Colin Gavaghan. 2019. Transparency in algorithmic and human decision-making: Is there a double standard?Philosophy & Technology 32, 4 (2019), 661\u2013683.",
      "doi": ""
    }
  ]
}