{
  "doi": "10.1145/3491102.3517446",
  "title": "Are Deepfakes Concerning? Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Implications",
  "published": "2022-04-28",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-19",
  "year": 2022,
  "badges": [],
  "abstract": "Deepfakes are synthetic content generated using advanced deep learning and AI technologies. The advancement of technology has created opportunities for anyone to create and share deepfakes much easier. This may lead to societal concerns based on how communities engage with it. However, there is limited research available to understand how communities perceive deepfakes. We examined deepfake conversations on Reddit from 2018 to 2021\u2014including major topics and their temporal changes as well as implications of these conversations. Using a mixed-method approach\u2014topic modeling and qualitative coding, we found 6,638 posts and 86,425 comments discussing concerns of the believable nature of deepfakes and how platforms moderate them. We also found Reddit conversations to be pro-deepfake and building a community that supports creating and sharing deepfake artifacts and building a marketplace regardless of the consequences. Possible implications derived from qualitative codes indicate that deepfake conversations raise societal concerns. We propose that there are implications for Human Computer Interaction (HCI) to mitigate the harm created from deepfakes.",
  "authors": [
    {
      "name": "Dilrukshi Gamage",
      "institution": "Department of Innovation Science, Tokyo Insitute of Technology, Japan",
      "img": "/do/10.1145/contrib-99658762536/rel-imgonly/usvisa.jpg",
      "acmid": "99658762536",
      "orcid": "missing"
    },
    {
      "name": "Piyush Ghasiya",
      "institution": "Department of Innovation Science, Tokyo Insititute of Technology, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660234145",
      "orcid": "missing"
    },
    {
      "name": "Vamshi Bonagiri",
      "institution": "International Institute of Information Technology, India",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660236569",
      "orcid": "missing"
    },
    {
      "name": "Mark E. Whiting",
      "institution": "Computer and Information Science, University of Pennsylvania, United States",
      "img": "/do/10.1145/contrib-99659079274/rel-imgonly/99659079274.jpeg",
      "acmid": "99659079274",
      "orcid": "missing"
    },
    {
      "name": "Kazutoshi Sasahara",
      "institution": "Department of Innovation Science, Tokyo Institute of Technology, Japan",
      "img": "/do/10.1145/contrib-99660237102/rel-imgonly/ks_photo_2017r.jpg",
      "acmid": "99660237102",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Shruti Agarwal and Hany Farid. 2021. Detecting Deep-Fake Videos From Aural and Oral Dynamics. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 981\u2013989.",
      "doi": ""
    },
    {
      "text": "Saifuddin Ahmed. 2021. Who inadvertently shares deepfakes? Analyzing the role of political interest, cognitive ability, and social network size. Telematics and Informatics 57 (2021), 101508.",
      "doi": ""
    },
    {
      "text": "Oxford Analytica. 2019. \u2019Deepfakes\u2019 could irreparably damage public trust. Emerald Expert Briefingsoxan-db (2019).",
      "doi": ""
    },
    {
      "text": "Oxford Analytica. 2019. \u2019deepfakes\u2019 could irreparably damage public trust. Expert Briefings (2019).",
      "doi": ""
    },
    {
      "text": "Sairam Balani and Munmun De\u00a0Choudhury. 2015. Detecting and characterizing mental health related self-disclosure in social media. In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems. 1373\u20131378.",
      "doi": "10.1145/2702613.2732733"
    },
    {
      "text": "Michael\u00a0S Bernstein, Margaret Levi, David Magnus, Betsy Rajala, Debra Satz, and Charla Waeiss. 2021. ESR: Ethics and Society Review of Artificial Intelligence Research. arXiv preprint arXiv:2106.11521(2021).",
      "doi": ""
    },
    {
      "text": "Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing with Python: analyzing text with the natural language toolkit. \u201d O\u2019Reilly Media, Inc.\u201d.",
      "doi": "10.5555/1717171"
    },
    {
      "text": "Jennifer Bisset. 2021. Lucasfilm hires deepfake YouTuber who fixed Luke Skywalker in The Mandalorian. Retrieved August 29, 2021 from https://www.cnet.com/news/lucasfilm-hires-deepfake-youtuber-who-fixed-luke-skywalker-in-the-mandalorian/",
      "doi": ""
    },
    {
      "text": "Christoph Bregler, Michele Covell, and Malcolm Slaney. 1997. Video Rewrite: Driving Visual Speech with Audio. In Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques(SIGGRAPH \u201997). ACM Press/Addison-Wesley Publishing Co., USA, 353\u2013360. https://doi.org/10.1145/258734.258880",
      "doi": "10.1145/258734.258880"
    },
    {
      "text": "Catherine\u00a0Francis Brooks. 2021. Popular discourse around deepfakes and the interdisciplinary challenge of fake video distribution. Cyberpsychology, Behavior, and Social Networking 24, 3(2021), 159\u2013163.",
      "doi": ""
    },
    {
      "text": "Jacquelyn Burkell and Chandell Gosse. 2019. Nothing new here: Emphasizing the social and cultural context of deepfakes. First Monday (2019).",
      "doi": ""
    },
    {
      "text": "Roberto Caldelli, Leonardo Galteri, Irene Amerini, and Alberto Del\u00a0Bimbo. 2021. Optical Flow based CNN for detection of unlearnt deepfake manipulations. Pattern Recognition Letters 146 (2021), 31\u201337.",
      "doi": ""
    },
    {
      "text": "Caroline Chan, Shiry Ginosar, Tinghui Zhou, and Alexei\u00a0A Efros. 2019. Everybody dance now. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 5933\u20135942.",
      "doi": ""
    },
    {
      "text": "Eshwar Chandrasekharan, Mattia Samory, Shagun Jhaver, Hunter Charvat, Amy Bruckman, Cliff Lampe, Jacob Eisenstein, and Eric Gilbert. 2018. The internet\u2019s hidden rules: An empirical study of Reddit norm violations at micro, meso, and macro Scales. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201325.",
      "doi": "10.1145/3274301"
    },
    {
      "text": "Justin\u00a0D Cochran and Stuart\u00a0A Napshin. 2021. Deepfakes: awareness, concerns, and platform accountability. Cyberpsychology, Behavior, and Social Networking 24, 3(2021), 164\u2013172.",
      "doi": ""
    },
    {
      "text": "Antonella De\u00a0Angeli, Mattia Falduti, Maria Menendez\u00a0Blanco, and Sergio Tessaris. 2021. Reporting Revenge Porn: a Preliminary Expert Analysis. In CHItaly 2021: 14th Biannual Conference of the Italian SIGCHI Chapter. 1\u20135.",
      "doi": ""
    },
    {
      "text": "Adrienne De\u00a0Ruiter. 2021. The distinct wrong of deepfakes. Philosophy & Technology 34, 4 (2021), 1311\u20131332.",
      "doi": ""
    },
    {
      "text": "Simone Eelmaa. 2021. Sexualization of Children in Deepfakes and Hentai: Examining Reddit User Views. (2021).",
      "doi": ""
    },
    {
      "text": "Don Fallis. 2020. The epistemic threat of deepfakes. Philosophy & Technology(2020), 1\u201321.",
      "doi": ""
    },
    {
      "text": "Casey Fiesler, Joshua McCann, Kyle Frye, Jed\u00a0R Brubaker, 2018. Reddit rules! characterizing an ecosystem of governance. In Twelfth International AAAI Conference on Web and Social Media.",
      "doi": ""
    },
    {
      "text": "Samuel Greengard. 2019. Will deepfakes do deep damage?Commun. ACM 63, 1 (2019), 17\u201319.",
      "doi": "10.1145/3371409"
    },
    {
      "text": "The Guardian. 2021. Mother charged with deepfake plot against daughter\u2019s cheerleading rivals. https://www.theguardian.com/us-news/2021/mar/15/mother-charged-deepfake-plot-cheerleading-rivals",
      "doi": ""
    },
    {
      "text": "Jeffrey\u00a0T Hancock and Jeremy\u00a0N Bailenson. 2021. The social impact of deepfakes. Cyberpsychology, Behavior, and Social Networking 24, 3(2021).",
      "doi": ""
    },
    {
      "text": "Karen Hao. 2021. Memers are making deepfakes, and things are getting weird. Retrieved August 29, 2021 from https://www.technologyreview.com/2020/08/28/1007746/ai-deepfakes-memes/",
      "doi": ""
    },
    {
      "text": "Douglas Harris. 2018. Deepfakes: False pornography is here and the law cannot protect you. Duke L. & Tech. Rev. 17(2018), 99.",
      "doi": ""
    },
    {
      "text": "Max Jaderberg, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014. Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition. arXiv preprint arXiv:1406.2227(2014).",
      "doi": ""
    },
    {
      "text": "JiJI. 2020. Two men arrested over deepfake pornography videos. Retrieved August 29, 2021 from https://www.japantimes.co.jp/news/2020/10/02/national/crime-legal/two-men-arrested-deepfake-pornography-videos/",
      "doi": ""
    },
    {
      "text": "Stamatis Karnouskos. 2020. Artificial intelligence in digital media: The era of deepfakes. IEEE Transactions on Technology and Society 1, 3 (2020), 138\u2013147.",
      "doi": ""
    },
    {
      "text": "David Khachaturov, Ilia Shumailov, Yiren Zhao, Nicolas Papernot, and Ross Anderson. 2021. Markpainting: Adversarial Machine Learning meets Inpainting. arxiv:2106.00660\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Zachary Kimo\u00a0Stine and Nitin Agarwal. 2020. Comparative Discourse Analysis Using Topic Models: Contrasting Perspectives on China from Reddit. In International Conference on Social Media and Society. 73\u201384.",
      "doi": "10.1145/3400806.3400816"
    },
    {
      "text": "Loukas Konstantinou, Ana Caraban, and Evangelos Karapanos. 2019. Combating Misinformation Through Nudging. In IFIP Conference on Human-Computer Interaction. Springer, 630\u2013634.",
      "doi": ""
    },
    {
      "text": "Johannes Langguth, Konstantin Pogorelov, Stefan Brenner, Petra Filkukov\u00e1, and Daniel\u00a0Thilo Schroeder. 2021. Don\u2019t Trust Your Eyes: Image Manipulation in the Age of DeepFakes. Frontiers in Communication 6 (2021), 26.",
      "doi": ""
    },
    {
      "text": "Lingzhi Li, Jianmin Bao, Ting Zhang, Hao Yang, Dong Chen, Fang Wen, and Baining Guo. 2020. Face x-ray for more general face forgery detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 5001\u20135010.",
      "doi": ""
    },
    {
      "text": "Xurong Li, Kun Yu, Shouling Ji, Yan Wang, Chunming Wu, and Hui Xue. 2020. Fighting against deepfake: Patch&pair convolutional neural networks (PPCNN). In Companion Proceedings of the Web Conference 2020. 88\u201389.",
      "doi": "10.1145/3366424.3382711"
    },
    {
      "text": "Yang Liu, Zhijun Yin, 2020. Understanding weight loss via online discussions: Content analysis of Reddit posts using topic modeling and word clustering techniques. Journal of medical Internet research 22, 6 (2020), e13745.",
      "doi": ""
    },
    {
      "text": "Sophie Maddocks. 2020. \u2018A Deepfake Porn Plot Intended to Silence Me\u2019: exploring continuities between pornographic and \u2018political\u2019deep fakes. Porn Studies 7, 4 (2020), 415\u2013423.",
      "doi": ""
    },
    {
      "text": "Artem\u00a0A Maksutov, Viacheslav\u00a0O Morozov, Aleksander\u00a0A Lavrenov, and Alexander\u00a0S Smirnov. 2020. Methods of deepfake detection based on machine learning. In 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus). IEEE, 408\u2013411.",
      "doi": ""
    },
    {
      "text": "December Maxwell, Sarah\u00a0R Robinson, Jessica\u00a0R Williams, and Craig Keaton. 2020. \u201d A Short Story of a Lonely Guy\u201d: A Qualitative Thematic Analysis of Involuntary Celibacy Using Reddit.Sexuality & Culture 24, 6 (2020).",
      "doi": ""
    },
    {
      "text": "Sara May. 2019. Ask Me Anything: Promoting Archive Collections on Reddit. Marketing Libraries Journal 3, 1 (2019).",
      "doi": ""
    },
    {
      "text": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg\u00a0S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111\u20133119.",
      "doi": ""
    },
    {
      "text": "Yisroel Mirsky and Wenke Lee. 2021. The creation and detection of deepfakes: A survey. ACM Computing Surveys (CSUR) 54, 1 (2021), 1\u201341.",
      "doi": "10.1145/3425780"
    },
    {
      "text": "Eryn\u00a0J Newman, Maryanne Garry, Christian Unkelbach, Daniel\u00a0M Bernstein, D\u00a0Stephen Lindsay, and Robert\u00a0A Nash. 2015. Truthiness and falsiness of trivia claims depend on judgmental contexts.Journal of Experimental Psychology: Learning, Memory, and Cognition 41, 5(2015), 1337.",
      "doi": ""
    },
    {
      "text": "Jennifer Otiono, Monsurat Olaosebikan, Orit Shaer, Oded Nov, and Mad\u00a0Price Ball. 2019. Understanding Users Information Needs and Collaborative Sensemaking of Microbiome Data. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201321.",
      "doi": "10.1145/3274470"
    },
    {
      "text": "Derek O\u2019callaghan, Derek Greene, Joe Carthy, and P\u00e1draig Cunningham. 2015. An analysis of the coherence of descriptors in topic modeling. Expert Systems with Applications 42, 13 (2015), 5645\u20135657.",
      "doi": "10.1016/j.eswa.2015.02.055"
    },
    {
      "text": "Jes\u00fas\u00a0\u00c1ngel P\u00e9rez\u00a0Dasilva, Koldobika Meso\u00a0Ayerdi, and Terese Mendiguren\u00a0Galdospin. 2021. Deepfakes on Twitter: Which Actors Control Their Spread?(2021).",
      "doi": ""
    },
    {
      "text": "Jiameng Pu, Neal Mangaokar, Bolun Wang, Chandan\u00a0K Reddy, and Bimal Viswanath. 2020. Noisescope: Detecting deepfake images in a blind setting. In Annual Computer Security Applications Conference. 913\u2013927.",
      "doi": "10.1145/3427228.3427285"
    },
    {
      "text": "Md\u00a0Shohel Rana and Andrew\u00a0H Sung. 2020. Deepfakestack: A deep ensemble-based learning technique for deepfake detection. In 2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom). IEEE, 70\u201375.",
      "doi": ""
    },
    {
      "text": "Helen Rosner. 2021. The Ethics of a Deepfake Anthony Bourdain Voice. Retrieved August 29, 2021 from https://www.newyorker.com/culture/annals-of-gastronomy/the-ethics-of-a-deepfake-anthony-bourdain-voice",
      "doi": ""
    },
    {
      "text": "Kelly\u00a0M Sayler and Laurie\u00a0A Harris. 2020. Deep fakes and national security. Technical Report. Congressional Research SVC Washington United States.",
      "doi": ""
    },
    {
      "text": "Lisa Schirch. 2021. The techtonic shift: How social media works. In Social Media Impacts on Conflict and Democracy. Routledge, 1\u201320.",
      "doi": ""
    },
    {
      "text": "Nicolas Schrading, Cecilia\u00a0Ovesdotter Alm, Raymond Ptucha, and Christopher Homan. 2015. An analysis of domestic abuse discourse on reddit. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2577\u20132583.",
      "doi": ""
    },
    {
      "text": "Zack Sharf. 2021. Lucasfilm Hired the YouTuber Who Used Deepfakes to Tweak Luke Skywalker \u2018Mandalorian\u2019 VFX. Retrieved August 29, 2021 from https://www.indiewire.com/2021/07/lucasfilm-hires-deepfake-youtuber-mandalorian-skywalker-vfx-1234653720/",
      "doi": ""
    },
    {
      "text": "Shaina\u00a0J Sowles, Monique McLeary, Allison Optican, Elizabeth Cahn, Melissa\u00a0J Krauss, Ellen\u00a0E Fitzsimmons-Craft, Denise\u00a0E Wilfley, and Patricia\u00a0A Cavazos-Rehg. 2018. A content analysis of an online pro-eating disorder community on Reddit. Body image 24(2018), 137\u2013144.",
      "doi": ""
    },
    {
      "text": "Catherine Stupp. 2019. Fraudsters used AI to mimic CEO\u2019s voice in unusual cybercrime case. The Wall Street Journal 30, 08 (2019).",
      "doi": ""
    },
    {
      "text": "Supasorn Suwajanakorn, Steven\u00a0M. Seitz, and Ira Kemelmacher-Shlizerman. 2017. Synthesizing Obama: Learning Lip Sync from Audio. ACM Trans. Graph. 36, 4, Article 95 (July 2017), 13\u00a0pages. https://doi.org/10.1145/3072959.3073640",
      "doi": "10.1145/3072959.3073640"
    },
    {
      "text": "Rashid Tahir, Brishna Batool, Hira Jamshed, Mahnoor Jameel, Mubashir Anwar, Faizan Ahmed, Muhammad\u00a0Adeel Zaffar, and Muhammad\u00a0Fareed Zaffar. 2021. Seeing is Believing: Exploring Perceptual Differences in DeepFake Videos. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3411764.3445699"
    },
    {
      "text": "Justus Thies, Michael Zollhofer, Marc Stamminger, Christian Theobalt, and Matthias Nie\u00dfner. 2016. Face2face: Real-time face capture and reenactment of rgb videos. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2387\u20132395.",
      "doi": "10.1145/2929464.2929475"
    },
    {
      "text": "Sachin Thukral, Hardik Meisheri, Tushar Kataria, Aman Agarwal, Ishan Verma, Arnab Chatterjee, and Lipika Dey. 2018. Analyzing behavioral trends in community driven discussion platforms like reddit. In 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM). IEEE, 662\u2013669.",
      "doi": "10.5555/3382225.3382371"
    },
    {
      "text": "Cristian Vaccari and Andrew Chadwick. 2020. Deepfakes and disinformation: Exploring the impact of synthetic political video on deception, uncertainty, and trust in news. Social Media+ Society 6, 1 (2020), 2056305120903408.",
      "doi": ""
    },
    {
      "text": "James Vincent. 2020. This is what a deepfake voice clone used in a failed fraud attempt sounds like. Retrieved August 29, 2021 from https://www.theverge.com/2020/7/27/21339898/deepfake-audio-voice-clone-scam-attempt-nisos",
      "doi": ""
    },
    {
      "text": "Travis\u00a0L Wagner and Ashley Blewer. 2019. \u201cThe Word Real Is No Longer Real\u201d: Deepfakes, Gender, and the Challenges of AI-Altered Video. Open Information Science 3, 1 (2019), 32\u201346.",
      "doi": ""
    },
    {
      "text": "Lei Wang, Yongcheng Zhan, Qiudan Li, Daniel\u00a0D Zeng, Scott\u00a0J Leischow, and Janet Okamoto. 2015. An examination of electronic cigarette content on social media: analysis of e-cigarette flavor content on Reddit. International journal of environmental research and public health 12, 11(2015), 14916\u201314935.",
      "doi": ""
    },
    {
      "text": "Leslie W\u00f6hler, Martin Zembaty, Susana Castillo, and Marcus Magnor. 2021. Towards Understanding Perceptual Differences between Genuine and Face-Swapped Videos. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3411764.3445627"
    },
    {
      "text": "Digvijay Yadav and Sakina Salmani. 2019. Deepfake: A survey on facial forgery technique using generative adversarial network. In 2019 International Conference on Intelligent Computing and Control Systems (ICCS). IEEE, 852\u2013857.",
      "doi": ""
    },
    {
      "text": "Youtube. 2019. Keanu goes Bollywood: a true deepfake story. Retrieved August 29, 2021 from https://www.youtube.com/watch?v=J-0kCua6Q08",
      "doi": ""
    },
    {
      "text": "Catherine Zeng and Rafael Olivera-Cintr\u00f3n. 2019. Preparing for the World of a\u201d Perfect\u201d Deepfake. Dostopno na: https://czeng. org/classes/6805/Final.pdf (18. 6. 2020) (2019).",
      "doi": ""
    },
    {
      "text": "Lilei Zheng, Ying Zhang, and Vrizlynn\u00a0LL Thing. 2019. A survey on image tampering and its detection in real-world photos. Journal of Visual Communication and Image Representation 58 (2019), 380\u2013399.",
      "doi": ""
    }
  ]
}