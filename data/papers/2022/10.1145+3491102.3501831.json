{
  "doi": "10.1145/3491102.3501831",
  "title": "How Child Welfare Workers Reduce Racial Disparities in Algorithmic Decisions",
  "published": "2022-04-28",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-22",
  "year": 2022,
  "badges": [],
  "abstract": "Machine learning tools have been deployed in various contexts to support human decision-making, in the hope that human-algorithm collaboration can improve decision quality. However, the question of whether such collaborations reduce or exacerbate biases in decision-making remains underexplored. In this work, we conducted a mixed-methods study, analyzing child welfare call screen workers\u2019 decision-making over a span of four years, and interviewing them on how they incorporate algorithmic predictions into their decision-making process. Our data analysis shows that, compared to the algorithm alone, workers reduced the disparity in screen-in rate between Black and white children from 20% to 9%. Our qualitative data show that workers achieved this by making holistic risk assessments and adjusting for the algorithm\u2019s limitations. Our analyses also show more nuanced results about how human-algorithm collaboration affects prediction accuracy, and how to measure these effects. These results shed light on potential mechanisms for improving human-algorithm collaboration in high-risk decision-making contexts.",
  "tags": [
    "child welfare",
    "algorithmic biases",
    "machine learning",
    "human-centered AI",
    "algorithm-assisted decision-making"
  ],
  "authors": [
    {
      "name": "Hao-Fei Cheng",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States and GroupLens Research, University of Minnesota, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659156442",
      "orcid": "missing"
    },
    {
      "name": "Logan Stapleton",
      "institution": "GroupLens Research, University of Minnesota, United States and School of Computer Science, Carnegie Mellon University, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659700796",
      "orcid": "missing"
    },
    {
      "name": "Anna Kawakami",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660234373",
      "orcid": "missing"
    },
    {
      "name": "Venkatesh Sivaraman",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659857571",
      "orcid": "0000-0002-6965-3961"
    },
    {
      "name": "Yanghuidi Cheng",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660237191",
      "orcid": "missing"
    },
    {
      "name": "Diana Qing",
      "institution": "University of California, Berkeley, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99660239283",
      "orcid": "missing"
    },
    {
      "name": "Adam Perer",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/do/10.1145/contrib-81100462318/rel-imgonly/adam_head.jpg",
      "acmid": "81100462318",
      "orcid": "0000-0002-8369-3847"
    },
    {
      "name": "Kenneth Holstein",
      "institution": "Human-Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659133171",
      "orcid": "0000-0001-6730-922X"
    },
    {
      "name": "Zhiwei Steven Wu",
      "institution": "School of Computer Science, Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "89758804757",
      "orcid": "missing"
    },
    {
      "name": "Haiyi Zhu",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University, United States",
      "img": "/do/10.1145/contrib-81484646857/rel-imgonly/headshot.png",
      "acmid": "81484646857",
      "orcid": "0000-0001-7271-9100"
    }
  ],
  "references": [
    {
      "text": "[n.d.]. Department Of Human Services Releases 2016 Child Protective Services Report. https://www.media.pa.gov/Pages/DHS_details.aspx?newsid=253 Online; accessed 6-January-2022.",
      "doi": ""
    },
    {
      "text": "J.\u00a0Khadijah Abdurahman. 2021. Calculating the Souls of Black Folk: Predictive Analytics in the New York City Administration for Children\u2019s Services. Columbia Journal of Race and Law Forum 11, 4 (2021), 75\u2013110. https://journals.library.columbia.edu/index.php/cjrl/article/view/8741",
      "doi": ""
    },
    {
      "text": "Alex Albright. 2019. If You Give a Judge a Risk Score: Evidence from Kentucky Bail Decisions. Law, Economics, and Business Fellows\u2019 Discussion Paper Series 85 (2019).",
      "doi": ""
    },
    {
      "text": "Ali Alkhatib and Michael Bernstein. 2019. Street-level algorithms: A theory at the gaps between policy and decisions. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3290605.3300760"
    },
    {
      "text": "(DHS) Allegheny County Department\u00a0of Human\u00a0Services. [n.d.]. DHS response to Automated Inequality by Virginia Eubanks. https://www.alleghenycounty.us/WorkArea/linkit.aspx?LinkIdentifier=id&ItemID=6442461672",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel Weld. 2021. Does the whole exceed its parts? the effect of ai explanations on complementary team performance. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3411764.3445717"
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative Research in Psychology 3, 2 (2006), 77\u2013101. https://doi.org/10.1191/1478088706qp063oa arXiv:https://www.tandfonline.com/doi/pdf/10.1191/1478088706qp063oa",
      "doi": "10.1191/1478088706QP063OA"
    },
    {
      "text": "Zana Bu\u00e7inca, Phoebe Lin, Krzysztof\u00a0Z Gajos, and Elena\u00a0L Glassman. 2020. Proxy tasks and subjective measures can be misleading in evaluating explainable ai systems. In Proceedings of the 25th International Conference on Intelligent User Interfaces. 454\u2013464.",
      "doi": "10.1145/3377325.3377498"
    },
    {
      "text": "Joy Buolamwini. 2017. Gender Shades: Intersectional Phenotypic and Demographic Evaluation of Face Datasets and Gender Classifiers. Master\u2019s thesis. Massachusetts Institute of Technology (MIT).",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Proceedings of Machine Learning Research Conference on Fairness, Accountability, and Transparency(Conference on Fairness, Accountability, and Transparency, Vol.\u00a081). 1\u201315.",
      "doi": ""
    },
    {
      "text": "Carrie\u00a0J Cai, Samantha Winter, David Steiner, Lauren Wilcox, and Michael Terry. 2019. \u201d Hello AI\u201d: Uncovering the Onboarding Needs of Medical Practitioners for Human-AI Collaborative Decision-Making. Proceedings of the ACM on Human-computer Interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359206"
    },
    {
      "text": "Toon Calders, Faisal Kamiran, and Mykola Pechenizkiy. 2009. Building classifiers with independency constraints. In ICDM Workshop Domain Driven Data Mining. 13\u201318.",
      "doi": "10.1109/ICDMW.2009.83"
    },
    {
      "text": "Kathy Charmaz. 2014. Constructing Grounded Theory. SAGE.",
      "doi": ""
    },
    {
      "text": "Marc Cherna. [n.d.]. We will use all resources to keep children safe. Pittsburgh Post-Gazette([n. d.]). https://www.post-gazette.com/opinion/letters/2018/03/23/We-will-use-all-resources-to-keep-children-safe/stories/201803230094 Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. 2018. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In Conference on Fairness, Accountability and Transparency. PMLR, 134\u2013148.",
      "doi": ""
    },
    {
      "text": "Eckerd Connects. [n.d.]. ECKERD RAPID SAFETY FEEDBACK. https://eckerd.org/family-children-services/ersf/. Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining. 797\u2013806.",
      "doi": "10.1145/3097983.3098095"
    },
    {
      "text": "Amanda Coston, Alan Mishler, Edward\u00a0H Kennedy, and Alexandra Chouldechova. 2020. Counterfactual risk assessments, evaluation, and fairness. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 582\u2013593.",
      "doi": "10.1145/3351095.3372851"
    },
    {
      "text": "Bo Cowgill. 2018. The Impact of Algorithms on Judicial Discretion: Evidence from Regression Discontinuities. (2018). http://www.columbia.edu/~bc2656/papers/RecidAlgo.pdf",
      "doi": ""
    },
    {
      "text": "Tim Dare and Eileen Gambrill. 2016. Ethical Analysis: Predictive Risk Models at Call Screening for Allegheny County. (2016). https://www.alleghenycountyanalytics.us/wp-content/uploads/2019/05/Ethical-Analysis-16-ACDHS-26_PredictiveRisk_Package_050119_FINAL-2.pdf Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Maria De-Arteaga, Artur Dubrawski, and Alexandra Chouldechova. 2018. Learning under selective labels in the presence of expert consistency. arXiv preprint arXiv:1807.00905 (2018).",
      "doi": ""
    },
    {
      "text": "Maria De-Arteaga, Artur Dubrawski, and Alexandra Chouldechova. 2021. Leveraging expert consistency to improve algorithmic decision support. arXiv preprint arXiv:2101.09648 (2021).",
      "doi": ""
    },
    {
      "text": "Maria De-Arteaga, Riccardo Fogliato, and Alexandra Chouldechova. 2020. A case for humans-in-the-loop: Decisions in the presence of erroneous algorithmic scores. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3313831.3376638"
    },
    {
      "text": "Alan\u00a0J Dettlaff and Reiko Boyd. 2020. Racial disproportionality and disparities in the child welfare system: Why do they exist, and what can be done to address them?The ANNALS of the American Academy of Political and Social Science 692, 1(2020), 253\u2013274.",
      "doi": ""
    },
    {
      "text": "Alan\u00a0J Dettlaff, Stephanie\u00a0L Rivaux, Donald\u00a0J Baumann, John\u00a0D Fluke, Joan\u00a0R Rycraft, and Joyce James. 2011. Disentangling substantiation: The influence of race, income, and risk on the substantiation decision in child welfare. Children and Youth Services Review 33, 9 (2011), 1630\u20131637.",
      "doi": ""
    },
    {
      "text": "Dorothy Roberts. 2002. Shattered bonds: The color of child welfare. Basic Books, New York.",
      "doi": ""
    },
    {
      "text": "Brett Drake, Jennifer\u00a0M Jolley, Paul Lanier, John Fluke, Richard\u00a0P Barth, and Melissa Jonson-Reid. 2011. Racial bias in child protection? A comparison of competing explanations using national data. Pediatrics 127, 3 (2011), 471\u2013478.",
      "doi": ""
    },
    {
      "text": "Julia Dressel and Hany Farid. 2018. The accuracy, fairness, and limits of predicting recidivism. Science advances 4, 1 (2018), eaao5580.",
      "doi": ""
    },
    {
      "text": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference. 214\u2013226.",
      "doi": "10.1145/2090236.2090255"
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto\u00a0A Novoa, Justin Ko, Susan\u00a0M Swetter, Helen\u00a0M Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. nature 542, 7639 (2017), 115\u2013118.",
      "doi": ""
    },
    {
      "text": "Virginia Eubanks. 2018. Automating Inequality: How High-tech Tools Profile, Police, and Punish the Poor. New York, NY: St. Martin\u2019s Press.",
      "doi": "10.5555/3208509"
    },
    {
      "text": "Michael Feldman, Sorelle\u00a0A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. 259\u2013268.",
      "doi": "10.1145/2783258.2783311"
    },
    {
      "text": "Shi Feng and Jordan Boyd-Graber. 2019. What can ai do for me? evaluating machine learning interpretations in cooperative play. In Proceedings of the 24th International Conference on Intelligent User Interfaces. 229\u2013239.",
      "doi": "10.1145/3301275.3302265"
    },
    {
      "text": "Child Welfare\u00a0Information Gateway. [n.d.]. Safety and Risk Assessment. https://www.childwelfare.gov/topics/systemwide/assessment/family-assess/safety/ Online; accessed 25-Dec-2021.",
      "doi": ""
    },
    {
      "text": "Jeremy\u00a0D Goldhaber-Fiebert and Lea Prince. 2019. Impact evaluation of a predictive risk modeling tool for Allegheny county\u2019s child welfare office. Pittsburgh: Allegheny County(2019).",
      "doi": ""
    },
    {
      "text": "Ben Green. [n.d.]. The Flaws of Policies Requiring Human Oversight of Government Algorithms. ([n. d.]). http://dx.doi.org/10.2139/ssrn.3921216",
      "doi": ""
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments. In Proceedings of Conference on Fairness, Accountability, and Transparency (FAT*). ACM.",
      "doi": "10.1145/3287560.3287563"
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. The principles and limits of algorithm-in-the-loop decision making. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359152"
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Christoph Engel, and Krishna\u00a0P Gummadi. 2019. Human decision making with machine assistance: An experiment on bailing and jailing. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201325.",
      "doi": ""
    },
    {
      "text": "Emil\u00a0J Haller. 1985. Pupil race and elementary school ability grouping: Are teachers biased against Black children?American Educational Research Journal 22, 4 (1985), 465\u2013483.",
      "doi": ""
    },
    {
      "text": "Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. Advances in neural information processing systems 29 (2016), 3315\u20133323.",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein and Vincent Aleven. 2021. Designing for human-AI complementarity in K-12 education. arXiv preprint arXiv:2104.01266(2021).",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Bruce\u00a0M McLaren, and Vincent Aleven. 2018. Student learning benefits of a mixed-reality teacher awareness tool in AI-enhanced classrooms. In International Conference on Artificial Intelligence in Education. Springer, 154\u2013168.",
      "doi": ""
    },
    {
      "text": "Naja Holten M\u00f8ller, Irina Shklovski, and Thomas\u00a0T. Hildebrandt. 2020. Shifting Concepts of Value: Designing Algorithmic Decision-Support Systems for Public Services. NordiCHI (2020), 1\u201312. https://doi.org/10.1145/3419249.3420149",
      "doi": "10.1145/3419249.3420149"
    },
    {
      "text": "Dan Hurley. [n.d.]. Can an Algorithm Tell When Kids Are in Danger?New York Times Magazine([n. d.]). nytimes.com/2018/01/02/magazine/can-an-algorithm-tell-when-kids-are-in-danger.html Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "SAS Institute. [n.d.]. Analytics for Child Well-Being. https://www.sas.com/en_us/software/analytics-for-child-well-being.html. Online; accessed 12-December-2021.",
      "doi": ""
    },
    {
      "text": "Sheriff\u2019s\u00a0Justice Institute. 2016. Central Bond Court Report. https://www.chicagoreader.com/pdf/20161026/Sheriff_s-Justice-Institute-Central-BondCourt-Study-070616.pdf",
      "doi": ""
    },
    {
      "text": "David Jackson and Gary Marx. [n.d.]. Data mining program designed to predict child abuse proves unreliable, DCFS says. Chicago Tribune ([n. d.]). https://www.chicagotribune.com/investigations/ct-dcfs-eckerd-met-20171206-story.html Online; accessed 6-January-2022.",
      "doi": ""
    },
    {
      "text": "Daniel Kahneman, Olivier Sibony, and Cass\u00a0R Sunstein. 2021. Noise: a flaw in human judgment. Little, Brown.",
      "doi": ""
    },
    {
      "text": "Nathan Kallus and Angela Zhou. 2018. Residual unfairness in fair machine learning from prejudiced data. In International Conference on Machine Learning. PMLR, 2439\u20132448.",
      "doi": ""
    },
    {
      "text": "Emily Keddell. 2019. Algorithmic Justice in Child Protection: Statistical Fairness, Social Justice and the Implications for Practice. Social Sciences (2019).",
      "doi": ""
    },
    {
      "text": "Gavin Kerrigan, Padhraic Smyth, and Mark Steyvers. 2021. Combining Human Predictions with Model Probabilities via Confusion Matrices and Calibration. Advances in Neural Information Processing Systems 34 (2021).",
      "doi": ""
    },
    {
      "text": "Niki Kilbertus, Mateo Rojas-Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing, and Bernhard Sch\u00f6lkopf. 2017. Avoiding discrimination through causal reasoning. arXiv preprint arXiv:1706.02744(2017).",
      "doi": ""
    },
    {
      "text": "Hyunil Kim, Christopher Wildeman, Melissa Jonson-Reid, and Brett Drake. 2017. Lifetime Prevalence of Investigating Child Maltreatment Among US Children. American Journal of Public Health 107, 2 (2017), 274\u2013280. https://doi.org/10.2105/AJPH.2016.303545",
      "doi": ""
    },
    {
      "text": "Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. 2018. Human decisions and machine predictions. The quarterly journal of economics 133, 1 (2018), 237\u2013293.",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Han Liu, and Chenhao Tan. 2020. \u201d Why is\u2019 Chicago\u2019deceptive?\u201d Towards Building Model-Driven Tutorials for Humans. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3313831.3376873"
    },
    {
      "text": "Vivian Lai and Chenhao Tan. 2019. On human predictions with explanations and predictions of machine learning models: A case study on deception detection. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 29\u201338.",
      "doi": "10.1145/3287560.3287590"
    },
    {
      "text": "Karen Levy, Kyla\u00a0E Chasalow, and Sarah Riley. 2021. Algorithms and Decision-Making in the Public Sector. Annual Review of Law and Social Science 17 (2021), 1\u201338.",
      "doi": ""
    },
    {
      "text": "Scott\u00a0M Lundberg, Bala Nair, Monica\u00a0S Vavilala, Mayumi Horibe, Michael\u00a0J Eisses, Trevor Adams, David\u00a0E Liston, Daniel King-Wai Low, Shu-Fang Newman, Jerry Kim, 2018. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nature biomedical engineering 2, 10 (2018), 749\u2013760.",
      "doi": ""
    },
    {
      "text": "David Madras, Toniann Pitassi, and Richard Zemel. 2017. Predict responsibly: improving fairness and accuracy by learning to defer. arXiv preprint arXiv:1711.06664(2017).",
      "doi": ""
    },
    {
      "text": "Aditya\u00a0Krishna Menon and Robert\u00a0C Williamson. 2018. The cost of fairness in binary classification. In Conference on Fairness, Accountability and Transparency. PMLR, 107\u2013118.",
      "doi": ""
    },
    {
      "text": "Clara Mosquera-Lopez, Sos Agaian, Alejandro Velez-Hoyos, and Ian Thompson. 2014. Computer-aided prostate cancer diagnosis from digitized histopathology: a review on texture-based systems. IEEE reviews in biomedical engineering 8 (2014), 98\u2013113.",
      "doi": ""
    },
    {
      "text": "Judge\u00a0Michael Nash. 2017. EXAMINATION OF USING STRUCTURED DECISION MAKING AND PREDICTIVE ANALYTICS IN ASSESSING SAFETY AND RISK IN CHILD WELFARE (ITEM NO. 49-A, AGENDA OF SEPTEMBER 20, 2016). http://ocp.lacounty.gov/Portals/OCP/PDF/Reports%20and%20Communication/Safety%20and%20Risk%20Assessment/SDM%20and%20Predictive%20Analytics%20Report%20(Risk%20Assessment%20Tools)%20(May%202017).pdf?ver=2018-10-24-083910-100 Online; accessed 6-January-2022.",
      "doi": ""
    },
    {
      "text": "NCCPR: National Coalition\u00a0for Child Protection\u00a0Reform. 2017. Los Angeles County quietly drops its first child welfare predictive analytics experiment. https://www.nccprblog.org/2017/05/los-angeles-county-quietly-drops-its.html Online; accessed 6-January-2022.",
      "doi": ""
    },
    {
      "text": "NCCPR: National Coalition\u00a0for Child Protection\u00a0Reform. 2018. Predictive analytics in Pittsburgh child welfare: Was the \u201cethics review\u201d of Allegheny County\u2019s \u201cscarlet number\u201d algorithm ethical?https://www.nccprblog.org/2018/03/predictive-analytics-in-pittsburgh.html Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "NCCPR: National Coalition\u00a0for Child Protection\u00a0Reform. 2019. No, you can\u2019t use predictive analytics to reduce racial bias in child welfare. https://www.nccprblog.org/2019/06/no-you-cant-use-predictive-analytics-to.html Online; accessed 2-December-2021.",
      "doi": ""
    },
    {
      "text": "U.S.\u00a0Department of Health & Human\u00a0Services. [n.d.]. Protection from Discrimination in Child Welfare Activities. https://www.hhs.gov/civil-rights/for-individuals/special-topics/adoption/index.html Online; accessed 6-January-2022.",
      "doi": ""
    },
    {
      "text": "Allegheny County\u00a0Department of Human\u00a0Services. [n.d.]. Allegheny Family Screening Tool, Frequently-Asked Questions | Updated August 2018. https://www.alleghenycountyanalytics.us/wp-content/uploads/2018/10/17-ACDHS-11_AFST_102518.pdf. Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Allegheny County\u00a0Department of Human\u00a0Services. 2019. Impact Evaluation Summary of the Allegheny Family Screening Too. Pittsburgh: Allegheny County(2019).",
      "doi": ""
    },
    {
      "text": "National\u00a0Council on Crime and Delinquency Children\u2019s\u00a0Research Center. [n.d.]. The Structured Decision Making System for Child Protective Services Policy and Procedures Manual. https://www.cdss.ca.gov/Portals/9/SDM%20Policy%20and%20Procedure%20Manual.pdf. Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Bhavik\u00a0N Patel, Louis Rosenberg, Gregg Willcox, David Baltaxe, Mimi Lyons, Jeremy Irvin, Pranav Rajpurkar, Timothy Amrhein, Rajan Gupta, Safwan Halabi, 2019. Human\u2013machine partnership with artificial intelligence for chest radiograph diagnosis. NPJ digital medicine 2, 1 (2019), 1\u201310.",
      "doi": ""
    },
    {
      "text": "Andi Peng, Besmira Nushi, Emre K\u0131c\u0131man, Kori Inkpen, Siddharth Suri, and Ece Kamar. 2019. What you see is what you get? the impact of representation criteria on human bias in hiring. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 125\u2013134.",
      "doi": ""
    },
    {
      "text": "Walt\u00a0L Perry. 2013. Predictive policing: The role of crime forecasting in law enforcement operations. Rand Corporation.",
      "doi": ""
    },
    {
      "text": "Forough Poursabzi-Sangdeh, Daniel\u00a0G Goldstein, Jake\u00a0M Hofman, Jennifer\u00a0Wortman Wortman\u00a0Vaughan, and Hanna Wallach. 2021. Manipulating and measuring model interpretability. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201352.",
      "doi": "10.1145/3411764.3445315"
    },
    {
      "text": "Inioluwa\u00a0Deborah Raji and Joy Buolamwini. 2019. Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 429\u2013435.",
      "doi": "10.1145/3306618.3314244"
    },
    {
      "text": "Naomi\u00a0Schaefer Riley. 2018. Can Big Data Help Save Abused Kids?https://reason.com/2018/01/22/can-big-data-help-save-abused/ Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Dorothy Roberts. 2019. Digitizing the Carceral State (Review of [31]). Harvard Law Review 132(2019), 1695\u20141728.",
      "doi": ""
    },
    {
      "text": "Anjana Samant, Aaron Horowitz, Kath Xu, and Sophie Beiers. 2021. Family Surveillance by Algorithm: The Rapidly Spreading Tools Few Have Heard Of. American Civil Liberties Union (ACLU)(2021). https://www.aclu.org/sites/default/files/field_document/2021.09.28a_family_surveillance_by_algorithm.pdf",
      "doi": ""
    },
    {
      "text": "Joaquin Sapien. 2016. Foiled by FOIL: How One City Agency Has Dragged Out a Request for Public Records for Nearly a Year. ProPublica (April 2016). https://www.propublica.org/article/how-city-agency-dragged-out-request-for-public-records-for-nearly-a-year",
      "doi": ""
    },
    {
      "text": "Devansh Saxena, Karla Badillo-Urquiola, Pamela Wisniewski, and Shion Guha. 2021. A Framework of High-Stakes Algorithmic Decision-Making for the Public Sector Developed through a Case Study of Child-Welfare. arXiv 5(2021). arxiv:arXiv:2107.03487v2",
      "doi": ""
    },
    {
      "text": "Devansh Saxena, Karla Badillo-Urquiola, Pamela\u00a0J Wisniewski, and Shion Guha. 2020. A Human-Centered Review of Algorithms used within the US Child Welfare System. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201315.",
      "doi": "10.1145/3313831.3376229"
    },
    {
      "text": "Barbara\u00a0White Stack. [n.d.]. CYF: An agency that works, helping kids and their families. Pittsburgh Post-Gazette([n. d.]). https://www.post-gazette.com/opinion/Op-Ed/2018/02/11/CYF-An-agency-that-works-helping-kids-and-their-families/stories/201802040037 Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "David Steinhart. 2006. Juvenile Detention Risk Assessment: A Practice Guide to Juvenile Detention Reform. https://assets.aecf.org/m/resourcedoc/aecf-juveniledetentionriskassessment1-2006.pdf",
      "doi": ""
    },
    {
      "text": "Megan Stevenson. 2018. Assessing Risk Assessment in Action. Law, Economics, and Business Fellows\u2019 Discussion Paper Series 85 103 (2018), 303\u2013384. https://scholarship.law.umn.edu/mlr/58/",
      "doi": ""
    },
    {
      "text": "Megan Stevenson and Jennifer Doleac. 2021. Algorithmic Risk Assessment in the Hands of Humans. (2021). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3489440",
      "doi": ""
    },
    {
      "text": "Sarah Tan, Julius Adebayo, Kori Inkpen, and Ece Kamar. 2018. Investigating human + machine complementarity for recidivism predictions. arXiv preprint arXiv:1808.09123(2018).",
      "doi": ""
    },
    {
      "text": "MindShare Technology. [n.d.]. Improving Outcomes using data you already have. https://mindshare-technology.com/analytics/. Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Song\u00fcl Tolan, Marius Miron, Emilia G\u00f3mez, and Carlos Castillo. 2019. Why machine learning may lead to unfairness: Evidence from risk assessment for juvenile justice in catalonia. In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law. 83\u201392.",
      "doi": "10.1145/3322640.3326705"
    },
    {
      "text": "Philipp Tschandl, Noel Codella, Beng\u00fc\u00a0Nisa Akay, Giuseppe Argenziano, Ralph\u00a0P Braun, Horacio Cabo, David Gutman, Allan Halpern, Brian Helba, Rainer Hofmann-Wellenhof, 2019. Comparison of the accuracy of human readers versus machine-learning algorithms for pigmented skin lesion classification: an open, web-based, international, diagnostic study. The Lancet Oncology 20, 7 (2019), 938\u2013947.",
      "doi": ""
    },
    {
      "text": "Indr\u0117 Z\u0306liobait\u0117. 2015. On the relation between accuracy and fairness in binary classification. In Workshop on Fairness, Accountability, and Transparency in Machine Learning (FATML).",
      "doi": ""
    },
    {
      "text": "Rhema Vaithianathan, Haley Dinh, Allon Kalisher, Chamari Kithulgoda, Emily Kulick, Megh Mayur, Athena Ning, and Diana Benavides\u00a0Prado. [n.d.]. Implementing a Child Welfare Decision Aide in Douglas County | Methodology Report. https://csda.aut.ac.nz/__data/assets/pdf_file/0009/347715/Douglas-County-Methodology_Final_3_02_2020.pdf. Online; accessed 8-September-2021.",
      "doi": ""
    },
    {
      "text": "Rhema Vaithianathan, Nan Jiang, Tim Maloney, Parma Nand, and Emily Putnam-Hornstein. 2017. Developing Predictive Risk Models to Support Child Maltreatment Hotline Screening Decisions. https://www.alleghenycountyanalytics.us/wp-content/uploads/2017/04/Developing-Predictive-Risk-Models-package-with-cover-1-to-post-1.pdf",
      "doi": ""
    },
    {
      "text": "Rhema Vaithianathan, Emily Kulick, Emily Putnam-Hornstein, and Diana Benavides\u00a0Prado. [n.d.]. Allegheny Family Screening Tool: Methodology, Version 2. https://www.alleghenycountyanalytics.us/wp-content/uploads/2019/05/Methodology-V2-from-16-ACDHS-26_PredictiveRisk_Package_050119_FINAL-7.pdf.",
      "doi": ""
    },
    {
      "text": "Rhema Vaithianathan, Emily Putnam-Hornstein, Alexandra Chouldechova, Diana Benavides-Prado, and Rachel Berger. 2020. Hospital injury encounters of children identified by a predictive risk model for screening child maltreatment referrals: evidence from the Allegheny Family Screening Tool. JAMA pediatrics 174, 11 (2020).",
      "doi": ""
    },
    {
      "text": "Dakuo Wang, Liuping Wang, Zhan Zhang, Ding Wang, Haiyi Zhu, Yvonne Gao, Xiangmin Fan, and Feng Tian. 2021. \u201cBrilliant AI Doctor\u201d in Rural Clinics: Challenges in AI-Powered Clinical Decision Support System Deployment. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1\u201318.",
      "doi": "10.1145/3411764.3445432"
    },
    {
      "text": "Human\u00a0Rights Watch. 2017. \u201cNot in it for Justice\u201d: How California\u2019s Pretrial Detention and Bail System Unfairly Punishes Poor People. (2017). https://www.hrw.org/report/2017/04/11/not-itjustice/how-californias-pretrial-detention-and-bail-system-unfairly",
      "doi": ""
    },
    {
      "text": "Bryan Wilder, Eric Horvitz, and Ece Kamar. 2020. Learning to complement humans. arXiv preprint arXiv:2005.00582(2020).",
      "doi": ""
    },
    {
      "text": "Qian Yang, Aaron Steinfeld, and John Zimmerman. 2019. Unremarkable AI: Fitting intelligent decision support into critical, clinical decision-making processes. Conference on Human Factors in Computing Systems - Proceedings (2019). https://doi.org/10.1145/3290605.3300468 arxiv:1904.09612",
      "doi": "10.1145/3290605.3300468"
    },
    {
      "text": "Yunfeng Zhang, Q\u00a0Vera Liao, and Rachel\u00a0KE Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in ai-assisted decision making. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 295\u2013305.",
      "doi": "10.1145/3351095.3372852"
    },
    {
      "text": "Haiyi Zhu, Bowen Yu, Aaron Halfaker, and Loren Terveen. 2018. Value-sensitive algorithm design: Method, case study, and lessons. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201323.",
      "doi": "10.1145/3274463"
    }
  ]
}