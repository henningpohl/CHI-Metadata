{
  "doi": "10.1145/3491102.3501915",
  "title": "How Accurate Does It Feel? \u2013 Human Perception of Different Types of Classification Mistakes",
  "published": "2022-04-29",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2022,
  "badges": [],
  "abstract": "Supervised machine learning utilizes large datasets, often with ground truth labels annotated by humans. While some data points are easy to classify, others are hard to classify, which reduces the inter-annotator agreement. This causes noise for the classifier and might affect the user\u2019s perception of the classifier\u2019s performance. In our research, we investigated whether the classification difficulty of a data point influences how strongly a prediction mistake reduces the \u201cperceived accuracy\u201d. In an experimental online study, 225 participants interacted with three fictive classifiers with equal accuracy (73%). The classifiers made prediction mistakes on three different types of data points (easy, difficult, impossible). After the interaction, participants judged the classifier\u2019s accuracy. We found that not all prediction mistakes reduced the perceived accuracy equally. Furthermore, the perceived accuracy differed significantly from the calculated accuracy. To conclude, accuracy and related measures seem unsuitable to represent how users perceive the performance of classifiers.",
  "tags": [
    "Perception",
    "Annotations",
    "Ground Truth",
    "Accuracy"
  ],
  "authors": [
    {
      "name": "Andrea Papenmeier",
      "institution": "GESIS - Leibniz Institute for the Social Sciences, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659548082",
      "orcid": "missing"
    },
    {
      "name": "Dagmar Kern",
      "institution": "GESIS - Leibniz-Institute for the Social Sciences, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81328488995",
      "orcid": "missing"
    },
    {
      "name": "Daniel Hienert",
      "institution": "GESIS - Leibniz Institute for the Social Sciences, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81488670300",
      "orcid": "missing"
    },
    {
      "name": "Yvonne Kammerer",
      "institution": "Hochschule der Medien, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81416593290",
      "orcid": "missing"
    },
    {
      "name": "Christin Seifert",
      "institution": "University of Duisburg-Essen, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81309511714",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "G\u00f6rkem Algan and Ilkay Ulusoy. 2021. Image classification with deep learning in the presence of noisy labels: A survey. Knowledge-Based Systems 215 (2021), 106771. https://doi.org/10.1016/j.knosys.2021.106771",
      "doi": ""
    },
    {
      "text": "Oscar Alvarado and Annika Waern. 2018. Towards Algorithmic Experience: Initial Efforts for Social Media Contexts. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3173574.3173860",
      "doi": ""
    },
    {
      "text": "Saleema Amershi, Maya Cakmak, William\u00a0Bradley Knox, and Todd Kulesza. 2014. Power to the People: The Role of Humans in Interactive Machine Learning. AI Magazine 35, 4 (Dec. 2014), 105\u2013120. https://doi.org/10.1609/aimag.v35i4.2513",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Walter\u00a0S. Lasecki, Daniel\u00a0S. Weld, and Eric Horvitz. 2019. Beyond Accuracy: The Role of Mental Models in Human-AI Team Performance. Proceedings of the AAAI Conference on Human Computation and Crowdsourcing 7, 1 (Oct. 2019), 2\u201311. https://ojs.aaai.org/index.php/HCOMP/article/view/5285",
      "doi": ""
    },
    {
      "text": "Emma Beede, Elizabeth Baylor, Fred Hersch, Anna Iurchenko, Lauren Wilcox, Paisan Ruamviboonsuk, and Laura\u00a0M. Vardoulakis. 2020. A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3313831.3376718",
      "doi": ""
    },
    {
      "text": "Andrew\u00a0P. Bradley. 1997. The use of the area under the ROC curve in the evaluation of machine learning algorithms. Pattern Recognit. 30, 7 (1997), 1145\u20131159. https://doi.org/10.1016/S0031-3203(96)00142-2",
      "doi": "10.1016/S0031-3203%2896%2900142-2"
    },
    {
      "text": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. 2009. ImageNet: A large-scale hierarchical image database. In 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2009), 20-25 June 2009, Miami, Florida, USA. IEEE Computer Society, 248\u2013255. https://doi.org/10.1109/CVPR.2009.5206848",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J Dietvorst, Joseph\u00a0P Simmons, and Cade Massey. 2015. Algorithm aversion: People erroneously avoid algorithms after seeing them err.Journal of Experimental Psychology: General 144, 1 (2015), 114.",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J. Dietvorst, Joseph\u00a0P. Simmons, and Cade Massey. 2018. Overcoming Algorithm Aversion: People Will Use Imperfect Algorithms If They Can (Even Slightly) Modify Them. Management Science 64, 3 (2018), 1155\u20131170. https://doi.org/10.1287/mnsc.2016.2643",
      "doi": "10.1287/mnsc.2016.2643"
    },
    {
      "text": "Anca Dumitrache, Lora Aroyo, and Chris Welty. 2018. Capturing Ambiguity in Crowdsourcing Frame Disambiguation. In Proceedings of the Sixth AAAI Conference on Human Computation and Crowdsourcing (HCOMP-18). Association for the Advancement of Artificial Intelligence, 12\u201320. the Sixth AAAI Conference on Human Computation and Crowdsourcing (HCOMP-18) ; Conference date: 05-07-2018 Through 08-07-2018.",
      "doi": ""
    },
    {
      "text": "Mary\u00a0T. Dzindolet, Linda\u00a0G. Pierce, Hall\u00a0P. Beck, and Lloyd\u00a0A. Dawe. 2002. The Perceived Utility of Human and Automated Aids in a Visual Detection Task. Human Factors 44, 1 (2002), 79\u201394. https://doi.org/10.1518/0018720024494856 arXiv:https://doi.org/10.1518/0018720024494856PMID: 12118875.",
      "doi": ""
    },
    {
      "text": "Charles Elkan. 2001. The Foundations of Cost-Sensitive Learning. In Proceedings of the 17th International Joint Conference on Artificial Intelligence - Volume 2 (Seattle, WA, USA) (IJCAI\u201901). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 973\u2013978.",
      "doi": ""
    },
    {
      "text": "Sophie Emerson, Ruair\u00ed Kennedy, Luke O\u2019Shea, and John O\u2019Brien. 2019. Trends and applications of machine learning in quantitative finance. In 8th international conference on economics and finance research (ICEFR 2019).",
      "doi": ""
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto\u00a0A Novoa, Justin Ko, Susan\u00a0M Swetter, Helen\u00a0M Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. nature 542, 7639 (2017), 115\u2013118.",
      "doi": ""
    },
    {
      "text": "Stephen\u00a0H. Fairclough, Alexander\u00a0J. Karran, and Kiel Gilleade. 2015. Classification Accuracy from the Perspective of the User: Real-Time Interaction with Physiological Computing. Association for Computing Machinery, New York, NY, USA, 3029\u20133038. https://doi.org/10.1145/2702123.2702454",
      "doi": ""
    },
    {
      "text": "Benoit Frenay and Michel Verleysen. 2014. Classification in the Presence of Label Noise: A Survey. IEEE Transactions on Neural Networks and Learning Systems 25, 5(2014), 845\u2013869. https://doi.org/10.1109/TNNLS.2013.2292894",
      "doi": ""
    },
    {
      "text": "Katy\u00a0Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan, James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David\u00a0R. Millen, Murray Campbell, Sadhana Kumaravel, and Wei Zhang. 2020. Mental Models of AI Agents in a Cooperative Game Setting. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3313831.3376316",
      "doi": "10.1145/3313831.3376316"
    },
    {
      "text": "Timothy\u00a0Robin Gibson. 1993. Towards a discourse theory of abstracts and abstracting. Department of English Studies, University of Nottingham. 306\u2013399 pages.",
      "doi": ""
    },
    {
      "text": "Mitchell\u00a0L. Gordon, Kaitlyn Zhou, Kayur Patel, Tatsunori Hashimoto, and Michael\u00a0S. Bernstein. 2021. The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 388, 14\u00a0pages. https://doi.org/10.1145/3411764.3445423",
      "doi": "10.1145/3411764.3445423"
    },
    {
      "text": "Nina Grgic-Hlaca, Elissa\u00a0M. Redmiles, Krishna\u00a0P. Gummadi, and Adrian Weller. 2018. Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction. In Proceedings of the 2018 World Wide Web Conference(Lyon, France) (WWW \u201918). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 903\u2013912. https://doi.org/10.1145/3178876.3186138",
      "doi": "10.1145/3178876.3186138"
    },
    {
      "text": "Danna Gurari and Kristen Grauman. 2017. CrowdVerge: Predicting If People Will Agree on the Answer to a Visual Question. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 3511\u20133522. https://doi.org/10.1145/3025453.3025781",
      "doi": "10.1145/3025453.3025781"
    },
    {
      "text": "Tharindu Kaluarachchi, Andrew Reis, and Suranga Nanayakkara. 2021. A Review of Recent Deep Learning Approaches in Human-Centered Machine Learning. Sensors 21, 7 (2021). https://doi.org/10.3390/s21072514",
      "doi": ""
    },
    {
      "text": "Matthew Kay, Shwetak\u00a0N. Patel, and Julie\u00a0A. Kientz. 2015. How Good is 85%? A Survey Tool to Connect Classifier Evaluation to Acceptability of Accuracy. Association for Computing Machinery, New York, NY, USA, 347\u2013356. https://doi.org/10.1145/2702123.2702603",
      "doi": ""
    },
    {
      "text": "Rafal Kocielnik, Saleema Amershi, and Paul\u00a0N. Bennett. 2019. Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-User Expectations of AI Systems. Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi.org/10.1145/3290605.3300641",
      "doi": "10.1145/3290605.3300641"
    },
    {
      "text": "Matjaz Kukar and Igor Kononenko. 1998. Cost-Sensitive Learning with Neural Networks. In 13th European Conference on Artificial Intelligence, Brighton, UK, August 23-28 1998, Proceedings., Henri Prade (Ed.). John Wiley and Sons, 445\u2013449.",
      "doi": ""
    },
    {
      "text": "Todd Kulesza, Saleema Amershi, Rich Caruana, Danyel Fisher, and Denis Charles. 2014. Structured Labeling for Facilitating Concept Evolution in Machine Learning. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Toronto, Ontario, Canada) (CHI \u201914). Association for Computing Machinery, New York, NY, USA, 3075\u20133084. https://doi.org/10.1145/2556288.2557238",
      "doi": "10.1145/2556288.2557238"
    },
    {
      "text": "Ariel Levy, Monica Agrawal, Arvind Satyanarayan, and David Sontag. 2021. Assessing the Impact of Automated Suggestions on Decision Making: Domain Experts Mediate Model Errors but Take Less Initiative. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 72, 13\u00a0pages. https://doi.org/10.1145/3411764.3445522",
      "doi": "10.1145/3411764.3445522"
    },
    {
      "text": "Xiao Li, Ye-Yi Wang, and Alex Acero. 2008. Learning Query Intent from Regularized Click Graphs. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Singapore, Singapore) (SIGIR \u201908). Association for Computing Machinery, New York, NY, USA, 339\u2013346. https://doi.org/10.1145/1390334.1390393",
      "doi": "10.1145/1390334.1390393"
    },
    {
      "text": "Cynthia C.\u00a0S. Liem, Markus Langer, Andrew Demetriou, Annemarie M.\u00a0F. Hiemstra, Achmadnoer Sukma\u00a0Wicaksana, Marise\u00a0Ph. Born, and Cornelius\u00a0J. K\u00f6nig. 2018. Psychology Meets Machine Learning: Interdisciplinary Perspectives on Algorithmic Job Candidate Screening. Springer International Publishing, Cham, 197\u2013253. https://doi.org/10.1007/978-3-319-98131-4_9",
      "doi": ""
    },
    {
      "text": "Zachary\u00a0C. Lipton. 2018. The Mythos of Model Interpretability: In Machine Learning, the Concept of Interpretability is Both Important and Slippery.Queue 16, 3 (jun 2018), 31\u201357. https://doi.org/10.1145/3236386.3241340",
      "doi": "10.1145/3236386.3241340"
    },
    {
      "text": "Zhuoran Lu and Ming Yin. 2021. Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 78, 16\u00a0pages. https://doi.org/10.1145/3411764.3445562",
      "doi": "10.1145/3411764.3445562"
    },
    {
      "text": "Michael\u00a0A. Madaio, Luke Stark, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2020. Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI. Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi.org/10.1145/3313831.3376445",
      "doi": "10.1145/3313831.3376445"
    },
    {
      "text": "Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van\u00a0den Hengel. 2015. Image-Based Recommendations on Styles and Substitutes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (Santiago, Chile) (SIGIR \u201915). Association for Computing Machinery, New York, NY, USA, 43\u201352. https://doi.org/10.1145/2766462.2767755",
      "doi": "10.1145/2766462.2767755"
    },
    {
      "text": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACM Comput. Surv. 54, 6, Article 115 (July 2021), 35\u00a0pages. https://doi.org/10.1145/3457607",
      "doi": "10.1145/3457607"
    },
    {
      "text": "Rishabh Misra. 2018. News Category Dataset. https://doi.org/10.13140/RG.2.2.20331.18729",
      "doi": ""
    },
    {
      "text": "Michael Muller, Christine\u00a0T. Wolf, Josh Andres, Michael Desmond, Narendra\u00a0Nath Joshi, Zahra Ashktorab, Aabhas Sharma, Kristina Brimijoin, Qian Pan, Evelyn Duesterwald, and Casey Dugan. 2021. Designing Ground Truth and the Social Life of Labels. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 94, 16\u00a0pages. https://doi.org/10.1145/3411764.3445402",
      "doi": "10.1145/3411764.3445402"
    },
    {
      "text": "Safiya\u00a0Umoja Noble. 2018. Algorithms of Oppression: How Search Engines Reinforce Racism. New York University Press.",
      "doi": ""
    },
    {
      "text": "Mahsan Nourani, Samia Kabir, Sina Mohseni, and Eric\u00a0D Ragan. 2019. The effects of meaningful and meaningless explanations on trust and perceived system accuracy in intelligent systems. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 97\u2013105.",
      "doi": ""
    },
    {
      "text": "Cathy O\u2019Neil. 2017. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Broadway Books.",
      "doi": "10.5555/3002861"
    },
    {
      "text": "Andrea Papenmeier, Gwenn Englebienne, and Christin Seifert. 2019. How model accuracy and explanation fidelity influence user trust in AI. https://sites.google.com/view/xai2019/home IJCAI Workshop on Explainable Artificial Intelligence (XAI) 2019, XAI 2019 ; Conference date: 11-08-2019 Through 11-08-2019.",
      "doi": ""
    },
    {
      "text": "Andrea Papenmeier, Dagmar Kern, Daniel Hienert, Alfred Sliwa, Ahmet Aker, and Norbert Fuhr. 2021. Dataset of Natural Language Queries for E-Commerce. In Proceedings of the 2021 Conference on Human Information Interaction and Retrieval (Canberra ACT, Australia) (CHIIR \u201921). Association for Computing Machinery, New York, NY, USA, 307\u2013311. https://doi.org/10.1145/3406522.3446043",
      "doi": "10.1145/3406522.3446043"
    },
    {
      "text": "Ellie Pavlick and Tom Kwiatkowski. 2019. Inherent Disagreements in Human Textual Inferences. Transactions of the Association for Computational Linguistics 7 (11 2019), 677\u2013694. https://doi.org/10.1162/tacl_a_00293",
      "doi": ""
    },
    {
      "text": "Joshua\u00a0C. Peterson, Ruairidh\u00a0M. Battleday, Thomas\u00a0L. Griffiths, and Olga Russakovsky. 2019. Human Uncertainty Makes Classification More Robust. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV).",
      "doi": ""
    },
    {
      "text": "Forough Poursabzi-Sangdeh, Daniel\u00a0G Goldstein, Jake\u00a0M Hofman, Jennifer\u00a0Wortman Wortman\u00a0Vaughan, and Hanna Wallach. 2021. Manipulating and Measuring Model Interpretability. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 237, 52\u00a0pages. https://doi.org/10.1145/3411764.3445315",
      "doi": "10.1145/3411764.3445315"
    },
    {
      "text": "Paul Resnick, Yuqing Kong, Grant Schoenebeck, and Tim Weninger. 2021. Survey Equivalence: A Procedure for Measuring Classifier Accuracy Against Human Labels. CoRR abs/2106.01254(2021). arxiv:2106.01254https://arxiv.org/abs/2106.01254",
      "doi": ""
    },
    {
      "text": "Quentin Roy, Futian Zhang, and Daniel Vogel. 2019. Automation Accuracy Is Good, but High Controllability May Be Better. Association for Computing Machinery, New York, NY, USA, 1\u20138. https://doi.org/10.1145/3290605.3300750",
      "doi": ""
    },
    {
      "text": "Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora\u00a0M Aroyo. 2021. \u201cEveryone Wants to Do the Model Work, Not the Data Work\u201d: Data Cascades in High-Stakes AI. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI \u201921). Association for Computing Machinery, New York, NY, USA, Article 39, 15\u00a0pages. https://doi.org/10.1145/3411764.3445518",
      "doi": "10.1145/3411764.3445518"
    },
    {
      "text": "Sashank Santhanam, Alireza Karduni, and Samira Shaikh. 2020. Studying the Effects of Cognitive Biases in Evaluation of Conversational Agents. Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376318",
      "doi": ""
    },
    {
      "text": "Victor\u00a0S. Sheng, Foster Provost, and Panagiotis\u00a0G. Ipeirotis. 2008. Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Las Vegas, Nevada, USA) (KDD \u201908). Association for Computing Machinery, New York, NY, USA, 614\u2013622. https://doi.org/10.1145/1401890.1401965",
      "doi": "10.1145/1401890.1401965"
    },
    {
      "text": "Ben Shneiderman. 2020. Human-centered artificial intelligence: Reliable, safe & trustworthy. International Journal of Human\u2013Computer Interaction 36, 6(2020), 495\u2013504.",
      "doi": ""
    },
    {
      "text": "Alison Smith-Renner, Ron Fan, Melissa Birchfield, Tongshuang Wu, Jordan Boyd-Graber, Daniel\u00a0S. Weld, and Leah Findlater. 2020. No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML. Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376624",
      "doi": "10.1145/3313831.3376624"
    },
    {
      "text": "Marina Sokolova, Nathalie Japkowicz, and Stan Szpakowicz. 2006. Beyond accuracy, F-score and ROC: a family of discriminant measures for performance evaluation. In Australasian Joint Conference on Artificial Intelligence. Springer, 1015\u20131021.",
      "doi": "10.1007/11941439_114"
    },
    {
      "text": "Nguyen Thai-Nghe, Zeno Gantner, and Lars Schmidt-Thieme. 2010. Cost-sensitive learning methods for imbalanced data. In The 2010 International Joint Conference on Neural Networks (IJCNN). 1\u20138. https://doi.org/10.1109/IJCNN.2010.5596486",
      "doi": ""
    },
    {
      "text": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Andrew Ilyas, and Aleksander Madry. 2020. From ImageNet to Image Classification: Contextualizing Progress on Benchmarks. In Proceedings of the 37th International Conference on Machine Learning(Proceedings of Machine Learning Research, Vol.\u00a0119), Hal\u00a0Daum\u00e9 III and Aarti Singh (Eds.). PMLR, 9625\u20139635. http://proceedings.mlr.press/v119/tsipras20a.html",
      "doi": ""
    },
    {
      "text": "Peter\u00a0D Turney. 2002. Types of cost in inductive concept learning. arXiv preprint cs/0212034(2002).",
      "doi": ""
    },
    {
      "text": "Amos Tversky and Daniel Kahneman. 1973. Availability: A heuristic for judging frequency and probability. Cognitive Psychology 5, 2 (1973), 207\u2013232. https://doi.org/10.1016/0010-0285(73)90033-9",
      "doi": ""
    },
    {
      "text": "Amos Tversky and Daniel Kahneman. 1974. Judgment under uncertainty: Heuristics and biases. science 185, 4157 (1974), 1124\u20131131.",
      "doi": ""
    },
    {
      "text": "Viswanath Venkatesh and Fred\u00a0D. Davis. 2000. A Theoretical Extension of the Technology Acceptance Model: Four Longitudinal Field Studies. Management Science 46, 2 (2000), 186\u2013204. https://doi.org/10.1287/mnsc.46.2.186.11926 arXiv:https://doi.org/10.1287/mnsc.46.2.186.11926",
      "doi": "10.5555/2786232.2786234"
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian\u00a0Y. Lim. 2019. Designing Theory-Driven User-Centric Explainable AI. Association for Computing Machinery, New York, NY, USA, 1\u201315. https://doi.org/10.1145/3290605.3300831",
      "doi": ""
    },
    {
      "text": "Haishuai Wang, Zhicheng Cui, Yixin Chen, Michael Avidan, Arbi\u00a0Ben Abdallah, and Alexander Kronzer. 2018. Predicting hospital readmission via cost-sensitive deep learning. IEEE/ACM transactions on computational biology and bioinformatics 15, 6(2018), 1968\u20131978.",
      "doi": "10.1109/TCBB.2018.2827029"
    },
    {
      "text": "Jing Wang and Xin Geng. 2019. Classification with Label Distribution Learning. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (Macao, China) (IJCAI\u201919). AAAI Press, 3712\u20133718.",
      "doi": "10.5555/3367471.3367557"
    },
    {
      "text": "Xinxi Wang and Ye Wang. 2014. Improving Content-Based and Hybrid Music Recommendation Using Deep Learning. In Proceedings of the 22nd ACM International Conference on Multimedia (Orlando, Florida, USA) (MM \u201914). Association for Computing Machinery, New York, NY, USA, 627\u2013636. https://doi.org/10.1145/2647868.2654940",
      "doi": "10.1145/2647868.2654940"
    },
    {
      "text": "Jennifer Wortman\u00a0Vaughan and Hanna Wallach. 2021. A human-centered agenda for intelligible machine learning. Machines We Trust: Getting Along with Artificial Intelligence. Ed. by PELILLO, M. and SCANTAMBURLO 2021 (2021), 224.",
      "doi": ""
    },
    {
      "text": "Jin Xiao, Xu Zhou, Yu Zhong, Ling Xie, Xin Gu, and Dunhu Liu. 2020. Cost-sensitive semi-supervised selective ensemble model for customer credit scoring. Knowledge-Based Systems 189 (2020), 105118. https://doi.org/10.1016/j.knosys.2019.105118",
      "doi": "10.1016/j.knosys.2019.105118"
    },
    {
      "text": "Ying Xu and Mark Warschauer. 2020. What Are You Talking To?: Understanding Children\u2019s Perceptions of Conversational Agents. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI \u201920). Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376416",
      "doi": "10.1145/3313831.3376416"
    },
    {
      "text": "Fumeng Yang, Zhuanyi Huang, Jean Scholtz, and Dustin\u00a0L. Arendt. 2020. How Do Visual Explanations Foster End Users\u2019 Appropriate Trust in Machine Learning?. In Proceedings of the 25th International Conference on Intelligent User Interfaces (Cagliari, Italy) (IUI \u201920). Association for Computing Machinery, New York, NY, USA, 189\u2013201. https://doi.org/10.1145/3377325.3377480",
      "doi": "10.1145/3377325.3377480"
    },
    {
      "text": "Shuo Yang, Mohammed Korayem, Khalifeh AlJadda, Trey Grainger, and Sriraam Natarajan. 2017. Combining content-based and collaborative filtering for job recommendation system: A cost-sensitive Statistical Relational Learning approach. Knowledge-Based Systems 136 (2017), 37\u201345. https://doi.org/10.1016/j.knosys.2017.08.017",
      "doi": "10.1016/j.knosys.2017.08.017"
    },
    {
      "text": "Ming Yin, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2019. Understanding the Effect of Accuracy on Trust in Machine Learning Models. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3290605.3300509",
      "doi": ""
    },
    {
      "text": "Xingquan Zhu and Xindong Wu. 2004. Class Noise vs. Attribute Noise: A Quantitative Study of Their Impacts. Artif. Intell. Rev. 22, 3 (Nov. 2004), 177\u2013210.",
      "doi": ""
    }
  ]
}