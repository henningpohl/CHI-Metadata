{
  "doi": "10.1145/3491102.3517681",
  "title": "Watch It, Don\u2019t Imagine It: Creating a Better Caption-Occlusion Metric by Collecting More Ecologically Valid Judgments from DHH Viewers",
  "published": "2022-04-29",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-14",
  "year": 2022,
  "badges": [],
  "abstract": "Television captions blocking visual information causes dissatisfaction among Deaf and Hard of Hearing (DHH) viewers, yet existing caption evaluation metrics do not consider occlusion. To create such a metric, DHH participants in a recent study imagined how bad it would be if captions blocked various on-screen text or visual content. To gather more ecologically valid data for creating an improved metric, we asked 24 DHH participants to give subjective judgments of caption quality after actually watching videos, and a regression analysis revealed which on-screen contents\u2019 occlusion related to users\u2019 judgments. For several video genres, a metric based on our new dataset out-performed the prior state-of-the-art metric for predicting the severity of captions occluding content during videos, which had been based on that prior study. We contribute empirical findings for improving DHH viewers\u2019 experience, guiding the placement of captions to minimize occlusions, and automated evaluation of captioning quality in television broadcasts.",
  "tags": [
    "Caption",
    "Accessibility",
    "Regression",
    "Metric"
  ],
  "authors": [
    {
      "name": "Akhter Al Amin",
      "institution": "Computing and Information Sciences, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-99659728719/rel-imgonly/13f8yhym_400x400.jpeg",
      "acmid": "99659728719",
      "orcid": "missing"
    },
    {
      "name": "Saad Hassan",
      "institution": "Computing and Information Sciences, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-99659729223/rel-imgonly/img_20210130_220348_279.jpg",
      "acmid": "99659729223",
      "orcid": "missing"
    },
    {
      "name": "Sooyeon Lee",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659135375",
      "orcid": "0000-0002-4971-2004"
    },
    {
      "name": "Matt Huenerfauth",
      "institution": "School of Information, Rochester Institute of Technology, United States",
      "img": "/do/10.1145/contrib-81100240888/rel-imgonly/huenerfauth-matt-headshot-1.jpg",
      "acmid": "81100240888",
      "orcid": "0000-0001-6290-2681"
    }
  ],
  "references": [
    {
      "text": "Ahmed Ali and Steve Renals. 2018. Word Error Rate Estimation for Speech Recognition: e-WER. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, Melbourne, Australia, 20\u201324. https://doi.org/10.18653/v1/P18-2004",
      "doi": ""
    },
    {
      "text": "Akhter\u00a0Al Amin, Abraham Glasser, Raja Kushalnagar, Christian Vogler, and Matt Huenerfauth. 2021. Preferences of Deaf or Hard of Hearing Users for Live-TV Caption Appearance. In Universal Access in Human-Computer Interaction. Access to Media, Learning and Assistive Environments, Margherita Antona and Constantine Stephanidis (Eds.). Springer International Publishing, Cham, 189\u2013201.",
      "doi": ""
    },
    {
      "text": "Akhter\u00a0Al Amin, Saad Hassan, and Matt Huenerfauth. 2021. Caption-Occlusion Severity Judgments across Live-Television Genres from Deaf and Hard-of-Hearing Viewers. Association for Computing Machinery, New York NY USA. https://doi.org/10.1145/3430263.3452429",
      "doi": "10.1145/3430263.3452429"
    },
    {
      "text": "Akhter\u00a0Al Amin, Saad Hassan, and Matt Huenerfauth. 2021. Effect of Occlusion on Deaf and Hard of\u00a0Hearing Users\u2019 Perception of\u00a0Captioned Video Quality. In Universal Access in Human-Computer Interaction. Access to Media, Learning and Assistive Environments, Margherita Antona and Constantine Stephanidis (Eds.). Springer International Publishing, Cham, 202\u2013220.",
      "doi": ""
    },
    {
      "text": "BBC.2018. BBC Subtitle Guidelines, 2018. British Broadcasting Corporation, Portland Place, London, United Kingdom. https://bbc.github.io/subtitle-guidelines",
      "doi": ""
    },
    {
      "text": "Larwan Berke, Khaled Albusays, Matthew Seita, and Matt Huenerfauth. 2019. Preferred Appearance of Captions Generated by Automatic Speech Recognition for Deaf and Hard-of-Hearing Viewers. In Extended Abstracts of the 2019 CHI Conference on Human FaWERctors in Computing Systems (Glasgow, Scotland Uk) (CHI EA \u201919). Association for Computing Machinery, New York, NY, USA, 1\u20136. https://doi.org/10.1145/3290607.3312921",
      "doi": "10.1145/3290607.3312921"
    },
    {
      "text": "Bonnie\u00a0B. Blanchfield, Jacob\u00a0J. Feldman, Jennifer\u00a0L. Dunbar, and Eric\u00a0N. Gardner. 2001. The severely to profoundly hearing-impaired population in the United States: prevalence estimates and demographics.Journal of the American Academy of Audiology 12, 4(2001), 183\u20139. http://www.ncbi.nlm.nih.gov/pubmed/11332518",
      "doi": ""
    },
    {
      "text": "G. Bradski. 2000. The OpenCV Library. Dr. Dobb\u2019s Journal of Software Tools(2000).",
      "doi": ""
    },
    {
      "text": "Tom Apone Brad Botkin\u00a0Marcia Brooks and Larry Goldberg. 2011. Caption Accuracy Metrics Project Research into Automated Error Ranking of Real-time Captions in Live Television News Programs. National Center for Accessible Media (NCAM) WGBH, WGBH (NCAM) One Guest Street Boston, MA 02135.",
      "doi": ""
    },
    {
      "text": "Andy Brown, Rhia Jones, Michael Crabb, James Sandford, Matthew Brooks, Michael Armstrong, and Caroline Jay. 2015. Dynamic Subtitles: The User Experience, In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video. Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video 1, 1. https://doi.org/10.1145/2745197.2745204",
      "doi": "10.1145/2745197.2745204"
    },
    {
      "text": "Wim\u00a0De Bruycker and G\u00e9ry d\u2019Ydewalle. 2003. Chapter 31 - Reading Native and Foreign Language Television Subtitles in Children and Adults. In The Mind\u2019s Eye, J.\u00a0Hy\u00f6n\u00e4, R.\u00a0Radach, and H.\u00a0Deubel (Eds.). North-Holland, Amsterdam, 671\u2013684. https://doi.org/10.1016/B978-044451020-4/50036-0",
      "doi": ""
    },
    {
      "text": "Le Chen, Ruijun Ma, Anik\u00f3 Hann\u00e1k, and Christo Wilson. 2018. Investigating the Impact of Gender on Rank in Resume Search Engines. Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi-org.ezproxy.rit.edu/10.1145/3173574.3174225",
      "doi": ""
    },
    {
      "text": "Federal\u00a0Communications Commission.2010. Captioning Key for Educational Media, Guidelines and Preferred Technique. Retrieved from:. The Described and Captioned Media Program. http://access-ed.r2d2.uwm.edu/resources/captioning-key.pdf",
      "doi": ""
    },
    {
      "text": "Federal\u00a0Communications Commission.2014. Closed Captioning Quality Report and Order, Declaratory Ruling, FNPRM. Retrieved from:. Federal Communications Commission., Washington, D.C., USA. https://www.fcc.gov/document/closed-captioning-quality-report-and-order-declaratory-ruling-fnprm",
      "doi": ""
    },
    {
      "text": "The\u00a0Qt Company. 2020. Qt 5 tool (Version 5.15) [Software]. https://doc.qt.io/qt-5.15/index.html",
      "doi": ""
    },
    {
      "text": "Michael Crabb, Rhianne Jones, Mike Armstrong, and Chris\u00a0J. Hughes. 2015. Online News Videos: The UX of Subtitle Position. In Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility (Lisbon, Portugal) (ASSETS \u201915). Association for Computing Machinery, New York, NY, USA, 215\u2013222. https://doi.org/10.1145/2700648.2809866",
      "doi": "10.1145/2700648.2809866"
    },
    {
      "text": "S. Cushion. 2015. News and Politics: The Rise of Live and Interpretive Journalism. Taylor & Francis, 5 Howick Place, London, SW1P 1WG.https://books.google.com/books?id=d8kqBwAAQBAJ",
      "doi": ""
    },
    {
      "text": "Carsten\u00a0F. Dormann, Jane Elith, Sven Bacher, Carsten Buchmann, Gudrun Carl, Gabriel Carr\u00e9, Jaime R.\u00a0Garc\u00eda Marqu\u00e9z, Bernd Gruber, Bruno Lafourcade, Pedro\u00a0J. Leit\u00e3o, Tamara M\u00fcnkem\u00fcller, Colin McClean, Patrick\u00a0E. Osborne, Bj\u00f6rn Reineking, Boris Schr\u00f6der, Andrew\u00a0K. Skidmore, Damaris Zurell, and Sven Lautenbach. 2013. Collinearity: a review of methods to deal with it and a simulation study evaluating their performance. Ecography 36, 1 (2013), 27\u201346. https://doi.org/10.1111/j.1600-0587.2012.07348.x arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1600-0587.2012.07348.x",
      "doi": ""
    },
    {
      "text": "A. Edwards and I. Curator\u00a0of Charleston Museum J\u00a0Long. 1995. Extraordinary Human-Computer Interaction: Interfaces for Users with Disabilities. Cambridge University Press, 1 Liberty Plaza New York, NY, USA 10006. https://books.google.com/books?id=3KBOAAAAIAAJ",
      "doi": ""
    },
    {
      "text": "David Fairbairn and Milad\u00a0Niroumand Jadidi. 2013. Influential Visual Design Parameters on TV Weather Maps. The Cartographic Journal 50, 4 (2013), 311\u2013323. https://doi.org/10.1179/1743277413Y.0000000040 arXiv:https://doi.org/10.1179/1743277413Y.0000000040",
      "doi": ""
    },
    {
      "text": "Olivia Gerber-Mor\u00f3n, Agnieszka Szarkowska, and Bencie Woll. 2018. The impact of text segmentation on subtitle reading. Journal of Eye Movement Research 11, 4 (Jun. 2018), 18\u00a0pages. https://doi.org/10.16910/11.4.2",
      "doi": ""
    },
    {
      "text": "Ulrike Groemping. 2006. Relative Importance for Linear Regression in R: The Package relaimpo. Journal of Statistical Software, Articles 17, 1 (2006), 1\u201327. https://doi.org/10.18637/jss.v017.i01",
      "doi": ""
    },
    {
      "text": "Stephen\u00a0R. Gulliver and Gheorghita Ghinea. 2003a. How level and type of deafness affect user perception of multimedia video clips.Inform. Soc. J. 2 2, 4 (2003a), 374\u2013386.",
      "doi": ""
    },
    {
      "text": "Stephen\u00a0R. Gulliver and Gheorghita Ghinea. 2003b. Impact of captions on hearing impaired and hearing perception of multimedia video clipsb. In Proceedings of the IEEE International Conference on Multimedia and Expo., USA.",
      "doi": ""
    },
    {
      "text": "Richang Hong, Meng Wang, Xiao-Tong Yuan, Mengdi Xu, Jianguo Jiang, Shuicheng Yan, and Tat-Seng Chua. 2011. Video Accessibility Enhancement for Hearing-Impaired Users. ACM Trans. Multimedia Comput. Commun. Appl. 7S, 1, Article 24 (Nov. 2011), 19\u00a0pages. https://doi.org/10.1145/2037676.2037681",
      "doi": "10.1145/2037676.2037681"
    },
    {
      "text": "Yongtao Hu, Jan Kautz, Yizhou Yu, and Wenping Wang. 2014. Speaker-following video subtitles, In ACM Transactions on Multimedia Computing, Communications and Applications. ACM Transactions on Multimedia Computing, Communications, and Applications 11 2, 32.",
      "doi": ""
    },
    {
      "text": "Neter J., Kutner\u00a0M. H., Nachtsheim, C. J., and W. Wasserman. 1996. Applied Linear Statistical Models. (1996). Chicago: Irwin, Chicago, USA.",
      "doi": ""
    },
    {
      "text": "David\u00a0G. Jenkins and Pedro\u00a0F. Quintana-Ascencio. 2020. A solution to minimum sample size for regressions. PLOS ONE 15, 2 (02 2020), 1\u201315. https://doi.org/10.1371/journal.pone.0229345",
      "doi": ""
    },
    {
      "text": "Yingyu Ji, Shigang Wang, Yang Lu, Jian Wei, and Yan Zhao. 2018. Eye and mouth state detection algorithm based on contour feature extraction. Journal of Electronic Imaging 27, 5 (2018), 1 \u2013 8. https://doi.org/10.1117/1.JEI.27.5.051205",
      "doi": ""
    },
    {
      "text": "Bo Jiang, Sijiang Liu, Liping He, Weimin Wu, Hongli Chen, and Yunfei Shen. 2017. Subtitle Positioning for E-Learning Videos Based on Rough Gaze Estimation and Saliency Detection. In SIGGRAPH Asia 2017 Posters (Bangkok, Thailand) (SA \u201917). Association for Computing Machinery, New York, NY, USA, Article 15, 2\u00a0pages. https://doi.org/10.1145/3145690.3145735",
      "doi": "10.1145/3145690.3145735"
    },
    {
      "text": "Hernisa Kacorri, Eshed Ohn-Bar, Kris\u00a0M. Kitani, and Chieko Asakawa. 2018. Environmental Factors in Indoor Navigation Based on Real-World Trajectories of Blind Users. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi-org.ezproxy.rit.edu/10.1145/3173574.3173630",
      "doi": ""
    },
    {
      "text": "Sushant Kafle and Matt Huenerfauth. 2019. Predicting the Understandability of Imperfect English Captions for People Who Are Deaf or Hard of Hearing. ACM Trans. Access. Comput. 12, 2, Article 7 (June 2019), 32\u00a0pages. https://doi.org/10.1145/3325862",
      "doi": "10.1145/3325862"
    },
    {
      "text": "Joos Korstanje. 2021. The Linear Regression. Apress, Berkeley, CA, 149\u2013157. https://doi.org/10.1007/978-1-4842-7150-6_11",
      "doi": ""
    },
    {
      "text": "Kuno Kurzhals, Emine Cetinkaya, Yongtao Hu, Wenping Wang, and Daniel Weiskopf. 2017. Close to the action: Eye-tracking evaluation of speaker-following subtitles. Association for Computing Machinery, New York, NY, USA, 6559\u20136568. https://doi.org/10.1145/3025453.3025772",
      "doi": "10.1145/3025453.3025772"
    },
    {
      "text": "Kuno Kurzhals, Fabian G\u00f6bel, Katrin Angerbauer, Michael Sedlmair, and Martin Raubal. 2020. A View on the Viewer: Gaze-Adaptive Captions for Videos. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI \u201920). Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3313831.3376266",
      "doi": "10.1145/3313831.3376266"
    },
    {
      "text": "Raja\u00a0S. Kushalnagar, Walter\u00a0S. Lasecki, and Jeffrey\u00a0P. Bigham. 2014. Accessibility Evaluation of Classroom Captions. ACM Trans. Access. Comput. 5, 3, Article 7 (Jan. 2014), 24\u00a0pages. https://doi.org/10.1145/2543578",
      "doi": "10.1145/2543578"
    },
    {
      "text": "English language Working Group\u00a0on Closed Captioning\u00a0Standards. 2018. English-language Working Group. 2008. Closed Captioning Standards and Protocol for Canadian English Language Television Programming Services. Retrieved from:. Canadian Association of Broadcasters. https://www.cab-acr.ca/english/social/captioning/captioning.pdf",
      "doi": ""
    },
    {
      "text": "Jonathan Lazar, Jinjuan\u00a0Heidi Feng, and Harry Hochheiser. 2010. Research Methods in Human-Computer Interaction. Wiley Publishing, Hoboken, NJ, USA.",
      "doi": "10.5555/1841406"
    },
    {
      "text": "R.H. Lindeman, P.F. Merenda, and R.Z. Gold. 1980. Introduction to Bivariate and Multivariate Analysis. Scott, Foresman, Northbrook, IL. https://books.google.com/books?id=-hfvAAAAMAAJ",
      "doi": ""
    },
    {
      "text": "Xingyu Liu, Patrick Carrington, Xiang\u00a0\u2019Anthony\u2019 Chen, and Amy Pavel. 2021. What Makes Videos Accessible to Blind and Visually Impaired People?Association for Computing Machinery, New York, NY, USA. https://doi-org.ezproxy.rit.edu/10.1145/3411764.3445233",
      "doi": ""
    },
    {
      "text": "Obach M, Lehr M, and Arruti A. 2007. Automatic speech recognition for live TV subtitling for hearing-impaired people. Challenges for Assistive Technology: AAATE 07 20 (2007), 286.",
      "doi": ""
    },
    {
      "text": "Fabio Masina, Valeria Orso, Patrik Pluchino, Giulia Dainese, Stefania Volpato, Cristian Nelini, Daniela Mapelli, Anna Spagnolli, and Luciano Gamberini. 2020. Investigating the Accessibility of Voice Assistants With Impaired Users: Mixed Methods Study. J Med Internet Res 22, 9 (25 Sep 2020), e18431. https://doi.org/10.2196/18431",
      "doi": ""
    },
    {
      "text": "Ali Mirza, Ossama Zeshan, Muhammad Atif, and Imran Siddiqi. 2020. Detection and recognition of cursive text from video frames. EURASIP Journal on Image and Video Processing 2020, 1 (Aug. 2020), 34.",
      "doi": "10.1186/s13640-020-00523-5"
    },
    {
      "text": "Ofcom.2015. Measuring live subtitling quality, UK.The Office of Communications. https://www.ofcom.org.uk/__data/assets/pdf_file/0019/45136/sampling-report.pdf",
      "doi": ""
    },
    {
      "text": "Andrew\u00a0D. Ouzts, Nicole\u00a0E. Snell, Prabudh Maini, and Andrew\u00a0T. Duchowski. 2013. Determining Optimal Caption Placement Using Eye Tracking. In Proceedings of the 31st ACM International Conference on Design of Communication (Greenville, North Carolina, USA) (SIGDOC \u201913). Association for Computing Machinery, New York, NY, USA, 189\u2013190. https://doi.org/10.1145/2507065.2507100",
      "doi": "10.1145/2507065.2507100"
    },
    {
      "text": "Anni Rander and Peter\u00a0Olaf Looms. 2010. The Accessibility of Television News with Live Subtitling on Digital Television. In Proceedings of the 8th European Conference on Interactive TV and Video (Tampere, Finland) (EuroITV \u201910). Association for Computing Machinery, New York, NY, USA, 155\u2013160. https://doi.org/10.1145/1809777.1809809",
      "doi": "10.1145/1809777.1809809"
    },
    {
      "text": "Rui Rodrigues, Ana Veloso, and Oscar Mealha. 2016. Influence of the graphical layout of television news on the viewers: An eye tracking study. Observatorio 10 (03 2016), 67\u201382.",
      "doi": ""
    },
    {
      "text": "Rui Rodrigues, Ana Veloso, and \u00d3scar Mealha. 2012. A Television News Graphical Layout Analysis Method Using Eye Tracking. In 2012 16th International Conference on Information Visualisation. IEEE Computer Society, USA, 357\u2013362. https://doi.org/10.1109/IV.2012.66",
      "doi": "10.1109/IV.2012.66"
    },
    {
      "text": "Pablo Romero-Fresco and Juan\u00a0Mart\u00ednez P\u00e9rez. 2015. Accuracy Rate in Live Subtitling: The NER Model. Palgrave Macmillan UK, London, 28\u201350. https://doi.org/10.1057/9781137552891_3",
      "doi": ""
    },
    {
      "text": "J. Sandford. 2015. The impact of subtitle display rate on enjoyment under normal television viewing conditions. IET Conference Proceedings 1 (2015), 8.\u20138.(1). https://digital-library.theiet.org/content/conferences/10.1049/ibc.2015.0018",
      "doi": ""
    },
    {
      "text": "Martin Schmettow. 2015. Tutorial: Modern Regression Techniques for HCI Researchers. In Human-Computer Interaction \u2013 INTERACT 2015, Julio Abascal, Simone Barbosa, Mirko Fetter, Tom Gross, Philippe Palanque, and Marco Winckler (Eds.). Springer International Publishing, Cham, 651\u2013654.",
      "doi": ""
    },
    {
      "text": "Mark\u00a0A. Schmuckler. 2001. What Is Ecological Validity? A Dimensional Analysis. Infancy 2, 4 (2001), 419\u2013436. https://doi.org/10.1207/S15327078IN0204_02",
      "doi": ""
    },
    {
      "text": "Elizabeth\u00a0C. Smith, Mary\u00a0Nell McNeese, Lin Harper, and Sherry Finneran. 2006. Factors Which Predict Compliance with Accessibility Guidelines for Disabled Users By Higher Education Institutions. In Proceedings of E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education 2006, Thomas Reeves and Shirley Yamashita (Eds.). Association for the Advancement of Computing in Education (AACE), Honolulu, Hawaii, USA, 922\u2013929. https://www.learntechlib.org/p/23819",
      "doi": ""
    },
    {
      "text": "Society of Cable Telecommunications Engineers. SCTE. 2012. Standard For Carriage Of VBI Data In Cable Digital Transport Streams. Technical Report. CableLabs.",
      "doi": ""
    },
    {
      "text": "Ruxandra Tapu, Bogdan Mocanu, and Titus Zaharia. 2019. DEEP-HEAR: A Multimodal Subtitle Positioning System Dedicated to Deaf and Hearing-Impaired People. IEEE Access 7(2019), 88150\u201388162. https://doi.org/10.1109/ACCESS.2019.2925806",
      "doi": ""
    },
    {
      "text": "S.\u00a0V. Tathe, A.\u00a0S. Narote, and S.\u00a0P. Narote. 2016. Human face detection and recognition in videos. In 2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI). 2200\u20132205. https://doi.org/10.1109/ICACCI.2016.7732378",
      "doi": ""
    },
    {
      "text": "The Nielsen Company (US), LLC.2020. The Nielson Total Audience Report: April 2020. Technical Report. Nielson.",
      "doi": ""
    },
    {
      "text": "Toinon Vigier, Yoann Baveye, Josselin Rousseau, and Patrick Le\u00a0Callet. 2016. Visual attention as a dimension of QoE: Subtitles in UHD videos. In 2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX). IEEE, Piscataway, NJ, 1\u20136. https://doi.org/10.1109/QoMEX.2016.7498924",
      "doi": ""
    },
    {
      "text": "Caroline Wagenbreth, Julia Rieger, Hans-Jochen Heinze, and Tino Zaehle. 2014. Seeing emotions in the eyes \u2013 inverse priming effects induced by eyes expressing mental states. Frontiers in Psychology 5 (2014), 1039. https://doi.org/10.3389/fpsyg.2014.01039",
      "doi": ""
    },
    {
      "text": "James\u00a0M. Waller and Raja\u00a0S. Kushalnagar. 2016. Evaluation of Automatic Caption Segmentation. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (Reno, Nevada, USA) (ASSETS \u201916). Association for Computing Machinery, New York, NY, USA, 331\u2013332. https://doi.org/10.1145/2982142.2982205",
      "doi": ""
    },
    {
      "text": "James\u00a0M. Waller and Raja\u00a0S. Kushalnagar. 2016. Evaluation of Automatic Caption Segmentation. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (Reno, Nevada, USA) (ASSETS \u201916). Association for Computing Machinery, New York, NY, USA, 331\u2013332. https://doi.org/10.1145/2982142.2982205",
      "doi": ""
    },
    {
      "text": "Jennifer Wehrmeyer. 2014. Eye-tracking Deaf and hearing viewing of sign language interpreted news broadcasts. Journal of Eye Movement Research, Moosgasse 16 CH-3305 Iffwil Switzerland.",
      "doi": ""
    },
    {
      "text": "WGBH. 2019. Closed Captioning on TV in the United States 101. Media Access Group (WGBH). https://blog.snapstream.com/closed-captioning-on-tv-in-the-united-states-101",
      "doi": ""
    },
    {
      "text": "X. Zhou, C. Yao, H. Wen, Y. Wang, S. Zhou, W. He, and J. Liang. 2017. EAST: An Efficient and Accurate Scene Text Detector. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, Los Alamitos, CA, USA, 2642\u20132651. https://doi.org/10.1109/CVPR.2017.283",
      "doi": ""
    }
  ]
}