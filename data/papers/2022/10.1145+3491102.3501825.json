{
  "doi": "10.1145/3491102.3501825",
  "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models",
  "published": "2022-04-29",
  "proctitle": "CHI '22: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-23",
  "year": 2022,
  "badges": [],
  "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.",
  "authors": [
    {
      "name": "Vivian Liu",
      "institution": "Columbia University, United States and Columbia University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659528782",
      "orcid": "missing"
    },
    {
      "name": "Lydia B Chilton",
      "institution": "Computer Science Department, Columbia University, United States and Computer Science Department, Columbia University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659480701",
      "orcid": "0000-0002-1737-1276"
    }
  ],
  "references": [
    {
      "text": "2021. Introduction to VQGAN CLIP. https://docs.google.com/document/d/1Lu7XPRKlNhBQjcKr8k8qRzUzbBW7kzxb5Vu72GMRn2E/edit",
      "doi": ""
    },
    {
      "text": "2021. VQGANCLIP Hashtag. https://twitter.com/hashtag/vqganclip?src=hashtag_click",
      "doi": ""
    },
    {
      "text": "Adverb. 2021. Advadnoun. https://twitter.com/advadnoun",
      "doi": ""
    },
    {
      "text": "Aesthetics Wiki Community. 2022. Aesthetics Wiki. https://aesthetics.fandom.com/wiki/",
      "doi": ""
    },
    {
      "text": "Gwern Branwen. 2020. Gpt-3 creative fiction. https://www.gwern.net/GPT-3",
      "doi": ""
    },
    {
      "text": "Andrew Brock, Jeff Donahue, and Karen Simonyan. 2019. Large Scale GAN Training for High Fidelity Natural Image Synthesis. arxiv:1809.11096\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Marc Brysbaert, Amy Warriner, and Victor Kuperman. 2013. Concreteness ratings for 40 thousand generally known English word lemmas. Behavior research methods 46 (10 2013). https://doi.org/10.3758/s13428-013-0403-5",
      "doi": ""
    },
    {
      "text": "Aylin Caliskan, Joanna\u00a0J. Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science 356, 6334 (Apr 2017), 183\u2013186. https://doi.org/10.1126/science.aal4230",
      "doi": ""
    },
    {
      "text": "Andrew Cantino. 2021. Prompt Engineering Tips and Tricks with GPT-3. https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/",
      "doi": ""
    },
    {
      "text": "Siddhartha Chaudhuri, Evangelos Kalogerakis, Stephen Giguere, and Thomas Funkhouser. 2013. Attribit: Content Creation with Semantic Attributes. In Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology (St. Andrews, Scotland, United Kingdom) (UIST \u201913). Association for Computing Machinery, New York, NY, USA, 193\u2013202. https://doi.org/10.1145/2501988.2502008",
      "doi": "10.1145/2501988.2502008"
    },
    {
      "text": "Katherine Crowson. 2021. afiaka87/clip-guided-diffusion: A CLI tool/python module for generating images from text using guided diffusion and CLIP from OpenAI.https://github.com/afiaka87/clip-guided-diffusion",
      "doi": ""
    },
    {
      "text": "Katherine Crowson. 2021. Rivers Have Wings. https://twitter.com/RiversHaveWings",
      "doi": ""
    },
    {
      "text": "Bestiario del Hypogripho. 2021. Ayuda:Generar im\u00e1genes con VQGAN CLIP/English. https://tuscriaturas.miraheze.org/w/index.php?title=Ayuda:Generar_im\u00e1genes_con_VQGAN CLIP/English",
      "doi": ""
    },
    {
      "text": "Ruta Desai, Fraser Anderson, Justin Matejka, Stelian Coros, James McCann, George Fitzmaurice, and Tovi Grossman. 2019. Geppetto: Enabling Semantic Design of Expressive Robot Behaviors. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland Uk) (CHI \u201919). ACM, New York, NY, USA, Article 369, 14\u00a0pages. https://doi.org/10.1145/3290605.3300599",
      "doi": "10.1145/3290605.3300599"
    },
    {
      "text": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arxiv:1810.04805\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "Leon\u00a0A. Gatys, Alexander\u00a0S. Ecker, and Matthias Bethge. 2015. A Neural Algorithm of Artistic Style. arxiv:1508.06576\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Songwei Ge and Devi Parikh. 2021. Visual Conceptual Blending with Large-scale Language and Vision Models. arxiv:2106.14127\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "Katy\u00a0Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan, James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David\u00a0R. Millen, Murray Campbell, Sadhana Kumaravel, and Wei Zhang. 2020. Mental Models of AI Agents in a Cooperative Game Setting. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3313831.3376316",
      "doi": "10.1145/3313831.3376316"
    },
    {
      "text": "Katy\u00a0Ilonka Gero and Lydia\u00a0B. Chilton. 2019. Metaphoria: An Algorithmic Companion for Metaphor Creation. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3290605.3300526",
      "doi": "10.1145/3290605.3300526"
    },
    {
      "text": "Arnab Ghosh, Richard Zhang, Puneet\u00a0K. Dokania, Oliver Wang, Alexei\u00a0A. Efros, Philip H.\u00a0S. Torr, and Eli Shechtman. 2019. Interactive Sketch and Fill: Multiclass Sketch-to-Image Translation. arxiv:1909.11081\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Ian\u00a0J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Networks. arxiv:1406.2661\u00a0[stat.ML]",
      "doi": ""
    },
    {
      "text": "Cheng-Zhi\u00a0Anna Huang, Hendrik\u00a0Vincent Koops, Ed Newton-Rex, Monica Dinculescu, and Carrie\u00a0J. Cai. 2020. AI Song Contest: Human-AI Co-Creation in Songwriting. arxiv:2010.05388\u00a0[cs.SD]",
      "doi": ""
    },
    {
      "text": "Youngseung Jeon, Seungwan Jin, Patrick\u00a0C. Shih, and Kyungsik Han. 2021. FashionQ: An AI-Driven Creativity Support Tool for Facilitating Ideation in Fashion Design. Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/3411764.3445093",
      "doi": "10.1145/3411764.3445093"
    },
    {
      "text": "Justin. 2021. Somewhere Systems Twitter. https://twitter.com/somewheresy",
      "doi": ""
    },
    {
      "text": "Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. 2020. Training Generative Adversarial Networks with Limited Data. CoRR abs/2006.06676(2020). arXiv:2006.06676https://arxiv.org/abs/2006.06676",
      "doi": ""
    },
    {
      "text": "Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. 2020. Analyzing and Improving the Image Quality of StyleGAN. arxiv:1912.04958\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Aran Komatsuzaki. 2021. When you generate images with VQGAN CLIP, the image quality dramatically improves if you add \u201dunreal engine\u201d to your prompt. People are now calling this \u201dunreal engine trick\u201d lole.g. \u201dthe angel of air. unreal engine\u201d pic.twitter.com/G4xBgVLyiv. https://twitter.com/arankomatsuzaki/status/1399471244760649729",
      "doi": ""
    },
    {
      "text": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. arxiv:2107.13586\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "Yang Liu, Eunice Jun, Qisheng Li, and Jeffrey Heer. 2019. Latent Space Cartography: Visual Analysis of Vector Space Embeddings. Computer Graphics Forum 38, 3 (2019), 67\u201378. https://doi.org/10.1111/cgf.13672",
      "doi": ""
    },
    {
      "text": "Ryan Louie, Andy Coenen, Cheng\u00a0Zhi Huang, Michael Terry, and Carrie\u00a0J. Cai. 2020. Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376739",
      "doi": "10.1145/3313831.3376739"
    },
    {
      "text": "Justin Matejka, Michael Glueck, Erin Bradner, Ali Hashemi, Tovi Grossman, and George Fitzmaurice. 2018. Dream Lens: Exploration and Visualization of Large-Scale Generative Design Datasets. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3173574.3173943",
      "doi": "10.1145/3173574.3173943"
    },
    {
      "text": "Alexander Mordvintsev, Michael Tyka, and Christopher Olah. 2015. google/deepdream. https://github.com/google/deepdream",
      "doi": ""
    },
    {
      "text": "Ryan Murdock. [n.d.]. lucidrains/big-sleep: A simple command line tool for text to image generation, using OpenAI\u2019s CLIP and a BigGAN. Technique was originally created by https://twitter.com/advadnoun. https://github.com/lucidrains/big-sleep",
      "doi": ""
    },
    {
      "text": "Ryan Murdock. 2022. lucidrains/big-sleep: A simple command line tool for text to image generation, using OpenAI\u2019s CLIP and a BigGAN. Technique was originally created by https://twitter.com/advadnoun. https://github.com/lucidrains/big-sleep",
      "doi": ""
    },
    {
      "text": "nerdyroden. 2022. nerdyrodent/VQGAN-CLIP. https://github.com/nerdyrodent/VQGAN-CLIP",
      "doi": ""
    },
    {
      "text": "OpenAI. 2022. Prompt_Engineering_for_ImageNet.ipynb. https://github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb",
      "doi": ""
    },
    {
      "text": "Alec Radford, Jong\u00a0Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From Natural Language Supervision. arxiv:2103.00020\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-Shot Text-to-Image Generation. arxiv:2102.12092\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "[39] reddit.com.2021. https://www.reddit.com/r/bigsleep/",
      "doi": ""
    },
    {
      "text": "Laria Reynolds and Kyle McDonell. 2021. Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. arxiv:2102.07350\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "Anna Rogers, Olga Kovaleva, and Anna Rumshisky. 2020. A Primer in BERTology: What we know about how BERT works. arxiv:2002.12327\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "Victor Sanh, Albert Webson, Colin Raffel, Stephen\u00a0H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven\u00a0Le Scao, Arun Raja, Manan Dey, M\u00a0Saiful Bari, Canwen Xu, Urmish Thakker, Shanya\u00a0Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng\u00a0Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason\u00a0Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander\u00a0M. Rush. 2021. Multitask Prompted Training Enables Zero-Shot Task Generalization. arxiv:2110.08207\u00a0[cs.LG]",
      "doi": ""
    },
    {
      "text": "Evan Shimizu, Matthew Fisher, Sylvain Paris, James McCann, and Kayvon Fatahalian. 2020. Design Adjectives: A Framework for Interactive Model-Guided Exploration of Parameterized Design Spaces. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology (Virtual Event, USA) (UIST \u201920). Association for Computing Machinery, New York, NY, USA, 261\u2013278. https://doi.org/10.1145/3379337.3415866",
      "doi": "10.1145/3379337.3415866"
    },
    {
      "text": "Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019. BERT Rediscovers the Classical NLP Pipeline. arxiv:1905.05950\u00a0[cs.CL]",
      "doi": ""
    },
    {
      "text": "The Metropolitan Museum of Art. 2022. Heilbrunn Timeline of Art History. https://www.metmuseum.org/toah/",
      "doi": ""
    },
    {
      "text": "@someheresy Twitter. 2021. VQGAN CLIP Colab Notebook. https://colab.research.google.com/drive/1_4Jl0a7WIJeqy5LTjPJfZOwMZopG5C-W?usp=sharing#scrollTo=ZdlpRFL8UAlW",
      "doi": ""
    },
    {
      "text": "wikiart.org. 2022. Visual Art Encyclopedia. https://www.wikiart.org/",
      "doi": ""
    },
    {
      "text": "Qian Yang, Aaron Steinfeld, Carolyn Ros\u00e9, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376301",
      "doi": "10.1145/3313831.3376301"
    },
    {
      "text": "Minfeng Zhu, Pingbo Pan, Wei Chen, and Yi Yang. 2019. DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis. arxiv:1904.01310\u00a0[cs.CV]",
      "doi": ""
    }
  ]
}