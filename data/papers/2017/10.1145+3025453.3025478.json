{
  "doi": "10.1145/3025453.3025478",
  "title": "Hybrid HFR Depth: Fusing Commodity Depth and Color Cameras to Achieve High Frame Rate, Low Latency Depth Camera Interactions",
  "published": "2017-05-02",
  "proctitle": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
  "pages": "5966-5975",
  "year": 2017,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "The low frame rate and high latency of consumer depth cameras limits their use in interactive applications. We propose combining the Kinect depth camera with an ordinary color camera to synthesize a high frame rate and low latency depth image. We exploit common CMOS camera region of interest (ROI) functionality to obtain a high frame rate image over a small ROI. Motion in the ROI is computed by a fast optical flow implementation. The resulting flow field is used to extrapolate Kinect depth images to achieve high frame rate and low latency depth, and optionally predict depth to further reduce latency. Our \"Hybrid HFR Depth\" prototype generates useful depth images at maximum 500Hz with minimum 20ms latency. We demonstrate Hybrid HFR Depth in tracking fast moving objects, handwriting in the air, and projecting onto moving hands. Based on commonly available cameras and image processing implementations, Hybrid HFR Depth may be useful to HCI practitioners seeking to create fast, fluid depth camera-based interactions.",
  "tags": [
    "frame rate",
    "kinect",
    "configurable",
    "depth camera",
    "latency"
  ],
  "authors": [
    {
      "name": "Jiajun Lu",
      "institution": "University of Illinois at Urbana Champaign & Microsoft Research, Urbana, IL, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658678935",
      "orcid": "missing"
    },
    {
      "name": "Hrvoje Benko",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/do/10.1145/contrib-81100182346/rel-imgonly/81100182346.jpg",
      "acmid": "81100182346",
      "orcid": "0000-0002-2059-3558"
    },
    {
      "name": "Andrew D. Wilson",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81350567780",
      "orcid": "0000-0001-5751-9354"
    }
  ],
  "references": [
    {
      "text": "Hrvoje Benko, Andrew D. Wilson, and Federico Zannier. 2014. Dyadic projected spatial augmented reality. In Proceedings of the 27th annual ACM symposium on User interface software and technology, pp. 645--655. ACM, 2014.  ",
      "doi": "10.1145/2642918.2647402"
    },
    {
      "text": "Thomas Brox, Andr\u00e9s Bruhn, Nils Papenberg, and Joachim Weickert. 2004. High accuracy optical flow estimation based on a theory for warping. In European conference on computer vision, pp. 25--36.",
      "doi": ""
    },
    {
      "text": "Sean Ryan Fanello, Christoph Rhemann, Vladimir Tankovich, A. Kowdle, S. Orts Escolano, D. Kim, and S. Izadi. 2016. Hyperdepth: Learning depth from structured light without matching. In CVPR, vol. 2, p. 7. 2016.",
      "doi": ""
    },
    {
      "text": "Brett R. Jones, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2013. IllumiRoom: peripheral projected illusions for interactive experiences. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 869--878.  ",
      "doi": "10.1145/2470654.2466112"
    },
    {
      "text": "Brett R. Jones, Rajinder Sodhi, Michael Murdock, Ravish Mehra, Hrvoje Benko, Andrew Wilson, Eyal Ofek, Blair MacIntyre, Nikunj Raghuvanshi, and Lior Shapira. 2014. RoomAlive: magical experiences enabled by scalable, adaptive projector-camera units. In Proceedings of the 27th annual ACM symposium on User interface software and technology, pp. 637--644.  ",
      "doi": "10.1145/2642918.2647383"
    },
    {
      "text": "Ricardo Jota, Albert Ng, Paul Dietz, and Daniel Wigdor. 2013. How fast is fast enough?: a study of the effects of latency in direct-touch pointing tasks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 2291--2300.  ",
      "doi": "10.1145/2470654.2481317"
    },
    {
      "text": "Kris Kitani, Kodai Horita, and Hideki Koike. 2012. BallCam!: dynamic view synthesis from spinning cameras. In Adjunct proceedings of the 25th annual ACM symposium on User interface software and technology, pp. 87--88.  ",
      "doi": "10.1145/2380296.2380335"
    },
    {
      "text": "Jarrod Knibbe, Hrvoje Benko, and Andrew D. Wilson. 2015. Juggling the Effects of Latency: Motion Prediction Approaches to Reducing Latency in Dynamic Projector-Camera Systems. Microsoft Research Technical Report MSR-TR-2015--35.",
      "doi": ""
    },
    {
      "text": "Hideki Koike, and Hiroaki Yamaguchi. 2015. LumoSpheres: real-time tracking of flying objects and image projection for a volumetric display. In Proceedings of the 6th Augmented Human International Conference, pp. 93--96.  ",
      "doi": "10.1145/2735711.2735824"
    },
    {
      "text": "Till Kroeger, Radu Timofte, Dengxin Dai and Luc Van Gool. 2016. Fast Optical Flow using Dense Inverse Search. In Proceedings of the European Conference on Computer Vision (ECCV).",
      "doi": ""
    },
    {
      "text": "Jiajun Lu, and David Forsyth. 2015. Sparse Depth Super Resolution. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 22452253.",
      "doi": ""
    },
    {
      "text": "Iason Oikonomidis, Nikolaos Kyriazis, and Antonis A. Argyros. 2011. Efficient model-based 3D tracking of hand articulations using Kinect. In BMVC, vol. 1, no. 2, p. 3.",
      "doi": ""
    },
    {
      "text": "Kohei Okumura, Hiromasa Oku, and Masatoshi Ishikawa. 2011. High-speed gaze controller for millisecond-order pan/tilt camera. In Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 6186--6191.",
      "doi": ""
    },
    {
      "text": "Giorgos Papadakis, Katerina Mania, and Eftichios Koutroulis. 2011. A system to measure, control and minimize end-to-end head tracking latency in immersive simulations. In Proceedings of the 10th International Conference on Virtual Reality Continuum and Its Applications in Industry, pp. 581--584.  ",
      "doi": "10.1145/2087756.2087869"
    },
    {
      "text": "Mirko Schmidt, Klaus Zimmermann, and Bernd J\u00e4hne. 2011. High frame rate for 3D Time-of-Flight cameras by dynamic sensor calibration. In ICCP 2011, pp. 1--8.",
      "doi": ""
    },
    {
      "text": "Toby Sharp, Cem Keskin, Duncan Robertson, Jonathan Taylor, Jamie Shotton, David Kim, Christoph Rhemann et al. 2015. Accurate, robust, and flexible real-time hand tracking. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, pp. 3633--3642.  ",
      "doi": "10.1145/2702123.2702179"
    },
    {
      "text": "Jan Stuhmer, Sebastian Nowozin, Andrew Fitzgibbon, Richard Szeliski, Travis Perry, Sunil Acharya, Daniel Cremers, and Jamie Shotton. 2015. Model-Based Tracking at 300Hz using Raw Time-of-Flight Observations. In ICCV, pp. 3577--3585.  ",
      "doi": "10.1109/ICCV.2015.408"
    },
    {
      "text": "Jacob O. Wobbrock, Andrew D. Wilson, and Yang Li. 2007. Gestures without libraries, toolkits or training: a $1 recognizer for user interface prototypes. In Proceedings of the 20th annual ACM symposium on User interface software and technology, pp. 159--168.  ",
      "doi": "10.1145/1294211.1294238"
    },
    {
      "text": "Haijun Xia, Ricardo Jota, Benjamin McCanny, Zhe Yu, Clifton Forlines, Karan Singh, and Daniel Wigdor. 2014. Zero-latency tapping: using hover information to predict touch locations and eliminate touchdown latency. In Proceedings of the 27th annual ACM symposium on User interface software and technology, pp. 205--214.  ",
      "doi": "10.1145/2642918.2647348"
    }
  ]
}