{
  "doi": "10.1145/3025453.3025821",
  "title": "EgoScanning: Quickly Scanning First-Person Videos with Egocentric Elastic Timelines",
  "published": "2017-05-02",
  "proctitle": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
  "pages": "6536-6546",
  "year": 2017,
  "badges": [],
  "abstract": "This work presents EgoScanning, a novel video fast-forwarding interface that helps users to find important events from lengthy first-person videos recorded with wearable cameras continuously. This interface is featured by an elastic timeline that adaptively changes playback speeds and emphasizes egocentric cues specific to first-person videos, such as hand manipulations, moving, and conversations with people, based on computer-vision techniques. The interface also allows users to input which of such cues are relevant to events of their interests. Through our user study, we confirm that users can find events of interests quickly from first-person videos thanks to the following benefits of using the EgoScanning interface: 1) adaptive changes of playback speeds allow users to watch fast-forwarded videos more easily; 2) Emphasized parts of videos can act as candidates of events actually significant to users; 3) Users are able to select relevant egocentric cues depending on events of their interests.",
  "authors": [
    {
      "name": "Keita Higuchi",
      "institution": "The University of Tokyo, Tokyo, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81482650519",
      "orcid": "missing"
    },
    {
      "name": "Ryo Yonetani",
      "institution": "The University of Tokyo, Tokyo, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81474703871",
      "orcid": "missing"
    },
    {
      "name": "Yoichi Sato",
      "institution": "The University of Tokyo, Tokyo, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100565790",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Kiyoharu Aizawa, Datchakorn Tancharoen, Shinya Kawasaki, and Toshihiko Yamasaki. 2004. Efficient Retrieval of Life Log Based on Context and Content. In In Proc. ACM Workshop on Continuous Archival and Retrieval of Personal Experiences (CARPE '04).  ",
      "doi": "10.1145/1026653.1026656"
    },
    {
      "text": "Abir Al-Hajri, Matthew Fong, Gregor Miller, and Sidney Fels. 2014. Fast Forward with Your VCR: Visualizing Single-video Viewing Statistics for Navigation and Sharing. In In Proc. Graphics Interface (GI '14). http://dl.acm.org/citation.cfm?id=2619648.2619669 ",
      "doi": "10.5555/2619648.2619669"
    },
    {
      "text": "Ido Arev, Hyun Soo Park, Yaser Sheikh, Jessica Hodgins, and Ariel Shamir. 2014. Automatic Editing of Footage from Multiple Social Cameras. ACM Transaction on Graphics 33, 4 (2014).  ",
      "doi": "10.1145/2601097.2601198"
    },
    {
      "text": "Minjie Cai, Kris M Kitani, and Yoichi Sato. 2015. A scalable approach for understanding the visual structures of hand grasps. In In Proc. IEEE International Conference on Robotics and Automation (ICRA '15). 1360--1366.",
      "doi": ""
    },
    {
      "text": "Yi Chen and Gareth JF Jones. 2010. Augmenting human memory using personal lifelogs. In In Proc. Augmented Human International Conference (AH '10). 24.  ",
      "doi": "10.1145/1785455.1785479"
    },
    {
      "text": "Kai-Yin Cheng, Sheng-Jie Luo, Bing-Yu Chen, and Hao-Hua Chu. 2009. SmartPlayer: User-centric Video Fast-forwarding. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '09).  ",
      "doi": "10.1145/1518701.1518823"
    },
    {
      "text": "Stephen R Dixon, Christopher D Wickens, and Jason S McCarley. 2007. On the independence of compliance and reliance: Are automation false alarms worse than misses' Human Factors: The Journal of the Human Factors and Ergonomics Society 49, 4 (2007).",
      "doi": ""
    },
    {
      "text": "Pierre Dragicevic, Gonzalo Ramos, Jacobo Bibliowitcz, Derek Nowrouzezahrai, Ravin Balakrishnan, and Karan Singh. 2008. Video Browsing by Direct Manipulation. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '08).  ",
      "doi": "10.1145/1357054.1357096"
    },
    {
      "text": "Alireza Fathi, Ali Farhadi, and James M. Rehg. 2011. Understanding Egocentric Activities. In In Proc. International Conference on Computer Vision (ICCV '11).  ",
      "doi": "10.1109/ICCV.2011.6126269"
    },
    {
      "text": "Alireza Fathi, Jessica K Hodgins, and James M Rehg. 2012. Social interactions: A first-person perspective. In In Proc. IEEE Conference On Computer Vision and Pattern Recognition. IEEE, 1226--1233. ",
      "doi": "10.5555/2354409.2354936"
    },
    {
      "text": "Alireza Fathi, Xiaofeng Ren, and James M Rehg. 2011. Learning to recognize objects in egocentric activities. In In Proc. IEEE Conference On Computer Vision and Pattern Recognition (CVPR '11).  ",
      "doi": "10.1109/CVPR.2011.5995444"
    },
    {
      "text": "Susan R. Fussell, Leslie D. Setlock, and Robert E. Kraut. 2003. Effects of Head-mounted and Scene-oriented Video Systems on Remote Collaboration on Physical Tasks. In In Proc. ACM CHI conference on Human factors in computing systems (CHI '03).  ",
      "doi": "10.1145/642611.642701"
    },
    {
      "text": "Keita Higuch, Ryo Yonetani, and Yoichi Sato. 2016. Can Eye Help You?: Effects of Visualizing Eye Fixations on Remote Collaboration Scenarios for Physical Tasks. In In Proc. ACM CHI conference on Human factors in computing systems (CHI '16). 5180--5190.  ",
      "doi": "10.1145/2858036.2858438"
    },
    {
      "text": "De-An Huang, Minghuang Ma, Wei-Chiu Ma, and Kris M Kitani. 2015. How do we use our hands? discovering a diverse set of common grasps. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '15).",
      "doi": ""
    },
    {
      "text": "Yoshio Ishiguro, Adiyan Mujibiya, Takashi Miyaki, and Jun Rekimoto. 2010. Aided Eyes: Eye Activity Sensing for Daily Life. In In Proc. Augmented Human International Conference (AH '10). 25.  ",
      "doi": "10.1145/1785455.1785480"
    },
    {
      "text": "Yoshio Ishiguro and Jun Rekimoto. 2012. GazeCloud: A Thumbnail Extraction Method Using Gaze Log Data for Video Life-Log. In In Proc. International Symposium on Wearable Computers. 72--75.  ",
      "doi": "10.1109/ISWC.2012.32"
    },
    {
      "text": "Neel Joshi, Wolf Kienzle, Mike Toelle, Matt Uyttendaele, and Michael F. Cohen. 2015. Real-time Hyperlapse Creation via Optimal Frame Selection. ACM Transaction on Graphics 34, 4 (2015).  ",
      "doi": "10.1145/2766954"
    },
    {
      "text": "Thorsten Karrer, Malte Weiss, Eric Lee, and Jan Borchers. 2008. DRAGON: A Direct Manipulation Interface for Frame-accurate In-scene Video Navigation. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '08).  ",
      "doi": "10.1145/1357054.1357097"
    },
    {
      "text": "Thorsten Karrer, Moritz Wittenhagen, and Jan Borchers. 2012. DragLocks: Handling Temporal Ambiguities in Direct Manipulation Video Navigation. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '12).  ",
      "doi": "10.1145/2207676.2207764"
    },
    {
      "text": "Shunichi Kasahara, Mitsuhito Ando, Kiyoshi Suganuma, and Jun Rekimoto. 2016. Parallel Eyes: Exploring Human Capability and Behaviors with Paralleled First Person View Sharing. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '16). 12.  ",
      "doi": "10.1145/2858036.2858495"
    },
    {
      "text": "Shunichi Kasahara and Jun Rekimoto. 2014. Jackin: Integrating first-person view with out-of-body vision generation for human-human augmentation. In In Proc. Augmented Human International Conference (AH '14).  ",
      "doi": "10.1145/2582051.2582097"
    },
    {
      "text": "Hiroshi Kera, Ryo Yonetani, Keita Higuchi, and Yoichi Sato. 2016. Discovering Objects of Joint Attention via First-Person Sensing. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW '16).",
      "doi": ""
    },
    {
      "text": "Ig-Jae Kim, Sang Chul Ahn, Heedong Ko, and Hyoung-Gon Kim. 2008. Automatic Lifelog media annotation based on heterogeneous sensor fusion. In In Proc. IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI '08).",
      "doi": ""
    },
    {
      "text": "Juho Kim, Philip J. Guo, Carrie J. Cai, Shang-Wen (Daniel) Li, Krzysztof Z. Gajos, and Robert C. Miller. 2014. Data-driven Interaction Techniques for Improving Navigation of Educational Videos. In In Proc. ACM Symposium on User Interface Software and Technology (UIST '14).  ",
      "doi": "10.1145/2642918.2647389"
    },
    {
      "text": "Kris. M. Kitani, Takanori Okabe, Yoichi Sato, and Akihiro Sugimoto. 2011. Fast unsupervised ego-action learning for first-person sports videos. In In Proc. IEEE Conference On Computer Vision and Pattern Recognition (CVPR '11). 3241--3248.  ",
      "doi": "10.1109/CVPR.2011.5995406"
    },
    {
      "text": "Johannes Kopf, Michael F. Cohen, and Richard Szeliski. 2014. First-person Hyper-lapse Videos. ACM Transaction on Graphics 33, 4 (2014).  ",
      "doi": "10.1145/2601097.2601195"
    },
    {
      "text": "Kazutaka Kurihara. 2012. CinemaGazer: A System for Watching Videos at Very High Speed. In In Proc. International Working Conference on Advanced Visual Interfaces (AVI '12).  ",
      "doi": "10.1145/2254556.2254579"
    },
    {
      "text": "Yong Jae Lee, Joydeep Ghosh, and Kristen Grauman. 2012. Discovering important people and objects for egocentric video summarization. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '12). ",
      "doi": "10.5555/2354409.2355016"
    },
    {
      "text": "Cheng Li and Kris M Kitani. 2013. Pixel-level hand detection in ego-centric videos. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '13).  ",
      "doi": "10.1109/CVPR.2013.458"
    },
    {
      "text": "Feng Liu, Michael Gleicher, Hailin Jin, and Aseem Agarwala. 2009. Content-preserving Warps for 3D Video Stabilization. ACM Transaction on Graphics 28, 3 (2009).  ",
      "doi": "10.1145/1531326.1531350"
    },
    {
      "text": "Feng Liu, Michael Gleicher, Jue Wang, Hailin Jin, and Aseem Agarwala. 2011. Subspace Video Stabilization. ACM Transaction on Graphics 30, 1 (2011).  ",
      "doi": "10.1145/1899404.1899408"
    },
    {
      "text": "Shuaicheng Liu, Lu Yuan, Ping Tan, and Jian Sun. 2014. Steadyflow: Spatially smooth optical flow for video stabilization. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '14). 4209--4216.  ",
      "doi": "10.1109/CVPR.2014.536"
    },
    {
      "text": "Zheng Lu and Kristen Grauman. 2013. Story-Driven Summarization for Egocentric Video. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '13). 2714--2721.  ",
      "doi": "10.1109/CVPR.2013.350"
    },
    {
      "text": "Minghuang Ma, Haoqi Fan, and Kris M Kitani. 2016. Going Deeper into First-Person Activity Recognition. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016).",
      "doi": ""
    },
    {
      "text": "S. Mann. 1997. Wearable computing: a first step toward personal imaging. IEEE Computer 30, 2 (1997).  ",
      "doi": "10.1109/2.566147"
    },
    {
      "text": "Justin Matejka, Tovi Grossman, and George Fitzmaurice. 2014. Video Lens: Rapid Playback and Exploration of Large Video Collections and Associated Metadata. In In Proc. ACM Symposium on User Interface Software and Technology (UIST '14). 10.  ",
      "doi": "10.1145/2642918.2647366"
    },
    {
      "text": "Cuong Nguyen, Yuzhen Niu, and Feng Liu. 2012. Video Summagator: An Interface for Video Summarization and Navigation. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '12).  ",
      "doi": "10.1145/2207676.2207767"
    },
    {
      "text": "Cuong Nguyen, Yuzhen Niu, and Feng Liu. 2013. Direct Manipulation Video Navigation in 3D. In In Proc. ACM CHI Conference on Human Factors in Computing Systems (CHI '13).  ",
      "doi": "10.1145/2470654.2466150"
    },
    {
      "text": "Yair Poleg, Chetan Arora, and Shmuel Peleg. 2014. Temporal Segmentation of Egocentric Videos. In In Proc. IEEE Conference On Computer Vision and Pattern Recognition (CVPR '14).  ",
      "doi": "10.1109/CVPR.2014.325"
    },
    {
      "text": "Yair Poleg, Ariel Ephrat, Shmuel Peleg, and Chetan Arora. 2016. Compact CNN for Indexing Egocentric Videos. In In Proc. IEEE Winter Conference on Applications of Computer Vision (WACV '16).",
      "doi": ""
    },
    {
      "text": "Yair Poleg, Tavi Halperin, Chetan Arora, and Shmuel Peleg. 2015. EgoSampling: Fast-forward and stereo for egocentric videos. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '15).",
      "doi": ""
    },
    {
      "text": "Suporn Pongnumkul, Jue Wang, and Michael Cohen. 2008. Creating Map-based Storyboards for Browsing Tour Videos. In In Proc. ACM Symposium on User Interface Software and Technology (UIST '08).  ",
      "doi": "10.1145/1449715.1449720"
    },
    {
      "text": "Suporn Pongnumkul, Jue Wang, Gonzalo Ramos, and Michael Cohen. 2010. Content-aware Dynamic Timeline for Video Browsing. In In Proc. ACM Symposium on User Interface Software and Technology (UIST '10).  ",
      "doi": "10.1145/1866029.1866053"
    },
    {
      "text": "Yael Pritch, Alex Rav-Acha, Avital Gutman, and Shmuel Peleg. 2007. Webcam Synopsis: Peeking Around the World. In In Proc. IEEE International Conference on Computer Vision (ICCV'07).",
      "doi": ""
    },
    {
      "text": "Yael Pritch, Alex Rav-Acha, and Shmuel Peleg. 2008. Nonchronological Video Synopsis and Indexing. IEEE Transactions on Pattern Analysis and Machine Intelligence 30, 11 (2008).  ",
      "doi": "10.1109/TPAMI.2008.29"
    },
    {
      "text": "Alex Rav-Acha, Yael Pritch, and Shmuel Peleg. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR'06).",
      "doi": ""
    },
    {
      "text": "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster R-CNN: Towards real-time object detection with region proposal networks. In In Proc. Annual Conference on Neural Information Processing Systems (NIPS '15). ",
      "doi": "10.5555/2969239.2969250"
    },
    {
      "text": "Julian Steil and Andreas Bulling. 2015. Discovery of Everyday Human Activities From Long-Term Visual Behaviour Using Topic Models. In In Proc. ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2015). 75--85.  ",
      "doi": "10.1145/2750858.2807520"
    },
    {
      "text": "Zhe Wang, Matthew D. Hoffman, Perry R. Cook, and Kai Li. 2006. VFerret: Content-based Similarity Search Tool for Continuous Archived Video. In In Proc. ACM Workshop on Continuous Archival and Retrival of Personal Experences (CARPE '06).  ",
      "doi": "10.1145/1178657.1178663"
    },
    {
      "text": "Jia Xu, Lopamudra Mukherjee, Yin Li, Jamieson Warner, James M. Rehg, and Vikas Singh. 2015. Gaze-enabled egocentric video summarization via constrained submodular maximization. In In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR '15).",
      "doi": ""
    },
    {
      "text": "Ting Yao, Tao Mei, and Yong Rui. 2016. Highlight Detection with Pairwise Deep Ranking for First-Person Video Summarization. (2016).",
      "doi": ""
    },
    {
      "text": "Ryo Yonetani, Kris M. Kitani, and Yoichi Sato. 2015. Ego-surfing first person videos. In In Proc. IEEE Conference On Computer Vision and Pattern Recognition (CVPR '15).",
      "doi": ""
    },
    {
      "text": "Ryo Yonetani, Kris M. Kitani, and Yoichi Sato. 2016a. Recognizing Micro-Actions and Reactions From Paired Egocentric Videos. In In Proc. IEEE Conference On Computer Vision and Pattern Recognition (CVPR '16).",
      "doi": ""
    },
    {
      "text": "Ryo Yonetani, Kris M. Kitani, and Yoichi Sato. 2016b. Visual Motif Discovery via First-Person Vision. In In Proc. European Conference on Computer Vision (ECCV '16).",
      "doi": ""
    }
  ]
}