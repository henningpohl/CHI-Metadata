{
  "doi": "10.1145/3025453.3025692",
  "title": "EarFieldSensing: A Novel In-Ear Electric Field Sensing to Enrich Wearable Gesture Input through Facial Expressions",
  "published": "2017-05-02",
  "proctitle": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
  "pages": "1911-1922",
  "year": 2017,
  "badges": [],
  "abstract": "EarFieldSensing (EarFS) is a novel input method for mobile and wearable computing using facial expressions. Facial muscle movements induce both electric field changes and physical deformations, which are detectable with electrodes placed inside the ear canal. The chosen ear-plug form factor is rather unobtrusive and allows for facial gesture recognition while utilizing the close proximity to the face. We collected 25 facial-related gestures and used them to compare the performance levels of several electric sensing technologies (EMG, CS, EFS, EarFS) with varying electrode setups. Our developed wearable fine-tuned electric field sensing employs differential amplification to effectively cancel out environmental noise while still being sensitive towards small facial-movement-related electric field changes and artifacts from ear canal deformations. By comparing a mobile with a stationary scenario, we found that EarFS continues to perform better in a mobile scenario. Quantitative results show EarFS to be capable of detecting a set of 5 facial gestures with a precision of 90% while sitting and 85.2% while walking. We provide detailed instructions to enable replication of our low-cost sensing device. Applying it to different positions of our body will also allow to sense a variety of other gestures and activities.",
  "authors": [
    {
      "name": "Denys J. C. Matthies",
      "institution": "Fraunhofer IGD Rostock, Rostock, Germany",
      "img": "/do/10.1145/contrib-81548327356/rel-imgonly/citations.jpg",
      "acmid": "81548327356",
      "orcid": "missing"
    },
    {
      "name": "Bernhard A. Strecker",
      "institution": "Fraunhofer IGD & University of Cologne, Rostock, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659161370",
      "orcid": "missing"
    },
    {
      "name": "Bodo Urban",
      "institution": "Fraunhofer IGD Rostock, Rostock, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100171887",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Ashbrook, D. (2010). Enabling mobile microinteractions. PhD Thesis, Georgia Institute of Technology",
      "doi": "10.5555/1970601"
    },
    {
      "text": "Ashtiani, B., & MacKenzie, I. S. (2010). BlinkWrite2: an improved text entry method using eye blinks. In Proceedings of the 2010 Symposium on Eye-Tracking Research & Applications, 339--345. ACM. http://dx.doi.org/10.1145/1743666.1743742  ",
      "doi": "10.1145/1743666.1743742"
    },
    {
      "text": "Bartlett, M. S., Littlewort, G., Fasel, I., & Movellan, J. R. (2003, June). Real Time Face Detection and Facial Expression Recognition: Development and Applications to Human Computer Interaction. In Conference on Computer Vision and Pattern Recognition. CVPRW'03. (Vol. 5), 53--53. IEEE. http://dx.doi.org/10.1109/CVPRW.2003.10057 ",
      "doi": ""
    },
    {
      "text": "Bulling, A., Roggen, D., & Tr\u00f6ster, G. (2009). Wearable EOG goggles: eye-based interaction in everyday environments, In CHI'09 Extended Abstracts on Human Factors in Computing System, 3259--3264. ACM. http://dx.doi.org/10.1145/1520340.1520468  ",
      "doi": "10.1145/1520340.1520468"
    },
    {
      "text": "Caruana, R., & Freitag, D. (1994). Greedy Attribute Selection. In Proceedings of International Conference on Machine Learning, 28--36. ",
      "doi": ""
    },
    {
      "text": "Chai, J. X., Xiao, J., & Hodgins, J. (2003). Visionbased control of 3d facial animation. In Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, 193--206. ACM.",
      "doi": "10.5555/846276.846304"
    },
    {
      "text": "Cohn, G., Gupta, S., Lee, T. J., Morris, D., Smith, J. R., Reynolds, M. S., ... & Patel, S. N. (2012). An ultralow-power human body motion sensor using static electric field sensing. In Proceedings of the 2012 ACM Conference on Ubiquitous Computing, 99--102. ACM. http://dx.doi.org/10.1145/2370216.2370233  ",
      "doi": "10.1145/2370216.2370233"
    },
    {
      "text": "Ekman, P., & Friesen, W. V. (1977). Facial action coding system. Consulting Psychologists Press, Stanford University, Palo Alto.",
      "doi": ""
    },
    {
      "text": "Fagan, M. J., Ell, S. R., Gilbert, J. M., Sarrazin, E., & Chapman, P. M. (2008). Development of a (silent) speech recognition system for patients following laryngectomy. In Medical engineering & physics, 30(4), 419--425. http://dx.doi.org/10.1016/j.medengphy.2007.05.003 ",
      "doi": ""
    },
    {
      "text": "Fasel, B., & Luettin, J. (2003). Automatic facial expression analysis: a survey. In Pattern recognition, 36(1), 259--275. Elsevier. http://dx.doi.org/10.1016/S0031-3203(02)00052-",
      "doi": ""
    },
    {
      "text": "Gips, J., Olivieri, P., & Tecce, J. (1993). Direct Control of the Computer Through Electrodes Placed Around the Eyes. In Human-Computer Interaction: Applications and Case Studies, 630--635. Elsevier.",
      "doi": ""
    },
    {
      "text": "Gips, J. (1998). On building intelligence into EagleEyes. In Assistive technology and artificial intelligence, 50--58. Springer Berlin Heidelberg. http://dx.doi.org/10.1007/BFb0055969 ",
      "doi": ""
    },
    {
      "text": "Grafsgaard, J., Wiggins, J. B., Boyer, K. E., Wiebe, E. N., & Lester, J. (2013). Automatically recognizing facial expression: Predicting engagement and frustration. In Educational Data Mining 2013.",
      "doi": ""
    },
    {
      "text": "Grosse-Puppendahl, T., Berghoefer, Y., Braun, A., Wimmer, R., & Kuijper, A. (2013). OpenCapSense: A rapid prototyping toolkit for pervasive interaction using capacitive sensing. In Proceedings of International Conference on Pervasive Computing and Communications, 152--159. IEEE. http://dx.doi.org/10.1109/PerCom.2013.6526726 ",
      "doi": ""
    },
    {
      "text": "Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009). The WEKA data mining software: an update. In ACM SIGKDD explorations newsletter, 11(1), 10--18. http://dx.doi.org/10.1145/1656274.1656278  ",
      "doi": "10.1145/1656274.1656278"
    },
    {
      "text": "Hausen, S. (2014) Peripheral Interaction - Exploring the Design Space, PhD Thesis, Faculty of Mathematics, Computer Science and Statistics, University of Munich.",
      "doi": ""
    },
    {
      "text": "Hazlett, R. (2003). Measurement of user frustration: a biologic approach. In CHI'03 extended abstracts on Human factors in computing systems, 734--735. ACM. http://dx.doi.org/10.1145/765891.765958  ",
      "doi": "10.1145/765891.765958"
    },
    {
      "text": "Hodgkin, A. L. (1951). The ionic basis of electrical activity in nerve and muscle. In Biological Reviews, 26(4), 339--409. http://dx.doi.org/10.1111/j.1469185X.1951.tb01204.x",
      "doi": ""
    },
    {
      "text": "Ishimaru, S., Kunze, K., Uema, Y., Kise, K., Inami, M., & Tanaka, K. (2014). Smarter eyewear: using commercial EOG glasses for activity recognition. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication, 239--242. ACM. http://dx.doi.org/10.1145/2638728.2638795  ",
      "doi": "10.1145/2638728.2638795"
    },
    {
      "text": "Majaranta, P., & R\u00e4ih\u00e4, K. J. (2007). Text entry by gaze: Utilizing eye-tracking. In Text entry systems: Mobility, accessibility, universality, 175--187.",
      "doi": ""
    },
    {
      "text": "Manabe, H., & Fukumoto, M. (2006). Full-time wearable headphone-type gaze detector. In CHI'06 Extended Abstracts on Human Factors in Computing Systems, 1073--1078. ACM. http://dx.doi.org/10.1145/1125451.1125655  ",
      "doi": "10.1145/1125451.1125655"
    },
    {
      "text": "Manabe, H., Fukumoto, M., & Yagi, T. (2015). Conductive rubber electrodes for earphone-based eye gesture input interface. In Personal and Ubiquitous Computing, 19(1), 143--154. Springer. http://dx.doi.org/10.1007/s00779-014-0818-8  ",
      "doi": "10.1007/s00779-014-0818-8"
    },
    {
      "text": "Mann, S. (1998). Humanistic computing: \"WearComp\" as a new framework and application for intelligent signal processing. In Proceedings of the IEEE, 86(11), 2123--215. IEEE. http://dx.doi.org/10.1109/5.726784 ",
      "doi": ""
    },
    {
      "text": "Matthies, D. J. C. (2013). InEar BioFeedController: a headset for hands-free and eyes-free interaction with mobile devices. In CHI'13 Extended Abstracts on Human Factors in Computing Systems, 1293--1298. ACM. http://dx.doi.org/10.1145/2468356.2468587  ",
      "doi": "10.1145/2468356.2468587"
    },
    {
      "text": "Matthies, D. J. C., Antons, J. N., Heidmann, F., Wettach, R., & Schleicher, R. (2012). NeuroPad: use cases for a mobile physiological interface. In Proceedings of the 7th Nordic Conference on HumanComputer Interaction: Making Sense Through Design, 795--796. ACM. http://dx.doi.org/10.1145/2399016.2399152  ",
      "doi": "10.1145/2399016.2399152"
    },
    {
      "text": "Matthies, D. J. C., Perrault, S. T., Urban, B., & Zhao, S. (2015). Botential: Localizing On-Body Gestures by Measuring Electrical Signatures on the Human Skin. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services, 207--216. ACM. http://dx.doi.org/10.1145/2785830.2785859  ",
      "doi": "10.1145/2785830.2785859"
    },
    {
      "text": "McFarland, D. J., & Wolpaw, J. R. (2011). Braincomputer interfaces for communication and control. In Communications of the ACM, 54(5), 60--66. ACM. http://dx.doi.org/10.1145/1941487.1941506  ",
      "doi": "10.1145/1941487.1941506"
    },
    {
      "text": "Nguyen, A., Alqurashi, R., Raghebi, Z., Banaeikashani, F., Halbower, A. C., & Vu, T. (2016). A Lightweight And Inexpensive In-ear Sensing System For Automatic Whole-night Sleep Stage Monitoring. In Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems 2016, 230--244. ACM. http://dx.doi.org/10.1145/2994551.2994562  ",
      "doi": "10.1145/2994551.2994562"
    },
    {
      "text": "Picard, R. W. (1995). Affective computing. MIT Media Laboratory Perceptual Computing Section Technical Report No. 321. Cambridge: MIT press.",
      "doi": ""
    },
    {
      "text": "Rantanen, V., Niemenlehto, P. H., Verho, J., & Lekkala, J. (2010). Capacitive facial movement detection for human-computer interaction to click by frowning and lifting eyebrows. In Medical & biological engineering & computing,48(1), 39--47. http://dx.doi.org/10.1007/s11517-009-0565-6 ",
      "doi": ""
    },
    {
      "text": "Rantanen, V., Venesvirta, H., Spakov, O., Verho, J., Vetek, A., Surakka, V., & Lekkala, J. (2013). Capacitive measurement of facial activity intensity. In IEEE Sensors Journal, 13(11), 4329--4338. http://dx.doi.org/10.1109/JSEN.2013.2269864 ",
      "doi": ""
    },
    {
      "text": "Sahni, H., Bedri, A., Reyes, G., Thukral, P., Guo, Z., Starner, T., & Ghovanloo, M. (2014). The tongue and ear interface: a wearable system for silent speech recognition. In Proceedings of the 2014 ACM International Symposium on Wearable Computers, 4754. ACM. http://dx.doi.org/10.1145/2634317.2634322  ",
      "doi": "10.1145/2634317.2634322"
    },
    {
      "text": "Saponas, T. S., Tan, D. S., Morris, D., Balakrishnan, R., Turner, J., & Landay, J. A. (2009). Enabling always-available input with muscle-computer interfaces. In Proceedings of the 22nd annual ACM symposium on User interface software and technology, 167--176. ACM. http://dx.doi.org/10.1145/1622176.1622208  ",
      "doi": "10.1145/1622176.1622208"
    },
    {
      "text": "San Agustin, J., Hansen, J. P., Hansen, D. W., & Skovsgaard, H. (2009). Low-cost gaze pointing and EMG clicking. In CHI'09 Extended Abstracts on Human Factors in Computing Systems, 3247--3252. ACM. http://dx.doi.org/10.1145/1520340.1520466  ",
      "doi": "10.1145/1520340.1520466"
    },
    {
      "text": "Scharfetter, H., Hartinger, P., Hinghofer-Szalkay, H., & Hutten, H. (1998). A model of artefacts produced by stray capacitance during whole body or segmental bioimpedance spectroscopy. In Physiological measurement, 19(2), 247. http://dx.doi.org/10.1088/0967-3334/19/2/012 ",
      "doi": ""
    },
    {
      "text": "Scheirer, J., Fernandez, R., & Picard, R. W. (1999). Expression glasses: a wearable device for facial expression recognition. In CHI'99 Extended Abstracts on Human Factors in Computing Systems, 262--263. ACM. http://dx.doi.org/10.1145/632716.632878  ",
      "doi": "10.1145/632716.632878"
    },
    {
      "text": "Smith, E., & Delargy, M. (2005). Locked-in syndrome. BMJ, 330(7488), 406--409. ",
      "doi": ""
    },
    {
      "text": "Smith, J. R. (1999). Electric Field Imaging. PhD Thesis, MIT - Massachusetts Institute of Technology.",
      "doi": "10.5555/929818"
    },
    {
      "text": "Yin, E., Zhou, Z., Jiang, J., Chen, F., Liu, Y., & Hu, D. (2013). A novel hybrid BCI speller based on the incorporation of SSVEP into the P300 paradigm. In Journal of neural engineering, 10(2), 026012. http://dx.doi.org/10.1088/17412560/10/2/026012",
      "doi": ""
    },
    {
      "text": "Zhang, Q., Gollakota, S., Taskar, B., & Rao, R. P. (2014). Non-intrusive tongue machine interface. In Proceedings of the 32nd annual ACM conference on Human factors in computing systems, 2555--2558. ACM. http://dx.doi.org/10.1145/2556288.2556981  ",
      "doi": "10.1145/2556288.2556981"
    }
  ]
}