{
  "doi": "10.1145/3025453.3025899",
  "title": "People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges",
  "published": "2017-05-02",
  "proctitle": "CHI '17: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems",
  "pages": "5839-5849",
  "year": 2017,
  "badges": [],
  "abstract": "Blind people often need to identify objects around them, from packages of food to items of clothing. Automatic object recognition continues to provide limited assistance in such tasks because models tend to be trained on images taken by sighted people with different background clutter, scale, viewpoints, occlusion, and image quality than in photos taken by blind users. We explore personal object recognizers, where visually impaired people train a mobile application with a few snapshots of objects of interest and provide custom labels. We adopt transfer learning with a deep learning system for user-defined multi-label k-instance classification. Experiments with blind participants demonstrate the feasibility of our approach, which reaches accuracies over 90% for some participants. We analyze user data and feedback to explore effects of sample size, photo-quality variance, and object shape; and contrast models trained on photos by blind participants to those by sighted participants and generic recognizers.",
  "authors": [
    {
      "name": "Hernisa Kacorri",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/do/10.1145/contrib-81474702153/rel-imgonly/81474702153.jpg",
      "acmid": "81474702153",
      "orcid": "0000-0002-7798-308X"
    },
    {
      "name": "Kris M. Kitani",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81331496187",
      "orcid": "missing"
    },
    {
      "name": "Jeffrey P. Bigham",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81338487593",
      "orcid": "0000-0002-2072-0625"
    },
    {
      "name": "Chieko Asakawa",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100044475",
      "orcid": "0000-0002-5447-1305"
    }
  ],
  "references": [
    {
      "text": "Tousif Ahmed, Roberto Hoyle, Kay Connelly, David Crandall, and Apu Kapadia. 2015. Privacy Concerns and Behaviors of People with Visual Impairments. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 3523--3532.  ",
      "doi": "10.1145/2702123.2702334"
    },
    {
      "text": "Aipoly. 2016. Vision through artificial intelligence. (2016). http://aipoly.com/",
      "doi": ""
    },
    {
      "text": "BeMyEyes. 2016. Lend you eyes to the blind. (2016). http://www.bemyeyes.org/",
      "doi": ""
    },
    {
      "text": "BeSpecular. 2016. Let blind people see through your eyes. (2016). https://www.bespecular.com/",
      "doi": ""
    },
    {
      "text": "Erin L Brady, Yu Zhong, Meredith Ringel Morris, and Jeffrey P Bigham. 2013. Investigating the appropriateness of social network question asking as a resource for blind users. In Proceedings of the 2013 Conference on Computer Supported Cooperative Work. ACM, 1225--1236.  ",
      "doi": "10.1145/2441776.2441915"
    },
    {
      "text": "CamFind. 2016. Search the physical world. (2016). http://camfindapp.com/",
      "doi": ""
    },
    {
      "text": "Julien Champ, Titouan Lorieul, Maximilien Servajean, and Alexis Joly. 2015. A comparative study of fine-grained classification methods in the context of the lifeclef plant identification challenge 2015. In CLEF 2015, Vol. 1391.",
      "doi": ""
    },
    {
      "text": "Talking Goggles. 2016. A camera with speech. (2016). http://www.sparklingapps.com/goggles/",
      "doi": ""
    },
    {
      "text": "i.d. mate. 2016. Talking bar code scanners. (2016). http://www.envisionamerica.com/store",
      "doi": ""
    },
    {
      "text": "Hernisa Kacorri, Sergio Mascetti, Andrea Gerino, Dragan Ahmetovic, Hironobu Takagi, and Chieko Asakawa. 2016. Supporting Orientation of People with Visual Impairment: Analysis of Large Scale Usage Data. In 18th International ACM SIGACCESS Conference on Computers and Accessibility. ACM.  ",
      "doi": "10.1145/2982142.2982178"
    },
    {
      "text": "Minghuang Ma, Haoqi Fan, and Kris M Kitani. 2016. Going Deeper into First-Person Activity Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
      "doi": ""
    },
    {
      "text": "Opticon. 2016. Handheld Scanner. (2016). http: //www.opticonusa.com/products/handheld-solutions/",
      "doi": ""
    },
    {
      "text": "Sinno Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. IEEE Transactions on knowledge and data engineering 22, 10 (2010), 1345--1359.  ",
      "doi": "10.1109/TKDE.2009.191"
    },
    {
      "text": "Novi Patricia and Barbara Caputo. 2014. Learning to learn, from transfer learning to domain adaptation: A unifying perspective. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1442--1449.  ",
      "doi": "10.1109/CVPR.2014.187"
    },
    {
      "text": "KNFB Reader. 2016. Access to print materials. (2016). http://www.knfbreader.com/",
      "doi": ""
    },
    {
      "text": "LookTel Recognizer. 2016. Instantly recognize everyday objects. (2016). http://www.looktel.com/recognizer",
      "doi": ""
    },
    {
      "text": "Larry D Rosen, Kelly Whaling, L Mark Carrier, Nancy A Cheever, and J Rokkum. 2013. The media and technology usage and attitudes scale: An empirical investigation. Computers in Human Behavior 29, 6 (2013), 2501--2511.  ",
      "doi": "10.1016/j.chb.2013.06.006"
    },
    {
      "text": "Andrew Rosenberg and Julia Hirschberg. 2007. V-Measure: A Conditional Entropy-Based External Cluster Evaluation Measure. In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL'07), Vol. 7. 410--420.",
      "doi": ""
    },
    {
      "text": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115, 3 (2015), 211--252.  ",
      "doi": "10.1007/s11263-015-0816-y"
    },
    {
      "text": "Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. 2015. Rethinking the inception architecture for computer vision. arXiv preprint arXiv:1512.00567 (2015).",
      "doi": ""
    },
    {
      "text": "TapTapSee. 2016. Mobile camera application designed specifically for the blind and visually impaired iOS users. (2016). http://www.taptapseeapp.com/",
      "doi": ""
    },
    {
      "text": "Color Teller. 2016. The Talking Color Identifier. (2016). http://www.brytech.com/colorteller/",
      "doi": ""
    },
    {
      "text": "Nees Jan Van Eck and Ludo Waltman. 2011. Text mining and visualization using VOSviewer. ISSI Newsletter 7, 3 (2011), 50--54.",
      "doi": ""
    },
    {
      "text": "Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, and Daan Wierstra. 2016. Matching Networks for One Shot Learning. In In Proceedings of the Conference on Neural Information Processing Systems (NIPS'16).",
      "doi": ""
    },
    {
      "text": "Yu Zhong, Pierre J Garrigues, and Jeffrey P Bigham. 2013. Real time object scanning using a mobile phone and cloud-based visual search engine. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 20.  ",
      "doi": "10.1145/2513383.2513443"
    }
  ]
}