{
  "doi": "10.1145/1978942.1979001",
  "title": "Usable gestures for blind people: understanding preference and performance",
  "published": "2011-05-07",
  "proctitle": "CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "413-422",
  "year": 2011,
  "badges": [
    "Best Paper"
  ],
  "abstract": "Despite growing awareness of the accessibility issues surrounding touch screen use by blind people, designers still face challenges when creating accessible touch screen interfaces. One major stumbling block is a lack of understanding about how blind people actually use touch screens. We conducted two user studies that compared how blind people and sighted people use touch screen gestures. First, we conducted a gesture elicitation study in which 10 blind and 10 sighted people invented gestures to perform common computing tasks on a tablet PC. We found that blind people have different gesture preferences than sighted people, including preferences for edge-based gestures and gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance study in which the same participants performed a set of reference gestures. We found significant differences in the speed, size, and shape of gestures performed by blind people versus those performed by sighted people. Our results suggest new design guidelines for accessible touch screen interfaces.",
  "tags": [
    "touch screens",
    "gestures",
    "accessibility",
    "blind",
    "gesture recognition"
  ],
  "authors": [
    {
      "name": "Shaun K. Kane",
      "institution": "University of Washington, Seattle, Washington, USA",
      "img": "/do/10.1145/contrib-81329489903/rel-imgonly/kane-headshot.jpg",
      "acmid": "81329489903",
      "orcid": "0000-0002-0276-9417"
    },
    {
      "name": "Jacob O. Wobbrock",
      "institution": "University of Washington, Seattle, Washington, USA",
      "img": "/do/10.1145/contrib-81100086173/rel-imgonly/wobbrock.jpg",
      "acmid": "81100086173",
      "orcid": "0000-0003-3675-5491"
    },
    {
      "name": "Richard E. Ladner",
      "institution": "University of Washington, Seattle, Washington, USA",
      "img": "/do/10.1145/contrib-81100297556/rel-imgonly/ladner3.jpg",
      "acmid": "81100297556",
      "orcid": "0000-0001-9413-6774"
    }
  ],
  "references": [
    {
      "text": "Anthony, L. and Wobbrock, J. O. A lightweight multistroke recognizer for user interface prototypes. Proc. GI '10, Canadian Information Processing Society (2010), 245--252. ",
      "doi": "10.5555/1839214.1839258"
    },
    {
      "text": "Baudel, T. and Beaudouin-Lafon, M. Charade: Remote control of objects using free-hand gestures. Communications of the ACM 36, 7 (1993), 28--35.  ",
      "doi": "10.1145/159544.159562"
    },
    {
      "text": "Baudisch, P. and Chu, G. Back-of-device interaction allows creating very small touch devices. Proc. CHI '09, ACM (2009), 1923--1932.  ",
      "doi": "10.1145/1518701.1518995"
    },
    {
      "text": "Bonner, M., Brudvik, J., Abowd, G. and Edwards, W. K. No-Look Notes: Accessible eyes-free multi-touch text entry. Proc. Pervasive '10, Springer (2010), 409--427.  ",
      "doi": "10.1007/978-3-642-12654-3_24"
    },
    {
      "text": "Buxton, W., Foulds, R., Rosen, M., Scadden, L. and Shein, F. Human interface design and the handicapped user. SIGCHI Bulletin 17, 4 (1986), 291--297.  ",
      "doi": "10.1145/22339.22386"
    },
    {
      "text": "Buxton, W., Hill, R. and Rowley, P. Issues and techniques in touch-sensitive tablet input. Proc. SIGGRAPH '85, ACM (1985), 215--224.  ",
      "doi": "10.1145/325334.325239"
    },
    {
      "text": "Crew, S. Touch-screen gadgets alienate blind. Reuters, January 8, 2009.",
      "doi": ""
    },
    {
      "text": "Crossan, A. and Brewster, S. Multimodal trajectory playback for teaching shape information and trajectories to visually impaired computer users. ACM TACCESS 1, 2 (2008), 1--34.  ",
      "doi": "10.1145/1408760.1408766"
    },
    {
      "text": "Epps, J., Lichman, S. and Wu, M. A study of hand shape use in tabletop gesture interaction. CHI '06 Extended Abstracts, ACM (2006), 748--753.  ",
      "doi": "10.1145/1125451.1125601"
    },
    {
      "text": "Goldreich, D. and Kanics, I. M. Tactile acuity is enhanced in blindness. Journal of Neuroscience 23, 8 (2003), 3439--3445.",
      "doi": ""
    },
    {
      "text": "Guerreiro, T., Lagoa, P., Nicolau, H., Gonalves, D. and Jorge, J. From tapping to touching: Making touch screens accessible to blind users. IEEE Multimedia 15, 4 (2008), 48--50.  ",
      "doi": "10.1109/MMUL.2008.88"
    },
    {
      "text": "Guimbreti&amp;#232;re, F., Stone, M. and Winograd, T. Fluid interaction with high-resolution wall-size displays. Proc. UIST '01, ACM (2001), 21--30.  ",
      "doi": "10.1145/502348.502353"
    },
    {
      "text": "Heller, M. A., Wilson, K., Steffen, H., Yoneyama, K. and Brackett, D. D. Superior haptic perceptual selectivity in late-blind and very-low-vision subjects. Perception 32, 4 (2003), 499--511.",
      "doi": ""
    },
    {
      "text": "Kamel, H. M. and Landay, J. A. A study of blind drawing practice: Creating graphical information without the visual channel. Proc. ASSETS '00, ACM (2000), 34--41.  ",
      "doi": "10.1145/354324.354334"
    },
    {
      "text": "Kane, S. K., Bigham, J. P. and Wobbrock, J. O. Slide Rule: Making mobile touch screens accessible to blind people using multi-touch interaction techniques. Proc. ASSETS '08, ACM (2008), 73--80.  ",
      "doi": "10.1145/1414471.1414487"
    },
    {
      "text": "Landau, S. and Wells, L. Merging tactile sensory input and audio data by means of the Talking Tactile Tablet. Proc. Eurohaptics '03, (2003), 414--418.",
      "doi": ""
    },
    {
      "text": "Law, C. and Vanderheiden, G. The development of a simple, low cost set of universal access features for electronic devices. Proc. CUU '00, ACM (2000), 118.  ",
      "doi": "10.1145/355460.355545"
    },
    {
      "text": "Liu, J., Pinelle, D., Sallam, S., Subramanian, S. and Gutwin, C. TNT: Improved rotation and translation on digital tables. Proc. GI '06, Canadian Information Processing Society (2006), 25--32. ",
      "doi": "10.5555/1143079.1143084"
    },
    {
      "text": "McGookin, D., Brewster, S. and Jiang, W. Investigating touchscreen accessibility for people with visual impairments. Proc. NordiCHI '08, ACM (2008), 298--307.  ",
      "doi": "10.1145/1463160.1463193"
    },
    {
      "text": "Morris, M. R., Wobbrock, J. O. and Wilson, A. D. Understanding users' preferences for surface gestures. Proc. GI '10, Canadian Information Processing Society (2010), 261--268. ",
      "doi": "10.5555/1839214.1839260"
    },
    {
      "text": "Sadato, N., Pascual-Leone, A., Grafman, J., Ibanez, V., Deiber, M. P., Dold, G. and Hallett, M. Activation of the primary visual cortex by Braille reading in blind subjects. Nature 380, 6574 (1996), 526--528.",
      "doi": ""
    },
    {
      "text": "S&amp;#225;nchez, J. and Aguayo, F. Mobile messenger for the blind. Proc. ECRIM '06, Springer (2006), 369--385. ",
      "doi": "10.5555/1783789.1783817"
    },
    {
      "text": "S&amp;#225;nchez, J. and Maureira, E. Subway mobility assistance tools for blind users. Proc. ECRIM '06, Springer (2006), 386--404. ",
      "doi": "10.5555/1783789.1783818"
    },
    {
      "text": "St&amp;#246;&amp;#223;el, C., Wandke, H. and Blessing, L. Gestural interfaces for elderly users: Help or hindrance? Gesture in Embodied Communication and Human-Computer Interaction, Springer (2010), 269--280.  ",
      "doi": "10.1007/978-3-642-12553-9_24"
    },
    {
      "text": "Tinwala, H. and MacKenzie, I. S. Eyes-free text entry with error correction on touchscreen mobile devices. Proc. NordiCHI '10, ACM (2010), 511--520.  ",
      "doi": "10.1145/1868914.1868972"
    },
    {
      "text": "Van Boven, R., Hamilton, R., Kauffman, T., Keenan, J. and Pascual-Leone, A. Tactile spatial resolution in blind Braille readers. Neurology, 54 (2000), 2230--2236.",
      "doi": ""
    },
    {
      "text": "Vanderheiden, G. C. Use of audio-haptic interface techniques to allow nonvisual access to touchscreen appliances. Proc. HFES 40, (1996), 1266.",
      "doi": ""
    },
    {
      "text": "Wobbrock, J. O., Morris, M. R. and Wilson, A. D. User-defined gestures for surface computing. Proc. CHI '09, ACM (2009), 1083--1092.  ",
      "doi": "10.1145/1518701.1518866"
    },
    {
      "text": "Yfantidis, G. and Evreinov, G. Adaptive blind interaction technique for touchscreens. Universal Access in the Information Society, 4 (2006), 328--337.  ",
      "doi": "10.1007/s10209-004-0109-7"
    },
    {
      "text": "Zhai, S. and Kristensson, P. Shorthand writing on stylus keyboard. Proc. CHI '03, ACM (2003), 97--104.  ",
      "doi": "10.1145/642611.642630"
    },
    {
      "text": "Zhao, S., Dragicevic, P., Chignell, M., Balakrishnan, R. and Baudisch, P. EarPod: Eyes-free menu selection using touch input and reactive audio feedback. Proc. CHI '07, ACM (2007), 1395--1404.  ",
      "doi": "10.1145/1240624.1240836"
    }
  ]
}