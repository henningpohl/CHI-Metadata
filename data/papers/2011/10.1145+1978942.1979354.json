{
  "doi": "10.1145/1978942.1979354",
  "title": "On the audio representation of radial direction",
  "published": "2011-05-07",
  "proctitle": "CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2779-2788",
  "year": 2011,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "We present and evaluate an approach towards eyes-free auditory display of spatial information that considers radial direction as a fundamental type of value primitive. There are many benefits to being able to sonify radial directions, such as indicating the heading towards a point of interest in a direct and dynamic manner, rendering a path or shape outline by sonifying a continual sequence of tangent directions as the path is traced, and providing direct feedback of the direction of motion of the user in a physical space or a pointer in a virtual space. We propose a concrete mapping of vowel-like sounds to radial directions as one potential method to enable sonification of such information. We conducted a longitudinal study with five sighted and two blind participants to evaluate the learnability and effectiveness of this method. Results suggest that our directional sound mapping can be learned within a few hours and be used to aurally perceive spatial information such as shape outlines and path contours.",
  "tags": [
    "audio display",
    "navigation",
    "non-speech",
    "non-verbal",
    "radial direction",
    "sonification",
    "visual impairment"
  ],
  "authors": [
    {
      "name": "Susumu Harada",
      "institution": "IBM Research - Tokyo, Yamato, Japan",
      "img": "/do/10.1145/contrib-81319492589/rel-imgonly/profile4.jpg",
      "acmid": "81319492589",
      "orcid": "missing"
    },
    {
      "name": "Hironobu Takagi",
      "institution": "IBM Research - Tokyo, Yamato, Japan",
      "img": "/do/10.1145/contrib-81408594028/rel-imgonly/1428.jpeg",
      "acmid": "81408594028",
      "orcid": "0000-0003-3087-3251"
    },
    {
      "name": "Chieko Asakawa",
      "institution": "IBM Research - Tokyo, Yamato, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100044475",
      "orcid": "0000-0002-5447-1305"
    }
  ],
  "references": [
    {
      "text": "Begault, D. R. 3-D sound for virtual reality and multimedia. Academic Press Professional, Inc., 1994. ",
      "doi": "10.5555/184407"
    },
    {
      "text": "Blauert, J. Spatial hearing: the psychophysics of human sound localization. MIT Press, 1997.",
      "doi": ""
    },
    {
      "text": "Brown, L. M. and Brewster, S. A. Drawing by ear: interpreting sonified line graphs. Proc. ICAD 2003, (2003).",
      "doi": ""
    },
    {
      "text": "Capp, M. and Picton, P. The optophone: an electronic blind aid. Engineering Science and Education Journal 9, 3 (2000), 137--143.",
      "doi": ""
    },
    {
      "text": "Cassidy, R. J., Berger, J., Lee, K., Maggioni, M., and Coifman, R. R. Auditory display of hyperspectral colon tissue images using vocal synthesis models. Proc. ICAD 2004, (2004).",
      "doi": ""
    },
    {
      "text": "Cohen, R. F., Haven, V., Lanzoni, J. A., Meacham, A., Skaff, J., and Wissell, M. Using an audio interface to assist users who are visually impaired with steering tasks. Proc. ASSETS 2006, ACM (2006), 119--124.  ",
      "doi": "10.1145/1168987.1169008"
    },
    {
      "text": "Crossan, A. and Brewster, S. Multimodal trajectory playback for teaching shape information and trajectories to visually impaired computer users. ACM Transactions on Accessible Computing 1, 2 (2008), 1--34.  ",
      "doi": "10.1145/1408760.1408766"
    },
    {
      "text": "van den Doel, K. SoundView: sensing color images by kinesthetic audio. Proc. ICAD 2003, (2003), 303--306.",
      "doi": ""
    },
    {
      "text": "Fox, J., Carlile, J., and Berger, J. SoniMime: sonification of fine motor skills. Proc. ICAD 2005, (2005).",
      "doi": ""
    },
    {
      "text": "Harada, S., Wobbrock, J. O., and Landay, J. A. VoiceDraw: a hands-free voice-driven drawing application for people with motor impairments. Proc. ASSETS 2007, ACM (2007), 27--34.  ",
      "doi": "10.1145/1296843.1296850"
    },
    {
      "text": "Harada, S., Wobbrock, J. O., Malkin, J., Bilmes, J. A., and Landay, J. A. Longitudinal study of people learning to use continuous voice-based cursor control. Proc. CHI 2009, ACM (2009), 347--356.  ",
      "doi": "10.1145/1518701.1518757"
    },
    {
      "text": "Hermann, T., Baier, G., Stephani, U., and Ritter, H. Kernel regression mapping for vocal EEG sonification. Proc. ICAD 2008, (2008).",
      "doi": ""
    },
    {
      "text": "Holland, S., Morse, D. R., and Gedenryd, H. AudioGPS: spatial audio navigation with a minimal attention interface. Personal Ubiq. Comp. 6, 4 (2002), 253--259.  ",
      "doi": "10.1007/s007790200025"
    },
    {
      "text": "Hummel, J., Hermann, T., Frauenberger, C., and Stockman, T. Interactive sonification of German wheel sports movement. Proc. ISon 2010, (2010), 17--22.",
      "doi": ""
    },
    {
      "text": "Kleiman-Weiner, M. and Berger, J. The sound of one arm swinging: a model for multidimensional auditory display of physical motion. Proc. ICAD 2006, (2006), 278--280.",
      "doi": ""
    },
    {
      "text": "Kramer, G. An introduction to auditory display. Addison Wesley Longman, 1992.",
      "doi": ""
    },
    {
      "text": "Loomis, J. M., Golledge, R. G., and Klatzky, R. L. Navigation system for the blind: auditory display modes and guidance. Presence: Teleoperators and Virtual Environments 7, 2 (1998), 193--203.  ",
      "doi": "10.1162/105474698565677"
    },
    {
      "text": "Malkin, J., Li, X., Harada, S., Landay, J., and Bilmes, J. The Vocal Joystick Engine v1.0. Computer Speech &amp;#38; Language in press, (2010).  ",
      "doi": "10.1016/j.csl.2010.03.005"
    },
    {
      "text": "Mansur, D. L., Blattner, M. M., and Joy, K. I. Sound Graphs: a numerical data analysis method for the blind. Journal of Medical Systems 9, 3 (1985), 163--174.",
      "doi": ""
    },
    {
      "text": "Meijer, P. An experimental system for auditory image representations. IEEE Transactions on Biomedical Engineering 39, 2 (1992), 112--121.",
      "doi": ""
    },
    {
      "text": "Plimmer, B., Crossan, A., Brewster, S. A., and Blagojevic, R. Multimodal collaborative handwriting training for visually-impaired people. Proc. CHI 2008, ACM (2008), 393--402.  ",
      "doi": "10.1145/1357054.1357119"
    },
    {
      "text": "Ramloll, R., Yu, W., Brewster, S., Riedel, B., Burton, M., and Dimigen, G. Constructing sonified haptic line graphs for the blind student: first steps. Proc. ASSETS 2000, ACM (2000), 17--25.  ",
      "doi": "10.1145/354324.354330"
    },
    {
      "text": "Rigas, D. and Alty, J. The rising pitch metaphor: an empirical study. International Journal of Human-Computer Studies 62, 1 (2005), 1--20.  ",
      "doi": "10.1016/j.ijhcs.2004.06.004"
    },
    {
      "text": "Talbot, M. and Cowan, W. On the audio representation of distance for blind users. Proc. CHI 2009, ACM (2009), 1839--1848.  ",
      "doi": "10.1145/1518701.1518984"
    },
    {
      "text": "Wilson, J., Walker, B. N., Lindsay, J., Cambias, C., and Dellaert, F. SWAN: system for wearable audio navigation. Proc. ISWC 2007, (2007), 1--8.  ",
      "doi": "10.1109/ISWC.2007.4373786"
    },
    {
      "text": "Zhao, H., Plaisant, C., and Shneiderman, B. \"I hear the pattern\": interactive sonification of geographical data patterns. Ext. Abtract CHI 2005, ACM (2005), 1905--1908.  ",
      "doi": "10.1145/1056808.1057052"
    }
  ]
}