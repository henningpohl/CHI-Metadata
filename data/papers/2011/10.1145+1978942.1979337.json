{
  "doi": "10.1145/1978942.1979337",
  "title": "Perceptual analysis of talking avatar head movements: a quantitative perspective",
  "published": "2011-05-07",
  "proctitle": "CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2699-2702",
  "year": 2011,
  "badges": [],
  "abstract": "Lifelike interface agents (e.g. talking avatars) have been increasingly used in human-computer interaction applications. In this work, we quantitatively analyze how human perception is affected by audio-head motion characteristics of talking avatars. Specifically, we quantify the correlation between perceptual user ratings (obtained via user study) and joint audio-head motion features as well as head motion patterns in the frequency-domain. Our quantitative analysis results clearly show that the correlation coefficient between the pitch of speech signals (but not the RMS energy of speech signals) and head motions is approximately linearly proportional to the perceptual user rating, and a larger proportion of high frequency signals in talking avatar head movements tends to degrade the user perception in terms of naturalness.",
  "tags": [
    "head motion",
    "quantitative analysis",
    "and audio-head motion features",
    "perceptual modeling"
  ],
  "authors": [
    {
      "name": "Xiaohan Ma",
      "institution": "University of Houston, Houston, Texas, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81442600092",
      "orcid": "missing"
    },
    {
      "name": "Binh Huy Le",
      "institution": "University of Houston, Houston, Texas, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81442608015",
      "orcid": "missing"
    },
    {
      "name": "Zhigang Deng",
      "institution": "University of Houston, Houston, Texas, USA",
      "img": "/do/10.1145/contrib-81100180219/rel-imgonly/recent_photo.jpg",
      "acmid": "81100180219",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "R. Azuma and G. Bishop. A frequency-domain analysis of head-motion prediction. In Proc. of SIGGRAPH'95, pages 401--408, 1995.  ",
      "doi": "10.1145/218380.218496"
    },
    {
      "text": "C. Busso, Z. Deng, U. Neumann, and S. Narayanan. Natural head motion synthesis driven by acoustic prosody features. Journal of Computer Animation and Virtual Worlds, 16(3--4):283--290, July 2005.  ",
      "doi": "10.5555/1089870.1089884"
    },
    {
      "text": "E. Chuang and C. Bregler. Mood swings: expressive speech animation. ACM Trans. Graph., 24:331--347, April 2005.  ",
      "doi": "10.1145/1061347.1061355"
    },
    {
      "text": "G. E. Grossman, R. J. Leigh, L. A. Abel, D. J. Lanska, and S. E. Thurston. Frequency and velocity of rotational head perturbations during locomotion. Experimental Brain Research, 70(3):470--476, 1988.",
      "doi": ""
    },
    {
      "text": "K. G. Munhall, J. A. Jones, D. E. Callan, T. Kuratate, and E. Vatikiotis-Basteson. Visual prosody and speech intelligibility: Head movement improves auditory speech perception. Psychological Science, 15:133--137, 2004.",
      "doi": ""
    },
    {
      "text": "E. Wang, C. Lignos, A. Vatsal, and B. Scassellati. Effects of head movement on perceptions of humanoid robot behavior. In HRI'06: Proc. of ACM SIGCHI/SIGART Conf. on Human-robot interaction, pages 180--185, 2006.  ",
      "doi": "10.1145/1121241.1121273"
    },
    {
      "text": "M. Williams, S. Moss, and J. Bradshaw. A unique look at face processing: the impact of masked faces on the processing of facial features. Cognition, 91(2):155--172, 2004.",
      "doi": ""
    },
    {
      "text": "N. Yee, J. N. Bailenson, and K. Rickertsen. A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces. In CHI'07, pages 1--10, 2007.  ",
      "doi": "10.1145/1240624.1240626"
    },
    {
      "text": "H. C. Yehia, T. Kuratate, and E. Vatikiotis-Basteson. Linking facial animation, head motion and speech acoustics. Journal of Phonetics, 30:555--568, 2002.",
      "doi": ""
    },
    {
      "text": "C. Yun, Z. Deng, and M. Hiscock. Can local avatars satisfy a global audience? a case study of high-fidelity 3d facial avatar animation in subject identification and emotion perception by us and international groups. ACM Computer In Entertainment, 7(2):1--26, 2009.  ",
      "doi": "10.1145/1541895.1541901"
    }
  ]
}