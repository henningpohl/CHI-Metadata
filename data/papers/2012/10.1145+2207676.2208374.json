{
  "doi": "10.1145/2207676.2208374",
  "title": "iRotate: automatic screen rotation based on face orientation",
  "published": "2012-05-05",
  "proctitle": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2203-2210",
  "year": 2012,
  "badges": [],
  "abstract": "We present iRotate, an approach to automatically rotate screens on mobile devices to match users' face orientation. Current approaches to automatic screen rotation are based on gravity and device orientation. Our survey of 513 users shows that 42% currently experience auto-rotation that leads to incorrect viewing orientation several times a week or more, and 24% find the problem to be very serious to extremely serious. iRotate augments gravity-based approach, and uses front cameras on mobile devices to detect users' faces and rotates screens accordingly. It requires no explicit user input and supports different user postures and device orientations. We have implemented a iRotate that works in real-time on iPhone and iPad, and we assess the accuracy and limitations of iRotate through a 20- participant feasibility study.",
  "authors": [
    {
      "name": "Lung-Pan Cheng",
      "institution": "National Taiwan University, Taipei, Taiwan",
      "img": "/do/10.1145/contrib-81470651683/rel-imgonly/32956970-44d4-41fa-95c3-df5faf94a414_1_201_a.jpeg",
      "acmid": "81470651683",
      "orcid": "0000-0002-7712-8622"
    },
    {
      "name": "Fang-I Hsiao",
      "institution": "National Taiwan University, Taipei, Taiwan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81484648413",
      "orcid": "missing"
    },
    {
      "name": "Yen-Ting Liu",
      "institution": "National Taiwan University, Taipei, Taiwan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81502699060",
      "orcid": "missing"
    },
    {
      "name": "Mike Y. Chen",
      "institution": "National Taiwan University, Taipei, Taiwan",
      "img": "/do/10.1145/contrib-81460645188/rel-imgonly/mikebiophotosmall.jpg",
      "acmid": "81460645188",
      "orcid": "0000-0001-5410-652X"
    }
  ],
  "references": [
    {
      "text": "Balakrishnan, R., Baudel, T., Kurtenbach, G., and Fitzmaurice, G. The Rockin'Mouse: integral 3D manipulation on a plane. Proceedings of the SIGCHI conference on Human factors in computing systems, ACM (1997), 311--318.  ",
      "doi": "10.1145/258549.258778"
    },
    {
      "text": "Ballagas, R., Rohs, M., and Sheridan, J. G. Sweep and point and shoot: phonecam-based interactions for large public displays. CHI'05 extended abstracts on Human factors in computing systems, ACM (2005), 1200--1203.  ",
      "doi": ""
    },
    {
      "text": "Bartlett, J. F. Rock 'n' Scroll is Here to Stay. IEEE Computer Graphics and Applications, May (2000), 40--45.  ",
      "doi": ""
    },
    {
      "text": "Blask\u00f3, G., Beaver, W., Kamvar, M., and Feiner, S. Workplane-orientation sensing techniques for tablet PCs. Proceedings of the 17th Annual ACM symposium on User Interface Software and Technology, (2004).",
      "doi": ""
    },
    {
      "text": "Bradski, G. R., Clara, S., and Corporation, I. Computer Vision Face Tracking For Use in a Perceptual User Interface. Intel Technology Journal 2, 2 (1998), 12--21.",
      "doi": ""
    },
    {
      "text": "Fitzmaurice, G. W., Balakrishnan, R., Kurtenbach, G., and Buxton, B. An exploration into supporting artwork orientation in the user interface. Proceedings of the SIGCHI conference on Human factors in computing systems: the CHI is the limit, ACM (1999), 167--174.  ",
      "doi": ""
    },
    {
      "text": "Forstall, S. and Blumenberg, C. Portrait-Landscape Rotation Heuristics for a Portable Multifunction Device. US Patent 7978176, 12 July, 2011.",
      "doi": ""
    },
    {
      "text": "Hannuksela, J., Sangi, P., Turtinen, M., and Heikkil\u00e4, J. Face tracking for spatially aware mobile user interfaces. Image and Signal Processing, (2008), 405--412.  ",
      "doi": ""
    },
    {
      "text": "Hannuksela, J., Sangi, P., and Heikkil\u00e4, J. Vision-based motion estimation for interaction with mobile devices. Computer Vision and Image Understanding 108, 1-2 (2007), 188--195.  ",
      "doi": ""
    },
    {
      "text": "Hansen, T. R., Eriksson, E., and Lykke-Olesen, A. Mixed interaction space: designing for camera based interaction with mobile devices. CHI'05 extended abstracts on Human factors in computing systems, ACM (2005), 1933--1936.  ",
      "doi": ""
    },
    {
      "text": "Hinckley, K. and Song, H. Sensor synaesthesia: touch in motion, and motion in touch. Proceedings of the 2011 annual conference on Human factors in computing systems, ACM (2011), 801--810.  ",
      "doi": ""
    },
    {
      "text": "Hinckley, K., Pierce, J., Sinclair, M., and Horvitz, E. Sensing techniques for mobile interaction. Proceedings of the 13th annual ACM symposium on User interface software and technology, ACM (2000), 91--100.  ",
      "doi": ""
    },
    {
      "text": "Hinckley, K., Sinclair, M., Hanson, E., Szeliski, R., and Conway, M. The VideoMouse: a camera-based multi-degree-of-freedom input device. Proceedings of the 12th annual ACM symposium on User interface software and technology, ACM (1999), 103--112.  ",
      "doi": ""
    },
    {
      "text": "Ip, H. H. S., Hay, Y., and Tang, A. C. C. Body-Brush: a body-driven interface for visual aesthetics. Proceedings of the tenth ACM international conference on Multimedia, ACM (2002), 664--665.  ",
      "doi": ""
    },
    {
      "text": "Janicek, M. CAPTURING AN IMAGE WITH A CAMERA INTEGRATED IN AN ELECTRONIC DISPLAY. US Patent App. 20,090/009,628, 2007.",
      "doi": ""
    },
    {
      "text": "Lienhart, R., Kuranov, A., and Pisarevsky, V. Empirical analysis of detection cascades of boosted classifiers for rapid object detection. The German 25th Pattern Recognition Symposium (DAGM '03), (2003), 297--304.",
      "doi": ""
    },
    {
      "text": "Ording, B., Van Os, M., and Chaudhri, I. Screen Rotation Gestures on a Portable Multifunction Device. US Patent 7978182, 12 July, 2011.",
      "doi": ""
    },
    {
      "text": "Schmidt, A., Beigl, M., and Gellersen, H. W. There is more to context than location. Computers & Graphics 23, 6 (1999), 893--901.",
      "doi": ""
    },
    {
      "text": "Segen, J. and Kumar, S. Human-Computer Interaction using Gesture Recognition and 3D Hand Tracking. Image Processing, 1998. ICIP 98. Proceedings. 1998 International Conference on, IEEE (1998), 188--192.",
      "doi": ""
    },
    {
      "text": "Sohn, M. and Lee, G. ISeeU: camera-based user interface for a handheld computer. Proceedings of the 7th international conference on Human computer interaction with mobile devices & services, ACM (2005), 299--302.  ",
      "doi": ""
    },
    {
      "text": "Sparacino, F., Wren, C., Davenport, G., and Pentland, A. Augmented performance in dance and theater. International Dance and Technology 99, (1999), 25--28.",
      "doi": ""
    },
    {
      "text": "Sparacino, F. (Some) computer vision based interfaces for interactive art and entertainment installations. INTER_FACE Body Boundaries, ed. Emanuele Quinz, Anomalie, n.2, Paris, France, Anomos, Citeseer (2001).",
      "doi": ""
    },
    {
      "text": "Wang, J. and Canny, J. TinyMotion: camera phone based interaction methods. CHI'06 extended abstracts on Human factors in computing systems, ACM (2006), 339--344.  ",
      "doi": ""
    },
    {
      "text": "Zhang, L., Shi, Y., and Fan, M. UCam: direct manipulation using handheld camera for 3d gesture interaction. Proceeding of the 16th ACM international conference on Multimedia, ACM (2008), 801--804.  ",
      "doi": ""
    }
  ]
}