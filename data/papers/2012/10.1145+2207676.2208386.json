{
  "doi": "10.1145/2207676.2208386",
  "title": "Voice typing: a new speech interaction model for dictation on touchscreen devices",
  "published": "2012-05-05",
  "proctitle": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2277-2286",
  "year": 2012,
  "badges": [],
  "abstract": "Dictation using speech recognition could potentially serve as an efficient input method for touchscreen devices. However, dictation systems today follow a mentally disruptive speech interaction model: users must first formulate utterances and then produce them, as they would with a voice recorder. Because utterances do not get transcribed until users have finished speaking, the entire output appears and users must break their train of thought to verify and correct it. In this paper, we introduce Voice Typing, a new speech interaction model where users' utterances are transcribed as they produce them to enable real-time error identification. For fast correction, users leverage a marking menu using touch gestures. Voice Typing aspires to create an experience akin to having a secretary type for you, while you monitor and correct the text. In a user study where participants composed emails using both Voice Typing and traditional dictation, they not only reported lower cognitive demand for Voice Typing but also exhibited 29% relative reduction of user corrections. Overall, they also preferred Voice Typing.",
  "authors": [
    {
      "name": "Anuj Kumar",
      "institution": "Microsoft Research, Redmond, Washington & Carnegie Mellon University, Pittsburgh, Pennsylvania, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81416596602",
      "orcid": "missing"
    },
    {
      "name": "Tim Paek",
      "institution": "Microsoft Research, Redmond, Washington, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100372905",
      "orcid": "missing"
    },
    {
      "name": "Bongshin Lee",
      "institution": "Microsoft Research, Redmond, Washington, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81409593205",
      "orcid": "0000-0002-4217-627X"
    }
  ],
  "references": [
    {
      "text": "Aist, G., Allen, J., Campana, E., Gallo, C., Stoness, S., Swift, M., and Tanenhaus, M. K. Incremental understanding in human-computer dialogue and experimental evidence for advantages over nonincremental methods. Proc. DECALOG 2007, (2007), 149--154.",
      "doi": ""
    },
    {
      "text": "Altmann, G. and Kamide, Y. Incremental interpretation at verbs: restricting the domain of subsequent reference. Cognition 73, 3 (1999), 247--264.",
      "doi": ""
    },
    {
      "text": "Basapur, S., Xu, S., Ahlenius, M., and Lee, Y. S. User expectations from dictation on mobile devices. Proc. HCI 2007, Springer-Verlag (2007), 217--225. ",
      "doi": "10.5555/1757268.1757294"
    },
    {
      "text": "Baumann, T., Atterer, M., and Schlangen, D. Assessing and improving the performance of speech recognition for incremental systems. Proc. HLT-NAACL 2009, (2009), 380--388. ",
      "doi": "10.5555/1620754.1620810"
    },
    {
      "text": "Bellegarda, J. Statistical language model adaptation: Review and perspectives. Speech Communication 42, (2004), 93--108.",
      "doi": ""
    },
    {
      "text": "Clark, H. H. and Brennan, S. E. Grounding in communication. Perspectives on Socially Shared Cognition, (1991), 127--149.",
      "doi": ""
    },
    {
      "text": "Fink, G., Schillo, C., Kummert, F., and Sagerer, G. Incremental speech recognition for multimodal interfaces. Proc. IECON 1998, (1998), 2012--2017.",
      "doi": ""
    },
    {
      "text": "Gales, M. J. F. Maximum Likelihood Linear Transformations for HMM-Based Speech Recognition. Computer Speech and Language 12, 2 (1998), 75--98.",
      "doi": ""
    },
    {
      "text": "Grover, D. L., King, M. T., and Kushler, C. A. Patent No. US5818437, Reduced keyboard disambiguating computer. Tegic Communications, Inc., Seattle (1998).",
      "doi": ""
    },
    {
      "text": "Gunawardana, A., Paek, T., and Meek, C. Usability guided key-target resizing for soft keyboards. Proc. IUI 2010, ACM Press (2010), 111--118.  ",
      "doi": "10.1145/1719970.1719986"
    },
    {
      "text": "Hart, S. G. Nasa-Task Load Index (Nasa-TLX); 20 Years Later. Proc. Human Factors and Ergonomics Society Annual Meeting, (2006), 904--908.",
      "doi": ""
    },
    {
      "text": "Hoggan, E., Brewster, S. A., and Johnston, J. Investigating the effectiveness of tactile feedback for mobile touchscreens. Proc. CHI 2008, ACM Press (2008), 1573--1582.  ",
      "doi": "10.1145/1357054.1357300"
    },
    {
      "text": "Karat, C. M., Halverson, C., Karat, J., and Horn, D. Patterns of entry and correction in large vocabulary continuous speech recognition systems. Proc. CHI 1999, ACM Press (1999), 568--575.  ",
      "doi": "10.1145/302979.303160"
    },
    {
      "text": "Kurtenbach, G. and Buxton, W. User learning and performance with marking menus. Proc. CHI 1994, ACM Press (1994), 258--264.  ",
      "doi": "10.1145/191666.191759"
    },
    {
      "text": "Lee, C.-H. and Gauvain, J.-L. MAP estimation of continuous density HMM: Theory and Applications. Proc. DARPA Speech & Nat. Lang Workshop, (1992), 185--190.  ",
      "doi": "10.3115/1075527.1075568"
    },
    {
      "text": "Levenshtein V. I. Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady 10, 8 (1966), 707--710.",
      "doi": ""
    },
    {
      "text": "Martin, T. B. and Welch, J. R. Practical speech recognizers and some performance effectiveness parameters. Trends in Speech Recognition. Prentice Hall, Englewood Cliffs, NJ, USA, 1980. ",
      "doi": "10.5555/539772"
    },
    {
      "text": "MacKenzie, I. S. and Soukoreff, R. W. Text entry for mobile computing: Models and methods, theory and practice. Human-Computer Interaction 17, (2002), 147--198.",
      "doi": ""
    },
    {
      "text": "Mobile Speech Recognition | Voice Recognition | Windows Phone 7. http://www.microsoft.com/windowsphone/enus/howto/wp7/basics/use-speech-on-my-phone.aspx.",
      "doi": ""
    },
    {
      "text": "Nuance - Dragon Dictation: iPhone - Dragon Dictation for iPad\u2122 , iPhone\u2122 and iPod touch\u2122 is an easy-to-use voice recognition application. http://www.nuance.com/for-business/byproduct/dragon-dictation-iphone/index.htm.",
      "doi": ""
    },
    {
      "text": "Payne, S. Mental Models in Human-Computer Interaction. The Human-Computer Interaction Handbook. Lawrence Erlbaum, Mahwah, NJ, USA, 2009.",
      "doi": ""
    },
    {
      "text": "Rabiner, L. and Juang, B. H. Fundamentals of Speech Recognition. Prentice Hall, Upper Saddle River, NJ, USA, 1993. ",
      "doi": "10.5555/153687"
    },
    {
      "text": "Rabiner L. R. A tutorial on hidden Markov models and selected applications in speech recognition. Proc. IEEE 77, 2 (1989), 257--286.",
      "doi": "10.5555/108235.108253"
    },
    {
      "text": "Rosen, L. D. A Review of Speech Recognition Software. The National Psychologist, 6(5), (1997), 28--29.",
      "doi": ""
    },
    {
      "text": "Selfridge, E., Arizmendi, I., Heeman, P., and Williams, J. Stability and accuracy in incremental speech recognition. Proc. SIGDIAL 2011, (2011), 110--119. ",
      "doi": "10.5555/2132890.2132904"
    },
    {
      "text": "Sherwani, J. and Rosenfeld, R. The case for speech and language technologies for developing regions. Proc. Human-Computer Interaction for Community and International Development Workshop, (2008).",
      "doi": ""
    },
    {
      "text": "Skantze, G. and Schlangen, D. (2009). Incremental dialogue processing in a micro-domain. Proc. EACL 2009, (2009), 745--753. ",
      "doi": "10.5555/1609067.1609150"
    },
    {
      "text": "Steele, J., To, N. The Android Developer's Cookbook: Building Applications With the Android SDK. AddisonWesley Professional, 1st Edition, October 2010. ",
      "doi": "10.5555/1942180"
    },
    {
      "text": "Suhm, B., Myers, B., and Waibel, A. Multi-Modal Error Correction for Speech User Interfaces. ACM TOCHI 8, 1 (2001), 60--98.  ",
      "doi": "10.1145/371127.371166"
    },
    {
      "text": "SWYPE | Type Fast, Swype Faster. http://www.swype.com.",
      "doi": ""
    },
    {
      "text": "Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K. M., and Sedivy, J. C. Integration of visual and linguistic information in spoken language comprehension. Science 268, 5217 (1995), 1632--1634.",
      "doi": ""
    },
    {
      "text": "Traxler, M. J., Bybee, M. D., and Pickering, M. J. Influence of connectives on language comprehension: Eye-tracking evidence for incremental interpretation. The Quarterly Journal of Experimental Psychology: Section A 50, 3 (1997), 481--497.",
      "doi": ""
    },
    {
      "text": "Voice to Text Application Powered by Intelligent Voice Recognition | Vlingo. http://www.vlingo.com.",
      "doi": ""
    },
    {
      "text": "Zhai, S. and Kristensson, P. O. Shorthand Writing on Stylus Keyboard. Proc. CHI 2003, ACM Press (2003), 97--104.  ",
      "doi": "10.1145/642611.642630"
    }
  ]
}