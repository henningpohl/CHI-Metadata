{
  "doi": "10.1145/2207676.2208303",
  "title": "Instructing people for training gestural interactive systems",
  "published": "2012-05-05",
  "proctitle": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "1737-1746",
  "year": 2012,
  "badges": [],
  "abstract": "Entertainment and gaming systems such as the Wii and XBox Kinect have brought touchless, body-movement based interfaces to the masses. Systems like these enable the estimation of movements of various body parts from raw inertial motion or depth sensor data. However, the interface developer is still left with the challenging task of creating a system that recognizes these movements as embodying meaning. The machine learning approach for tackling this problem requires the collection of data sets that contain the relevant body movements and their associated semantic labels. These data sets directly impact the accuracy and performance of the gesture recognition system and should ideally contain all natural variations of the movements associated with a gesture. This paper addresses the problem of collecting such gesture datasets. In particular, we investigate the question of what is the most appropriate semiotic modality of instructions for conveying to human subjects the movements the system developer needs them to perform. The results of our qualitative and quantitative analysis indicate that the choice of modality has a significant impact on the performance of the learnt gesture recognition system; particularly in terms of correctness and coverage.",
  "tags": [
    "natural gesture recognition",
    "data collection",
    "instructing movement",
    "machine learning"
  ],
  "authors": [
    {
      "name": "Simon Fothergill",
      "institution": "University of Cambridge, Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81388601696",
      "orcid": "missing"
    },
    {
      "name": "Helena Mentis",
      "institution": "Microsoft Research, Cambridge, United Kingdom",
      "img": "/do/10.1145/contrib-81100393102/rel-imgonly/profmentisphoto.jpg",
      "acmid": "81100393102",
      "orcid": "0000-0002-0142-3529"
    },
    {
      "name": "Pushmeet Kohli",
      "institution": "Microsoft Research, Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81339510339",
      "orcid": "missing"
    },
    {
      "name": "Sebastian Nowozin",
      "institution": "Microsoft Research, Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81414597536",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Chalearn gesture dataset (cgd2011), chalearn, california, 2011.",
      "doi": ""
    },
    {
      "text": "Aggarwal, J., and Ryoo, M. Human activity analysis: A review. ACM Computing Surveys (2011). To appear.  ",
      "doi": "10.1145/1922649.1922653"
    },
    {
      "text": "Breiman, L. Random forests. Machine Learning 45, 1 (2001).  ",
      "doi": "10.1023/A%3A1010933404324"
    },
    {
      "text": "Bruner, J. Toward a theory of instruction. Belknap Press of Harvard University Press, 1966.",
      "doi": ""
    },
    {
      "text": "Charbonneau, E., Miller, A., and LaViola, J. Teach me to dance: Exploring player experience and performance in full body dance games.",
      "doi": ""
    },
    {
      "text": "Fothergill, S., Harle, R., and Holden, S. Modelling the model athlete : Automatic coaching of rowing technique. In Structural, Syntactic, and Statistical Pattern Recognition, vol. 5342 of LNCS (2008), 372--381.  ",
      "doi": "10.1007/978-3-540-89689-0_41"
    },
    {
      "text": "Furui, S., Nakamura, M., Ichiba, T., and Iwano, K. Why is the recognition of spontaneous speech so hard? In Text, Speech and Dialogue, V. Matouek, P. Mautner, and T. Pavelka, Eds., vol. 3658 of Lecture Notes in Computer Science. Springer Berlin / Heidelberg, 2005, 747--747.  ",
      "doi": "10.1007/11551874_3"
    },
    {
      "text": "Gorelick, L., Blank, M., Shechtman, E., Irani, M., and Basri, R. Actions as space-time shapes. Transactions on Pattern Analysis and Machine Intelligence 29, 12 (December 2007), 2247--2253.  ",
      "doi": "10.1109/TPAMI.2007.70711"
    },
    {
      "text": "Guest, A. H. Labanotation, or, Kinetography Laban: The System of Analyzing and Recording Movements. Dance Books, 1996.",
      "doi": ""
    },
    {
      "text": "Hwang, B.-W., K. S., and Lee, S.-W. A full-body gesture database for automatic gesture recognition. In Proceedings of the 7th International Conference on Automatic Face and Gesture Recognition, FGR '06, IEEE Computer Society) (2006), 243--248.  ",
      "doi": "10.5555/1126250.1126345"
    },
    {
      "text": "Kress, and van Leeuwen. Reading Images: Grammar of Visual Design. Routledge, 1996.",
      "doi": ""
    },
    {
      "text": "Kuehne, H., J. H. G. E. P. T., and Serre, T. HMDB: a large video database for human motion recognition. In Proceedings of the International Conference on Computer Vision (ICCV) (2011).  ",
      "doi": "10.1109/ICCV.2011.6126543"
    },
    {
      "text": "Laptev, I., Marszalek, M., Schmid, C., and Rozenfeld, B. Learning realistic human actions from movies. In CVPR, IEEE Computer Society (2008).",
      "doi": ""
    },
    {
      "text": "Lin, Z., Jiang, Z., and Davis, L. S. Recognizing actions by shape-motion prototype trees. In ICCV, IEEE (2009), 444--451.",
      "doi": ""
    },
    {
      "text": "Liu, J. G., Luo, J. B., and Shah, M. Recognizing realistic actions from videos 'in the wild'. In CVPR (2009), 1996--2003.",
      "doi": ""
    },
    {
      "text": "Marsza\u0142ek, M., Laptev, I., and Schmid, C. Actions in context. In CVPR, IEEE (2009), 2929--2936.",
      "doi": ""
    },
    {
      "text": "McNeil, D. Hand and Mind, What Gestures Reveal about Thought. The University of Chicago Press, 1992.",
      "doi": ""
    },
    {
      "text": "Nowozin, S., and Shotton, J. Action points: A representation for low-latency online human action recognition.",
      "doi": ""
    },
    {
      "text": "Nunnally, J. C., and Bernstein, I. H. Psychometric Theory. McGraw-Hill, 1994.",
      "doi": ""
    },
    {
      "text": "Oh, S., Hoogs, A., Perera, A., Cuntoor, N., Chen, C.-C., Lee, J. T., Mukherjee, S., and et al. A large-scale benchmark dataset for event recognition in surveillance video. In CVPR (2011).",
      "doi": ""
    },
    {
      "text": "Padmanabhan, M., Ramaswamy, G., Ramabhadran, B., Gopalakrishnan, P. S., and Dunn, C. Issues involved in voicemail data collection. In DARPA Hub 4 Workshop (1998).",
      "doi": ""
    },
    {
      "text": "Peirce, C. On a new list of categories. Proceedings of the American Academy of Arts and Sciences (1867).",
      "doi": ""
    },
    {
      "text": "Poppe, R. A survey on vision-based human action recognition. Image and Vision Computing 28, 6 (2010), 976--990.  ",
      "doi": "10.1016/j.imavis.2009.11.014"
    },
    {
      "text": "Quinn, D. Personal communication with David Quinn (RARE, UK), August 2011.",
      "doi": ""
    },
    {
      "text": "Rijsbergen, C. J. V. Information Retrieval. Butterworths, 1979. ",
      "doi": "10.5555/539927"
    },
    {
      "text": "Rodriguez, M. D., Ahmed, J., and Shah, M. Action MACH a spatio-temporal maximum average correlation height filter for action recognition. In CVPR, IEEE Computer Society (2008).",
      "doi": ""
    },
    {
      "text": "Schindler, K., and Gool, L. J. V. Action snippets: How many frames does human action recognition require? In CVPR, IEEE Computer Society (2008).",
      "doi": ""
    },
    {
      "text": "Sch\u00fcldt, C., Laptev, I., and Caputo, B. Recognizing human actions: A local SVM approach. In ICPR (2004), 32--36.  ",
      "doi": "10.5555/1018429.1020906"
    },
    {
      "text": "Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M., Moore, R., Kipman, A., and Blake, A. Real-time human pose recognition in parts from a single depth image. In CVPR (2011).  ",
      "doi": "10.1109/CVPR.2011.5995316"
    },
    {
      "text": "Stone, E., and Skubic, M. Evaluation of an inexpensive depth camera for passive in-home fall risk assessment. In Pervasive Health Conference (2011).",
      "doi": ""
    },
    {
      "text": "Turaga, P. K., Chellappa, R., Subrahmanian, V. S., and Udrea, O. Machine recognition of human activities: A survey. IEEE Trans. Circuits Syst. Video Techn 18, 11 (2008), 1473--1488.  ",
      "doi": "10.1109/TCSVT.2008.2005594"
    },
    {
      "text": "Weinland, D., Ronfard, R., and Boyer, E. A survey of vision-based methods for action representation, segmentation and recognition. Tech. rep., INRIA, February 2010.",
      "doi": ""
    },
    {
      "text": "Yao, A., Gall, J., Fanelli, G., and van Gool, L. Does human action recognition benefit from pose estimation? In BMVC (2011).",
      "doi": ""
    }
  ]
}