{
  "doi": "10.1145/2207676.2207786",
  "title": "How do couples use CheekTouch over phone calls?",
  "published": "2012-05-05",
  "proctitle": "CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "763-766",
  "year": 2012,
  "badges": [],
  "abstract": "In this paper we introduce CheekTouch, an affective audio-tactile communication technique that transmits multi-finger touch gestures applied on a sender's mobile phone to a receiver's cheek in real time during a call. We made a pair of CheekTouch prototypes each with a multi-touch screen and vibrotactile display to enable bidirectional touch delivery. We observed four romantic couples in their twenties using our prototype system in a lab setting over five consecutive days, and analyzed how CheekTouch affected their non-verbal and emotional communication. The results of the user study showed that CheekTouch could effectively support audio-tactile communication in various ways - persuading, conveying status, delivering information, emphasizing emotion/words, calling for attention, and being playful.",
  "tags": [
    "affective communication",
    "vibrotactile feedback",
    "on-the-cheek interaction",
    "mobile phone",
    "remote touch",
    "multi-finger touch"
  ],
  "authors": [
    {
      "name": "Young-Woo Park",
      "institution": "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
      "img": "/do/10.1145/contrib-81413599235/rel-imgonly/untitled-1.jpg",
      "acmid": "81413599235",
      "orcid": "0000-0003-2257-9394"
    },
    {
      "name": "Seok-Hyung Bae",
      "institution": "Korea Advanced Institute of Science and Technologhy, Daejeon, Republic of Korea",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81392591403",
      "orcid": "missing"
    },
    {
      "name": "Tek-Jin Nam",
      "institution": "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100320511",
      "orcid": "0000-0002-7942-0766"
    }
  ],
  "references": [
    {
      "text": "Brave, S., Ishii, H. and Dahley, A. Tangible interfaces for remote collaboration and communication. Proc. CSCW 1998, ACM Press (1998), 169--178.  ",
      "doi": "10.1145/289444.289491"
    },
    {
      "text": "Brown, L., Sellen, A., Krishna, R. and Harper, R. Exploring the potential of audio-tactile messaging for remote interpersonal communication. Proc. CHI 2009, ACM Press (2009), 1527--1530.  ",
      "doi": "10.1145/1518701.1518934"
    },
    {
      "text": "Chang, A., O'Modhrain, S., Jacob, R., Gunther, E. and Ishii, H. ComTouch: design of a vibrotactile communication device. Proc. DIS 2002, ACM Press (2002), 312--320.  ",
      "doi": "10.1145/778712.778755"
    },
    {
      "text": "Fukumoto, M. and Tonomura, Y. Whisper: a wrist-watch style wearable handset. Proc. CHI 1999, ACM Press (1999), 112--119.  ",
      "doi": "10.1145/302979.303009"
    },
    {
      "text": "Hashimoto, Y. and Kajimoto, H. Emotional touch: a novel interface to display emotional tactile information to a palm. SIGGRAPH 2008 new tech demos, ACM Press (2008), Article 5.  ",
      "doi": "10.1145/1401615.1401630"
    },
    {
      "text": "OSCemote. www.appstorehq.com/oscemote-iphone/.",
      "doi": ""
    },
    {
      "text": "Wang, R. and Quek, F. Touch & talk: contextualizing remote touch for affective interaction. Proc. TEI 2010, ACM Press (2010), 13--20.  ",
      "doi": "10.1145/1709886.1709891"
    }
  ]
}