{
  "doi": "10.1145/1753326.1753620",
  "title": "SoundNet: investigating a language composed of environmental sounds",
  "published": "2010-04-10",
  "proctitle": "CHI '10: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "1945-1954",
  "year": 2010,
  "badges": [],
  "abstract": "Auditory displays have been used in both human-machine and computer interfaces. However, the use of non-speech audio in assistive communication for people with language disabilities, or in other applications that employ visual representations, is still under-investigated. In this paper, we introduce SoundNet, a linguistic database that associates natural environmental sounds with words and concepts. A sound labeling study was carried out to verify SoundNet associations and to investigate how well the sounds evoke concepts. A second study was conducted using the verified SoundNet data to explore the power of environmental sounds to convey concepts in sentence contexts, compared with conventional icons and animations. Our results show that sounds can effectively illustrate (especially concrete) concepts and can be applied to assistive interfaces.",
  "authors": [
    {
      "name": "Xiaojuan Ma",
      "institution": "Princeton University, Princeton, NJ, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81416606526",
      "orcid": "missing"
    },
    {
      "name": "Christiane Fellbaum",
      "institution": "Princeton University, Princeton, NJ, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100035454",
      "orcid": "missing"
    },
    {
      "name": "Perry R. Cook",
      "institution": "Princeton University, Princeton, NJ, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100111473",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Ageless Project. http://jenett.org/ageless/. 2009.",
      "doi": ""
    },
    {
      "text": "Amazon Mechanical Turk. https://www.mturk.com. 2009.",
      "doi": ""
    },
    {
      "text": "BBC Sound Effects Library. http://www.sound--ideas.com/bbc.html. 2009.",
      "doi": ""
    },
    {
      "text": "Begault, D., Wenzel, E., Shrum, R., and Miller, Joel. A Virtual Audio Guidance and Alert System for Commercial Aircraft Operations. ICAD'96, 1996.",
      "doi": ""
    },
    {
      "text": "Blattner, M., Sumikawa, D., and Greenberg, R. Earcons and Icons: Their Structure and Common Design Principles. Human--Computer Interaction. 4(1), pp. 11--44. 1989.  ",
      "doi": "10.1207/s15327051hci0401_1"
    },
    {
      "text": "Brewster, S. Using nonspeech sounds to provide navigation cues. ACM Transaction on Computer-Human Interactions. 5(3), pp. 224--259. 1998.  ",
      "doi": "10.1145/292834.292839"
    },
    {
      "text": "Clarke, S., Bellmann, A., De Ribaupierre, F., and Assal, G. Non-verbal auditory recognition in normal subjects and brain-damaged patients: Evidence for parallel processing. Neuropsychologia. 34 (6), 587--603. 1996.",
      "doi": ""
    },
    {
      "text": "Dick, F., Bussiere, J., and Saygm, A. The Effects of Linguistic Mediation on the Identification of Environmental Sounds. Newsletter of the Center for Research in Language. 14 (3). University of California, San Diego. 2002.",
      "doi": ""
    },
    {
      "text": "Fellbaum, C. WordNet: Electronic Lexical Database, A semantic network of English verbs. 1998.",
      "doi": ""
    },
    {
      "text": "FindSounds. http://www.findsounds.com/. 2008.",
      "doi": ""
    },
    {
      "text": "Freesound Project. http://www.freesound.org/. 2008.",
      "doi": ""
    },
    {
      "text": "Lingraphica. http://www.lingraphicare.com/. 2009.",
      "doi": ""
    },
    {
      "text": "Garzonis, S., Jones, S., Jay, T., and O'Neill, E. Auditory Icon and Earcon Mobile Service Notifications: Intuitiveness, Learnability, Memorability and Preferences. In Proc. CHI'09. pp. 1513--1522. 2009.  ",
      "doi": "10.1145/1518701.1518932"
    },
    {
      "text": "Gaver, W. The SonicFinder: An Interface That Uses Auditory Icons. Human-Computer Interaction. 4, pp. 67--94. 1989.  ",
      "doi": "10.1207/s15327051hci0401_3"
    },
    {
      "text": "Gaver, W., Smith, R., and O'Shea, T. Effective Sounds in Complex Systems: The ARKola Simulation. In Proc. CHI'91. pp. 85--90. 1991.  ",
      "doi": "10.1145/108844.108857"
    },
    {
      "text": "Ma, X., Boy-Graber, J., Nikolova, S., and Cook, P. Speaking Through Pictures: Images vs. Icons. In Proc. ASSETS09. 2009.  ",
      "doi": "10.1145/1639642.1639672"
    },
    {
      "text": "Ma, X. and Cook, P. How Well do Visual Verbs Work in Daily Communication for Young and Old Adults? In Proc. CHI 2009, 2009.  ",
      "doi": "10.1145/1518701.1518759"
    },
    {
      "text": "Mayer-Johnson. http://www.dynavoxtech.com/. 2009.",
      "doi": ""
    },
    {
      "text": "Mynatt, J. Designing with Auditory Icons: How Well do We Identify Auditory Cues? In Proc. CHI'94. pp 269--270. 1994.  ",
      "doi": "10.1145/259963.260483"
    },
    {
      "text": "Patterson, R, and Milroy, R. Auditory warnings on civil aircraft: The learning and retention of warnings. MRC Applied Psychology Unit. Cambridge, England. 1980.",
      "doi": ""
    },
    {
      "text": "Saygm, A., Dick, F., Wilson, S., Dronkers, N., and Bates, E. Neural Resources for Processing Language and Environmental Sounds: Evidence from Aphasia. Brain. 126(4), 928--945. 2003",
      "doi": ""
    },
    {
      "text": "Scavone, G., Lakatos, S., Cook, P., and Harbke, C. Perceptual Spaces for Sound Effects Obtained with an Interactive Similarity Rating Program. Intl. Symposium on Musical Acoustics, Perugia, Italy. 2001.",
      "doi": ""
    },
    {
      "text": "Steele R., Weinrich M., Wertz R., Kleczewska, M., and Carlson, G. Computer-based Visual Communication in Aphasia. Neuropsychologia. 27(4). pp. 409--426. 1989.",
      "doi": ""
    },
    {
      "text": "Takasaki, T. PictNet: Semantic Infrastructure for Pictogram Communication. In Proc. Global WordNet Conference 2006. pp. 279--284. 2006",
      "doi": ""
    },
    {
      "text": "Tzanetakis, G. and Cook, P. Musical Genre Classification of Audio Signals. In Proc. IEEE Transaction of Speech and Audio Processing. 10 (5), 293--302. IEEE Press, 2002.",
      "doi": ""
    },
    {
      "text": "UWA Psychology. MRC Psycholinguistic Database. http://www.psy.uwa.edu.au/mrcdatabase/uwa_mrc.htm. 2009.",
      "doi": ""
    },
    {
      "text": "Van Hell, J. and De Groot, A. Conceptual Representation in Bilingual Memory: Effects of Concreteness and Cognate Status in Word Association. Bilingualism, 1(3),193--211. 1998.",
      "doi": ""
    },
    {
      "text": "Visuri, P. J. Multi-variate alarm handling and display. In Proc. the International Meeting on Thermal Nuclear Reactor Safety. National Technical Information Service. 1983.",
      "doi": ""
    }
  ]
}