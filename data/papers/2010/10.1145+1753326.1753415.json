{
  "doi": "10.1145/1753326.1753415",
  "title": "Speech dasher: fast writing using speech and gaze",
  "published": "2010-04-10",
  "proctitle": "CHI '10: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "595-598",
  "year": 2010,
  "badges": [],
  "abstract": "Speech Dasher allows writing using a combination of speech and a zooming interface. Users first speak what they want to write and then they navigate through the space of recognition hypotheses to correct any errors. Speech Dasher's model combines information from a speech recognizer, from the user, and from a letter-based language model. This allows fast writing of anything predicted by the recognizer while also providing seamless fallback to letter-by-letter spelling for words not in the recognizer's predictions. In a formative user study, expert users wrote at 40 (corrected) words per minute. They did this despite a recognition word error rate of 22%. Furthermore, they did this using only speech and the direction of their gaze (obtained via an eye tracker).",
  "authors": [
    {
      "name": "Keith Vertanen",
      "institution": "University of Cambridge, Cambridge, United Kingdom",
      "img": "/do/10.1145/contrib-81413602297/rel-imgonly/keith_cs.png",
      "acmid": "81413602297",
      "orcid": "missing"
    },
    {
      "name": "David J.C. MacKay",
      "institution": "University of Cambridge, Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100237704",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "D. Huggins-Daines, M. Kumar, A. Chan, A. W. Black, M. Ravishankar, and A. I. Rudnicky. PocketSphinx: A free, real-time continuous speech recognition system for hand-held devices. In Proc. of ICASSP, 185--188, 2006.",
      "doi": ""
    },
    {
      "text": "C.-M. Karat, C. Halverson, D. Horn, and J. Karat. Patterns of entry and correction in large vocabulary continuous speech recognition systems. In Proc. of CHI, 568--575, 1999.  ",
      "doi": "10.1145/302979.303160"
    },
    {
      "text": "K. Larson and D. Mowatt. Speech error correction: The story of the alternates list. International Journal of Speech Technology, 183--194, 2003.",
      "doi": ""
    },
    {
      "text": "S. Oviatt. Taming recognition errors with a multimodal interface. Comm. of the ACM, 43(9):45--51, 2000.  ",
      "doi": "10.1145/330534.330538"
    },
    {
      "text": "B. Suhm, B. Myers, and A. Waibel. Multimodal error correction for speech user interfaces. ACM Transactions on Computer-Human Interaction, 8(1):60--98, 2001.  ",
      "doi": "10.1145/371127.371166"
    },
    {
      "text": "D. J. Ward, A. F. Blackwell, and D. J. C. MacKay. Dasher - a data entry interface using continuous gestures and language models. In Proc. of UIST, 129--137, 2000.  ",
      "doi": "10.1145/354401.354427"
    },
    {
      "text": "D. J. Ward and D. J. C. MacKay. Fast hands-free writing by gaze direction. Nature, 418(6900):838, 2002.",
      "doi": ""
    }
  ]
}