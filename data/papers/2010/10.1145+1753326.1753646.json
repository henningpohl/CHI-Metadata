{
  "doi": "10.1145/1753326.1753646",
  "title": "Gazemarks: gaze-based visual placeholders to ease attention switching",
  "published": "2010-04-10",
  "proctitle": "CHI '10: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "2093-2102",
  "year": 2010,
  "badges": [],
  "abstract": "Many tasks require attention switching. For example, searching for information on one sheet of paper and then entering this information onto another one. With paper we see that people use fingers or objects as placeholders. Using these simple aids, the process of switching attention between displays can be simplified and speeded up. With large or multiple visual displays we have many tasks where both attention areas are on the screen and where using a finger as a placeholder is not suitable. One way users deal with this is to use the mouse and highlight their current focus. However, this also has its limitations -- in particular in environments where there is no pointing device. Our approach is to utilize the user's gaze position to provide a visual placeholder. The last area where a user fixated on the screen (before moving their attention away) is highlighted; we call this visual reminder a Gazemark. Gazemarks ease orientation and the resumption of the interrupted task when coming back to this display. In this paper we report on a study where the effectiveness of using Gazemarks was investigated, in particular we show how they can ease attention switching. Our results show faster completion times for a resumed simple visual search task when using this technique. The paper analyzes relevant parameters for the implementation of Gazemarks and discusses some further application areas for this approach.",
  "authors": [
    {
      "name": "Dagmar Kern",
      "institution": "Pervasive Computing and User Interface Engineering Group, University of Duisburg-Essen, Essen, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81328488995",
      "orcid": "missing"
    },
    {
      "name": "Paul Marshall",
      "institution": "Pervasive Interaction Lab, Open University, Milton Keynes, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100280485",
      "orcid": "0000-0003-2950-8310"
    },
    {
      "name": "Albrecht Schmidt",
      "institution": "Pervasive Computing and User Interface Engineering Group, University of Duisburg-Essen, Essen, Germany",
      "img": "/do/10.1145/contrib-81100588072/rel-imgonly/albrecht.jpg",
      "acmid": "81100588072",
      "orcid": "0000-0003-3890-1990"
    }
  ],
  "references": [
    {
      "text": "Alliance of Automobile Manufacturers: Statement of Principles, Criteria and Verification Procedures on Driver Interaction with Advanced In-Vehicle Information and Communication Systems, 2003.",
      "doi": ""
    },
    {
      "text": "Anderson, R.E. Social impacts of computing: Codes of professional ethics. Social Science Computing Review 10, 2 (1992), 453--469.",
      "doi": ""
    },
    {
      "text": "Ashdown, M., Oka, K., Sato, Y. Combining head tracking and mouse input for a gui on multiple monitors. Ext. Abstracts CHI 2005, ACM Press (2005), pp 1188--1191.  ",
      "doi": "10.1145/1056808.1056873"
    },
    {
      "text": "Ashmore, M., Duchowski, A.T., and Shoemaker, G. Efficient Eye Pointing with a FishEye Lens. Proc Graphics Interface 2005, pp. 203--10. ",
      "doi": "10.5555/1089508.1089542"
    },
    {
      "text": "Ballard, D., Hayhoe, M., Pook, P., Rao, R. Deictic codes for the embodiment of cognition. Behavioral and Brain Sciences, 20, 723--767, (1997).",
      "doi": ""
    },
    {
      "text": "Benko, H., Feiner, F. Multi--Monitor Mouse. Ext. Abstracts CHI 2005. ACM Press (2005), pp 1208--1211.  ",
      "doi": "10.1145/1056808.1056878"
    },
    {
      "text": "Bolt, R.A. Gaze-orchestrated dynamic windows. SIGGRAPH '81, ACM Press (1981), 109--119.  ",
      "doi": "10.1145/800224.806796"
    },
    {
      "text": "Commission of the European Communities: Commission Recommendation of 22 December 2006 on safe and efficient in-vehicle information and communication systems: Update of the European Statement of Principles on human machine interface, 2006.",
      "doi": ""
    },
    {
      "text": "Czerwinski, M., Smith, G., Regan, T., Meyers, B., Robertson, G., Starkweather, G. Toward characterizing the productivity benefits of very large displays. Proc. Interact 2003, IOS Press (2003), 9--16.",
      "doi": ""
    },
    {
      "text": "Dickie, C., Hart, J., Vertegaal, R., Eiser, A. LookPoint: an evaulation of eye input for hands-free switching of input devices between multiple computers. Proc. OZCHI 2006, pp 119--126.  ",
      "doi": "10.1145/1228175.1228198"
    },
    {
      "text": "Dix A, Ramduny-Ellis D, Wilkinson J. Trigger analysis-understanding broken tasks. In: Diaper D, Stanton N (eds) The handbook of task analysis for human-computer interaction. Lawrence Erlbaum Associates, London (2002).",
      "doi": ""
    },
    {
      "text": "Drewes, H., Schmidt A,. Interacting with the Computer Using Gaze Gestures. Proc. INTERACT 2007, pp 475--488. ",
      "doi": "10.5555/1778331.1778385"
    },
    {
      "text": "Drewes, H., De Luca, A., Schmidt, A. Eye-Gaze Interaction for Mobile Phones. Proc. Mobility 2007.  ",
      "doi": "10.1145/1378063.1378122"
    },
    {
      "text": "Duchowski, A.T. Eye Tracking Methodology: Theory and Practice. Springer-Verlag New York (2003), ISBN:1852336668. ",
      "doi": "10.5555/640601"
    },
    {
      "text": "Eriksson, M. Papanikotopoulos, N.P. (1997). Eye-tracking for detection of driver fatigue. Proc. Seventheenth Annual Conference of the Cognitive Science Society 1995, pp. 212--217.",
      "doi": ""
    },
    {
      "text": "Fono, D., Vertegaal, R. EyeWindows: Evaluation of Eye-Controlled Zooming Windows for Focus Selection. Proc. CHI 2005, ACM Press (2005), pp 151--160.  ",
      "doi": "10.1145/1054972.1054994"
    },
    {
      "text": "Gonzalez, V.M. and G. Mark, Constant, constant, multi-tasking craziness: managing multiple working spheres. Proc. CHI 2004, ACM Press (2004), pp 113--120.  ",
      "doi": "10.1145/985692.985707"
    },
    {
      "text": "Grudin, J. Partitioning Digital Worlds: Focal and Peripheral Awareness in Multiple Monitor Use. In Proc. CHI 2002, ACM Press (2002), 458--465.  ",
      "doi": "10.1145/365024.365312"
    },
    {
      "text": "Holleis, P., Schmidt, A. MAKEIT: Integrate User Interaction Times in the Design Process of Mobile Applications. Proc. of the Sixth International Conference on Pervasive Computing, Pervasive'08. Springer LNCS Sydney, Australia (2008), S. 56--74.  ",
      "doi": "10.1007/978-3-540-79576-6_4"
    },
    {
      "text": "Horrey, W.J., Wickens, C.D. Driving and side task performance: The effects of display clutter, separation, and modality. Human Factors, 46(4), 611--624, (2004).",
      "doi": ""
    },
    {
      "text": "Hutchings, D., Czerwinski, M., Smith, G., Meyers, B., Robertson, G. Display space usage and window management operation comparisons between single monitor and multiple monitor users. Proc. AVI 2004, ACM Press (2004), pp 32--39.  ",
      "doi": "10.1145/989863.989867"
    },
    {
      "text": "Hyrskykari, A., Majaranta, P., Aaltonen, A., R\u00e4ih\u00e4, K. Design issues of iDict: A gaze-assisted translation aid. Proc of the Eye Tracking Research and Applications Symposium 2000, ACM Press (2000), pp. 9--14.  ",
      "doi": "10.1145/355017.355019"
    },
    {
      "text": "Iqbal, S.T., Horvitz, E. Disruption and recovery of computing tasks: Field study, analysis, and directions, Proc. CHI 2007, ACM Press (2007), pp 677--686.  ",
      "doi": "10.1145/1240624.1240730"
    },
    {
      "text": "Jacob, R.J.K., Karn, K.S. Eye tracking in human-computer interaction and usability research: Ready to deliver the promises (Section commentary). In J. Hyona, R. Radach, & H. Deubel (Eds.), The Mind's Eyes: Cognitive and Applied Aspects of Eye Movements. Oxford: Elsevier Science (2003).",
      "doi": "10.5555/772072.772084"
    },
    {
      "text": "Jacob, R.J. What you look at is what you get: eye movement-based interaction techniques. Proc. CHI '90, ACM Press (1990), 11--18.  ",
      "doi": "10.1145/97243.97246"
    },
    {
      "text": "Kang, Y., Stasko, J. Lightweight task/application performance using single versus multiple monitors: a comparative study. In Proc. GI 2008, pp 17--24. ",
      "doi": "10.5555/1375714.1375718"
    },
    {
      "text": "Kirsh, D. A Few Thoughts on Cognitive Overload, Intellectica, 2000 pp 19--51.",
      "doi": ""
    },
    {
      "text": "Kirsh, D. The Context of Work, Human computer Interaction, 2001 Vol 16(2-4), pp. 305--322.  ",
      "doi": "10.1207/S15327051HCI16234_12"
    },
    {
      "text": "Kumar, M., Paepcke, A., Winograd, T. EyePoint: Practical Pointing and Selection Using Gaze and Keyboard. Proc CHI 2007, ACM Press (2007), pp 421--430.  ",
      "doi": "10.1145/1240624.1240692"
    },
    {
      "text": "Lankford, C. Effective Eye-Gaze Input into Windows. Proc. ETRA 2000: Eye Tracking Research & Applications Symposium. ACM Press (2000). pp. 23--27.  ",
      "doi": "10.1145/355017.355021"
    },
    {
      "text": "Laqua, S., Bandara, S.U., Sasse, M.A.. GazeSpace: Eye Gaze Controlled Content Spaces. Proc BCS HCI Group Conference. (2007). ",
      "doi": "10.5555/1531407.1531422"
    },
    {
      "text": "Lidwell, W., Holden, K., Butler, J.: Universal Principles of Design. Rockport (2005).",
      "doi": ""
    },
    {
      "text": "Lin, C.-S., Huan, C.-C., Chan, C.-N., Yeh, M.-S., Chiu C.-C. The design of a computer game using an eye tracking device for eye's activity rehabilitation, Optics and Lasers in Engineering 42(1), 2004, pp. 91--108.",
      "doi": ""
    },
    {
      "text": "Mark, G., Gonzalez, V., Harris, J. (2005). No Task Left Behind? Examining the Nature of Fragmented Ext. Abstracts CHI 2005, ACM Press (2005), pp. 321--330.  ",
      "doi": "10.1145/1054972.1055017"
    },
    {
      "text": "Monk, C.A., Boehm-Davis, D.A., Trafton, J.G.. The attentional costs of interrupting task performance at various stages. Proc. Human factors and Ergonomics Society 46th annual meeting 2002.",
      "doi": ""
    },
    {
      "text": "Moses RA. in Adler's Physiology of the eye clinical application, Robert A. Moses., Ed. (Mosby, 1981), chap. 1, pp. 1--15.",
      "doi": ""
    },
    {
      "text": "Robertson, G.G., Czerwinski, M., Baudisch, P., Meyers, B., Robbins, D., Smith, G., Tan, D. Large Display user experience. In IEEE CG&A special issue on large displays, 25(4), pp. 44--51, (2005).  ",
      "doi": "10.1109/MCG.2005.88"
    },
    {
      "text": "Salvucci, D.D. Intelligent Gaze-Added Interfaces. Proc CHI 2000, ACM Press (2000). pp. 273--80.  ",
      "doi": "10.1145/332040.332444"
    },
    {
      "text": "Scaife, M., Rogers, Y. External cognition: how do graphical representations work? International Journal of Human-Computer Studies, 45, 185--213, (1996).  ",
      "doi": "10.1006/ijhc.1996.0048"
    },
    {
      "text": "Smith, J.D., Graham, T.C. Use of eye movements for video game control. Proc. ACE 2006.  ",
      "doi": "10.1145/1178823.1178847"
    },
    {
      "text": "Yamato, M., Monden, A., Matsumoto, K.-c., Inoue, K., Torii, K. Quick Button Selection with Eye Gazing for General GUI Environment. Proc. of International Conference on Software: Theory and Practice (ICS2000), pp.712--719.",
      "doi": ""
    },
    {
      "text": "Zhai, S., Morimoto, C., Ihde, S. Manual and Gaze Input Cascaded (MAGIC) Pointing. Proc. CHI 1999, ACM Press (1999), pp. 246--53, 1999.  ",
      "doi": "10.1145/302979.303053"
    }
  ]
}