{
  "doi": "10.1145/332040.332449",
  "title": "Speak out and annoy someone: experience with intelligent kiosks",
  "published": "2000-04-01",
  "proctitle": "CHI '00: Proceedings of the SIGCHI conference on Human Factors in Computing Systems",
  "pages": "313-320",
  "year": 2000,
  "badges": [],
  "abstract": "An intelligent kiosk is a public information kiosk that senses the presence of humans and communicates in a natural way. To examine issues of human-kiosk interaction, we have built and deployed two versions of intelligent kiosks. The first kiosk design combines machine vision to locate and track people in the vicinity with an animated talking head that focuses on clients and talks to them. The second kiosk design uses infrared and sonar sensors to sense clients and multiple interacting agents to communicate with the client.\nThe foremost lessons learned from public trials include (1) people are attracted to an animated face that watches them, (2) small mobile agents interact better with kiosk content than a single fixed face, (3) speaker-independent speech recognition is only useful in targeted applications, and (4) the quality of the content on the kiosk strongly influences the client's evaluation of the quality of the technology.",
  "tags": [
    "user interface design",
    "information display",
    "speech recognition",
    "machine vision",
    "talking avatar",
    "public kiosk"
  ],
  "authors": [
    {
      "name": "Andrew D. Christian",
      "institution": "Cambridge Research Laboratory, Compaq Computer Corporation, One Kendall Square, Building 700, Cambridge, MA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81542965256",
      "orcid": "missing"
    },
    {
      "name": "Brian L. Avery",
      "institution": "Cambridge Research Laboratory, Compaq Computer Corporation, One Kendall Square, Building 700, Cambridge, MA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100366117",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Christian, A. and Avery, B., Digital Smart Kiosk Project. ACM Proceedings of the SIGCHI Conference, Los Angeles, California, April, 1998.155-162.  ",
      "doi": "10.1145/274644.274668"
    },
    {
      "text": "Developing for Microsoft Agent, Microsoft Press, 1997.",
      "doi": ""
    },
    {
      "text": "Frey, R. L. and Hoyle, E., According to Hoyle: Official Rules of More Than 200 Popular Games of Skill and Chance, Ballantine Books, 1996.",
      "doi": ""
    },
    {
      "text": "Goldenthal, W., Waters, K., Van Thong, J.M., and Glickman, O. Driving Synthetic Mouth Gestures: Phonetic Recognition for FaceMe!, EuroSpeech, 1997.",
      "doi": ""
    },
    {
      "text": "Lee, Y. Terzopoulos, D., and Waters, K. Realistic modeling for facial animation. Computer Graphics (SIGGRAPH'95), 1995, 55-62.  ",
      "doi": "10.1145/218380.218407"
    },
    {
      "text": "Parke, F., and Waters, K. Computer Facial Animation. A. K. Peters, Ltd., 1996. ",
      "doi": ""
    },
    {
      "text": "Waters, K. and Levergood, T. An automatic lipsynchronization algorithm for synthetic faces. ACM Proceedings of the Multimedia Conference, San Francisco, California, September, 1994. 149-156.  ",
      "doi": ""
    }
  ]
}