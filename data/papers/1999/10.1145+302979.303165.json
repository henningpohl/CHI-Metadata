{
  "doi": "10.1145/302979.303165",
  "title": "Model-based and empirical evaluation of multimodal interactive error correction",
  "published": "1999-05-01",
  "proctitle": "CHI '99: Proceedings of the SIGCHI conference on Human Factors in Computing Systems",
  "pages": "584-591",
  "year": 1999,
  "badges": [],
  "abstract": "Our research addresses the problem of error correction in speech\nuser interfaces. Previous work hypothesized that switching modality\ncould speed up interactive correction of recognition errors\n(so-called multimodal error correction). We present a user study\nthat compares, on a dictation task, multimodal error correction\nwith conventional interactive correction, such as speaking again,\nchoosing Tom a list, and keyboard input. Results show that\nmultimodal correction is faster than conventional correction\nwithout keyboard input, but slower than correction by typing for\nusers with good typing skills. Furthermore, while users initially\nprefer speech, they learn to avoid ineffective correction\nmodalities with experience. To extrapolate results from this user\nstudy we developed a performance model of multimodal interaction\nthat predicts input speed including time needed for error\ncorrection. We apply the model to estimate the impact of\nrecognition technology improvements on correction speeds and the\ninfluence of recognition accuracy and correction method on the\nproductivity of dictation systems. Our model is a first step\ntowards formalizing multimodal (recognition-based) interaction.",
  "tags": [
    "interactive error correction",
    "quantitive performance model",
    "speech and pen input",
    "multimodal interaction",
    "speech user interfaces"
  ],
  "authors": [
    {
      "name": "Bernhard Suhm",
      "institution": "Interactive Systems Laboratories, Carnegie Mellon University/Universit\u00e4t Karlsruhe",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100059950",
      "orcid": "missing"
    },
    {
      "name": "Brad Myers",
      "institution": "Human Computer Interaction Institute, Carnegie Mellon University",
      "img": "/do/10.1145/contrib-81100013136/rel-imgonly/brad-myers-120x120.jpg",
      "acmid": "81100013136",
      "orcid": "0000-0002-4769-0219"
    },
    {
      "name": "Alex Waibel",
      "institution": "Interactive Systems Laboratories, Carnegie Mellon University/Universit\u00e4t Karlsruhe",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100599954",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Alto, P., et al. \"Experimenting Natual-Language Dictation with a 20000-Word Speech Recognizer,\" in VLSI and Computer Peripherals. 1989. IEEE Computer Society Press. 2: pp. 78-81.]]",
      "doi": ""
    },
    {
      "text": "Baber, C., Stammers, R.B., and Usher, D.M., \"Error correction requirements in automatic speech recognition,\" in Contemporary Ergonomics, E.J. Levesey, Editor 1990, Taylor and Francis. London.]]",
      "doi": ""
    },
    {
      "text": "Gibbon, D., Moore, R., and Winski, R., eds. Handbook of Standards and Resources for Spoken Language Systems. 1997, Mouton de Gruyter: Berlin, New York.]] ",
      "doi": "10.5555/550161"
    },
    {
      "text": "Gould, J.D., \"How Experts Dictate.\" Journal of Experimental Psychology: Human Perception and Performance, 1978. 4(4): pp. 648-661.]]",
      "doi": ""
    },
    {
      "text": "Gould, J.D., Conti, J., and Hovanyecz, T., \"Composing Letters with a Simulated Listening Typewriter.\" Communications of the ACM, 1983.26(4): pp. 295-308.]]  ",
      "doi": "10.1145/2163.358100"
    },
    {
      "text": "Hild, H., Buchstabiererkennung mit neuronalen Netzen in Auskunfissystemen. Fakult~it fiir Informatik Fredericiana, 1997, Karlsruhe. 216 pages.]]",
      "doi": ""
    },
    {
      "text": "Kieras, D.E., Wood, S., D., and Meyer, D.E., \"Predictive Engineering Models Based on the EPIC Architecture for a Multimodal High-Performance Human-Computer Interaction Task.\" ACM Transactions on Computer-Human interaction, 1997.4(3): pp. 230-275.]]  ",
      "doi": "10.1145/264645.264658"
    },
    {
      "text": "Lai, J. and Vergo, J. \"MedSpeak: Report Creation with Continuous Speech Recognition,\" in International Conference on Computer-Human Interaction CItI. 1997. Atlanta (USA). i: pp. 431-438.]]  ",
      "doi": "10.1145/258549.258829"
    },
    {
      "text": "Manke, S., Finke, M., and Waibel, A. \"NPen++: A Writer Independent, Large Vocabulary On-Line Cursive Handwriting Recognition System,\" in International Conference on Document Analysis and Recognition. 1995. Montreal.]] ",
      "doi": "10.5555/844379.844686"
    },
    {
      "text": "McNair, A.E. and Waibel, A. \"Improving Recognizer Acceptance through Robust, Natural Speech Repair,\" in International Conference on Spoken Language Processing. 1994. Yokohama (Japan). 3: pp. 1299-1302.]]",
      "doi": ""
    },
    {
      "text": "Mellor, B. and Baber, C. \"Modelling of Speech-based User Interfaces,\" in European Conference on Speech Communication and Technology. 1997. Rhodes (Greece): ESCA. 4: pp. 2263- 2266.]]",
      "doi": ""
    },
    {
      "text": "Oviatt, S. and VanGent, R. \"Error Resolution During Multimodal Human-Computer Interaction,\" in International Conference on Spoken Language Processing. 1996. Philadelphia (PA). 2: pp. 204-207.]]",
      "doi": ""
    },
    {
      "text": "Rhyne, J.R. and Wolf, C.G., \"Recognition-Based User Interfaces,\" in Advances in Human-Computer Interaction, H.R. Hartson and D. Hix, Editors. 1993, Ablex Publishing. Norwood (NJ). pp. 191-212.]]",
      "doi": ""
    },
    {
      "text": "Rogina, I. and Waibel, A. \"The JANUS Speech Recognizer,\" in ARPA Workshop on Spoken Language Technology. 1995. Austin (TX). Morgan Kaufmann. pp. 166- 169.]]",
      "doi": ""
    },
    {
      "text": "Rubine, D., \"Specifying Gestures by Example.\" ACM Journal on Computer Graphics, 1991.25(4): pp. 329-337.]]  ",
      "doi": "10.1145/127719.122753"
    },
    {
      "text": "Soltau, H., 1998. Personal Communication.]]",
      "doi": ""
    },
    {
      "text": "Suhm, B., Multimodal Interactive Error Recovery for Non- Conversational Speech User Interfaces. PhD, Computer Science Department, Fredericiana University, 1998, Karlsruhe.]]",
      "doi": ""
    }
  ]
}