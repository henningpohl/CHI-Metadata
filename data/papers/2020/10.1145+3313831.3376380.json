{
  "doi": "10.1145/3313831.3376380",
  "title": "Decipher: An Interactive Visualization Tool for Interpreting Unstructured Design Feedback from Multiple Providers",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2020,
  "badges": [],
  "abstract": "Feedback from diverse audiences can vary in focus, differ in structure, and contradict each other, making it hard to interpret and act on. While prior work has explored generating quality feedback, our work helps a designer interpret that feedback. Through a formative study with professional designers (N=10), we discovered that the interpretation process includes categorizing feedback, identifying valuable feedback, and prioritizing which feedback to incorporate in a revision. We also found that designers leverage feedback topic and sentiment, and the status of the provider to aid interpretation. Based on the findings, we created a new tool (Decipher) that enables designers to visualize and navigate a collection of feedback using its topic and sentiment structure. In a preliminary evaluation (N=20), we found that Decipher helped users feel less overwhelmed during feedback interpretation tasks and better attend to critical issues and conflicting opinions compared to using a typical document-editing tool.",
  "tags": [
    "creativity",
    "feedback",
    "sense-making",
    "creativity support tools"
  ],
  "authors": [
    {
      "name": "Yu-Chun Grace Yen",
      "institution": "University of Illinois at Urbana-Champaign, Urbana, IL, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659036609",
      "orcid": "missing"
    },
    {
      "name": "Joy O. Kim",
      "institution": "Adobe Research, San Francisco, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659440389",
      "orcid": "missing"
    },
    {
      "name": "Brian P. Bailey",
      "institution": "University of Illinois at Urbana-Champaign, Urbana, IL, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100615948",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "2019. Amazon. (2019). https://amazon.com.",
      "doi": ""
    },
    {
      "text": "2019. Upwork. (2019). https://www.upwork.com/.",
      "doi": ""
    },
    {
      "text": "Paul Andr\u00e9, Aniket Kittur, and Steven P. Dow. 2014. Crowd Synthesis: Extracting Categories and Clusters from Complex Data. In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing (CSCW '14). ACM, NY, NY, USA, 989--998. DOI: http://dx.doi.org/10.1145/2531602.2531653",
      "doi": ""
    },
    {
      "text": "Frederik Anseel, Filip Lievens, and Eveline Schollaert. 2009. Reflection as a strategy to enhance task performance after feedback. Organizational Behavior and Human Decision Processes 110, 1 (2009), 23--35.",
      "doi": ""
    },
    {
      "text": "David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. Journal of machine Learning research 3, Jan (2003), 993--1022.",
      "doi": "10.5555/944919.944937"
    },
    {
      "text": "Kirsten R Butcher and Tamara Sumner. 2011. Self-directed learning and the sensemaking paradox. Human--Computer Interaction 26, 1--2 (2011), 123--159.",
      "doi": ""
    },
    {
      "text": "Stuart K. Card, Jock D. Mackinlay, and Ben Shneiderman (Eds.). 1999. Readings in Information Visualization: Using Vision to Think. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.",
      "doi": "10.5555/300679"
    },
    {
      "text": "Lydia B. Chilton, Greg Little, Darren Edge, Daniel S. Weld, and James A. Landay. 2013. Cascade: Crowdsourcing Taxonomy Creation. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, NY, NY, USA, 1999--2008. DOI: http://dx.doi.org/10.1145/2470654.2466265",
      "doi": ""
    },
    {
      "text": "Amy Cook, Jessica Hammer, Salma Elsayed-Ali, and Steven Dow. 2019. How Guiding Questions Facilitate Feedback Exchange in Project-Based Learning. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19). ACM, NY, NY, USA, Article 138, 12 pages. DOI: http://dx.doi.org/10.1145/3290605.3300368",
      "doi": "10.1145/3290605.3300368"
    },
    {
      "text": "Patrick A. Crain and Brian P. Bailey. 2017. Share Once or Share Often?: Exploring How Designers Approach Iteration in a Large Online Community. In Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition (C&C '17). ACM, NY, NY, USA, 80--92. DOI: http://dx.doi.org/10.1145/3059454.3059476",
      "doi": ""
    },
    {
      "text": "Stanford d.school. 2019. Design method: I like, I wish, what if. (2019). https://dschool-old.stanford.edu/wp-content/themes/dschool/method-cards/i-like-i-wish-what-if.pdf.",
      "doi": ""
    },
    {
      "text": "K Anders Ericsson, Ralf T Krampe, and Clemens Tesch-R\u00f6mer. 1993. The role of deliberate practice in the acquisition of expert performance. Psychological review 100, 3 (1993), 363--406.",
      "doi": ""
    },
    {
      "text": "Siamak Faridani, Ephrat Bitton, Kimiko Ryokai, and Ken Goldberg. 2010. Opinion space: a scalable tool for browsing online comments. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1175--1184.",
      "doi": "10.1145/1753326.1753502"
    },
    {
      "text": "Eureka Foong, Steven P. Dow, Brian P. Bailey, and Elizabeth M. Gerber. 2017a. Online Feedback Exchange: A Framework for Understanding the Socio-Psychological Factors. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). Association for Computing Machinery, New York, NY, USA, 4454--4467. DOI: http://dx.doi.org/10.1145/3025453.3025791",
      "doi": ""
    },
    {
      "text": "Eureka Foong, Darren Gergle, and Elizabeth M. Gerber. 2017b. Novice and Expert Sensemaking of Crowdsourced Design Feedback. Proc. ACM Hum.-Comput. Interact. 1, CSCW, Article 45 (Dec. 2017), 18 pages. DOI: http://dx.doi.org/10.1145/3134680",
      "doi": ""
    },
    {
      "text": "C. Ailie Fraser, Tricia J. Ngoon, Ariel S. Weingarten, Mira Dontcheva, and Scott Klemmer. 2017. CritiqueKit: A Mixed-Initiative, Real-Time Interface For Improving Feedback. In Adjunct Publication of the 30th Annual ACM Symposium on User Interface Software and Technology (UIST '17). ACM, NY, NY, USA, 7--9. DOI: http://dx.doi.org/10.1145/3131785.3131791",
      "doi": ""
    },
    {
      "text": "Michael D. Greenberg, Matthew W. Easterday, and Elizabeth M. Gerber. 2015. Critiki: A Scaffolded Approach to Gathering Design Feedback from Paid Crowdworkers. In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition (C&C '15). ACM, NY, NY, USA, 235--244. DOI: http://dx.doi.org/10.1145/2757226.2757249",
      "doi": ""
    },
    {
      "text": "Nathan Hahn, Joseph Chang, Ji Eun Kim, and Aniket Kittur. 2016. The Knowledge Accelerator: Big Picture Thinking in Small Pieces. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, NY, NY, USA, 2258--2270. DOI: http://dx.doi.org/10.1145/2858036.2858364",
      "doi": "10.1145/2858036.2858364"
    },
    {
      "text": "John Hattie and Helen Timperley. 2007. The power of feedback. Review of educational research 77, 1 (2007), 81--112.",
      "doi": ""
    },
    {
      "text": "Amy J. Henley and Florence D. DiGennaro Reed. 2015. Should you order the feedback sandwich? Efficacy of feedback sequence and timing. Journal of Organizational Behavior Management 35, 3--4 (2015), 321--335. DOI: http://dx.doi.org/10.1080/01608061.2015.1093057",
      "doi": ""
    },
    {
      "text": "Pamela J Hinds. 1999. The curse of expertise: The effects of expertise and debiasing methods on prediction of novice performance. Journal of Experimental Psychology: Applied 5, 2 (1999), 205--221.",
      "doi": ""
    },
    {
      "text": "Jeff Huang, Oren Etzioni, Luke Zettlemoyer, Kevin Clark, and Christian Lee. 2012. RevMiner: An Extractive Interface for Navigating Reviews on a Smartphone. In Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology (UIST '12). Association for Computing Machinery, New York, NY, USA, 3--12. DOI: http://dx.doi.org/10.1145/2380116.2380120",
      "doi": "10.1145/2380116.2380120"
    },
    {
      "text": "Maria Jackson and Leah Marks. 2016. Improving the effectiveness of feedback by use of assessed reflections and withholding of grades. Assessment & Evaluation in Higher Education 41, 4 (2016), 532--547.",
      "doi": ""
    },
    {
      "text": "Anders Jonsson. 2013. Facilitating productive use of feedback in higher education. Active learning in higher education 14, 1 (2013), 63--76.",
      "doi": ""
    },
    {
      "text": "Hyeonsu B. Kang, Gabriel Amoako, Neil Sengupta, and Steven P. Dow. 2018. Paragon: An Online Gallery for Enhancing Design Feedback with Visual Examples. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, NY, NY, USA, Article 606, 13 pages. DOI: http://dx.doi.org/10.1145/3173574.3174180",
      "doi": ""
    },
    {
      "text": "Kenneth A Kiewra. 1985. Students' note-taking behaviors and the efficacy of providing the instructor's notes for review. Contemporary educational psychology 10, 4 (1985), 378--386.",
      "doi": ""
    },
    {
      "text": "Kenneth A Kiewra, Nelson F DuBois, David Christian, Anne McShane, Michelle Meyerhoffer, and David Roskelley. 1991. Note-taking functions and techniques. Journal of educational psychology 83, 2 (1991), 240--245.",
      "doi": ""
    },
    {
      "text": "Robert E Kraut and Paul Resnick. 2012. Building successful online communities: Evidence-based social design. Mit Press.",
      "doi": "10.5555/2207798"
    },
    {
      "text": "Chinmay Kulkarni, Koh Pang Wei, Huy Le, Daniel Chia, Kathryn Papadopoulos, Justin Cheng, Daphne Koller, and Scott R. Klemmer. 2013. Peer and Self Assessment in Massive Online Classes. ACM Trans. Comput.-Hum. Interact. 20, 6, Article 33 (Dec. 2013), 31 pages. DOI: http://dx.doi.org/10.1145/2505057",
      "doi": "10.1145/2505057"
    },
    {
      "text": "Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion Observer: Analyzing and Comparing Opinions on the Web. In Proceedings of the 14th International Conference on World Wide Web (WWW '05). ACM, NY, NY, USA, 342--351. DOI: http://dx.doi.org/10.1145/1060745.1060797",
      "doi": "10.1145/1060745.1060797"
    },
    {
      "text": "Michael Xieyang Liu, Jane Hsieh, Nathan Hahn, Angelina Zhou, Emily Deng, Shaun Burley, Cynthia Taylor, Aniket Kittur, and Brad A. Myers. 2019. Unakite: Scaffolding Developers' Decision-Making Using the Web. In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology (UIST '19). Association for Computing Machinery, New York, NY, USA, 67--80. DOI: http://dx.doi.org/10.1145/3332165.3347908",
      "doi": "10.1145/3332165.3347908"
    },
    {
      "text": "Weichen Liu, Sijia Xiao, Jacob T. Browne, Ming Yang, and Steven P. Dow. 2018. ConsensUs: Supporting Multi-Criteria Group Decisions by Visualizing Points of Disagreement. Trans. Soc. Comput. 1, 1, Article Article 4 (Jan. 2018), 26 pages. DOI: http://dx.doi.org/10.1145/3159649",
      "doi": "10.1145/3159649"
    },
    {
      "text": "Kurt Luther, Jari-Lee Tolentino, Wei Wu, Amy Pavel, Brian P. Bailey, Maneesh Agrawala, Bj\u00f6rn Hartmann, and Steven P. Dow. 2015. Structuring, Aggregating, and Evaluating Crowdsourced Design Critique. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing (CSCW '15). ACM, NY, NY, USA, 473--485. DOI: http://dx.doi.org/10.1145/2675133.2675283",
      "doi": ""
    },
    {
      "text": "Kerry Platman. 2004. 'Portfolio careers' and the search for flexibility in later life. Work, employment and society 18, 3 (2004), 573--599.",
      "doi": ""
    },
    {
      "text": "Daniel M Russell, Mark J Stefik, Peter Pirolli, and Stuart K Card. 1993. The cost structure of sensemaking. In Proceedings of the INTERACT'93 and CHI'93 conference on Human factors in computing systems. ACM, 269--276.",
      "doi": "10.1145/169059.169209"
    },
    {
      "text": "Donald A Sch\u00f6n. 2017. The reflective practitioner: How professionals think in action. Routledge.",
      "doi": ""
    },
    {
      "text": "David R Thomas. 2003. A general inductive approach for qualitative data analysis. (2003).",
      "doi": ""
    },
    {
      "text": "Karl E Weick, Kathleen M Sutcliffe, and David Obstfeld. 2005. Organizing and the process of sensemaking. Organization science 16, 4 (2005), 409--421.",
      "doi": "10.1287/orsc.1050.0133"
    },
    {
      "text": "Naomi E Winstone, Robert A Nash, James Rowntree, and Michael Parker. 2017. 'It'd be useful, but I wouldn't use it': barriers to university students' feedback seeking and recipience. Studies in Higher Education 42, 11 (2017), 2026--2041.",
      "doi": ""
    },
    {
      "text": "Y. Wayne Wu and Brian P. Bailey. 2018. Soften the Pain, Increase the Gain: Enhancing Users' Resilience to Negative Valence Feedback. Proc. ACM Hum.-Comput. Interact. 2, CSCW, Article Article 186 (Nov. 2018), 20 pages. DOI: http://dx.doi.org/10.1145/3274455",
      "doi": ""
    },
    {
      "text": "Anbang Xu, Shih-Wen Huang, and Brian Bailey. 2014. Voyant: Generating Structured Feedback on Visual Designs Using a Crowd of Non-experts. In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing (CSCW '14). ACM, NY, NY, USA, 1433--1444. DOI: http://dx.doi.org/10.1145/2531602.2531604",
      "doi": "10.1145/2531602.2531604"
    },
    {
      "text": "Koji Yatani, Michael Novati, Andrew Trusty, and Khai N. Truong. 2011. Review Spotlight: A User Interface for Summarizing User-Generated Reviews Using Adjective-Noun Word Pairs. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11). Association for Computing Machinery, New York, NY, USA, 1541--1550. DOI: http://dx.doi.org/10.1145/1978942.1979167",
      "doi": ""
    },
    {
      "text": "Yu-Chun (Grace) Yen, Steven P. Dow, Elizabeth Gerber, and Brian P. Bailey. 2016. Social Network, Web Forum, or Task Market?: Comparing Different Crowd Genres for Design Feedback Exchange. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems (DIS '16). ACM, NY, NY, USA, 773--784. DOI: http://dx.doi.org/10.1145/2901790.2901820",
      "doi": ""
    },
    {
      "text": "Yu-Chun Grace Yen, Steven P. Dow, Elizabeth Gerber, and Brian P. Bailey. 2017. Listen to Others, Listen to Yourself: Combining Feedback Review and Reflection to Improve Iterative Design. In Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition (C&C '17). ACM, NY, NY, USA, 158--170. DOI: http://dx.doi.org/10.1145/3059454.3059468",
      "doi": ""
    },
    {
      "text": "Alvin Yuan, Kurt Luther, Markus Krause, Sophie Isabel Vennix, Steven P Dow, and Bjorn Hartmann. 2016. Almost an Expert: The Effects of Rubrics and Expertise on Perceived Value of Crowdsourced Design Critiques. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing (CSCW '16). ACM, NY, NY, USA, 1005--1017. DOI: http://dx.doi.org/10.1145/2818048.2819953",
      "doi": "10.1145/2818048.2819953"
    }
  ]
}