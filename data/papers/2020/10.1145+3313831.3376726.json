{
  "doi": "10.1145/3313831.3376726",
  "title": "VoiceCoach: Interactive Evidence-based Training for Voice Modulation Skills in Public Speaking",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2020,
  "badges": [],
  "abstract": "The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews and the user study provide support for the effectiveness and usability of VoiceCoach.",
  "tags": [
    "public speaking",
    "evidence-based training",
    "voice modulation",
    "data visualization"
  ],
  "authors": [
    {
      "name": "Xingbo Wang",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659529278",
      "orcid": "missing"
    },
    {
      "name": "Haipeng Zeng",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659527757",
      "orcid": "missing"
    },
    {
      "name": "Yong Wang",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659193437",
      "orcid": "missing"
    },
    {
      "name": "Aoyu Wu",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659527249",
      "orcid": "0000-0001-9187-9265"
    },
    {
      "name": "Zhida Sun",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659090601",
      "orcid": "0000-0003-4689-986X"
    },
    {
      "name": "Xiaojuan Ma",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81484654594",
      "orcid": "0000-0002-9847-7784"
    },
    {
      "name": "Huamin Qu",
      "institution": "Hong Kong University of Science and Technology, Hong Kong, China",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100337801",
      "orcid": "0000-0002-3344-9694"
    }
  ],
  "references": [
    {
      "text": "Tony Bergstrom and Karrie Karahalios. 2007. Conversation Clock: Visualizing audio patterns in co-located groups. In Proceedings of the Hawaii International Conference on System Sciences. IEEE, 78--78.",
      "doi": "10.1109/HICSS.2007.151"
    },
    {
      "text": "Jordan L Boyd-Graber, Sonya S Nikolova, Karyn A Moffatt, Kenrick C Kin, Joshua Y Lee, Lester W Mackey, Marilyn M Tremaine, and Maria M Klawe. 2006. Participatory design with proxies: developing a desktop-PDA system to support people with aphasia. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 151--160.",
      "doi": "10.1145/1124772.1124797"
    },
    {
      "text": "Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, and others. 2018. Universal sentence encoder. arXiv preprint arXiv:1803.11175 (2018).",
      "doi": ""
    },
    {
      "text": "Ionut Damian, Chiew Seng Sean Tan, Tobias Baur, Johannes Sch\u00a8 oning, Kris Luyten, and Elisabeth Andr\u00b4 e. 2015. Augmenting social interactions: Realtime behavioural feedback using social signal processing techniques. In Proceedings of the International Conference on Human Factors in Computing Systems. ACM, 565--574.",
      "doi": "10.1145/2702123.2702314"
    },
    {
      "text": "Fiona Dermody and Alistair Sutherland. 2016. Multimodal system for public speaking with real time feedback: a positive computing perspective. In Proceedings of the International Conference on Multimodal Interaction. ACM, 408--409.",
      "doi": "10.1145/2993148.2998536"
    },
    {
      "text": "Joseph A DeVito. 2003. The essential elements of public speaking. Allyn and Bacon.",
      "doi": ""
    },
    {
      "text": "Jonathan Foote. 1999. Visualizing music and audio using self-similarity. In Proceedings of the International Conference on Multimedia. ACM, 77--80.",
      "doi": "10.1145/319463.319472"
    },
    {
      "text": "C. Gallo. 2014. Talk Like TED: The 9 Public Speaking Secrets of the World's Top Minds. Pan Macmillan. https://books.google.com.hk/books?id=K3v8AgAAQBAJ",
      "doi": ""
    },
    {
      "text": "Jiawei Han, Jian Pei, and Yiwen Yin. 2000. Mining frequent patterns without candidate generation. In Proceedings of the ACM SIGMOD International Conference on Management of Data, Vol. 29. ACM, 1--12.",
      "doi": "10.1145/342009.335372"
    },
    {
      "text": "Julia Bell Hirschberg and Andrew Rosenberg. 2005. Acoustic/prosodic and lexical correlates of charismatic speech. In Proceedings of European Conference on Speech Communication and Technology. Lisbon, 539--546.",
      "doi": ""
    },
    {
      "text": "Mohammed Ehsan Hoque, Matthieu Courgeon, Jean-Claude Martin, Bilge Mutlu, and Rosalind W Picard. 2013. Mach: My automated conversation coach. In Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 697--706.",
      "doi": "10.1145/2493432.2493502"
    },
    {
      "text": "Toastmasters International. 2011. Your speaking voice. https://www.toastmasters.org/Resources/Your-Speaking-Voice. (2011). Last accessed on 2019-09--20.",
      "doi": ""
    },
    {
      "text": "Dasaem Jeong and Juhan Nam. 2016. Visualizing music in its entirety using acoustic features: Music flowgram. In Proceedings of the International Conference on Technologies for Music Notation and Representation. Anglia Ruskin University, 25--32.",
      "doi": ""
    },
    {
      "text": "Kazutaka Kurihara, Masataka Goto, Jun Ogata, Yosuke Matsusaka, and Takeo Igarashi. 2007. Presentation sensei: a presentation training system using speech and image processing. In Proceedings of the International Conference on Multimodal Interfaces. ACM, 358--365.",
      "doi": "10.1145/1322192.1322256"
    },
    {
      "text": "Stephen Lucas and Paul Stob. 2004. The art of public speaking. McGraw-Hill New York.",
      "doi": ""
    },
    {
      "text": "Piet Mertens. 2004. The prosogram: Semi-automatic transcription of prosody based on a tonal perception model. In Proceedings of the International Conference on Speech Prosody. Nara, Japan, 23--26.",
      "doi": ""
    },
    {
      "text": "Leslie Milton and Christine Lu. 2015. VerseVis: Visualization of spoken features in poetry. University of Maryland, Tech. Rep (2015), 1--9.",
      "doi": ""
    },
    {
      "text": "Fabian M\u00a8 orchen, Alfred Ultsch, Mario N\u00a8 ocker, and Christian Stamm. 2005. Databionic visualization of music collections according to perceptual distance. In Proceedings of the International Society for Music Information Retrieval. 396--403.",
      "doi": ""
    },
    {
      "text": "Chris Muelder, Thomas Provan, and Kwan-Liu Ma. 2010. Content based graph visualization of audio data for music library navigation. In Proceedings of the International Symposium on Multimedia. IEEE, 129--136.",
      "doi": "10.1109/ISM.2010.27"
    },
    {
      "text": "Arina Nikitina. 2011. Successful public speaking. Bookboon.",
      "doi": ""
    },
    {
      "text": "Alp \u00a8 Oktem, Mireia Farr\u00b4 us, and Leo Wanner. 2017. Prosograph: a tool for prosody visualisation of large speech corpora. In Proceedings of the Annual Conference of the International Speech Communication Association. 809--810.",
      "doi": ""
    },
    {
      "text": "Elias Pampalk, Andreas Rauber, and Dieter Merkl. 2002. Content-based organization and visualization of music archives. In Proceedings of the ACM International Conference on Multimedia. ACM, 570--579.",
      "doi": "10.1145/641007.641121"
    },
    {
      "text": "Rupal Patel and William Furr. 2011. Read N' Karaoke: visualizing prosody in children's books for expressive oral reading. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3203--3206.",
      "doi": "10.1145/1978942.1979417"
    },
    {
      "text": "Katarzyna Pisanski, Valentina Cartei, Carolyn McGettigan, Jordan Raine, and David Reby. 2016. Voice modulation: a window into the origins of human vocal control? Trends in Cognitive Sciences 20, 4 (2016), 304--318.",
      "doi": ""
    },
    {
      "text": "Steve Rubin, Floraine Berthouzoz, Gautham J Mysore, and Maneesh Agrawala. 2015. Capture-time feedback for recording scripted narration. In Proceedings of the Annual ACM Symposium on User Interface Software & Technology. ACM, 191--199.",
      "doi": "10.1145/2807442.2807464"
    },
    {
      "text": "RA. Schmidt, DE. Young, S. Swinnen, and DC. Shapiro. 1989. Summary knowledge of results for skill acquisition: support for the guidance hypothesis. Journal of Experimental Psychology: Learning, Memory and Cognition 15, 2 (1989), 352--359.",
      "doi": ""
    },
    {
      "text": "Jan Schneider, Dirk B\u00a8 orner, Peter Van Rosmalen, and Marcus Specht. 2015. Presentation trainer, your public speaking multimodal coach. In Proceedings of the International Conference on Multimodal Interaction. ACM, 539--546.",
      "doi": "10.1145/2818346.2830603"
    },
    {
      "text": "Jan Schneider, Dirk B\u00a8 orner, Peter Van Rosmalen, and Marcus Specht. 2017. Presentation Trainer: what experts and computers can tell about your nonverbal communication. Computer Assisted Learning 33, 2 (2017), 164--177.",
      "doi": "10.1111/jcal.12175"
    },
    {
      "text": "Prem Seetharaman, Gautham Mysore, Bryan Pardo, Paris Smaragdis, and Celso Gomes. 2019. VoiceAssist: Guiding Users to High-Quality Voice Recordings. In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 1--6.",
      "doi": "10.1145/3290605.3300539"
    },
    {
      "text": "Eva Strangert. 2005. Prosody in public speech: analyses of a news announcement and a political interview. In Proceedings of the European Conference on Speech Communication and Technology. 3401--3404.",
      "doi": ""
    },
    {
      "text": "Eva Strangert and Joakim Gustafson. 2008. What makes a good speaker? subject ratings, acoustic measurements and perceptual evaluations. In Proceedings of the Annual Conference of the International Speech Communication Association. KTH, Speech, Music and Hearing, TMH, 1688--1691.",
      "doi": ""
    },
    {
      "text": "Hiroki Tanaka, Sakriani Sakti, Graham Neubig, Tomoki Toda, Hideki Negoro, Hidemi Iwasaka, and Satoshi Nakamura. 2015. Automated social skills trainer. In Proceedings of the International Conference on Intelligent User Interfaces. ACM, 17--27.",
      "doi": "10.1145/2678025.2701368"
    },
    {
      "text": "M Iftekhar Tanveer, Emy Lin, and Mohammed Ehsan Hoque. 2015. Rhema: A real-time in-situ intelligent interface to help people with public speaking. In Proceedings of the International Conference on Intelligent User Interfaces. ACM, 286--295.",
      "doi": "10.1145/2678025.2701386"
    },
    {
      "text": "Ha Trinh, Reza Asadi, Darren Edge, and T Bickmore. 2017. RoboCOP: A Robotic Coach for Oral Presentations. In Proceedings of the ACM International Conference on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1. ACM, 1--24.",
      "doi": "10.1145/3090092"
    },
    {
      "text": "TJ Tsai. 2015. Are You TED Talk material? Comparing prosody in professors and TED speakers. In Proceedings of the Annual Conference of the International Speech Communication Association. ISCA, 2534--2538.",
      "doi": ""
    },
    {
      "text": "Haipeng Zeng, Xingbo Wang, Aoyu Wu, Yong Wang, Quan Li, Alex Endert, and Huamin Qu. 2019. EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos. IEEE Transactions on Visualization and Computer Graphics 26, 1 (2019), 927--937.",
      "doi": ""
    },
    {
      "text": "Ru Zhao, Vivian Li, Hugo Barbosa, Gourab Ghoshal, and Mohammed Ehsan Hoque. 2017. Semi-automated & collaborative online training module for improving communication skills. In Proceedings of the ACM International Conference on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1. ACM, 1--20.",
      "doi": "10.1145/3090097"
    }
  ]
}