{
  "doi": "10.1145/3313831.3376257",
  "title": "Do I Look Like a Criminal? Examining how Race Presentation Impacts Human Judgement of Recidivism",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2020,
  "badges": [],
  "abstract": "Understanding how racial information impacts human decision making in online systems is critical in today's world. Prior work revealed that race information of criminal defendants, when presented as a text field, had no significant impact on users' judgements of recidivism. We replicated and extended this work to explore how and when race information influences users' judgements, with respect to the saliency of presentation. Our results showed that adding photos to the race labels had a significant impact on recidivism predictions for users who identified as female, but not for those who identified as male. The race of the defendant also impacted these results, with black defendants being less likely to be predicted to recidivate compared to white defendants. These results have strong implications for how system-designers choose to display race information, and cautions researchers to be aware of gender and race effects when using Amazon Mechanical Turk workers.",
  "authors": [
    {
      "name": "Keri Mallari",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659527052",
      "orcid": "missing"
    },
    {
      "name": "Kori Inkpen",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100519232",
      "orcid": "0000-0001-5661-4659"
    },
    {
      "name": "Paul Johns",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81416608130",
      "orcid": "missing"
    },
    {
      "name": "Sarah Tan",
      "institution": "Cornell University, Ithaca, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659343500",
      "orcid": "missing"
    },
    {
      "name": "Divya Ramesh",
      "institution": "University of Michigan, Ann Arbor, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87059882557",
      "orcid": "missing"
    },
    {
      "name": "Ece Kamar",
      "institution": "Microsoft Research, Redmond, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81365597792",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. How we analyzed the compas recidivism algorithm. (2016). https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm Accessed May 26, 2017.",
      "doi": ""
    },
    {
      "text": "Saeideh Bakhshi, David A Shamma, and Eric Gilbert. 2014. Faces engage us: Photos with faces attract more likes and comments on instagram. In SIGCHI Conference on Human Factors in Computing Systems. 965--974.",
      "doi": "10.1145/2556288.2557403"
    },
    {
      "text": "Andrew W Barrett and Lowell W Barrington. 2005. Is a picture worth a thousand words? Newspaper photographs and voter evaluations of political candidates. Harvard International Journal of Press/Politics 10, 4 (2005), 98--113.",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on fairness, accountability and transparency. 77--91.",
      "doi": ""
    },
    {
      "text": "Carrie J. Cai, Samantha Winter, David Steiner, Lauren Wilcox, and Michael Terry. 2019. \"Hello AI\": Uncovering the onboarding needs of medical practitioners for human-AI collaborative decision-making. Proceedings of the ACM on Human Computer Interaction 3, CSCW (2019), 1--24.",
      "doi": "10.1145/3359206"
    },
    {
      "text": "Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science 356, 6334 (2017), 183--186.",
      "doi": ""
    },
    {
      "text": "Yujia Cao, Mari\u00ebt Theune, and Anton Nijholt. 2009. Modality effects on cognitive load and performance in high-load information presentation. In International Conference on Intelligent User Interfaces. 335--344.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big Data 5, 2 (2017), 153--163.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. 2018. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In Conference on Fairness, Accountability and Transparency. 134--148.",
      "doi": ""
    },
    {
      "text": "Travis L Dixon and Keith B Maddox. 2005. Skin tone, crime news, and social reality judgments: Priming the stereotype of the dark and dangerous black criminal. Journal of Applied Social Psychology 35, 8 (2005), 1555--1570.",
      "doi": ""
    },
    {
      "text": "Jonathan Dodge, Q Vera Liao, Yunfeng Zhang, Rachel K.E. Bellamy, and Casey Dugan. 2019. Explaining models: An empirical study of how explanations impact fairness judgment. In International Conference on Intelligent User Interfaces. 275--285.",
      "doi": "10.1145/3301275.3302310"
    },
    {
      "text": "Judith Donath. 2007. Signals in social supernets. Journal of Computer-Mediated Communication 13, 1 (2007), 231--251.",
      "doi": "10.1111/j.1083-6101.2007.00394.x"
    },
    {
      "text": "Julia Dressel and Hany Farid. 2018. The accuracy, fairness, and limits of predicting recidivism. Science Advances 4, 1 (2018), eaao5580.",
      "doi": ""
    },
    {
      "text": "Laurel Eckhouse, Kristian Lum, Cynthia Conti-Cook, and Julie Ciccolini. 2019. Layers of bias: A unified approach for understanding problems with risk assessment. Criminal Justice and Behavior 46, 2 (2019), 185--209.",
      "doi": ""
    },
    {
      "text": "Asle Fagerstr\u00f8m, Sanchit Pawar, Valdimar Sigurdsson, Gordon R Foxall, and Mirella Yani-de Soriano. 2017. That personal profile image might jeopardize your rental opportunity! On the relative impact of the seller's facial expressions upon buying behavior on Airbnb?. Computers in Human Behavior 72 (2017), 123--131.",
      "doi": "10.1016/j.chb.2017.02.029"
    },
    {
      "text": "Batya Friedman and Helen Nissenbaum. 1996. Bias in computer systems. Transactions on Information Systems 14, 3 (1996), 330--347.",
      "doi": "10.1145/230538.230561"
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. Disparate interactions: An algorithm-in-the-loop analysis of fairness in risk assessments. In Conference on Fairness, Accountability, and Transparency. 90--99.",
      "doi": "10.1145/3287560.3287563"
    },
    {
      "text": "Anthony G Greenwald and Linda Hamilton Krieger. 2006. Implicit bias: Scientific foundations. California Law Review 94, 4 (2006), 945--967.",
      "doi": ""
    },
    {
      "text": "Nina Grgic-Hlaca, Christoph Engel, and Krishna P. Gummadi. 2019. Human decision making with machine assistance: An experiment on bailing and jailing. Proceedings of the ACM on Human Computer Interaction 3, CSCW (2019).",
      "doi": ""
    },
    {
      "text": "David Hankerson, Andrea R Marshall, Jennifer Booker, Houda El Mimouni, Imani Walker, and Jennifer A Rode. 2016. Does technology have race?. In CHI Conference Extended Abstracts on Human Factors in Computing Systems. 473--486.",
      "doi": "10.1145/2851581.2892578"
    },
    {
      "text": "Jan Hartmann, Antonella De Angeli, and Alistair Sutcliffe. 2008. Framing the user experience: Information biases on website quality judgement. In SIGCHI Conference on Human Factors in Computing Systems. 855--864.",
      "doi": "10.1145/1357054.1357190"
    },
    {
      "text": "Alexander M. Holsinger, Christopher T. Lowenkamp, Edward J. Latessa, Ralph Serin, Thomas H. Cohen, Charles R. Robinson, Anthony W. Flores, and Scott W. VanBenschoten. 2018. A rejoinder to Dressel and Farid: New study finds computer algorithm is more accurate than humans at predicting arrest and as good as a group of 20 lay experts. Federal Probation 82, 2 (2018), 50--55.",
      "doi": ""
    },
    {
      "text": "Weiyin Hong, James YL Thong, and Kar Yan Tam. 2004. Designing product listing pages on e-commerce websites: An examination of presentation mode and information format. International Journal of Human-Computer Studies 61, 4 (2004), 481--503.",
      "doi": "10.1016/j.ijhcs.2004.01.006"
    },
    {
      "text": "Farnaz Jahanbakhsh, Justin Cranshaw, Kori Inkpen, Scott Counts, and Walter Lasecki. 2020. Bias in social rating systems: The role of performance quality and gender. In CHI Conference on Human Factors in Computing Systems.",
      "doi": ""
    },
    {
      "text": "Jerry Kang, Mark Bennett, Devon Carbado, and Pam Casey. 2011. Implicit bias in the courtroom. UCLA Law Review 59 (2011), 1124.",
      "doi": ""
    },
    {
      "text": "Matthew Kay, Cynthia Matuszek, and Sean A Munson. 2015. Unequal representation and gender stereotypes in image search results for occupations. In CHI Conference on Human Factors in Computing Systems. 3819--3828.",
      "doi": "10.1145/2702123.2702520"
    },
    {
      "text": "William Kilbourne and Susan Weeks. 1997. A socio-economic perspective on gender bias in technology. The Journal of Socio-Economics 26, 3 (1997), 243--260.",
      "doi": ""
    },
    {
      "text": "Heather M Kleider, Sarah E Cavrak, and Leslie R Knuycky. 2012. Looking like a criminal: Stereotypical black facial features promote face source memory error. Memory & Cognition 40, 8 (2012), 1200--1213.",
      "doi": ""
    },
    {
      "text": "Heather M Kleider-Offutt, Alesha D Bond, and Shanna E.A. Hegerty. 2017. Black stereotypical features: When a face type can get you in trouble. Current Directions in Psychological Science 26, 1 (2017), 28--33.",
      "doi": ""
    },
    {
      "text": "Debbie S Ma, Joshua Correll, and Bernd Wittenbrink. 2015. The Chicago face database: A free stimulus set of faces and norming data. Behavior Research Methods 47, 4 (2015), 1122--1135.",
      "doi": ""
    },
    {
      "text": "Esther I Madriz. 1997. Images of criminals and victims: A study on women's fear and social control. Gender & Society 11, 3 (1997), 342--356.",
      "doi": ""
    },
    {
      "text": "Jennifer Martin, Elspeth McKay, and Janki Shankar. 2006. Bias, misinformation and disinformation: Mental health, employment and human computer interaction. In Informing Science and IT Education Joint Conference.",
      "doi": ""
    },
    {
      "text": "Winter Mason and Siddharth Suri. 2012. Conducting behavioral research on Amazon's Mechanical Turk. Behavior Research Methods 44, 1 (2012), 1--23.",
      "doi": ""
    },
    {
      "text": "Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 220--229.",
      "doi": "10.1145/3287560.3287596"
    },
    {
      "text": "Alexandra Olteanu, Carlos Castillo, Fernando Diaz, and Emre Kiciman. 2019. Social data: Biases, methodological pitfalls, and ethical boundaries. Frontiers in Big Data 2 (2019), 13.",
      "doi": ""
    },
    {
      "text": "Andi Peng, Besmira Nushi, Emre Kiciman, Kori Inkpen, Siddharth Suri, and Ece Kamar. 2019. What you see is what you get? The impact of representation criteria on human bias in hiring. In AAAI Conference on Human Computation and Crowdsourcing. 125--134.",
      "doi": ""
    },
    {
      "text": "Jeffrey J Rachlinski, Sheri Lynn Johnson, Andrew J Wistrich, and Chris Guthrie. 2008. Does unconscious racial bias affect trial judges. Notre Dame Law Review 84 (2008), 1195.",
      "doi": ""
    },
    {
      "text": "Ari Schlesinger, Kenton P O'Hara, and Alex S Taylor. 2018. Let's talk about race: Identity, chatbots, and AI. In SIGCHI Conference on Human Factors in Computing Systems. 315.",
      "doi": "10.1145/3173574.3173889"
    },
    {
      "text": "Craig S Schwalbe, Mark W Fraser, Steven H Day, and Valerie Cooley. 2006. Classifying juvenile offenders according to risk of recidivism: Predictive validity, race/ethnicity, and gender. Criminal Justice and Behavior 33, 3 (2006), 305--324.",
      "doi": ""
    },
    {
      "text": "Jennifer L Skeem and Christopher T Lowenkamp. 2016. Risk, race, and recidivism: Predictive bias and disparate impact. Criminology 54, 4 (2016), 680--712.",
      "doi": ""
    },
    {
      "text": "Douglas A Smith, Christy A Visher, and Laura A Davidson. 1984. Equity and discretionary justice: The influence of race on police arrest decisions. Journal of Criminal Law and Criminology 75 (1984), 234.",
      "doi": ""
    },
    {
      "text": "Sarah Tan, Julius Adebayo, Kori Inkpen, and Ece Kamar. 2018a. Investigating Human+Machine Complementarity for Recidivism Predictions. arXiv preprint arXiv:1808.09123 (2018).",
      "doi": ""
    },
    {
      "text": "Sarah Tan, Rich Caruana, Giles Hooker, and Yin Lou. 2018b. Distill-and-compare: auditing black-box models using transparent model distillation. In AAAI/ACM Conference on AI, Ethics, and Society. 303--310.",
      "doi": "10.1145/3278721.3278725"
    },
    {
      "text": "Bethany A Teachman and Kelly D Brownell. 2001. Implicit anti-fat bias among health professionals: is anyone immune? International Journal of Obesity 25, 10 (2001), 1525.",
      "doi": ""
    },
    {
      "text": "Michelle Vaccaro and Jim Waldo. 2019. The effects of mixing machine learning and human judgment. Commun. ACM 62, 11 (2019), 104--110.",
      "doi": "10.1145/3359338"
    },
    {
      "text": "Niels van Berkel, Jorge Goncalves, Danula Hettiachchi, Senuri Wijenayake, Ryan M Kelly, and Vassilis Kostakos. 2019. Crowdsourcing perceptions of fair predictors for machine learning: A recidivism case study. Proceedings of the ACM on Human Computer Interaction 3, CSCW (2019).",
      "doi": "10.1145/3359130"
    },
    {
      "text": "Michael M Wehrman. 2010. Race, concentrated disadvantage, and recidivism: A test of interaction effects. Journal of Criminal Justice 38, 4 (2010), 538--544.",
      "doi": ""
    },
    {
      "text": "David R Williams. 1997. Race and health: basic questions, emerging directions. Annals of epidemiology 7, 5 (1997), 322--333.",
      "doi": ""
    },
    {
      "text": "John Paul Wilson, Kurt Hugenberg, and Nicholas O Rule. 2017. Racial bias in judgments of physical size and formidability: From size to threat. Journal of personality and social psychology 113, 1 (2017), 59.",
      "doi": ""
    },
    {
      "text": "Jacob O Wobbrock, Anya K Hsu, Marijn A Burger, and Michael J Magee. 2019. Isolating the effects of web page visual appearance on the perceived credibility of online news among college students. In Conference on Hypertext and Social Media. 191--200.",
      "doi": "10.1145/3342220.3343663"
    },
    {
      "text": "Shannon N Zenk, Amy J Schulz, Barbara A Israel, Sherman A James, Shuming Bao, and Mark L Wilson. 2005. Neighborhood racial composition, neighborhood poverty, and the spatial accessibility of supermarkets in metropolitan Detroit. American journal of public health 95, 4 (2005), 660--667.",
      "doi": ""
    }
  ]
}