{
  "doi": "10.1145/3313831.3376533",
  "title": "Paths Explored, Paths Omitted, Paths Obscured: Decision Points & Selective Reporting in End-to-End Data Analysis",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-14",
  "year": 2020,
  "badges": [],
  "abstract": "Drawing reliable inferences from data involves many, sometimes arbitrary, decisions across phases of data collection, wrangling, and modeling. As different choices can lead to diverging conclusions, understanding how researchers make analytic decisions is important for supporting robust and replicable analysis. In this study, we pore over nine published research studies and conduct semi-structured interviews with their authors. We observe that researchers often base their decisions on methodological or theoretical concerns, but subject to constraints arising from the data, expertise, or perceived interpretability. We confirm that researchers may experiment with choices in search of desirable results, but also identify other reasons why researchers explore alternatives yet omit findings. In concert with our interviews, we also contribute visualizations for communicating decision processes throughout an analysis. Based on our results, we identify design opportunities for strengthening end-to-end analysis, for instance via tracking and meta-analysis of multiple decision paths.",
  "authors": [
    {
      "name": "Yang Liu",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659260627",
      "orcid": "missing"
    },
    {
      "name": "Tim Althoff",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/do/10.1145/contrib-81549260356/rel-imgonly/tim_headshot_infolab_2016_zoom_250.jpg",
      "acmid": "81549260356",
      "orcid": "0000-0003-4793-2289"
    },
    {
      "name": "Jeffrey Heer",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/do/10.1145/contrib-81100465553/rel-imgonly/jeff-heer.jpg",
      "acmid": "81100465553",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Sara Alspaugh, Nava Zokaei, Andrea Liu, Cindy Jin, and Marti A. Hearst. 2019. Futzing and moseying: Interviews with professional data analysts on exploration practices. IEEE Transactions on Visualization and Computer Graphics 25, 1 (2019), 22--31. DOI: http://dx.doi.org/10.1109/TVCG.2018.2865040",
      "doi": "10.1109/TVCG.2018.2865040"
    },
    {
      "text": "David R. Anderson, William A. Link, Douglas H. Johnson, and Kenneth P. Burnham. 2001. Suggestions for presenting the results of data analyses. The Journal of Wildlife Management 65, 3 (2001), 373--378. DOI: http://dx.doi.org/10.2307/3803088",
      "doi": ""
    },
    {
      "text": "Monya Baker. 2016. 1,500 scientists lift the lid on reproducibility. Nature 533, 7604 (2016), 452--454. DOI: http://dx.doi.org/10.1038/533452a",
      "doi": ""
    },
    {
      "text": "Leilani Battle and Jeffrey Heer. 2019. Characterizing exploratory visual analysis: A literature review and evaluation of analytic provenance in tableau. Computer Graphics Forum (Proc. EuroVis) (2019). DOI: http://dx.doi.org/10.1111/cgf.13678",
      "doi": ""
    },
    {
      "text": "C. Glenn Begley and Lee M. Ellis. 2012. Raise standards for preclinical cancer research. Nature 483, 7391 (2012), 531--533. DOI: http://dx.doi.org/10.1038/483531a",
      "doi": ""
    },
    {
      "text": "Richard Border, Emma C. Johnson, Luke M. Evans, Andrew Smolen, Noah Berley, Patrick F. Sullivan, and Matthew C. Keller. 2019. No support for historical candidate gene or candidate gene-by-interaction hypotheses for major depression across multiple large samples. American Journal of Psychiatry 176, 5 (2019), 376--387. DOI: http://dx.doi.org/10.1176/appi.ajp.2018.18070881 PMID: 30845820.",
      "doi": ""
    },
    {
      "text": "Steven P. Callahan, Juliana Freire, Emanuele Santos, Carlos E. Scheidegger, Cl\u00e1udio T. Silva, and Huy T. Vo. 2006. VisTrails: Visualization meets data management. In Proc. ACM SIGMOD International Conference on Management of Data. 745--747. DOI: http://dx.doi.org/10.1145/1142473.1142574",
      "doi": ""
    },
    {
      "text": "Dylan Cashman, Shah Rukh Humayoun, Florian Heimerl, Kendall Park, Subhajit Das, John R. Thompson, Bahador Saket, Abigail Mosca, John Stasko, Alex Endert, Michael Gleicher, and Remco Chang. 2019. A user-based visual analytics workflow for exploratory model analysis. Computer Graphics Forum (Proc. EuroVis) (2019). DOI: http://dx.doi.org/10.1111/cgf.13681",
      "doi": ""
    },
    {
      "text": "Kwok Cheung and Jane Hunter. 2006. Provenance explorer -- customized provenance views using semantic inferencing. In International Semantic Web Conference. 215--227. DOI: http://dx.doi.org/10.1007/11926078_16",
      "doi": "10.1007/11926078_16"
    },
    {
      "text": "Andy Cockburn, Carl Gutwin, and Alan Dix. 2018. HARK no more: On the preregistration of CHI Experiments. In Proc. ACM Human Factors in Computing Systems. 141:1--141:12. DOI: http://dx.doi.org/10.1145/3173574.3173715",
      "doi": ""
    },
    {
      "text": "John W. Creswell and Cheryl N. Poth. 2018. Qualitative inquiry and research design: Choosing among five approaches. SAGE publications.",
      "doi": ""
    },
    {
      "text": "Robert A Cribbie. 2017. Multiplicity control, school uniforms, and other perplexing debates. Canadian Journal of Behavioural Science 49, 3 (2017), 159.",
      "doi": ""
    },
    {
      "text": "Geoff Cumming and Robert Calin-Jageman. 2016. Introduction to the new statistics: Estimation, open science, and beyond (1 ed.). Routledge. DOI: http://dx.doi.org/10.4324/9781315708607",
      "doi": ""
    },
    {
      "text": "Pierre Dragicevic. 2016. Fair statistical communication in HCI. In Modern Statistical Methods for HCI. Springer, 291--330. DOI: http://dx.doi.org/10.1007/978--3--319--26633--6_13",
      "doi": ""
    },
    {
      "text": "Pierre Dragicevic, Yvonne Jansen, Abhraneel Sarma, Matthew Kay, and Fanny Chevalier. 2019. Increasing the transparency of research papers with explorable multiverse analyses. In Proc. ACM Human Factors in Computing Systems. 65:1--65:15. DOI: http://dx.doi.org/10.1145/3290605.3300295",
      "doi": ""
    },
    {
      "text": "Alexander Eiselmayer, Chat Wacharamanotham, Michel Beaudouin-Lafon, and Wendy E. Mackay. 2019. Touchstone2: An interactive environment for exploring trade-offs in HCI experiment design. In Proc. ACM Human Factors in Computing Systems. 217:1--217:11. DOI: http://dx.doi.org/10.1145/3290605.3300447",
      "doi": ""
    },
    {
      "text": "Sebastian S. Feger, S\u00fcnje Dallmeier-Tiessen, Albrecht Schmidt, and Pawel W. Wo\u00b4 zniak. 2019a. Designing for reproducibility: A qualitative study of challenges and opportunities in high energy physics. In Proc. ACM Human Factors in Computing Systems. 455:1--455:14. DOI: http://dx.doi.org/10.1145/3290605.3300685",
      "doi": ""
    },
    {
      "text": "Sebastian S. Feger, S\u00fcnje Dallmeier-Tiessen, Pawel W. Wo\u00b4zniak, and Albrecht Schmidt. 2019b. Gamification in science: A study of requirements in the context of reproducible research. In Proc. ACM Human Factors in Computing Systems. 460:1--460:14. DOI: http://dx.doi.org/10.1145/3290605.3300690",
      "doi": ""
    },
    {
      "text": "Wolfgang Forstmeier and Holger Schielzeth. 2011. Cryptic multiple hypotheses testing in linear models: Overestimated effect sizes and the winner's curse. Behavioral Ecology and Sociobiology 65, 1 (2011), 47--55. DOI: http://dx.doi.org/10.1007/s00265-010--1038--5",
      "doi": ""
    },
    {
      "text": "Wolfgang Forstmeier, Eric-Jan Wagenmakers, and Timothy H. Parker. 2017. Detecting and avoiding likely false-positive findings - A practical guide. Biological Reviews 92, 4 (2017), 1941--1968. DOI: http://dx.doi.org/10.1111/brv.12315",
      "doi": ""
    },
    {
      "text": "Juliana Freire, David Koop, Emanuele Santos, and Cl\u00e1udio T Silva. 2008. Provenance for computational tasks: A survey. Computing in Science & Engineering 10, 3 (2008), 11--21. DOI: http://dx.doi.org/10.1109/MCSE.2008.79",
      "doi": "10.1109/MCSE.2008.79"
    },
    {
      "text": "Andrew Gelman, Jennifer Hill, and Masanao Yajima. 2012. Why we (usually) don't have to worry about multiple comparisons. Journal of Research on Educational Effectiveness 5, 2 (2012), 189--211. DOI: http://dx.doi.org/10.1080/19345747.2011.618213",
      "doi": ""
    },
    {
      "text": "Andrew Gelman and Eric Loken. 2013. The garden of forking paths: Why multiple comparisons can be a problem, even when there is no \"fishing expedition\" or \"p-hacking\" and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University (2013).",
      "doi": ""
    },
    {
      "text": "Andrew Gelman and Eric Loken. 2014. The statistical crisis in science. American Scientist 102, 6 (2014), 460. DOI: http://dx.doi.org/10.1511/2014.111.460",
      "doi": ""
    },
    {
      "text": "Philip J Guo and Margo I Seltzer. 2012. BURRITO: Wrapping your lab notebook in computational infrastructure. In USENIX Workshop on the Theory and Practice of Provenance. https://www.usenix.org/ conference/tapp12/workshop-program/presentation/Guo",
      "doi": ""
    },
    {
      "text": "Greg Guest, Arwen Bunce, and Laura Johnson. 2006. How many interviews are enough? An experiment with data saturation and variability. Field methods 18, 1 (2006), 59--82. DOI: http://dx.doi.org/10.1177/1525822X05279903",
      "doi": ""
    },
    {
      "text": "Bj\u00f6rn Hartmann, Loren Yu, Abel Allison, Yeonsoo Yang, and Scott R. Klemmer. 2008. Design as exploration: Creating interface alternatives through parallel authoring and runtime tuning. In Proc. ACM User Interface Software and Technology. 91--100. DOI: http://dx.doi.org/10.1145/1449715.1449732",
      "doi": ""
    },
    {
      "text": "Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup, and David Meger. 2018. Deep reinforcement learning that matters. In Proceedings of the AAAI Conference on Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Leslie K. John, George Loewenstein, and Drazen Prelec. 2012. Measuring the prevalence of questionable research practices with incentives for truth telling. Psychological Science 23, 5 (2012), 524--532. DOI: http://dx.doi.org/10.1177/0956797611430953",
      "doi": ""
    },
    {
      "text": "Eunice Jun, Maureen Daum, Jared Roesch, Sarah E. Chasins, Emery D. Berger, Ren\u00e9 Just, and Katharina Reinecke. 2019. Tea: A high-level language and runtime system for automating statistical analysis. CoRR abs/1904.05387 (2019). http://arxiv.org/abs/1904.05387",
      "doi": ""
    },
    {
      "text": "Alex Kale, Matthew Kay, and Jessica Hullman. 2019. Decision-making under uncertainty in research synthesis: Designing for the garden of forking paths. In Proc. ACM Human Factors in Computing Systems. 202:1--202:14. DOI: http://dx.doi.org/10.1145/3290605.3300432",
      "doi": ""
    },
    {
      "text": "Matthew Kay, Gregory L. Nelson, and Eric B. Hekler. 2016. Researcher-centered design of statistics: Why Bayesian statistics better fit the culture and incentives of HCI. In Proc. ACM Human Factors in Computing Systems. 4521--4532. DOI: http://dx.doi.org/10.1145/2858036.2858465",
      "doi": "10.1145/2858036.2858465"
    },
    {
      "text": "Norbert L. Kerr. 1998. HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review 2, 3 (1998), 196--217. DOI: http://dx.doi.org/10.1207/s15327957pspr0203_4",
      "doi": ""
    },
    {
      "text": "Mary B. Kery, Bonnie E. John, Patrick O'Flaherty, Amber Horvath, and Brad A. Myers. 2019. Towards effective foraging by data scientists to find past analysis choices. In Proc. ACM Human Factors in Computing Systems. 92:1--92:13. DOI: http://dx.doi.org/10.1145/3290605.3300322",
      "doi": ""
    },
    {
      "text": "Mary B. Kery and Brad A. Myers. 2018. Interactions for untangling messy history in a computational notebook. In 2018 IEEE Symposium on Visual Languages and Human-Centric Computing. 147--155. DOI: http://dx.doi.org/10.1109/VLHCC.2018.8506576",
      "doi": ""
    },
    {
      "text": "Jiali Liu, Nadia Boukhelifa, and James R. Eagan. 2019. Understanding the role of alternatives in data analysis practices. IEEE Transactions on Visualization and Computer Graphics (2019), 1--1. DOI: http://dx.doi.org/10.1109/TVCG.2019.2934593",
      "doi": ""
    },
    {
      "text": "Bertram Lud\u00e4scher, Ilkay Altintas, Chad Berkley, Dan Higgins, Efrat Jaeger, Matthew Jones, Edward A. Lee, Jing Tao, and Yang Zhao. 2006. Scientific workflow management and the Kepler system. Concurrency and Computation: Practice and Experience 18, 10 (2006), 1039--1065. DOI: http://dx.doi.org/10.1002/cpe.994",
      "doi": "10.5555/1148437.1148454"
    },
    {
      "text": "Wendy E. Mackay, Caroline Appert, Michel Beaudouin-Lafon, Olivier Chapuis, Yangzhou Du, Jean-Daniel Fekete, and Yves Guiard. 2007. Touchstone: Exploratory design of experiments. In Proc. ACM Human Factors in Computing Systems. 1425--1434. DOI: http://dx.doi.org/10.1145/1240624.1240840",
      "doi": "10.1145/1240624.1240840"
    },
    {
      "text": "Marcus R. Munaf\u00f2, Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie Du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017. A manifesto for reproducible science. Nature Human Behaviour 1 (2017), 0021. DOI: http://dx.doi.org/10.1038/s41562-016-0021",
      "doi": ""
    },
    {
      "text": "James D. Myers, Carmen M. Pancerella, Carina S. Lansing, Karen L. Schuchardt, Brett T. Didier, and Goble C. Ashish, N. 2003. Multi-scale science: Supporting emerging practice with semantically derived provenance. International Semantic Web Conference Workshop: Semantic Web Technologies for Searching and Retrieving Scientific Data (2003). https://www.osti.gov/biblio/15016920",
      "doi": ""
    },
    {
      "text": "Leif D. Nelson, Joseph Simmons, and Uri Simonsohn. 2018. Psychology's renaissance. Annual Review of Psychology 69, 1 (2018), 511--534. DOI: http://dx.doi.org/10.1146/annurev-psych-122216-011836",
      "doi": ""
    },
    {
      "text": "Tom Oinn, Matthew Addis, Justin Ferris, Darren Marvin, Martin Senger, Mark Greenwood, Tim Carver, Kevin Glover, Matthew R. Pocock, Anil Wipat, and Peter Li. 2004. Taverna: A tool for the composition and enactment of bioinformatics workflows. Bioinformatics 20, 17 (2004), 3045--3054. DOI: http://dx.doi.org/10.1093/bioinformatics/bth361",
      "doi": "10.1093/bioinformatics/bth361"
    },
    {
      "text": "Open Science Collaboration. 2015. Estimating the reproducibility of psychological science. Science 349, 6251 (2015). DOI: http://dx.doi.org/10.1126/science.aac4716",
      "doi": ""
    },
    {
      "text": "Chirag J. Patel, Belinda Burford, and John P. A. Ioannidis. 2015. Assessment of vibration of effects due to model specification can demonstrate the instability of observational associations. Journal of Clinical Epidemiology 68, 9 (2015), 1046--1058. DOI: http://dx.doi.org/10.1016/j.jclinepi.2015.05.029",
      "doi": ""
    },
    {
      "text": "Joao Felipe Nicolaci Pimentel, Vanessa Braganholo, Leonardo Murta, and Juliana Freire. 2015. Collecting and analyzing provenance on interactive notebooks: When IPython meets noWorkflow. In USENIX Workshop on the Theory and Practice of Provenance. https://www.usenix.org/conference/tapp15/ workshop-program/presentation/pimentel",
      "doi": ""
    },
    {
      "text": "Florian Prinz, Thomas Schlange, and Khusru Asadullah. 2011. Believe it or not: How much can we rely on published data on potential drug targets? Nature Reviews Drug Discovery 10, 9 (2011), 712. DOI: http://dx.doi.org/10.1038/nrd3439-c1",
      "doi": ""
    },
    {
      "text": "Xiaoying Pu and Matthew Kay. 2018. The garden of forking paths in visualization: A design space for reliable exploratory visual analytics. In 2018 IEEE Evaluation and Beyond - Methodological Approaches for Visualization (BELIV). 37--45. DOI: http://dx.doi.org/10.1109/BELIV.2018.8634103",
      "doi": ""
    },
    {
      "text": "James R. Rae, Selin G\u00fclg\u00f6z, Lily Durwood, Madeleine DeMeules, Riley Lowe, Gabrielle Lindquist, and Kristina R. Olson. 2019. Predicting early-childhood gender transitions. Psychological Science (2019). DOI: http://dx.doi.org/10.1177/0956797619830649",
      "doi": ""
    },
    {
      "text": "Adam Rule, Aur\u00e9lien Tabard, and James D. Hollan. 2018. Exploration and explanation in computational notebooks. In Proc. ACM Human Factors in Computing Systems. 32. DOI: http://dx.doi.org/10.1145/3173574.3173606",
      "doi": ""
    },
    {
      "text": "Raphael Silberzahn, Eric Luis Uhlmann, Dan Martin, Pasquale Anselmi, Frederik Aust, Eli C Awtrey, Feng Bai, Colin Bannard, Evelina Bonnier, R. Carlsson, F. Cheung, G. Christensen, R. Clay, M. A. Craig, A. Dalla Rosa, L. Dam, M. H. Evans, I. Flores Cervantes, N. Fong, M. Gamez-Djokic, A. Glenz, S. Gordon-McKeon, T. J. Heaton, K. Hederos, M. Heene, A. J. Hofelich Mohr, F. H\u00f6gden, K. Hui, M. Johannesson, J. Kalodimos, E. Kaszubowski, D. M. Kennedy, R. Lei, T. A. Lindsay, S. Liverani, C. R. Madan, D. Molden, E. Molleman, R. D. Morey, L. B. Mulder, B. R. Nijstad, N. G. Pope, B. Pope, J. M. Prenoveau, F. Rink, E. Robusto, H. Roderique, A. Sandberg, E. Schl\u00fcter, F. D. Sch\u00f6nbrodt, M. F. Sherman, S. A. Sommer, K. Sotak, S. Spain, C. Sp\u00f6rlein, T. Stafford, L. Stefanutti, S. Tauber, J. Ullrich, M. Vianello, E.-J. Wagenmakers, M. Witkowiak, S. Yoon, and B. A. Nosek. 2018. Many analysts, one data set: Making transparent how variations in analytic choices affect results. Advances in Methods and Practices in Psychological Science 1, 3 (2018), 337--356. DOI: http://dx.doi.org/10.1177/2515245917747646",
      "doi": ""
    },
    {
      "text": "Joseph P. Simmons, Leif D. Nelson, and Uri Simonsohn. 2011. False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological Science 22, 11 (2011), 1359--1366. DOI: http://dx.doi.org/10.1177/0956797611417632",
      "doi": ""
    },
    {
      "text": "Uri Simonsohn, Joseph P Simmons, and Leif D Nelson. 2015. Specification curve: Descriptive and inferential statistics on all reasonable specifications. (2015). DOI: http://dx.doi.org/10.2139/ssrn.2694998",
      "doi": ""
    },
    {
      "text": "Transparent statistics in Human--Computer Interaction working group. 2019. Transparent statistics guidelines. (Feb 2019). DOI: http://dx.doi.org/10.5281/zenodo.1186169 (Available at https://transparentstats.github.io/guidelines).",
      "doi": ""
    },
    {
      "text": "Sara Steegen, Francis Tuerlinckx, Andrew Gelman, and Wolf Vanpaemel. 2016. Increasing transparency through a multiverse analysis. Perspectives on Psychological Science 11, 5 (2016), 702--712. DOI: http://dx.doi.org/10.1177/1745691616658637",
      "doi": ""
    },
    {
      "text": "Michael Terry, Elizabeth D. Mynatt, Kumiyo Nakakoji, and Yasuhiro Yamamoto. 2004. Variation in element and action: Supporting simultaneous development of alternative solutions. In Proc. ACM Human Factors in Computing Systems. 711--718. DOI: http://dx.doi.org/10.1145/985692.985782",
      "doi": "10.1145/985692.985782"
    },
    {
      "text": "Anna E. van't Veer and Roger Giner-Sorolla. 2016. Pre-registration in social psychology -- A discussion and suggested template. Journal of Experimental Social Psychology 67 (2016), 2--12. DOI: http://dx.doi.org/10.1016/j.jesp.2016.03.004",
      "doi": ""
    },
    {
      "text": "Chat Wacharamanotham, Krishna Subramanian, Sarah Theres V\u00f6lkel, and Jan Borchers. 2015. Statsplorer: Guiding novices in statistical analysis. In Proc. ACM Human Factors in Computing Systems. 2693--2702. DOI: http://dx.doi.org/10.1145/2702123.2702347",
      "doi": "10.1145/2702123.2702347"
    },
    {
      "text": "Eric-Jan Wagenmakers, Ruud Wetzels, Denny Borsboom, Han L. J. van der Maas, and Rogier A. Kievit. 2012. An agenda for purely confirmatory research. Perspectives on Psychological Science 7, 6 (2012), 632--638. DOI: http://dx.doi.org/10.1177/1745691612463078",
      "doi": ""
    },
    {
      "text": "Jelte M. Wicherts, Coosje L. S. Veldkamp, Hilde E. M. Augusteijn, Marjan Bakker, Robbie C. M. van Aert, and Marcel A. L. M. van Assen. 2016. Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to avoid p-hacking. Frontiers in Psychology 7 (2016), 1832. DOI: http://dx.doi.org/10.3389/fpsyg.2016.01832",
      "doi": ""
    },
    {
      "text": "Cristobal Young and Katherine Holsteen. 2017. Model uncertainty and robustness: A computational framework for multimodel analysis. Sociological Methods & Research 46, 1 (2017), 3--40. DOI: http://dx.doi.org/10.1177/0049124115610347",
      "doi": ""
    },
    {
      "text": "Emanuel Zgraggen, Zheguang Zhao, Robert Zeleznik, and Tim Kraska. 2018. Investigating the effect of the multiple comparisons problem in visual analysis. In Proc. ACM Human Factors in Computing Systems. 479:1--479:12. DOI: http://dx.doi.org/10.1145/3173574.3174053",
      "doi": ""
    },
    {
      "text": "Jun Zhao, Chris Wroe, Carole Goble, Robert Stevens, Dennis Quan, and Mark Greenwood. 2004. Using semantic web technologies for representing e-science provenance. In International Semantic Web Conference. 92--106. DOI: http://dx.doi.org/10.1007/978--3--540--30475--3_8",
      "doi": "10.1007/978-3-540-30475-3_8"
    }
  ]
}