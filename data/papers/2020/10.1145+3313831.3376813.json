{
  "doi": "10.1145/3313831.3376813",
  "title": "Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-14",
  "year": 2020,
  "badges": [],
  "abstract": "Algorithmic decision-making systems are increasingly used throughout the public and private sectors to make important decisions or assist humans in making these decisions with real social consequences. While there has been substantial research in recent years to build fair decision-making algorithms, there has been less research seeking to understand the factors that affect people's perceptions of fairness in these systems, which we argue is also important for their broader acceptance. In this research, we conduct an online experiment to better understand perceptions of fairness, focusing on three sets of factors: algorithm outcomes, algorithm development and deployment procedures, and individual differences. We find that people rate the algorithm as more fair when the algorithm predicts in their favor, even surpassing the negative effects of describing algorithms that are very biased against particular demographic groups. We find that this effect is moderated by several variables, including participants' education level, gender, and several aspects of the development procedure. Our findings suggest that systems that evaluate algorithmic fairness through users' feedback must consider the possibility of \"outcome favorability\" bias.",
  "tags": [
    "algorithm development",
    "algorithmoutcome",
    "algorithmic decision-making",
    "perceived fairness"
  ],
  "authors": [
    {
      "name": "Ruotong Wang",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659365678",
      "orcid": "missing"
    },
    {
      "name": "F. Maxwell Harper",
      "institution": "Amazon, Seattle, WA, USA",
      "img": "/do/10.1145/contrib-81320490116/rel-imgonly/max6.jpg",
      "acmid": "81320490116",
      "orcid": "missing"
    },
    {
      "name": "Haiyi Zhu",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/do/10.1145/contrib-81484646857/rel-imgonly/headshot.png",
      "acmid": "81484646857",
      "orcid": "0000-0001-7271-9100"
    }
  ],
  "references": [
    {
      "text": "2019a. Amazon Mechanical Turk. (2019). https://www.mturk.com/worker/help",
      "doi": ""
    },
    {
      "text": "2019b. NSF Program on Fairness in Artificial Intelligence in Collaboration with Amazon (FAI) (nsf19571). (2019). https://www.nsf.gov/pubs/2019/nsf19571/nsf19571.htm",
      "doi": ""
    },
    {
      "text": "J Stacy Adams. 1965. Inequity in social exchange. In Advances in experimental social psychology. Vol. 2. Academic Press, 267--299.",
      "doi": ""
    },
    {
      "text": "Alekh Agarwal, Alina Beygelzimer, Miroslav Dud\u00edk, John Langford, and Hanna Wallach. 2018. A reductions approach to fair classification. arXiv preprint arXiv:1803.02453 (2018).",
      "doi": ""
    },
    {
      "text": "Ifeoma Ajunwa, Sorelle Friedler, Carlos E Scheidegger, and Suresh Venkatasubramanian. 2016. Hiring by algorithm: predicting and preventing disparate impact. Available at SSRN (2016). https://papers.ssrn.com/abstract=2746078",
      "doi": ""
    },
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine Bias. (May 2016). https://www.propublica.org/article/ machine-bias-risk-assessments-in-criminal-sentencing",
      "doi": ""
    },
    {
      "text": "C Daniel Batson, Nadia Ahmad, Jodi Yin, Steven J Bedell, Jennifer W Johnson, and Christie M Templin. 1999. Two threats to the common good: Self-interested egoism and empathy-induced altruism. Personality and Social Psychology Bulletin 25, 1 (1999), 3--16.",
      "doi": ""
    },
    {
      "text": "David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. 2017. Network dissection: Quantifying interpretability of deep visual representations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 6541--6549.",
      "doi": ""
    },
    {
      "text": "Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. 2018a. Fairness in criminal justice risk assessments: The state of the art. Sociological Methods & Research (2018).",
      "doi": ""
    },
    {
      "text": "Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. 2018b. Fairness in criminal justice risk assessments: The state of the art. Sociological Methods & Research (2018), 1--24.",
      "doi": ""
    },
    {
      "text": "Quoctrung Bui. 2017. How Many Americans Would Pass an Immigration Test Endorsed by Trump? The New York Times (2017). https://www.nytimes.com/interactive/2017/08/23/ upshot/immigration-quiz-raise-act-trump.html",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on Fairness, Accountability and Transparency. 77--91.",
      "doi": ""
    },
    {
      "text": "Pew Research Center. 2016a. Mechanical Turk: Research in the Crowdsourcing Age. (July 2016). https://www.pewinternet.org/2016/07/11/ research-in-the-crowdsourcing-age-a-case-study/",
      "doi": ""
    },
    {
      "text": "Pew Research Center. 2016b. On Views of Race and Inequality, Blacks and Whites Are Worlds Apart. (June 2016). https://www.pewsocialtrends.org/2016/06/27/onviews-of-race-and-inequality-blacks-and-whites-areworlds-apart/.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova and Aaron Roth. 2018. The frontiers of fairness in machine learning. arXiv preprint arXiv:1810.08810 (2018).",
      "doi": ""
    },
    {
      "text": "Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 797--806.",
      "doi": "10.1145/3097983.3098095"
    },
    {
      "text": "Bo Cowgill. 2018. Bias and Productivity in Humans and Algorithms: Theory and Evidence from Resume Screening. Columbia Business School, Columbia University 29 (2018).",
      "doi": ""
    },
    {
      "text": "Jeffrey Dastin. 2018. Amazon scraps secret AI recruiting tool that showed bias against women. Reuters (Oct. 2018). https://www.reuters.com/article/us-amazon-comjobs-automation-insight/amazon-scraps-secret-airecruiting-tool-that-showed-bias-against-womenidUSKCN1MK08G.",
      "doi": ""
    },
    {
      "text": "Morton Deutsch. 1985. Distributive justice: A social-psychological perspective. Vol. 437. Yale University Press New Haven, CT.",
      "doi": ""
    },
    {
      "text": "Michael A DeVito, Darren Gergle, and Jeremy Birnholtz. 2017. Algorithms ruin everything:# RIPTwitter, folk theories, and resistance to algorithmic change in social media. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 3163--3174.",
      "doi": "10.1145/3025453.3025659"
    },
    {
      "text": "Michael A DeVito, Ashley Marie Walker, and Jeremy Birnholtz. 2018. 'Too Gay for Facebook': Presenting LGBTQ+ Identity Throughout the Personal Social Media Ecosystem. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 44.",
      "doi": "10.1145/3274313"
    },
    {
      "text": "Kristina A Diekmann, Steven M Samuels, Lee Ross, and Max H Bazerman. 1997. Self-interest and fairness in problems of resource allocation: allocators versus recipients. Journal of personality and social psychology 72, 5 (1997), 1061.",
      "doi": ""
    },
    {
      "text": "Berkeley J Dietvorst, Joseph P Simmons, and Cade Massey. 2015. Algorithm aversion: People erroneously avoid algorithms after seeing them err. Journal of Experimental Psychology: General 144, 1 (2015), 114.",
      "doi": ""
    },
    {
      "text": "Berkeley J Dietvorst, Joseph P Simmons, and Cade Massey. 2016. Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them. Management Science 64, 3 (2016), 1155--1170.",
      "doi": "10.1287/mnsc.2016.2643"
    },
    {
      "text": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference. ACM, 214--226.",
      "doi": "10.1145/2090236.2090255"
    },
    {
      "text": "Cynthia Dwork, Nicole Immorlica, Adam Tauman Kalai, and Max Leiserson. 2018. Decoupled classifiers for group-fair and efficient machine learning. In Conference on Fairness, Accountability and Transparency. 119--133.",
      "doi": ""
    },
    {
      "text": "Isil Erel, Lea H. Stern, Chenhao Tan, and Michael S. Weisbach. 2018. Research: Could Machine Learning Help Companies Select Better Board Directors? Harvard Business Review (April 2018). https://hbr.org/2018/04/research-could-machinelearning-help-companies-select-better-board-directors.",
      "doi": ""
    },
    {
      "text": "Justin Esarey, Timothy C Salmon, and Charles Barrilleaux. 2012. What Motivates Political Preferences? Self-Interest, Ideology, and Fairness in a Laboratory Democracy. Economic Inquiry 50, 3 (2012), 604--624.",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee Rickman, Kevin Hamilton, and Alex Kirlik. 2016. First I like it, then I hide it: Folk theories of social feeds. In Proceedings of the 2016 CHI conference on human factors in computing systems. ACM, 2371--2382.",
      "doi": "10.1145/2858036.2858494"
    },
    {
      "text": "Motahhare Eslami, Kristen Vaccaro, Min Kyung Lee, Amit Elazari Bar On, Eric Gilbert, and Karrie Karahalios. 2019. User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 494.",
      "doi": "10.1145/3290605.3300724"
    },
    {
      "text": "Robert Folger and Jerald Greenberg. 1985. Procedural justice: An interpretive analysis of personnel systems. (1985).",
      "doi": ""
    },
    {
      "text": "Nikolaus Franke, Peter Keinz, and Katharina Klausberger. 2013. ?Does this sound like a fair deal?\": Antecedents and consequences of fairness expectations in the individual's decision to participate in firm innovation. Organization science 24, 5 (2013), 1495--1516.",
      "doi": ""
    },
    {
      "text": "Megan French and Jeff Hancock. 2017. What's the folk theory? Reasoning about cyber-social systems. Available at SSRN (2017). https://papers.ssrn.com/abstract=2910571",
      "doi": ""
    },
    {
      "text": "Stephen W Gilliland. 1993. The perceived fairness of selection systems: An organizational justice perspective. Academy of management review 18, 4 (1993), 694--734.",
      "doi": ""
    },
    {
      "text": "Nina Grgic-Hlaca, Elissa M Redmiles, Krishna P Gummadi, and Adrian Weller. 2018. Human perceptions of fairness in algorithmic decision making: A case study of criminal risk prediction. In Proceedings of the 2018 World Wide Web Conference. International World Wide Web Conferences Steering Committee, 903--912.",
      "doi": "10.1145/3178876.3186138"
    },
    {
      "text": "Moritz Hardt, Eric Price, Nati Srebro, and others. 2016. Equality of opportunity in supervised learning. In Advances in neural information processing systems. 3315--3323.",
      "doi": ""
    },
    {
      "text": "Lisa Anne Hendricks, Zeynep Akata, Marcus Rohrbach, Jeff Donahue, Bernt Schiele, and Trevor Darrell. 2016. Generating visual explanations. In European Conference on Computer Vision. Springer, 3--19.",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Jennifer Wortman Vaughan, Hal Daum\u00e9 III, Miro Dudik, and Hanna Wallach. 2019. Improving fairness in machine learning systems: What do industry practitioners need?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 600.",
      "doi": "10.1145/3290605.3300830"
    },
    {
      "text": "George C Homans. 1974. Social behavior: Its elementary forms. (1974).",
      "doi": ""
    },
    {
      "text": "Youyang Hou, Cliff Lampe, Maximilian Bulinski, and James J Prescott. 2017. Factors in Fairness and Emotion in Online Case Resolution Systems. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 2511--2522.",
      "doi": "10.1145/3025453.3025968"
    },
    {
      "text": "Dan Hurley. 2018. Can an Algorithm Tell When Kids Are in Danger? The New York Times (Jan. 2018). https://www.nytimes.com/2018/01/02/magazine/ can-an-algorithm-tell-when-kids-are-in-danger.html",
      "doi": ""
    },
    {
      "text": "Joichi Ito. 2016. Society in the Loop Artificial Intelligence. Joi Ito's Web (June 2016). DOI: http://dx.doi.org/10.31859/20160623.1937",
      "doi": ""
    },
    {
      "text": "Anil Kalhan. 2013. Immigration policing and federalism through the lens of technology, surveillance, and privacy. Ohio St. LJ 74 (2013), 1105.",
      "doi": ""
    },
    {
      "text": "Ren\u00e9 F Kizilcec. 2016. How much information?: Effects of transparency on trust in an algorithmic interface. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 2390--2395.",
      "doi": "10.1145/2858036.2858402"
    },
    {
      "text": "Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. 2017. Human decisions and machine predictions. The quarterly journal of economics 133, 1 (2017), 237--293.",
      "doi": ""
    },
    {
      "text": "Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent trade-offs in the fair determination of risk scores. arXiv preprint arXiv:1609.05807 (2016).",
      "doi": ""
    },
    {
      "text": "Pang Wei Koh and Percy Liang. 2017. Understanding black-box predictions via influence functions. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1885--1894.",
      "doi": "10.5555/3305381.3305576"
    },
    {
      "text": "Nathan R Kuncel, David M Klieger, and Deniz S Ones. 2014. In hiring, algorithms beat instinct. Harvard business review 92, 5 (2014), 32. https://hbr.org/2014/05/in-hiring-algorithms-beat-instinct",
      "doi": ""
    },
    {
      "text": "Kai Lamertz. 2002. The social construction of fairness: Social influence and sense making in organizations. Journal of Organizational Behavior 23, 1 (2002), 19--37.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 1--16.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee and Su Baykal. 2017. Algorithmic mediation in group decisions: Fairness perceptions of algorithmically mediated vs. discussion-based social division. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing. ACM, 1035--1048.",
      "doi": "10.1145/2998181.2998230"
    },
    {
      "text": "Min Kyung Lee, Ji Tae Kim, and Leah Lizarondo. 2017. A human-centered approach to algorithmic services: Considerations for fair and motivating smart community service management that allocates donations to non-profit organizations. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 3365--3376.",
      "doi": "10.1145/3025453.3025884"
    },
    {
      "text": "Min Kyung Lee, Daniel Kusbit, Evan Metsky, and Laura Dabbish. 2015. Working with machines: The impact of algorithmic and data-driven management on human workers. In Proceedings of the 2015 CHI Conference on Human Factors in Computing Systems. ACM, 1603--1612.",
      "doi": "10.1145/2702123.2702548"
    },
    {
      "text": "Bruno Lepri, Nuria Oliver, Emmanuel Letouz\u00e9, Alex Pentland, and Patrick Vinck. 2018. Fair, transparent, and accountable algorithmic decision-making processes. Philosophy & Technology 31, 4 (2018), 611--627.",
      "doi": ""
    },
    {
      "text": "Melvin J Lerner. 1974. The justice motive:\"Equity\" and? parity\" among children. Journal of Personality and Social Psychology 29, 4 (1974), 539.",
      "doi": ""
    },
    {
      "text": "Brenda Major and Kay Deaux. 1982. Individual differences in justice behavior. In Equity and justice in social behavior. Academic Press, 43--76.",
      "doi": ""
    },
    {
      "text": "Louise Matsakis. 2016. The Unknown, Poorly Paid Labor Force Powering Academic Research. (Feb. 2016). https://motherboard.vice.com/en_us/article/8q8ggb/ the-unknown-poorly-paid-labor-force-powering-academic-research",
      "doi": ""
    },
    {
      "text": "Aditya Krishna Menon and Robert C Williamson. 2018. The cost of fairness in binary classification. In Conference on Fairness, Accountability and Transparency. 107--118.",
      "doi": ""
    },
    {
      "text": "Alex P. Miller. 2018. Want Less-Biased Decisions? Use Algorithms. Harvard Business Review (July 2018). https://hbr.org/2018/07/ want-less-biased-decisions-use-algorithms",
      "doi": ""
    },
    {
      "text": "Carolina Moliner, Vicente Mart\u00ednez-Tur, Jos\u00e9 M Peir\u00f3, Jos\u00e9 Ramos, and Russell Cropanzano. 2013. Perceived Reciprocity and Well-Being at Work in Non-Professional Employees: Fairness or Self-Interest? Stress and Health 29, 1 (2013), 31--39.",
      "doi": ""
    },
    {
      "text": "Diana C Mutz and Jeffery J Mondak. 1997. Dimensions of sociotropic behavior: Group-based judgements of fairness and well-being. American Journal of Political Science (1997), 284--308.",
      "doi": ""
    },
    {
      "text": "Rupert W Nacoste. 1987. But do they care about fairness? The dynamics of preferential treatment and minority interest. Basic and Applied Social Psychology 8, 3 (1987), 177--191.",
      "doi": ""
    },
    {
      "text": "Clifford Nass and Youngme Moon. 2000. Machines and mindlessness: Social responses to computers. Journal of social issues 56, 1 (2000), 81--103.",
      "doi": "10.1111/0022-4537.00153"
    },
    {
      "text": "Rachel O'Dwyer. 2018. Algorithms are making the same mistakes as humans assessing credit scores. (2018). https://qz.com/1276781/algorithms-are-making-thesame-mistakes-assessing-credit-scores-that-humansdid-a-century-ago/.",
      "doi": ""
    },
    {
      "text": "Emma Pierson. 2017. Demographics and discussion influence views on algorithmic fairness. arXiv preprint arXiv:1712.09124 (2017).",
      "doi": ""
    },
    {
      "text": "Carrie Pomeroy. 2019. How community members in Ramsey County stopped a big-data plan from flagging students as at-risk. (Feb. 2019). https://www.tcdailyplanet.net/how-communitymembers-in-ramsey-county-stopped-a-big-data-planfrom-flagging-students-as-at-risk/.",
      "doi": ""
    },
    {
      "text": "Forough Poursabzi-Sangdeh, Daniel G Goldstein, Jake M Hofman, Jennifer Wortman Vaughan, and Hanna Wallach. 2018. Manipulating and measuring model interpretability. arXiv preprint arXiv:1802.07810 (2018).",
      "doi": ""
    },
    {
      "text": "Iyad Rahwan. 2018. Society-in-the-loop: programming the algorithmic social contract. Ethics and Information Technology 20, 1 (2018), 5--14.",
      "doi": "10.1007/s10676-017-9430-8"
    },
    {
      "text": "Byron Reeves and Clifford Ivar Nass. 1996. The media equation: How people treat computers, television, and new media like real people and places. Cambridge university press.",
      "doi": "10.5555/236605"
    },
    {
      "text": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 1135--1144.",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Lauren A Rivera. 2012. Hiring as cultural matching: The case of elite professional service firms. American sociological review 77, 6 (2012), 999--1022.",
      "doi": ""
    },
    {
      "text": "Ismael Rodriguez-Lara and Luis Moreno-Garrido. 2012. Self-interest and fairness: self-serving choices of justice principles. Experimental Economics 15, 1 (2012), 158--175.",
      "doi": ""
    },
    {
      "text": "E Elisabet Rutstr\u00f6m and Melonie B Williams. 2000. Entitlements and fairness:: an experimental study of distributive preferences. Journal of Economic Behavior & Organization 43, 1 (2000), 75--89.",
      "doi": ""
    },
    {
      "text": "Gunar Schirner, Deniz Erdogmus, Kaushik Chowdhury, and Taskin Padir. 2013. The future of human-in-the-loop cyber-physical systems. Computer 1 (2013), 36--45.",
      "doi": "10.1109/MC.2013.31"
    },
    {
      "text": "Daniel B Shank. 2012. Perceived Justice and Reactions to Coercive Computers. In Sociological Forum, Vol. 27. Wiley Online Library, 372--391.",
      "doi": ""
    },
    {
      "text": "Linda J Skitka. 1999. Ideological and attributional boundaries on public compassion: Reactions to individuals and communities affected by a natural disaster. Personality and Social Psychology Bulletin 25, 7 (1999), 793--808.",
      "doi": ""
    },
    {
      "text": "Linda J Skitka, Jennifer Winquist, and Susan Hutchinson. 2003. Are outcome fairness and outcome favorability distinguishable psychological constructs? A meta-analytic review. Social Justice Research 16, 4 (2003), 309--341.",
      "doi": ""
    },
    {
      "text": "Megha Srivastava, Hoda Heidari, and Andreas Krause. 2019. Mathematical Notions vs. Human Perception of Fairness: A Descriptive Approach to Fairness for Machine Learning. arXiv preprint arXiv:1902.04783 (2019).",
      "doi": ""
    },
    {
      "text": "Meng-Jung Tsai, Ching-Yeh Wang, and Po-Fen Hsu. 2019. Developing the computer programming self-efficacy scale for computer literacy education. Journal of Educational Computing Research 56, 8 (2019), 1345--1360.",
      "doi": ""
    },
    {
      "text": "Tom R Tyler. 2000. Social justice: Outcome and procedure. International journal of psychology 35, 2 (2000), 117--125.",
      "doi": ""
    },
    {
      "text": "Ilja Van Beest and Eric Van Dijk. 2007. Self-interest and fairness in coalition formation: A social utility approach to understanding partner selection and payoff allocations in groups. European Review of Social Psychology 18, 1 (2007), 132--174.",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in high-stakes public sector decision-making. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 440.",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "Elaine Walster, G William Walster, and Ellen Berscheid. 1978. Equity: Theory and research. (1978).",
      "doi": ""
    },
    {
      "text": "Connie R Wanberg, Mark B Gavin, and Larry W Bunce. 1999. Perceived fairness of layoffs among individuals who have been laid off: A longitudinal study. Personnel Psychology 52, 1 (1999), 59--84.",
      "doi": ""
    },
    {
      "text": "Ann Wilkinson, Julia Roberts, and Alison E While. 2010. Construction of an instrument to measure student information and communication technology skills, experience and attitudes to e-learning. Computers in Human Behavior 26, 6 (2010), 1369--1376.",
      "doi": "10.1016/j.chb.2010.04.010"
    },
    {
      "text": "Haiyi Zhu, Bowen Yu, Aaron Halfaker, and Loren Terveen. 2018. Value-sensitive algorithm design: Method, case study, and lessons. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 194.",
      "doi": "10.1145/3274463"
    }
  ]
}