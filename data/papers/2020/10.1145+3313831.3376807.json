{
  "doi": "10.1145/3313831.3376807",
  "title": "CheXplain: Enabling Physicians to Explore and Understand Data-Driven, AI-Enabled Medical Imaging Analysis",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2020,
  "badges": [],
  "abstract": "The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain \u2014 a system that enables physicians to explore and understand AI-enabled chest X-ray analysis: (i) a paired survey between referring physicians and radiologists reveals whether, when, and what kinds of explanations are needed; (ii) a low-fidelity prototype co-designed with three physicians formulates eight key features; and (iii) a high-fidelity prototype evaluated by another six physicians provides detailed summative insights on how each feature enables the exploration and understanding of AI. We summarize by discussing recommendations for future work to design and implement explainable medical AI systems that encompass four recurring themes: motivation, constraint, explanation, and justification.",
  "authors": [
    {
      "name": "Yao Xie",
      "institution": "University of California, Los Angeles, Los Angeles, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659529208",
      "orcid": "missing"
    },
    {
      "name": "Melody Chen",
      "institution": "University of California, Los Angeles, Los Angeles, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659528938",
      "orcid": "missing"
    },
    {
      "name": "David Kao",
      "institution": "University of California, Los Angeles, Los Angeles, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659527577",
      "orcid": "missing"
    },
    {
      "name": "Ge Gao",
      "institution": "University of Maryland, College Park, MD, USA",
      "img": "/do/10.1145/contrib-81498646640/rel-imgonly/ge_photo.png",
      "acmid": "81498646640",
      "orcid": "0000-0003-2733-2681"
    },
    {
      "name": "Xiang 'Anthony' Chen",
      "institution": "University of California, Los Angeles, Los Angeles, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659468135",
      "orcid": "0000-0002-8527-1744"
    }
  ],
  "references": [
    {
      "text": "Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian Y. Lim, and Mohan Kankanhalli. 2018. Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, NY, NY, USA, 582:1--582:18.",
      "doi": ""
    },
    {
      "text": "Acr. 2010. ACR Practice Guideline for Communication of Diagnostic Imaging Findings. 1076, Revised 2008 (2010), 1--6.",
      "doi": ""
    },
    {
      "text": "Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. 2015. Vqa: Visual question answering. In Proceedings of the IEEE international conference on computer vision. 2425--2433.",
      "doi": "10.1109/ICCV.2015.279"
    },
    {
      "text": "G O Barnett, J J Cimino, J A Hupp, and E P Hoffer. 1987. DXplain. An evolving diagnostic decision-support system. JAMA 258, 1 (July 1987), 67--74.",
      "doi": ""
    },
    {
      "text": "Victoria Bellotti and Keith Edwards. 2001. Intelligibility and Accountability: Human Considerations in Context-Aware Systems. Human--Computer Interaction 16, 2--4 (Dec. 2001), 193--212.",
      "doi": "10.1207/S15327051HCI16234_05"
    },
    {
      "text": "Leonard Berlin. 2007. Communicating results of all radiologic examinations directly to patients: has the time come? AJR Am. J. Roentgenol. 189, 6 (Dec. 2007), 1275--1282.",
      "doi": ""
    },
    {
      "text": "O. Biran and C. Cotton. 2017. Explanation and justification in machine learning: A survey. IJCAI-17 Workshop on Explainable AI (XAI) (2017).",
      "doi": ""
    },
    {
      "text": "Jan ML Bosmans, Joost J Weyler, Arthur M De Schepper, and Paul M Parizel. 2011. The radiology report as seen by radiologists and referring clinicians: results of the COVER and ROVER surveys. Radiology 259, 1 (2011), 184--195.",
      "doi": ""
    },
    {
      "text": "A Bussone, S Stumpf, and D O'Sullivan. 2015. The Role of Explanations on Trust and Reliance in Clinical Decision Support Systems. In 2015 International Conference on Healthcare Informatics. 160--169.",
      "doi": ""
    },
    {
      "text": "Carrie J. Cai, Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel Smilkov, Martin Wattenberg, Fernanda Viegas, Greg S Corrado, Martin C Stumpe, and others. 2019. Human-centered tools for coping with imperfect algorithms during medical decision-making. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 4.",
      "doi": "10.1145/3290605.3300234"
    },
    {
      "text": "Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad. 2015. Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '15). ACM, NY, NY, USA, 1721--1730.",
      "doi": "10.1145/2783258.2788613"
    },
    {
      "text": "Neal J. Clinger, Tim B. Hunter, and Bruce J. Hillman. 1988. Radiology reporting: attitudes of referring physicians. Radiology 169, 3 (1988), 825--826.",
      "doi": ""
    },
    {
      "text": "Piotr Dabkowski and Yarin Gal. 2017. Real time image saliency for black box classifiers. In Advances in Neural Information Processing Systems. 6967--6976.",
      "doi": ""
    },
    {
      "text": "Anind K. Dey and Alan Newberger. 2009. Support for context-aware intelligibility and control. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 859--868.",
      "doi": ""
    },
    {
      "text": "Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Paishun Ting, Karthikeyan Shanmugam, and Payel Das. 2018. Explanations based on the missing: Towards contrastive explanations with pertinent negatives. In Advances in Neural Information Processing Systems. 592--603.",
      "doi": ""
    },
    {
      "text": "Nicholas Diakopoulos. 2016. Accountability in Algorithmic Decision Making. Commun. ACM 59, 2 (Jan. 2016), 56--62.",
      "doi": "10.1145/2844110"
    },
    {
      "text": "Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. 2014. DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. In International Conference on Machine Learning. jmlr.org, 647--655.",
      "doi": ""
    },
    {
      "text": "Yinpeng Dong, Hang Su, Jun Zhu, and Bo Zhang. 2017. Improving interpretability of deep neural networks with semantic information. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4306--4314.",
      "doi": ""
    },
    {
      "text": "Finale Doshi-Velez and Been Kim. 2017. Towards A Rigorous Science of Interpretable Machine Learning. (Feb. 2017).",
      "doi": ""
    },
    {
      "text": "Paul Dourish. 1995. Developing a reflective model of collaborative systems. ACM Trans. Comput. Hum. Interact. 2, 1 (March 1995), 40--63.",
      "doi": "10.1145/200968.200970"
    },
    {
      "text": "Wenjuan Fan, Jingnan Liu, Shuwan Zhu, and Panos M Pardalos. 2018. Investigating the impacting factors for the healthcare professionals to adopt artificial intelligence-based medical diagnosis support system (AIMDSS). Ann. Oper. Res. (March 2018).",
      "doi": ""
    },
    {
      "text": "M. Fieschi. 2013. Artificial Intelligence in Medicine: Expert Systems. Springer.",
      "doi": ""
    },
    {
      "text": "Harry W Fischer. 1983. Better communication between the referring physician and the radiologist. Radiology 146, 3 (1983), 845--845.",
      "doi": ""
    },
    {
      "text": "Ruth C Fong and Andrea Vedaldi. 2017. Interpretable explanations of black boxes by meaningful perturbation. In Proceedings of the IEEE International Conference on Computer Vision. 3429--3437.",
      "doi": ""
    },
    {
      "text": "J. Fox, D. Glasspool, D. Grecu, S Modgil, M South, and V Patkar. 2007. Argumentation-Based Inference and Decision Making--A Medical Perspective. IEEE Intell. Syst. 22, 6 (Nov. 2007), 34--41.",
      "doi": "10.1109/MIS.2007.102"
    },
    {
      "text": "Nicholas Frosst and Geoffrey Hinton. 2017. Distilling a Neural Network Into a Soft Decision Tree. (Nov. 2017).",
      "doi": ""
    },
    {
      "text": "Dimitris Gritzalis and Costas Lambrinoudakis. 2004. A security architecture for interconnecting health information systems. International Journal of Medical Informatics 73, 3 (2004), 305--309.",
      "doi": ""
    },
    {
      "text": "Tovi Grossman and George Fitzmaurice. 2010. ToolClips: An Investigation of Contextual Video Assistance for Functionality Understanding. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10). ACM, NY, NY, USA, 1515--1524.",
      "doi": "10.1145/1753326.1753552"
    },
    {
      "text": "R Gunderman, W. T. Ambrosius, and M. Cohen. 2000. Radiology reporting in an academic children's hospital: what referring physicians think. Pediatr. Radiol. 30, 5 (May 2000), 307--314.",
      "doi": ""
    },
    {
      "text": "Lisa Anne Hendricks, Zeynep Akata, Marcus Rohrbach, Jeff Donahue, Bernt Schiele, and Trevor Darrell. 2016. Generating visual explanations. In European Conference on Computer Vision. Springer, 3--19.",
      "doi": ""
    },
    {
      "text": "Lisa Anne Hendricks, Ronghang Hu, Trevor Darrell, and Zeynep Akata. 2018. Generating counterfactual explanations with natural language. arXiv preprint arXiv:1806.09809 (2018).",
      "doi": ""
    },
    {
      "text": "Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, and Others. 2019. Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. In Thirty-Third AAAI Conference on Artificial Intelligence. aaai.org.",
      "doi": ""
    },
    {
      "text": "W. James Murdoch and Arthur Szlam. 2017. Automatic Rule Extraction from Long Short Term Memory Networks. (Feb. 2017).",
      "doi": ""
    },
    {
      "text": "Saurabh Jha and Eric J Topol. 2016. Adapting to Artificial Intelligence: Radiologists and Pathologists as Information Specialists. JAMA 316, 22 (Dec. 2016), 2353--2354.",
      "doi": ""
    },
    {
      "text": "Fei Jiang, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen, and Yongjun Wang. 2017. Artificial intelligence in healthcare: past, present and future. Stroke Vasc Neurol 2, 4 (Dec. 2017), 230--243.",
      "doi": ""
    },
    {
      "text": "Saif Khairat, David Marc, William Crosby, and Ali Al Sanousi. 2018. Reasons For Physicians Not Adopting Clinical Decision Support Systems: Critical Analysis. JMIR Med Inform 6, 2 (April 2018), e24.",
      "doi": ""
    },
    {
      "text": "Charles Kilhenny. 1972. Improving communications between team physician and radiologist. (1972).",
      "doi": ""
    },
    {
      "text": "Ajay Kohli and Saurabh Jha. 2018. Why CAD Failed in Mammography. (2018).",
      "doi": ""
    },
    {
      "text": "Josua Krause, Adam Perer, and Kenney Ng. 2016. Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI '16). ACM, NY, NY, USA, 5686--5697.",
      "doi": "10.1145/2858036.2858529"
    },
    {
      "text": "Zachary C. Lipton. 2016. The Mythos of Model Interpretability. (June 2016).",
      "doi": ""
    },
    {
      "text": "Tania Lombrozo. 2010. Causal--explanatory pluralism: How intentions, functions, and mechanisms influence causal ascriptions. Cogn. Psychol. 61, 4 (Dec. 2010), 303--332.",
      "doi": ""
    },
    {
      "text": "Tania Lombrozo and Susan Carey. 2006. Functional explanation and the function of explanation. Cognition 99, 2 (March 2006), 167--204.",
      "doi": ""
    },
    {
      "text": "Rodrigues Mark and Qureshi Zeshan. 2017. The Unofficial Guide to Radiology: Chest, Abdominal and Orthopaedic X Rays, Plus CTs, MRIs and Other Important Modalities: Core Radiology Curriculum. (2017).",
      "doi": ""
    },
    {
      "text": "D Douglas Miller and Eric W Brown. 2018. Artificial Intelligence in Medical Practice: The Question to the Answer? Am. J. Med. 131, 2 (Feb. 2018), 129--133.",
      "doi": ""
    },
    {
      "text": "Tim Miller. 2019. Explanation in artificial intelligence: Insights from the social sciences. Artif. Intell. 267 (2019), 1--38.",
      "doi": "10.1145/1824760.1824761"
    },
    {
      "text": "Travis B. Murdoch and Allan S. Detsky. 2013. The inevitable application of big data to health care. JAMA 309, 13 (April 2013), 1351--1352.",
      "doi": ""
    },
    {
      "text": "Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Bernt Schiele, Trevor Darrell, and Marcus Rohrbach. 2016. Attentive explanations: Justifying decisions and pointing to the evidence. arXiv preprint arXiv:1612.04757 (2016).",
      "doi": ""
    },
    {
      "text": "Seong Ho Park and Kyunghwa Han. 2018. Methodologic Guide for Evaluating Clinical Performance and Effect of Artificial Intelligence Technology for Medical Diagnosis and Prediction. Radiology 286, 3 (March 2018), 800--809.",
      "doi": ""
    },
    {
      "text": "Gabri\u00eblle Ras, Marcel van Gerven, and Pim Haselager. 2018. Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges. In Explainable and Interpretable Models in Computer Vision and Machine Learning, Hugo Jair Escalante, Sergio Escalera, Isabelle Guyon, Xavier Bar\u00f3, Ya?mur G\u00fc\u00e7l\u00fct\u00fcrk, Umut G\u00fc\u00e7l\u00fc, and Marcel van Gerven (Eds.). Springer International Publishing, Cham, 19--36.",
      "doi": ""
    },
    {
      "text": "Raymond Reiter. 1987. A theory of diagnosis from first principles. Artif. Intell. 32, 1 (April 1987), 57--95.",
      "doi": "10.1016/0004-3702%2887%2990062-2"
    },
    {
      "text": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why Should I Trust You?: Explaining the Predictions of Any Classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1135--1144.",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Timothy Lillicrap. 2017. A simple neural network module for relational reasoning. In Advances in Neural Information Processing Systems 30, I Guyon, U V Luxburg, S Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 4967--4976.",
      "doi": ""
    },
    {
      "text": "Sectra. 2013. How radiology can improve communication with referring physicians. June (2013).",
      "doi": ""
    },
    {
      "text": "Ramprasaath R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, and Dhruv Batra. 2016. Grad-CAM: Why did you say that? arXiv preprint arXiv:1611.07450 (2016).",
      "doi": ""
    },
    {
      "text": "Hoo-Chang Shin, Kirk Roberts, Le Lu, Dina Demner-Fushman, Jianhua, and Ronald M Summers. 2016. Learning to read chest x-rays: Recurrent neural cascade model for automated image annotation. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2497--2506.",
      "doi": ""
    },
    {
      "text": "Ben Shneiderman. 2016. Opinion: The dangers of faulty, biased, or malicious algorithms requires independent oversight. Proc. Natl. Acad. Sci. U. S. A. 113, 48 (Nov. 2016), 13538--13540.",
      "doi": ""
    },
    {
      "text": "Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017. Learning Important Features Through Propagating Activation Differences. In Proceedings of the 34th International Conference on Machine Learning - Volume 70 (ICML'17). JMLR.org, Sydney, NSW, Australia, 3145--3153.",
      "doi": ""
    },
    {
      "text": "Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034 (2013).",
      "doi": ""
    },
    {
      "text": "William R Swartout. 1983. Xplain: A system for creating and explaining expert consulting programs. Technical Report. UNIVERSITY OF SOUTHERN CALIFORNIA MARINA DEL REY INFORMATION SCIENCES INST.",
      "doi": ""
    },
    {
      "text": "R. Takemiya, S. Kido, Y. Hirano, and S. Mabu. 2019. Detection of pulmonary nodules on chest x-ray images using R-CNN. In International Forum on Medical Imaging in Asia 2019, Vol. 11050. International Society for Optics and Photonics, 110500W.",
      "doi": ""
    },
    {
      "text": "Jacob Thebault-Spieker, Loren Terveen, and Brent Hecht. 2017. Toward a Geographic Understanding of the Sharing Economy: Systemic Biases in UberX and TaskRabbit. ACM Trans. Comput.-Hum. Interact. 24, 3 (April 2017), 21:1--21:40.",
      "doi": "10.1145/3058499"
    },
    {
      "text": "Carlos Valls. 2001. Pitfalls of the Vague Radiology Report. (2001).",
      "doi": ""
    },
    {
      "text": "William van Melle, Edward H Shortliffe, and Bruce G Buchanan. 1984. EMYCIN: A knowledge engineer's tool for constructing rule-based expert systems. Rule-based expert systems: The MYCIN experiments of the Stanford Heuristic Programming Project (1984), 302--313.",
      "doi": ""
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian Y Lim. 2019. Designing Theory-Driven User-Centric Explainable AI. (2019).",
      "doi": ""
    },
    {
      "text": "Tianfu Wu, Wei Sun, Xilai Li, Xi Song, and Bo Li. 2017. Towards Interpretable R-CNN by Unfolding Latent Structures. (Nov. 2017).",
      "doi": ""
    },
    {
      "text": "Qian Yang, John Zimmerman, Aaron Steinfeld, Lisa Carey, and James F. Antaki. 2016. Investigating the Heart Pump Implant Decision Process: Opportunities for Decision Support Tools to Help. ACM Trans. Comput. Hum. Interact. 2016 (May 2016), 4477--4488.",
      "doi": ""
    },
    {
      "text": "Xie Yao, Ge Gao, and Xiang 'anthony' Chen. 2019. Outlining the Design Space of Explainable Intelligent Systems for Medical Diagnosis. (Feb. 2019).",
      "doi": ""
    },
    {
      "text": "Matthew D. Zeiler and Rob Fergus. 2014. Visualizing and Understanding Convolutional Networks. In Computer Vision -- ECCV 2014. Springer International Publishing, 818--833.",
      "doi": ""
    },
    {
      "text": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. 2017. Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Stroudsburg, PA, USA, 2979--2989.",
      "doi": ""
    },
    {
      "text": "Qiao Zheng, Herv\u00e9 Delingette, and Nicholas Ayache. 2019. Explainable cardiac pathology classification on cine MRI with motion characterization by semi-supervised learning of apparent flow. Med. Image Anal. 56 (Aug. 2019), 80--95.",
      "doi": ""
    },
    {
      "text": "Luisa M. Zintgraf, Taco S. Cohen, Tameem Adel, and Max Welling. 2017. Visualizing Deep Neural Network Decisions: Prediction Difference Analysis. (Feb. 2017).",
      "doi": ""
    }
  ]
}