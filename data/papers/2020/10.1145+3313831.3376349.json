{
  "doi": "10.1145/3313831.3376349",
  "title": "Explore, Create, Annotate: Designing Digital Drawing Tools with Visually Impaired People",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2020,
  "badges": [],
  "abstract": "People often use text in their drawings to communicate their ideas. For visually impaired people, adding textual information to tactile graphics is challenging. Labeling in braille is a laborious process and clutters the drawings. Audio labels provide an alternative way to add text. However, digital drawing tools for visually impaired people have not examined the use of audio for creating labels. We conducted a study comprising three tasks with 11 visually impaired adults. Our goal was to understand how participants explored and created labeled tactile graphics (both braille and audio), and their interaction preferences. We find that audio labels were quicker to use and easier to create. However, braille labels enabled flexible exploration strategies. We also find that participants preferred multimodal interaction commands, and report hand postures and movements observed during the drawing process for designing recognizable interactions. Based on our findings, we derive design implications for digital drawing tools.",
  "tags": [
    "drawing applications",
    "tactile graphics",
    "blind",
    "accessibility"
  ],
  "authors": [
    {
      "name": "Maulishree Pandey",
      "institution": "University of Michigan - Ann Arbor, Ann Arbor, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659281805",
      "orcid": "missing"
    },
    {
      "name": "Hariharan Subramonyam",
      "institution": "University of Michigan - Ann Arbor, Ann Arbor, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658702532",
      "orcid": "0000-0002-3450-0447"
    },
    {
      "name": "Brooke Sasia",
      "institution": "California Polytechnic State University, San Luis Obispo, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659529662",
      "orcid": "missing"
    },
    {
      "name": "Steve Oney",
      "institution": "University of Michigan - Ann Arbor, Ann Arbor, MI, USA",
      "img": "/do/10.1145/contrib-81453662914/rel-imgonly/81453662914.jpg",
      "acmid": "81453662914",
      "orcid": "0000-0002-5823-1499"
    },
    {
      "name": "Sile O'Modhrain",
      "institution": "University of Michigan - Ann Arbor, Ann Arbor, MI, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100106087",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "2012. Guidelines and Standards for Tactile Graphics, 2010. (Feb 2012). http://www.brailleauthority.org/tg/web-manual/index.html",
      "doi": ""
    },
    {
      "text": "2013. National Federation of the Blind Resolutions for 2013. (Aug 2013). https://nfb.org/images/nfb/publications/bm/bm13/bm1308/bm130813.htm",
      "doi": ""
    },
    {
      "text": "2019. TouchGraphics - Tactile Design for Universal Access. http://touchgraphics.com/. (2019). Accessed: May, 2019.",
      "doi": ""
    },
    {
      "text": "2019. ViewPlus - Delivering Sense Ability. https://viewplus.com/. (2019). Accessed: May, 2019.",
      "doi": ""
    },
    {
      "text": "Frances K Aldrich and Linda Sheppard. 2001. Tactile graphics in school education: perspectives from pupils. British Journal of Visual Impairment 19, 2 (2001), 69--73.",
      "doi": ""
    },
    {
      "text": "Catherine M Baker, Lauren R Milne, Jeffrey Scofield, Cynthia L Bennett, and Richard E Ladner. 2014. Tactile graphics with a voice: using QR codes to access text in tactile graphics. In Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility. ACM, 75--82.",
      "doi": "10.1145/2661334.2661366"
    },
    {
      "text": "Sandra Bardot, Marcos Serrano, Bernard Oriola, and Christophe Jouffrais. 2017. Identifying How Visually Impaired People Explore Raised-line Diagrams to Improve the Design of Touch Interfaces. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI '17). ACM, NY, NY, USA, 550--555. DOI: http://dx.doi.org/10.1145/3025453.3025582",
      "doi": "10.1145/3025453.3025582"
    },
    {
      "text": "Jens Bornschein, Denise Bornschein, and Gerhard Weber. 2018a. Blind Pictionary: Drawing Application for Blind Users. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems (CHI EA '18). ACM, NY, NY, USA, Article D117, 4 pages. DOI: http://dx.doi.org/10.1145/3170427.3186487",
      "doi": "10.1145/3170427.3186487"
    },
    {
      "text": "Jens Bornschein, Denise Bornschein, and Gerhard Weber. 2018b. Comparing Computer-Based Drawing Methods for Blind People with Real-Time Tactile Feedback. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 115.",
      "doi": "10.1145/3173574.3173689"
    },
    {
      "text": "Jens Bornschein and Gerhard Weber. 2017. Digital Drawing Tools for Blind Users: A State-of-the-Art and Requirement Analysis. In Proceedings of the 10th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA '17). ACM, NY, NY, USA, 21--28. DOI: http://dx.doi.org/10.1145/3056540.3056542",
      "doi": "10.1145/3056540.3056542"
    },
    {
      "text": "Anke Brock and Christophe Jouffrais. 2015. Interactive Audio-tactile Maps for Visually Impaired People. SIGACCESS Access. Comput. 113 (Nov. 2015), 3--12. DOI: http://dx.doi.org/10.1145/2850440.2850441",
      "doi": ""
    },
    {
      "text": "Anke M. Brock, Philippe Truillet, Bernard Oriola, Delphine Picard, and Christophe Jouffrais. 2015. Interactivity Improves Usability of Geographic Maps for Visually Impaired People. Hum.-Comput. Interact. 30, 2 (March 2015), 156--194. DOI: http://dx.doi.org/10.1080/07370024.2014.924412",
      "doi": ""
    },
    {
      "text": "Julien Epps, Serge Lichman, and Mike Wu. 2006. A study of hand shape use in tabletop gesture interaction. In CHI'06 extended abstracts on human factors in computing systems. ACM, 748--753.",
      "doi": "10.1145/1125451.1125601"
    },
    {
      "text": "Silvia Fajardo Flores and Dominique Archambault. 2014. Multimodal interface for working with algebra: Interaction between the sighted and the non sighted. In International Conference on Computers for Handicapped Persons. Springer, 606--613.",
      "doi": ""
    },
    {
      "text": "Giovanni Fusco and Valerie S. Morash. 2015. The Tactile Graphics Helper: Providing Audio Clarification for Tactile Graphics Using Machine Vision. In Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility (ASSETS '15). ACM, NY, NY, USA, 97--106. DOI: http://dx.doi.org/10.1145/2700648.2809868",
      "doi": ""
    },
    {
      "text": "William Grussenmeyer and Eelke Folmer. 2016. AudioDraw: user preferences in non-visual diagram drawing for touchscreens. In Proceedings of the 13th Web for All Conference. ACM, 22.",
      "doi": "10.1145/2899475.2899483"
    },
    {
      "text": "Hesham M. Kamel and James A. Landay. 1999. The Integrated Communication 2 Draw (IC2D): A Drawing Program for the Visually Impaired. In CHI '99 Extended Abstracts on Human Factors in Computing Systems (CHI EA '99). ACM, NY, NY, USA, 222--223. DOI: http://dx.doi.org/10.1145/632716.632854",
      "doi": ""
    },
    {
      "text": "Hesham M. Kamel and James A. Landay. 2000. A Study of Blind Drawing Practice: Creating Graphical Information Without the Visual Channel. In Proceedings of the Fourth International ACM Conference on Assistive Technologies (Assets '00). ACM, NY, NY, USA, 34--41. DOI: http://dx.doi.org/10.1145/354324.354334",
      "doi": ""
    },
    {
      "text": "Shaun K Kane, Brian Frey, and Jacob O Wobbrock. 2013. Access lens: a gesture-based screen reader for real-world documents. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 347--350.",
      "doi": "10.1145/2470654.2470704"
    },
    {
      "text": "Shaun K Kane and Jacob O Wobbrock. 2011. Usable Gestures for Blind People: Understanding Preference and Performance. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 413--422.",
      "doi": "10.1145/1978942.1979001"
    },
    {
      "text": "John M Kennedy. 1980. Blind people recognizing and making haptic pictures. In D\u00fcrer's Devices: Beyond the Projective Model of Pictures. Elsevier, 263--303.",
      "doi": ""
    },
    {
      "text": "John M Kennedy. 1983. What can we learn about pictures from the blind? Blind people unfamiliar with pictures can draw in a universally recognizable outline style. American Scientist 71, 1 (1983), 19--26.",
      "doi": ""
    },
    {
      "text": "Martin Kurze. 1996. TDraw: a computer-based tactile drawing tool for blind people. In International ACM Conference on Assistive Technologies. 131--138.",
      "doi": "10.1145/228347.228368"
    },
    {
      "text": "Susan J Lederman and Roberta L Klatzky. 1987. Hand Movements: A Window into Haptic Object Recognition. Cognitive Psychology 19, 3 (1987), 342--368.",
      "doi": "10.1016/0010-0285%2887%2990008-"
    },
    {
      "text": "Susan J Lederman and Roberta L Klatzky. 1993. Extracting object properties through haptic exploration. Acta Psychologica 84, 1 (1993), 29--40.",
      "doi": ""
    },
    {
      "text": "Christophe Mignot, Claude Valot, and Noelle Carbonell. 1993. An experimental study of future \"natural\" multimodal human-computer interaction. In INTERACT'93 and CHI'93 Conference Companion on Human Factors in Computing Systems. ACM, 67--68.",
      "doi": "10.1145/259964.260075"
    },
    {
      "text": "Valerie Morash, Alliosn Collen Pensky, and Joshua Miele. 2012. The Tactile Map Open Stimulus Set for tactile and haptic research. Journal of Visual Impairment and Blindness 106, 8 (2012), 501.",
      "doi": ""
    },
    {
      "text": "Valerie S Morash, Allison E Connell Pensky, Steven TW Tseng, and Joshua A Miele. 2014. Effects of using multiple hands and fingers on haptic performance in individuals who are blind. Perception 43, 6 (2014), 569--588.",
      "doi": ""
    },
    {
      "text": "Meredith Ringel Morris. 2012. Web on the wall: insights from a multimodal interaction elicitation study. In Proceedings of the 2012 ACM international conference on Interactive tabletops and surfaces. ACM, 95--104.",
      "doi": "10.1145/2396636.2396651"
    },
    {
      "text": "Jo\u00e3o Oliveira, Tiago Guerreiro, Hugo Nicolau, Joaquim Jorge, and Daniel Gon\u00e7alves. 2011. BrailleType: unleashing braille over touch screen mobile phones. In IFIP Conference on Human-Computer Interaction. Springer, 100--107.",
      "doi": ""
    },
    {
      "text": "Scott Orlosky and Deborah Gilden. 1992. Simulating a full screen of braille. Journal of microcomputer applications 15, 1 (1992), 47--56.",
      "doi": "10.1016/0745-7138%2892%2990046-8"
    },
    {
      "text": "Delphine Picard, Jean-Michel Albaret, and Ana\u00efs Mazella. 2014. Haptic identification of raised-line drawings when categorical information is given: A comparison between visually impaired and sighted children. Psicologica: International Journal of Methodology and Experimental Psychology 35, 2 (2014), 277--290.",
      "doi": ""
    },
    {
      "text": "Delphine Picard and Samuel Lebaz. 2012. Identifying raised-line drawings by touch: A hard but not impossible task. Journal of Visual Impairment & Blindness 106, 7 (2012), 427--431.",
      "doi": ""
    },
    {
      "text": "Sandrine Robbe. 1998. An empirical study of speech and gesture interaction: Toward the definition of ergonomic design guidelines. In CHI 98 Conference Summary on Human Factors in Computing Systems. ACM, 349--350.",
      "doi": "10.1145/286498.286815"
    },
    {
      "text": "Sandrine Robbe-Reiter, No\u00eblle Carbonell, and Pierre Dauchy. 2000. Expression constraints in multimodal human-computer interaction. In Proceedings of the 5th international conference on Intelligent user interfaces. ACM, 225--228.",
      "doi": "10.1145/325737.325852"
    },
    {
      "text": "Francisco J. Romero-Ramirez, Rafael Mu\u00f1oz-Salinas, and Rafael Medina-Carnicer. 2018. Speeded up detection of squared fiducial markers. Image and vision Computing 76 (2018), 38--47.",
      "doi": ""
    },
    {
      "text": "Jeff Sauro and James R. Lewis. 2010. Average task times in usability tests: what to report?. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2347--2350.",
      "doi": ""
    },
    {
      "text": "Linda Sheppard and Frances K Aldrich. 2001. Tactile graphics in school education: perspectives from teachers. British Journal of Visual Impairment 19, 3 (2001), 93--97.",
      "doi": ""
    },
    {
      "text": "Lei Shi, Yuhang Zhao, and Shiri Azenkot. 2017. Designing interactions for 3D printed models with blind people. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 200--209.",
      "doi": "10.1145/3132525.3132549"
    },
    {
      "text": "Annie Vinter, Viviane Fernandes, Oriana Orlandi, and Pascal Morgan. 2012. Exploratory procedures of tactile images in visually impaired and blindfolded sighted children: How they relate to their consequent performance in drawing. Research in Developmental Disabilities 33, 6 (2012), 1819--1831.",
      "doi": ""
    },
    {
      "text": "Jacob O Wobbrock, Meredith Ringel Morris, and Andrew D Wilson. 2009. User-Defined Gestures for Surface Computing. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1083--1092.",
      "doi": "10.1145/1518701.1518866"
    },
    {
      "text": "Kim T Zebehazy and Adam P Wilton. 2014. Straight from the source: Perceptions of students with visual impairments about graphic use. Journal of Visual Impairment & Blindness 108, 4 (2014), 275--286.",
      "doi": ""
    }
  ]
}