{
  "doi": "10.1145/3313831.3376318",
  "title": "Studying the Effects of Cognitive Biases in Evaluation of Conversational Agents",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2020,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "Humans quite frequently interact with conversational agents. The rapid advancement in generative language modeling through neural networks has helped advance the creation of intelligent conversational agents. Researchers typically evaluate the output of their models through crowdsourced judgments, but there are no established best practices for conducting such studies. Moreover, it is unclear if cognitive biases in decision-making are affecting crowdsourced workers' judgments when they undertake these tasks. To investigate, we conducted a between-subjects study with 77 crowdsourced workers to understand the role of cognitive biases, specifically anchoring bias, when humans are asked to evaluate the output of conversational agents. Our results provide insight into how best to evaluate conversational agents. We find increased consistency in ratings across two experimental conditions may be a result of anchoring bias. We also determine that external factors such as time and prior experience in similar tasks have effects on inter-rater consistency.",
  "authors": [
    {
      "name": "Sashank Santhanam",
      "institution": "University of North Carolina at Charlotte, Charlotte, NC, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659349248",
      "orcid": "missing"
    },
    {
      "name": "Alireza Karduni",
      "institution": "University of North Carolina at Charlotte, Charlotte, NC, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659349355",
      "orcid": "0000-0001-9719-7513"
    },
    {
      "name": "Samira Shaikh",
      "institution": "University of North Carolina at Charlotte, Charlotte, NC, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81453608167",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Dan Ariely, George Loewenstein, and Drazen Prelec. 2003. Coherent arbitrariness\": Stable demand curves without stable preferences. The Quarterly journal of economics 118, 1 (2003), 73--106.",
      "doi": ""
    },
    {
      "text": "Nabiha Asghar, Pascal Poupart, Jesse Hoey, Xin Jiang, and Lili Mou. 2018. Affective Neural Response Generation. In European Conference on Information Retrieval. Springer, 154--166.",
      "doi": ""
    },
    {
      "text": "Bence Bago and Wim De Neys. 2017. Fast logic?: Examining the time course assumption of dual process theory. Cognition 158 (2017), 90--109.",
      "doi": ""
    },
    {
      "text": "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).",
      "doi": ""
    },
    {
      "text": "Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65--72.",
      "doi": ""
    },
    {
      "text": "Srinivas Bangalore and Owen Rambow. 2000. Corpus-based Lexical Choice in Natural Language Generation. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics (ACL '00). Association for Computational Linguistics, Stroudsburg, PA, USA, 464--471. DOI: http://dx.doi.org/10.3115/1075218.1075277",
      "doi": "10.3115/1075218.1075277"
    },
    {
      "text": "Ellen Gurman Bard, Dan Robertson, and Antonella Sorace. 1996. Magnitude estimation of linguistic acceptability. Language (1996), 32--68.",
      "doi": ""
    },
    {
      "text": "Hans Baumgartner and Jan-Benedict EM Steenkamp. 2001. Response styles in marketing research: A cross-national investigation. Journal of marketing research 38, 2 (2001), 143--156.",
      "doi": ""
    },
    {
      "text": "Anja Belz and Eric Kow. 2010. Comparing rating scales and preference judgements in language evaluation. In Proceedings of the 6th International Natural Language Generation Conference. Association for Computational Linguistics, 7--15.",
      "doi": "10.5555/1873738.1873743"
    },
    {
      "text": "Anja Belz and Eric Kow. 2011. Discrete vs. continuous rating scales for language evaluation in nlp. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2. Association for Computational Linguistics, 230--235.",
      "doi": "10.5555/2002736.2002785"
    },
    {
      "text": "Yoshua Bengio, R\u00e9jean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic language model. Journal of machine learning research 3, Feb (2003), 1137--1155.",
      "doi": "10.5555/944919.944966"
    },
    {
      "text": "Yevgeni Berzak, Yan Huang, Andrei Barbu, Anna Korhonen, and Boris Katz. 2016. Anchoring and Agreement in Syntactic Annotations. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Austin, Texas, 2215--2224. DOI: http://dx.doi.org/10.18653/v1/D16--1239",
      "doi": ""
    },
    {
      "text": "Antoine Bordes, Y-Lan Boureau, and Jason Weston. 2016. Learning end-to-end goal-oriented dialog. arXiv preprint arXiv:1605.07683 (2016).",
      "doi": ""
    },
    {
      "text": "Hongshen Chen, Zhaochun Ren, Jiliang Tang, Yihong Eric Zhao, and Dawei Yin. 2018. Hierarchical variational memory network for dialogue generation. In Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1653--1662.",
      "doi": "10.1145/3178876.3186077"
    },
    {
      "text": "Isaac Cho, Ryan Wesslen, Ali Karduni, Sashank Santhanam, Samira Shaikh, and Wenwen Dou. 2017. The Anchoring Effect in Decision-Making with Visual Analytics. In IEEE Conference on Visual Analytics Science and Technology (VAST).",
      "doi": ""
    },
    {
      "text": "Kenneth Mark Colby. 1975. Artificial paranoia: a computer simulation of paranoid process. Pergamon Press.",
      "doi": ""
    },
    {
      "text": "Evanthia Dimara, Steven Franconeri, Catherine Plaisant, Anastasia Bezerianos, and Pierre Dragicevic. 2018. A task-based taxonomy of cognitive biases for information visualization. IEEE transactions on visualization and computer graphics (2018).",
      "doi": ""
    },
    {
      "text": "Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2018. Wizard of Wikipedia: Knowledge-Powered Conversational agents. arXiv preprint arXiv:1811.01241 (2018).",
      "doi": ""
    },
    {
      "text": "Nouha Dziri, Ehsan Kamalloo, Kory Mathewson, and Osmar Zaiane. 2019. Evaluating Coherence in Dialogue Systems using Entailment. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 3806--3812. DOI: http://dx.doi.org/10.18653/v1/N19--1381",
      "doi": ""
    },
    {
      "text": "Nouha Dziri, Ehsan Kamalloo, Kory W Mathewson, and Osmar Zaiane. 2018. Augmenting Neural Response Generation with Context-Aware Topical Attention. arXiv preprint arXiv:1811.01063 (2018).",
      "doi": ""
    },
    {
      "text": "George Ellis. 2018. Cognitive Biases in Visualizations. In Springer International Publishing.",
      "doi": ""
    },
    {
      "text": "Adrian Furnham and Hua Chu Boo. 2011. A literature review of the anchoring effect. The Journal of Socio-Economics 40, 1 (2011), 35--42.",
      "doi": ""
    },
    {
      "text": "Albert Gatt and Emiel Krahmer. 2018. Survey of the State of the Art in Natural Language Generation: Core Tasks, Applications and Evaluation. J. Artif. Int. Res. 61, 1 (Jan. 2018), 65--170. http://dl.acm.org/citation.cfm?id=3241691.3241693",
      "doi": ""
    },
    {
      "text": "Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and Michel Galley. 2018. A knowledge-grounded neural conversation model. In Thirty-Second AAAI Conference on Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "T Gilovich, N Robert, and A Amos. 2001. Putting adjustment back into the anchoring and adjustment heuristic: Differential processing of self-generated and experimenterprovided anchors. Psychological Science (2001).",
      "doi": ""
    },
    {
      "text": "Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735--1780.",
      "doi": "10.1162/neco.1997.9.8.1735"
    },
    {
      "text": "Matthew Hoffman, Francis R Bach, and David M Blei. 2010. Online learning for latent dirichlet allocation. In advances in neural information processing systems. 856--864.",
      "doi": ""
    },
    {
      "text": "Daniel Kahneman. 2003. A perspective on judgment and choice: mapping bounded rationality. American psychologist 58, 9 (2003), 697.",
      "doi": ""
    },
    {
      "text": "Daniel Kahneman. 2016. 36 Heuristics and Biases. Scientists Making a Difference: One Hundred Eminent Behavioral and Brain Scientists Talk about Their Most Important Contributions (2016), 171.",
      "doi": ""
    },
    {
      "text": "Daniel Kahneman and Amos Tversky. 1972. Subjective probability: A judgment of representativeness. Cognitive psychology 3, 3 (1972), 430--454.",
      "doi": ""
    },
    {
      "text": "J Peter Kincaid, Robert P Fishburne Jr, Richard L Rogers, and Brad S Chissom. 1975. Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. (1975).",
      "doi": ""
    },
    {
      "text": "Svetlana Kiritchenko and Saif Mohammad. 2017. Best-Worst Scaling More Reliable than Rating Scales: A Case Study on Sentiment Intensity Annotation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, Vancouver, Canada, 465--470. DOI: http://dx.doi.org/10.18653/v1/P17--2074",
      "doi": ""
    },
    {
      "text": "Robert Kosara and Steve Haroz. 2018. Skipping the Replication Crisis in Visualization: Threats to Study Validity and How to Address Them. (2018).",
      "doi": ""
    },
    {
      "text": "J Richard Landis and Gary G Koch. 1977. The measurement of observer agreement for categorical data. biometrics (1977), 159--174.",
      "doi": ""
    },
    {
      "text": "Irene Langkilde-Geary and Kevin Knight. 2002. Halogen statistical sentence generator. In Proceedings of the ACL-02 Demonstrations Session. 102--103.",
      "doi": ""
    },
    {
      "text": "Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016a. A Diversity-Promoting Objective Function for Neural Conversation Models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, San Diego, California, 110--119. DOI: http://dx.doi.org/10.18653/v1/N16--1014",
      "doi": ""
    },
    {
      "text": "Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao. 2016b. Deep Reinforcement Learning for Dialogue Generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 1192--1202. DOI: http://dx.doi.org/10.18653/v1/D16--1127",
      "doi": ""
    },
    {
      "text": "Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao, and Asli Celikyilmaz. 2017. End-to-End Task-Completion Neural Dialogue Systems. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Asian Federation of Natural Language Processing, Taipei, Taiwan, 733--743. https://www.aclweb.org/anthology/I17--1074",
      "doi": ""
    },
    {
      "text": "Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. Text Summarization Branches Out (2004).",
      "doi": ""
    },
    {
      "text": "Zachary Lipton, Xiujun Li, Jianfeng Gao, Lihong Li, Faisal Ahmed, and Li Deng. 2018. Bbq-networks: Efficient exploration in deep reinforcement learning for task-oriented dialogue systems. In Thirty-Second AAAI Conference on Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2122--2132. DOI: http://dx.doi.org/10.18653/v1/D16--1230",
      "doi": ""
    },
    {
      "text": "Ryan Lowe, Michael Noseworthy, Iulian Vlad Serban, Nicolas Angelard-Gontier, Yoshua Bengio, and Joelle Pineau. 2017. Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Vancouver, Canada, 1116--1126. DOI: http://dx.doi.org/10.18653/v1/P17--1103",
      "doi": ""
    },
    {
      "text": "Susan W McRoy, Songsak Channarukul, and Syed S Ali. 2003. An augmented template-based approach to text realization. Natural Language Engineering 9, 4 (2003), 381--420.",
      "doi": "10.1017/S1351324903003188"
    },
    {
      "text": "Hongyuan Mei, Mohit Bansal, and Matthew R. Walter. 2017. Coherent Dialogue with Attention-Based Language Models. In Proceedings of the National Conference on Artificial Intelligence (AAAI). San Francisco, CA.",
      "doi": ""
    },
    {
      "text": "Jekaterina Novikova, Ondrej Dusek, Amanda Cercas Curry, and Verena Rieser. 2017. Why We Need New Evaluation Metrics for NLG. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Copenhagen, Denmark, 2241--2252. DOI: http://dx.doi.org/10.18653/v1/D17--1238",
      "doi": ""
    },
    {
      "text": "Jekaterina Novikova, Ondrej Dusek, and Verena Rieser. 2018. RankME: Reliable Human Ratings for Natural Language Generation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). Association for Computational Linguistics, New Orleans, Louisiana, 72--78. DOI: http://dx.doi.org/10.18653/v1/N18--2012",
      "doi": ""
    },
    {
      "text": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 311--318.",
      "doi": ""
    },
    {
      "text": "Howard Schuman and Stanley Presser. 1996. Questions and answers in attitude surveys: Experiments on question form, wording, and context. Sage.",
      "doi": ""
    },
    {
      "text": "Abigail See, Stephen Roller, Douwe Kiela, and Jason Weston. 2019. What makes a good conversation? How controllable attributes affect human judgments. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 1702--1723. DOI: http://dx.doi.org/10.18653/v1/N19--1170",
      "doi": ""
    },
    {
      "text": "Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C Courville, and Joelle Pineau. 2016. Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.. In AAAI, Vol. 16. 3776--3784.",
      "doi": "10.5555/3016387.3016435"
    },
    {
      "text": "Fabian Sperrle, Udo Schlegel, Mennatallah El-Assady, and Daniel Keim. 2019. Human Trust Modeling for Bias Mitigation in Artificial Intelligence. In ACM CHI 2019 Workshop: Where is the Human? Bridging the Gap Between AI and HCI.",
      "doi": ""
    },
    {
      "text": "Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. 3104--3112.",
      "doi": ""
    },
    {
      "text": "Zhiliang Tian, Rui Yan, Lili Mou, Yiping Song, Yansong Feng, and Dongyan Zhao. 2017. How to Make Context More Useful? An Empirical Study on Context-Aware Neural Conversational Models. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, Vancouver, Canada, 231--236. DOI: http://dx.doi.org/10.18653/v1/P17--2036",
      "doi": ""
    },
    {
      "text": "Amos Tversky and Daniel Kahneman. 1974. Judgment under uncertainty: Heuristics and biases. science 185, 4157 (1974), 1124--1131.",
      "doi": ""
    },
    {
      "text": "Kees van Deemter, Mari\u00ebt Theune, and Emiel Krahmer. 2005. Real vs. template-based natural language generation: a false opposition. Computational Linguistics 31, 1 (2005), 15--24.",
      "doi": "10.1162/0891201053630291"
    },
    {
      "text": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Gukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.",
      "doi": ""
    },
    {
      "text": "Anu Venkatesh, Chandra Khatri, Ashwin Ram, Fenfei Guo, Raefer Gabriel, Ashish Nagar, Rohit Prasad, Ming Cheng, Behnam Hedayatnia, Angeliki Metallinou, and others. 2018. On Evaluating and Comparing Conversational Agents. arXiv preprint arXiv:1801.03625 (2018).",
      "doi": ""
    },
    {
      "text": "Oriol Vinyals and Quoc Le. 2015. A neural conversational model. arXiv preprint arXiv:1506.05869 (2015).",
      "doi": ""
    },
    {
      "text": "Marilyn A Walker, Diane J Litman, Candace A Kamm, and Alicia Abella. 1997. PARADISE: A framework for evaluating spoken dialogue agents. In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics. Association for Computational Linguistics, 271--280.",
      "doi": ""
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian Y Lim. 2019. Designing Theory-Driven User-Centric Explainable AI. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 601.",
      "doi": "10.1145/3290605.3300831"
    },
    {
      "text": "Joseph Weizenbaum. 1966. ELIZA-a computer program for the study of natural language communication between man and machine. Commun. ACM 9, 1 (1966), 36--45.",
      "doi": "10.1145/365153.365168"
    },
    {
      "text": "R Wesslen, S Santhanam, A Karduni, I Cho, S Shaikh, and W Dou. 2019. Investigating Effects of Visual Anchors on Decision-Making about Misinformation. In Computer Graphics Forum, Vol. 38. Wiley Online Library, 161--171.",
      "doi": ""
    },
    {
      "text": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing Dialogue Agents: I have a dog, do you have pets too?. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Melbourne, Australia, 2204--2213. DOI: http://dx.doi.org/10.18653/v1/P18--1205",
      "doi": ""
    }
  ]
}