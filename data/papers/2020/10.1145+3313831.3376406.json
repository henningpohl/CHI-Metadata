{
  "doi": "10.1145/3313831.3376406",
  "title": "Evaluating Smartwatch-based Sound Feedback for Deaf and Hard-of-hearing Users Across Contexts",
  "published": "2020-04-23",
  "proctitle": "CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2020,
  "badges": [],
  "abstract": "We present a qualitative study with 16 deaf and hard of hearing (DHH) participants examining reactions to smartwatch-based visual + haptic sound feedback designs. In Part 1, we conducted a Wizard-of-Oz (WoZ) evaluation of three smartwatch feedback techniques (visual alone, visual + simple vibration, and visual + tacton) and investigated vibrational patterns (tactons) to portray sound loudness, direction, and identity. In Part 2, we visited three public or semi-public locations where we demonstrated sound feedback on the smartwatch in situ to examine contextual influences and explore sound filtering options. Our findings characterize uses for vibration in multimodal sound awareness, both for push notification and for immediately actionable sound information displayed through vibrational patterns (tactons). In situ experiences caused participants to request sound filtering - particularly to limit haptic feedback - as a method for managing soundscape complexity. Additional concerns arose related to learnability, possibility of distraction, and system trust. Our findings have implications for future portable sound awareness systems.",
  "tags": [
    "smartwatches",
    "sound awareness",
    "deaf and hard of hearing"
  ],
  "authors": [
    {
      "name": "Steven Goodman",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81464650547",
      "orcid": "0000-0002-7381-1942"
    },
    {
      "name": "Susanne Kirchner",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659527463",
      "orcid": "missing"
    },
    {
      "name": "Rose Guttman",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659366538",
      "orcid": "missing"
    },
    {
      "name": "Dhruv Jain",
      "institution": "University of Washington, Seatte, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658697222",
      "orcid": "missing"
    },
    {
      "name": "Jon Froehlich",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/do/10.1145/contrib-81331492504/rel-imgonly/81331492504.jpg",
      "acmid": "81331492504",
      "orcid": "0000-0001-8291-3353"
    },
    {
      "name": "Leah Findlater",
      "institution": "University of Washington, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100170743",
      "orcid": "0000-0002-5619-4452"
    }
  ],
  "references": [
    {
      "text": "Tanja Blascheck, Lonni Besancon, Anastasia Bezerianos, Bongshin Lee, and Petra Isenberg. 2019. Glanceable Visualization: Studies of Data Comparison Performance on Smartwatches. IEEE Trans. Vis. Comput. Graph. 25, 1 (January 2019), 630--640. DOI:https://doi.org/10.1109/TVCG.2018.2865142",
      "doi": "10.1109/TVCG.2018.2865142"
    },
    {
      "text": "Danielle Bragg, Nicholas Huynh, and Richard E Ladner. 2016. A Personalizable Mobile Sound Detector App Design for Deaf and Hard-of-Hearing Users. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '16), 3--13. DOI:https://doi.org/10.1145/2982142.2982171",
      "doi": "10.1145/2982142.2982171"
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qual. Res. Psychol. 3, 2 (2006), 77--101.",
      "doi": ""
    },
    {
      "text": "Stephen Brewster and Lorna M Brown. 2004. Tactons: Structured Tactile Messages for Non-visual Information Display. In Proceedings of the Fifth Conference on Australasian User Interface - Volume 28 (AUIC '04), 15--23.",
      "doi": "10.5555/976310.976313"
    },
    {
      "text": "Yang Chen. 2017. Visualizing Large Time-series Data on Very Small Screens. In EuroVis 2017 - Short Papers. DOI:https://doi.org/10.2312/eurovisshort.20171130",
      "doi": ""
    },
    {
      "text": "Mohammad I. Daoud, Mahmoud Al-Ashi, Fares Abawi, and Ala Khalifeh. 2015. In-house alert sounds detection and direction of arrival estimation to assist people with hearing difficulties. In 2015 IEEE/ACIS 14th International Conference on Computer and Information Science (ICIS), 297--302. DOI:https://doi.org/10.1109/ICIS.2015.7166609",
      "doi": ""
    },
    {
      "text": "Harvey Dillon. 2008. Hearing aids. Hodder Arnold.",
      "doi": ""
    },
    {
      "text": "Johan Engstr\u00f6m, Nina \u00c5berg, Emma Johansson, and Jakob Hammarb\u00e4ck. 2005. Comparison Between Visual and Tactile Signal Detection Tasks Applied to the Safety Assessment of In-Vehicle Information Systems. In Driving assessment 2005?: proceedings of the 3rd International Driving Symposium on Human Factors in Driver Assessment, Training, and Vehicle Design, 232--239. DOI:https://doi.org/10.17077/drivingassessment.1166",
      "doi": ""
    },
    {
      "text": "Leah Findlater, Bonnie Chinh, Dhruv Jain, Jon Froehlich, Raja Kushalnagar, and Angela Carey Lin. 2019. Deaf and Hard-of-hearing Individuals' Preferences for Wearable and Mobile Sound Awareness Technologies. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19), 1--13. DOI:https://doi.org/10.1145/3290605.3300276",
      "doi": "10.1145/3290605.3300276"
    },
    {
      "text": "Karyn L. Galvin, Jan Ginis, Robert S. C. Cowan, Peter J. Blamey, and Graeme M. Clark. 2001. A Comparison of a New Prototype Tickle TalkerTM with the Tactaid 7. Aust. New Zeal. J. Audiol. 23, 1 (May 2001), 18--36. DOI:https://doi.org/10.1375/audi.23.1.18.31095",
      "doi": ""
    },
    {
      "text": "Jort F. Gemmeke, Daniel P. W. Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R. Channing Moore, Manoj Plakal, and Marvin Ritter. 2017. Audio Set: An ontology and human-labeled dataset for audio events. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 776--780. DOI:https://doi.org/10.1109/ICASSP.2017.7952261",
      "doi": ""
    },
    {
      "text": "L. Giuliani, L. Brayda, S. Sansalone, S. Repetto, and M. Ricchetti. 2017. Evaluation of a complementary hearing aid for spatial sound segregation. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 221--225. DOI:https://doi.org/10.1109/ICASSP.2017.7952150",
      "doi": ""
    },
    {
      "text": "Benjamin M. Gorman. 2014. VisAural: A Wearable Sound-Localisation Device for People with Impaired Hearing. In Proceedings of the 16th International ACM SIGACCESS Conference on Computers & Accessibility (ASSETS '14), 337--338. DOI:https://doi.org/10.1145/2661334.2661410",
      "doi": "10.1145/2661334.2661410"
    },
    {
      "text": "J. Harkins, P. E. Tucker, N. Williams, and J. Sauro. 2010. Vibration Signaling in Mobile Devices for Emergency Alerting: A Study With Deaf Evaluators. J. Deaf Stud. Deaf Educ. 15, 4 (October 2010), 438--445. DOI:https://doi.org/10.1093/deafed/enq018",
      "doi": ""
    },
    {
      "text": "F. Wai-ling Ho-Ching, Jennifer Mankoff, and James A. Landay. 2003. Can You See What I Hear?: The Design and Evaluation of a Peripheral Sound Display for the Deaf. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '03), 161--168. DOI:https://doi.org/10.1145/642611.642641",
      "doi": ""
    },
    {
      "text": "InnoCaption. Real Time Mobile Captioning for Hearing Loss. Retrieved August 12, 2019 from https://www.innocaption.com/",
      "doi": ""
    },
    {
      "text": "Dhruv Jain, Leah Findlater, Jamie Gilkeson, Benjamin Holland, Ramani Duraiswami, Dmitry Zotkin, Christian Vogler, and Jon E Froehlich. 2015. Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15), 241--250. DOI:https://doi.org/10.1145/2702123.2702393",
      "doi": "10.1145/2702123.2702393"
    },
    {
      "text": "Dhruv Jain, Rachel Franz, Leah Findlater, Jackson Cannon, Raja Kushalnagar, and Jon Froehlich. 2018. Towards Accessible Conversations in a Mobile Context for People Who Are Deaf and Hard of Hearing. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '18), 81--92. DOI:https://doi.org/10.1145/3234695.3236362",
      "doi": "10.1145/3234695.3236362"
    },
    {
      "text": "Dhruv Jain, Angela Lin, Rose Guttman, Marcus Amalachandran, Aileen Zeng, Leah Findlater, and Jon Froehlich. 2019. Exploring Sound Awareness in the Home for People who are Deaf or Hard of Hearing. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI '19), 1--13. DOI:https://doi.org/10.1145/3290605.3300324",
      "doi": "10.1145/3290605.3300324"
    },
    {
      "text": "Yoshihiro Kaneko, Inho Chung, and Kenji Suzuki. 2013. Light-Emitting Device for Supporting Auditory Awareness of Hearing-Impaired People during Group Conversations. In 2013 IEEE International Conference on Systems, Man, and Cybernetics, 3567--3572. DOI:https://doi.org/10.1109/SMC.2013.608",
      "doi": "10.1109/SMC.2013.608"
    },
    {
      "text": "Hamed Ketabdar and Tim Polzehl. 2009. Tactile and visual alerts for deaf people by mobile phones. In Proceeding of the eleventh international ACM SIGACCESS conference on Computers and accessibility - ASSETS '09, 253--254. DOI:https://doi.org/10.1145/1639642.1639701",
      "doi": ""
    },
    {
      "text": "Ki-Won Kim, Jung-Woo Choi, and Yang-Hann Kim. 2013. An Assistive Device for Direction Estimation of a Sound Source. Assist. Technol. 25, 4 (October 2013), 216--221. DOI:https://doi.org/10.1080/10400435.2013.768718",
      "doi": ""
    },
    {
      "text": "Raja S. Kushalnagar, Gary W. Behm, Joseph S. Stanislow, and Vasu Gupta. 2014. Enhancing caption accessibility through simultaneous multimodal information. In Proceedings of the 16th International ACM SIGACCESS Conference on Computers & Accessibility (ASSETS '14), 185--192. DOI:https://doi.org/10.1145/2661334.2661381",
      "doi": "10.1145/2661334.2661381"
    },
    {
      "text": "Seungyon \"Claire\" Lee and Thad Starner. 2010. BuzzWear: Alert Perception in Wearable Tactile Displays on the Wrist. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '10), 433--442. DOI:https://doi.org/10.1145/1753326.1753392",
      "doi": "10.1145/1753326.1753392"
    },
    {
      "text": "Live Caption. Live Caption. Retrieved August 12, 2019 from http://www.livecaptionapp.com/",
      "doi": ""
    },
    {
      "text": "Patrizia Marti, Iolanda Iacono, and Michele Tittarelli. 2018. Experiencing sound through interactive jewellery and fashion accessories. In Congress of the International Ergonomics Association, 1382--1391.",
      "doi": ""
    },
    {
      "text": "Tara Matthews, Scott Carter, Carol Pai, Janette Fong, and Jennifer Mankoff. 2006. Scribe4Me: Evaluating a Mobile Sound Transcription Tool for the Deaf. In Proceedings of the 8th International Conference on Ubiquitous Computing (UbiComp '06), 159--176. DOI:https://doi.org/10.1007/11853565_10",
      "doi": "10.1007/11853565_10"
    },
    {
      "text": "Tara Matthews, Janette Fong, F. Wai-Ling Ho-Ching, and Jennifer Mankoff. 2006. Evaluating non-speech sound visualizations for the deaf. Behav. Inf. Technol. 25, 4 (July 2006), 333--351. DOI:https://doi.org/10.1080/01449290600636488",
      "doi": ""
    },
    {
      "text": "Tara Matthews, Janette Fong, and Jennifer Mankoff. 2005. Visualizing non-speech sounds for the deaf. In Proceedings of the 7th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '05), 52. DOI:https://doi.org/10.1145/1090785.1090797",
      "doi": "10.1145/1090785.1090797"
    },
    {
      "text": "Matthias Mielke and Rainer Bruck. 2016. AUDIS wear: A smartwatch based assistive device for ubiquitous awareness of environmental sounds. In 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 5343--5347. DOI:https://doi.org/10.1109/EMBC.2016.7591934",
      "doi": ""
    },
    {
      "text": "Matthias Mielke and Rainer Br\u00fcck. 2015. A Pilot Study about the Smartwatch as Assistive Device for Deaf People. In Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility (ASSETS '15), 301--302. DOI:https://doi.org/10.1145/2700648.2811347",
      "doi": "10.1145/2700648.2811347"
    },
    {
      "text": "Matthias Mielke and Rainer Br\u00fcck. 2015. Design and evaluation of a smartphone application for non-speech sound awareness for people with hearing loss. In 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 5008--5011. DOI:https://doi.org/10.1109/EMBC.2015.7319516",
      "doi": ""
    },
    {
      "text": "Chulhong Min, Seungwoo Kang, Chungkuk Yoo, Jeehoon Cha, Sangwon Choi, Younghan Oh, and Junehwa Song. 2015. Exploring current practices for battery use and management of smartwatches. In Proceedings of the 2015 ACM International Symposium on Wearable Computers - ISWC '15, 11--18. DOI:https://doi.org/10.1145/2802083.2802085",
      "doi": "10.1145/2802083.2802085"
    },
    {
      "text": "Yi-Hao Peng, Ming-Wei Hsi, Paul Taele, Ting-Yu Lin, Po-En Lai, Leon Hsu, Tzu-chuan Chen, Te-Yen Wu, Yu-An Chen, Hsien-Hui Tang, and Mike Y Chen. 2018. SpeechBubbles: Enhancing Captioning Experiences for Deaf and Hard-of-Hearing People in Group Conversations. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18), 293:1--293:10. DOI:https://doi.org/10.1145/3173574.3173867",
      "doi": "10.1145/3173574.3173867"
    },
    {
      "text": "Erik Pescara, Alexander Wolpert, Matthias Budde, Andrea Schankin, and Michael Beigl. 2017. Lifetact: Utilizing Smartwatches As Tactile Heartbeat Displays in Video Games. In Proceedings of the 16th International Conference on Mobile and Ubiquitous Multimedia (MUM '17), 97--101. DOI:https://doi.org/10.1145/3152832.3152863",
      "doi": "10.1145/3152832.3152863"
    },
    {
      "text": "A. J. Phillips, A. R. D. Thornton, S. Worsfold, A. Downie, and J. Milligan. 1994. Experience of using vibrotactile aids with the profoundly deafened. Int. J. Lang. Commun. Disord. 29, 1 (January 1994), 17--26. DOI:https://doi.org/10.3109/13682829409041478",
      "doi": ""
    },
    {
      "text": "Martin Pielot, Benjamin Poppinga, and Susanne Boll. 2010. PocketNavigator. In Proceedings of the 12th international conference on Human computer interaction with mobile devices and services - MobileHCI '10 (MobileHCI '10), 423. DOI:https://doi.org/10.1145/1851600.1851696",
      "doi": ""
    },
    {
      "text": "Stefania Pizza, Barry Brown, Donald McMillan, and Airi Lampinen. 2016. Smartwatch in vivo. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI '16, 5456--5469. DOI:https://doi.org/10.1145/2858036.2858522",
      "doi": "10.1145/2858036.2858522"
    },
    {
      "text": "Steven Schirra and Frank R. Bentley. 2015. \"It's kind of like an extra screen for my phone.\" In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA '15, 2151--2156. DOI:https://doi.org/10.1145/2702613.2732931",
      "doi": "10.1145/2702613.2732931"
    },
    {
      "text": "Caitlyn Seim, Rodrigo Pontes, Sanjana Kadiveti, Zaeem Adamjee, Annette Cochran, Timothy Aveni, Peter Presti, and Thad Starner. 2018. Towards Haptic Learning on a Smartwatch. In Proceedings of the 2018 ACM International Symposium on Wearable Computers (ISWC '18), 228--229. DOI:https://doi.org/10.1145/3267242.3267269",
      "doi": "10.1145/3267242.3267269"
    },
    {
      "text": "Kristen Shinohara and Jacob O Wobbrock. 2011. In the Shadow of Misperception: Assistive Technology Use and Social Interactions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '11), 705--714. DOI:https://doi.org/10.1145/1978942.1979044",
      "doi": "10.1145/1978942.1979044"
    },
    {
      "text": "Liu Sicong, Zhou Zimu, Du Junzhao, Shangguan Longfei, Jun Han, and Xin Wang. 2017. UbiEar: Bringing Location-independent Sound Awareness to the Hard-of-hearing People with Smartphones. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 1, 2 (June 2017), 17:1--17:21. DOI:https://doi.org/10.1145/3090082",
      "doi": "10.1145/3090082"
    },
    {
      "text": "I. R. Summers, M. A. Peake, and M. C. Martin. 1981. Field Trials of a Tactile Acoustic Monitor for the Profoundly Deaf. Br. J. Audiol. 15, 3 (January 1981), 195--199. DOI:https://doi.org/10.3109/03005368109081437",
      "doi": ""
    },
    {
      "text": "Martin Tomitsch and Thomas Grechenig. 2007. Design Implications for a Ubiquitous Ambient Sound Display for the Deaf. In Conference & Workshop on Assistive Technologies for People with Vision & Hearing Impairments Assistive Technology for All Ages (CVHI 2007).",
      "doi": ""
    },
    {
      "text": "Eddy Yeung, Arthur Boothroyd, and Cecil Redmond. 1988. A wearable multichannel tactile display of voice fundamental frequency. Ear Hear. 9, 6 (1988), 342--350.",
      "doi": ""
    },
    {
      "text": "Hanfeng Yuan, Charlotte M. Reed, and Nathaniel I. Durlach. 2005. Tactual display of consonant voicing as a supplement to lipreading. J. Acoust. Soc. Am. 118, 2 (August 2005), 1003--1015. DOI:https://doi.org/10.1121/1.1945787",
      "doi": ""
    }
  ]
}