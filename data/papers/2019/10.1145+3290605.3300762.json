{
  "doi": "10.1145/3290605.3300762",
  "title": "Personalising the TV Experience using Augmented Reality: An Exploratory Study on Delivering Synchronised Sign Language Interpretation",
  "published": "2019-05-02",
  "proctitle": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2019,
  "badges": [],
  "abstract": "Augmented Reality (AR) technology has the potential to extend the screen area beyond the rigid frames of televisions. The additional display area can be used to augment televisions (TVs) with extra information tailored to individuals, for instance, the provision of access services like sign language interpretations. We invited 23 (11 in the UK, 12 in Germany) users of signed content to evaluate three methods of watching a sign language interpreted programme - one traditional in-vision method with signed programme content on TV and two AR-enabled methods in which an AR sign language interpreter (a 'half-body' version and a 'full-body' version) is projected just outside the frame of the TV presenting the programme. In the UK, participants were split 3-ways in their preferences while in Germany, half the participants preferred the traditional method followed closely by the 'half-body' version. We discuss our participants reasoning behind their preferences and implications for future research.",
  "authors": [
    {
      "name": "Vinoba Vinayagamoorthy",
      "institution": "BBC R&D, London, United Kingdom",
      "img": "/do/10.1145/contrib-81100355462/rel-imgonly/image2017-06-2316-50-25-208.jpg",
      "acmid": "81100355462",
      "orcid": "missing"
    },
    {
      "name": "Maxine Glancy",
      "institution": "BBC R&D, Salford, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81344491064",
      "orcid": "missing"
    },
    {
      "name": "Christoph Ziegler",
      "institution": "IRT, Munich, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659179084",
      "orcid": "missing"
    },
    {
      "name": "Richard Sch\u00e4ffer",
      "institution": "IRT, Munich, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659279100",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "2-Immerse. 2018. 2-Immerse home page. Retrieved March 27, 2018 from http://2immerse.eu",
      "doi": ""
    },
    {
      "text": "Nicoletta Adamo-Villani and Saikiran Anasingaraju. 2016. Holographic Signing Avatars for Deaf Education. In E-Learning, E-Education, and Online Training. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, Giovanni Vincenti, Alberto Bucciero, Markus Helfert, and Matthias Glowatz (Eds.). Springer International Publishing, Cham, 54--61.",
      "doi": ""
    },
    {
      "text": "Diana Affi, Jo\u00ebl Dumoulin, Marco Bertini, Elena Mugellini, Omar Abou Khaled, and Alberto Del Bimbo. 2015. SensiTV: Smart EmotioNal System for Impaired People's TV. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video (TVX '15). ACM, New York, NY, USA, 125--130.  ",
      "doi": "10.1145/2745197.2755512"
    },
    {
      "text": "Edward Anstead, Steve Benford, and Robert J. Houghton. 2014. Manyscreen Viewing: Evaluating an Olympics Companion Application. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video (TVX '14). ACM, New York, NY, USA, 103--110.  ",
      "doi": "10.1145/2602299.2602304"
    },
    {
      "text": "Mike Armstrong. 2013. The Development of a Methodology to Evaluate the Perceived Quality of Live TV Subtitles. In IBC2013 Conference. IET, Amsterdam.",
      "doi": ""
    },
    {
      "text": "Augmen.tv. 2018. Augmen.TV homepage. Retrieved September 21, 2018 from http://augmen.tv",
      "doi": ""
    },
    {
      "text": "BBC. 2016. Access Services at the BBC: Subtitling, Audio Description & Signing - Inside the BBC. Retrieved September 11, 2018 from https:// www.bbc.co.uk/corporate2/insidethebbc/whatwedo/access-services",
      "doi": ""
    },
    {
      "text": "BBC News. 2017. National Theatre Specs create floating subtitles. Retrieved September 21, 2018 from https://www.bbc.co.uk/news/av/technology-41491953/national-theatre-specs-create-floating-subtitles",
      "doi": ""
    },
    {
      "text": "BBC R&D. 2012. Companion Screens: Creating a viewing experience across more than one screen. Retrieved March 27, 2018 from http: //www.bbc.co.uk/rd/projects/companion-screens",
      "doi": ""
    },
    {
      "text": "BBC R&D. 2013. Unconventional Screens: Exploring the potential of future display technologies. Retrieved March 27, 2018 from https: //www.bbc.co.uk/rd/projects/unconventional-screens",
      "doi": ""
    },
    {
      "text": "BBC R&D. 2015. Forecaster: our experimental object-based weather forecast. Retrieved September 4, 2018 from https://www.bbc.co.uk/rd/blog/2015--11-forecaster-our-experimental-object-based-weather-forecast",
      "doi": ""
    },
    {
      "text": "British Sign Language. 2018. Online resources, games & course. Retrieved September 19, 2018 from https://www.british-sign.co.uk",
      "doi": ""
    },
    {
      "text": "Andy Brown, Rhia Jones, Mike Crabb, James Sandford, Matthew Brooks, Mike Armstrong, and Caroline Jay. 2015. Dynamic Subtitles: The User Experience. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video (TVX '15). ACM, New York, NY, USA, 103--112.  ",
      "doi": "10.1145/2745197.2745204"
    },
    {
      "text": "Andy Brown, Jayson Turner, Jake Patterson, Anastasia Schmitz, Mike Armstrong, and Maxine Glancy. 2017. Subtitles in 360-degree Video. In Adjunct Publication of the 2017 ACM International Conference on Interactive Experiences for TV and Online Video (TVX '17 Adjunct). ACM, New York, NY, USA, 3--8.  ",
      "doi": "10.1145/3084289.3089915"
    },
    {
      "text": "BSL Zone. 2018. Watch. Retrieved September 19, 2018 from https: //www.bslzone.co.uk/watch/",
      "doi": ""
    },
    {
      "text": "Sarah Ebling, Sarah Johnson, Rosalee Wolfe, Robyn Moncrief, John McDonald, Souad Baowidan, Tobias Haug, Sandra Sidler-Miserez, and Katja Tissi. 2017. Evaluation of Animated Swiss German Sign Language Fingerspelling Sequences and Signs. In Universal Access in Human-- Computer Interaction. Designing Novel Interactions, Margherita Antona and Constantine Stephanidis (Eds.). Springer International Publishing, Cham, 3--13.",
      "doi": ""
    },
    {
      "text": "Fachverband f\u00fcr Menschen mit H\u00f6r- und Sprachbehinderung e.V. 2018. Home page. Retrieved September 5, 2018 from http://www.blwg.eu/",
      "doi": ""
    },
    {
      "text": "Geh\u00f6rlose Bergfreunde M\u00fcnchen e.V. 2018. Home page. Retrieved September 5, 2018 from http://www.gbf-muenchen.de/",
      "doi": ""
    },
    {
      "text": "Geh\u00f6rlosenverband M\u00fcnchen und Umland e.V. 2018. Home page. Retrieved September 5, 2018 from https://www.gmu.de/",
      "doi": ""
    },
    {
      "text": "Uwe Gruenefeld, Dana Hsiao, Wilko Heuten, and Susanne Boll. 2017. EyeSee: Beyond Reality with Microsoft HoloLens. In Proceedings of the 5th Symposium on Spatial User Interaction (SUI '17). ACM, New York, NY, USA, 148--148.  ",
      "doi": "10.1145/3131277.3134362"
    },
    {
      "text": "HbbTV. 2018. TS 102796 V1.5.1 -- Hybrid Broadcast Broadband Television. ETSI, Sophia Antipolis Cedex, France.",
      "doi": ""
    },
    {
      "text": "HealthiAR. 2018. Microsoft HoloHear. Retrieved September 21, 2018 from https://healthiar.com/holohear-translates-the-spoken-word-to-asl-in-mixed-reality",
      "doi": ""
    },
    {
      "text": "Chris J. Hughes, Mike Armstrong, Rhianne Jones, and Michael Crabb. 2015. Responsive Design for Personalised Subtitles. In Proceedings of the 12th Web for All Conference (W4A '15). ACM, New York, NY, USA, Article 8, 4 pages.  ",
      "doi": "10.1145/2745555.2746650"
    },
    {
      "text": "Dhruv Jain, Bonnie Chinh, Leah Findlater, Raja Kushalnagar, and Jon Froehlich. 2018. Exploring Augmented Reality Approaches to RealTime Captioning: A Preliminary Autoethnographic Study. In Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems (DIS '18 Companion). ACM, New York, NY, USA, 7--11.  ",
      "doi": "10.1145/3197391.3205404"
    },
    {
      "text": "Hernisa Kacorri, Matt Huenerfauth, Sarah Ebling, Kasmira Patel, Kellie Menzies, and Mackenzie Willard. 2017. Regression Analysis of Demographic and Technology-Experience Factors Influencing Acceptance of Sign Language Animation. ACM Trans. Access. Comput. 10, 1, Article 3 (April 2017), 33 pages.  ",
      "doi": "10.1145/3046787"
    },
    {
      "text": "Kellie Kercher and Dale C Rowe. 2012. Improving the learning experience for the deaf through augment reality innovations. In Engineering, Technology and Innovation (ICE), 2012 18th International ICE Conference on. IEEE, Munich, 1--11.",
      "doi": ""
    },
    {
      "text": "Michael Kipp, Alexis Heloir, and Quan Nguyen. 2011. Sign language avatars: Animation and comprehensibility. In International Workshop on Intelligent Virtual Agents. Springer, Berlin, Heidelberg, 113--126. ",
      "doi": "10.5555/2041666.2041682"
    },
    {
      "text": "Michael Kipp, Quan Nguyen, Alexis Heloir, and Silke Matthes. 2011. Assessing the Deaf User Perspective on Sign Language Avatars. In The Proceedings of the 13th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS '11). ACM, New York, NY, USA, 107--114.  ",
      "doi": "10.1145/2049536.2049557"
    },
    {
      "text": "Ines Ko\u017euh, Simon Hauptman, Primo Kosec, and Matjaz Debevc. 2015. Assessing the efficiency of using augmented reality for learning sign language. In International Conference on Universal Access in HumanComputer Interaction. Springer, Cham, 404--415.",
      "doi": ""
    },
    {
      "text": "Tomoki Kurahashi, Kazuki Suemitsu, Keiichi Zempo, Koichi Mizutani, and Naoto Wakatsuki. 2017. Disposition of captioning interface using see-through head-mounted display for conversation support. In Consumer Electronics (GCCE), 2017 IEEE 6th Global Conference on. IEEE, Nagoya, Japan, 1--4.",
      "doi": ""
    },
    {
      "text": "Microsoft. 2018. Hologram stability. Retrieved September 20, 2018 from https://docs.microsoft.com/en-us/windows/mixed-reality/hologram-stability#color-separation",
      "doi": ""
    },
    {
      "text": "Microsoft. 2018. Microsoft HoloLens. Retrieved March 28, 2018 from https://www.microsoft.com/en-gb/hololens",
      "doi": ""
    },
    {
      "text": "Mario Montagud, Issac Fraile, Juan A. Nu\u00f1ez, and Sergi Fern\u00e1ndez. 2018. ImAc: Enabling Immersive, Accessible and Personalized Media Experiences. In Proceedings of the 2018 ACM International Conference on Interactive Experiences for TV and Online Video (TVX '18). ACM, New York, NY, USA, 245--250.  ",
      "doi": "10.1145/3210825.3213570"
    },
    {
      "text": "Timothy Neate, Matt Jones, and Michael Evans. 2015. Mediating Attention for Second Screen Companion Content. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15). ACM, New York, NY, USA, 3103--3106.  ",
      "doi": "10.1145/2702123.2702278"
    },
    {
      "text": "Katy C. Noland and Louise H. Truong. 2015. A Survey of UK Television Viewing Conditions. Technical Report WHP 287. BBC R&D. Retrieved December 19, 2018 from http://downloads.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP287.pdf",
      "doi": ""
    },
    {
      "text": "Ofcom. 2017. The Ofcom Code on Television Access Services. Retrieved March 27, 2018 from https://www.ofcom.org.uk/tv-radio-and-on-demand/broadcast-codes/tv-access-services",
      "doi": ""
    },
    {
      "text": "Yi-Hao Peng, Ming-Wei Hsi, Paul Taele, Ting-Yu Lin, Po-En Lai, Leon Hsu, Tzu-chuan Chen, Te-Yen Wu, Yu-An Chen, Hsien-Hui Tang, and Mike Y. Chen. 2018. SpeechBubbles: Enhancing Captioning Experiences for Deaf and Hard-of-Hearing People in Group Conversations. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 293, 10 pages.  ",
      "doi": "10.1145/3173574.3173867"
    },
    {
      "text": "Pok\u00e9mon Go. 2018. Homepage. Retrieved September 3, 2018 from https://www.pokemongo.com/en-gb/",
      "doi": ""
    },
    {
      "text": "BBC R&D. 2018. Companion Device Research - Information and Questionnaire Sheet. Retrieved December 19, 2018 from https://docs.google.com/forms/d/e/ 1FAIpQLSfX3WsFiY1Y5NMLY46UiydrHh-WsfWG3-cDJb2HSKwTJ3D8TA/viewform",
      "doi": ""
    },
    {
      "text": "Sylvia Rothe, Kim Tran, and Heinrich Hu\u00dfmann. 2018. Dynamic Subtitles in Cinematic Virtual Reality. In Proceedings of the 2018 ACM International Conference on Interactive Experiences for TV and Online Video (TVX '18). ACM, New York, NY, USA, 209--214.  ",
      "doi": "10.1145/3210825.3213556"
    },
    {
      "text": "Rufat Rzayev, Pawel W. Wozniak, Tilman Dingler, and Niels Henze. 2018. Reading on Smart Glasses: The Effect of Text Position, Presentation Type and Walking. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). ACM, New York, NY, USA, Article 45, 9 pages.  ",
      "doi": "10.1145/3173574.3173619"
    },
    {
      "text": "Ege Sezen. 2015. Enhancing Watching Experience of Football Matches on TV via Modes of Interaction and Types of Visualisation of MatchRelated Information on Second Screen. In ACM TVX'2015 Doctoral Consortium. ACM, Brussels.",
      "doi": ""
    },
    {
      "text": "Simax. 2018. Home page. Retrieved September 21, 2018 from https://simax.media/?lang=en",
      "doi": ""
    },
    {
      "text": "Vinoba Vinayagamoorthy, Penelope Allen, Matt Hammond, and Michael Evans. 2012. Researching the User Experience for Connected Tv: A Case Study. In CHI '12 Extended Abstracts on Human Factors in Computing Systems (CHI EA '12). ACM, New York, NY, USA, 589--604.  ",
      "doi": "10.1145/2212776.2212832"
    },
    {
      "text": "Vinoba Vinayagamoorthy, Maxine Glancy, Paul Debenham, Alastair Bruce, Christoph Ziegler, and Richard Sch\u00e4ffer. 2018. Personalising the TV Experience with Augmented Reality Technology: Synchronised Sign Language Interpretation. In Proceedings of the 2018 ACM International Conference on Interactive Experiences for TV and Online Video (TVX '18). ACM, New York, NY, USA, 179--184.  ",
      "doi": "10.1145/3210825.3213562"
    },
    {
      "text": "Vinoba Vinayagamoorthy, Rajiv Ramdhany, and Matt Hammond. 2016. Enabling Frame-Accurate Synchronised Companion Screen Experiences. In Proceedings of the ACM International Conference on Interactive Experiences for TV and Online Video (TVX '16). ACM, New York, NY, USA, 83--92.  ",
      "doi": "10.1145/2932206.2932214"
    },
    {
      "text": "ZDF Mediathek. 2018. Wetterinformationen. Retrieved September 5, 2018 from https://www.zdf.de/nachrichten/wetter",
      "doi": ""
    },
    {
      "text": "Christoph Ziegler, Christian Keimel, Rajiv Ramdhany, and Vinoba Vinayagamoorthy. 2017. On Time or Not on Time: A User Study on Delays in a Synchronised Companion-Screen Experience. In Proceedings of the 2017 ACM International Conference on Interactive Experiences for TV and Online Video (TVX '17). ACM, New York, NY, USA, 105--114.  ",
      "doi": "10.1145/3077548.3077557"
    }
  ]
}