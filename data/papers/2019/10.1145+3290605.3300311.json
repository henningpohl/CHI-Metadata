{
  "doi": "10.1145/3290605.3300311",
  "title": "B-Script: Transcript-based B-roll Video Editing with Recommendations",
  "published": "2019-05-02",
  "proctitle": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-11",
  "year": 2019,
  "badges": [],
  "abstract": "In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position and content. To evaluate the system, we conducted a within-subject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcript-based editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided.",
  "tags": [
    "video editing",
    "machine learning",
    "video blogging"
  ],
  "authors": [
    {
      "name": "Bernd Huber",
      "institution": "Harvard University, Cambridge, MA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81557229156",
      "orcid": "missing"
    },
    {
      "name": "Hijung Valentina Shin",
      "institution": "Adobe Research, Cambridge, MA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658757071",
      "orcid": "missing"
    },
    {
      "name": "Bryan Russell",
      "institution": "Adobe Research, San Francisco, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81300459801",
      "orcid": "missing"
    },
    {
      "name": "Oliver Wang",
      "institution": "Adobe Research, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81365594740",
      "orcid": "missing"
    },
    {
      "name": "Gautham J. Mysore",
      "institution": "Adobe Research, San Francisco, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81418598351",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "2018. Adobe Stock. https://stock.adobe.com/. Accessed: 2018-08--30.",
      "doi": ""
    },
    {
      "text": "2018. Giphy. https://www.giphy.com. Accessed: 2018-08--30.",
      "doi": ""
    },
    {
      "text": "2018. Vlogs Statistics. https://blog.globalwebindex.com/ chart-of-the-day/over-4-in-10-watch-vlogs/. Accessed: 201808--30.",
      "doi": ""
    },
    {
      "text": "2018. Wibbitz. https://www.wibbitz.com. Accessed: 2018-08--30.",
      "doi": ""
    },
    {
      "text": "2018. Wochit. https://www.wochit.com. Accessed: 2018-08--30.",
      "doi": ""
    },
    {
      "text": "Ido Arev, Hyun Soo Park, Yaser Sheikh, Jessica Hodgins, and Ariel Shamir. 2014. Automatic editing of footage from multiple social cameras. ACM Transactions on Graphics (TOG) 33, 4 (2014), 81.  ",
      "doi": "10.1145/2601097.2601198"
    },
    {
      "text": "Floraine Berthouzoz, Wilmot Li, and Maneesh Agrawala. 2012. Tools for placing cuts and transitions in interview video. ACM Trans. Graph. 31, 4 (2012), 67--1.  ",
      "doi": "10.1145/2185520.2185563"
    },
    {
      "text": "Joan-Isaac Biel and Daniel Gatica-Perez. 2011. VlogSense: Conversational behavior and social attention in YouTube. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) 7, 1 (2011), 33.  ",
      "doi": "10.1145/2037676.2037690"
    },
    {
      "text": "Juan Casares, A Chris Long, Brad A Myers, Rishi Bhatnagar, Scott M Stevens, Laura Dabbish, Dan Yocum, and Albert Corbett. 2002. Simplifying video editing using metadata. In Proceedings of the 4th conference on Designing interactive systems: processes, practices, methods, and techniques. ACM, 157--166.  ",
      "doi": "10.1145/778712.778737"
    },
    {
      "text": "Marc Davis. 2003. Editing out video editing. IEEE multimedia 10, 2 (2003), 54--64.  ",
      "doi": "10.1109/MMUL.2003.1195161"
    },
    {
      "text": "Andreas Girgensohn, John Boreczky, Patrick Chiu, John Doherty, Jonathan Foote, Gene Golovchinsky, Shingo Uchihashi, and Lynn Wilcox. 2000. A semi-automatic approach to home video editing. In Proceedings of the 13th annual ACM symposium on User interface software and technology. ACM, 81--89.  ",
      "doi": "10.1145/354401.354415"
    },
    {
      "text": "Floraine Grabler, Maneesh Agrawala, Wilmot Li, Mira Dontcheva, and Takeo Igarashi. 2009. Generating photo manipulation tutorials by demonstration. In ACM Transactions on Graphics (TOG), Vol. 28. ACM, 66.  ",
      "doi": "10.1145/1531326.1531372"
    },
    {
      "text": "Sandra G Hart and Lowell E Staveland. 1988. Development of NASATLX (Task Load Index): Results of empirical and theoretical research. In Advances in psychology. Vol. 52. Elsevier, 139--183.",
      "doi": ""
    },
    {
      "text": "Clayton J Hutto and Eric Gilbert. 2014. Vader: A parsimonious rulebased model for sentiment analysis of social media text. In Eighth international AAAI conference on weblogs and social media.",
      "doi": ""
    },
    {
      "text": "Emmanuel Iarussi, Adrien Bousseau, and Theophanis Tsandilas. 2013. The drawing assistant: Automated drawing guidance and feedback from photographs. In ACM Symposium on User Interface Software and Technology (UIST). ACM.  ",
      "doi": "10.1145/2501988.2501997"
    },
    {
      "text": "Eakta Jain, Yaser Sheikh, Ariel Shamir, and Jessica Hodgins. 2015. Gazedriven video re-editing. ACM Transactions on Graphics (TOG) 34, 2 (2015), 21.  ",
      "doi": "10.1145/2699644"
    },
    {
      "text": "Eliyahu Kiperwasser and Yoav Goldberg. 2016. Simple and accurate dependency parsing using bidirectional LSTM feature representations. arXiv preprint arXiv:1603.04351 (2016).",
      "doi": ""
    },
    {
      "text": "Jihyeon Janel Lee, Mitchell Gordon, and Maneesh Agrawala. 2017. Automatically Visualizing Audio Travel Podcasts. In Adjunct Publication of the 30th Annual ACM Symposium on User Interface Software and Technology. ACM, 165--167.  ",
      "doi": "10.1145/3131785.3131818"
    },
    {
      "text": "Zheng Lu and Kristen Grauman. 2013. Story-driven summarization for egocentric video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2714--2721.  ",
      "doi": "10.1109/CVPR.2013.350"
    },
    {
      "text": "Walter Murch. 2001. In the blink of an eye: A perspective on film editing. Silman-James Press.",
      "doi": ""
    },
    {
      "text": "Bobbie O'steen. 2009. The invisible cut. Michael Wiese Productions.",
      "doi": ""
    },
    {
      "text": "Amy Pavel, Dan B Goldman, Bj\u00f6rn Hartmann, and Maneesh Agrawala. 2015. Sceneskim: Searching and browsing movies using synchronized captions, scripts and plot summaries. In Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology. ACM, 181-- 190.  ",
      "doi": "10.1145/2807442.2807502"
    },
    {
      "text": "Amy Pavel, Dan B Goldman, Bj\u00f6rn Hartmann, and Maneesh Agrawala. 2016. VidCrit: video-based asynchronous video review. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. ACM, 517--528.  ",
      "doi": "10.1145/2984511.2984552"
    },
    {
      "text": "Steve Rubin, Floraine Berthouzoz, Gautham J Mysore, Wilmot Li, and Maneesh Agrawala. 2013. Content-based tools for editing audio stories. In Proceedings of the 26th annual ACM symposium on User interface software and technology. ACM, 113--122.  ",
      "doi": "10.1145/2501988.2501993"
    },
    {
      "text": "Amy Schmittauer. 2017. Vlog Like a Boss: How to Kill it Online with Video Blogging. Author Academy Elite. ",
      "doi": "10.5555/3137538"
    },
    {
      "text": "Hijung Valentina Shin, Floraine Berthouzoz, Wilmot Li, and Fr\u00e9do Durand. 2015. Visual transcripts: lecture notes from blackboard-style lecture videos. ACM Transactions on Graphics (TOG) 34, 6 (2015), 240.  ",
      "doi": "10.1145/2816795.2818123"
    },
    {
      "text": "Hijung Valentina Shin, Wilmot Li, and Fr\u00e9do Durand. 2016. Dynamic authoring of audio with linked scripts. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. ACM, 509--516.  ",
      "doi": "10.1145/2984511.2984561"
    },
    {
      "text": "Johan AK Suykens and Joos Vandewalle. 1999. Least squares support vector machine classifiers. Neural processing letters 9, 3 (1999), 293--300.  ",
      "doi": "10.1023/A%3A1018628609742"
    },
    {
      "text": "Anh Truong, Floraine Berthouzoz, Wilmot Li, and Maneesh Agrawala. 2016. Quickcut: An interactive tool for editing narrated video. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. ACM, 497--507.  ",
      "doi": "10.1145/2984511.2984569"
    },
    {
      "text": "Cheng-Yao Wang, Wei-Chen Chu, Hou-Ren Chen, Chun-Yen Hsu, and Mike Y Chen. 2014. EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 4027--4036.  ",
      "doi": "10.1145/2556288.2557407"
    },
    {
      "text": "Vilmos Zsombori, Michael Frantzis, Rodrigo Laiola Guimaraes, Marian Florin Ursu, Pablo Cesar, Ian Kegel, Roland Craigie, and Dick CA Bulterman. 2011. Automatic generation of video narratives from shared UGC. In Proceedings of the 22nd ACM conference on Hypertext and hypermedia. ACM, 325--334.  ",
      "doi": "10.1145/1995966.1996009"
    }
  ]
}