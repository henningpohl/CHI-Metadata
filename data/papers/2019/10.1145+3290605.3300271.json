{
  "doi": "10.1145/3290605.3300271",
  "title": "Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services",
  "published": "2019-05-02",
  "proctitle": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2019,
  "badges": [],
  "abstract": "Algorithmic decision-making systems are increasingly being adopted by government public service agencies. Researchers, policy experts, and civil rights groups have all voiced concerns that such systems are being deployed without adequate consideration of potential harms, disparate impacts, and public accountability practices. Yet little is known about the concerns of those most likely to be affected by these systems. We report on workshops conducted to learn about the concerns of affected communities in the context of child welfare services. The workshops involved 83 study participants including families involved in the child welfare system, employees of child welfare agencies, and service providers. Our findings indicate that general distrust in the existing system contributes significantly to low comfort in algorithmic decision-making. We identify strategies for improving comfort through greater transparency and improved communication strategies. We discuss the implications of our study for accountable algorithm design for child welfare applications.",
  "authors": [
    {
      "name": "Anna Brown",
      "institution": "College of Creative Arts, Massey University, Wellington, New Zealand",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659365127",
      "orcid": "missing"
    },
    {
      "name": "Alexandra Chouldechova",
      "institution": "Carnegie Mellon University & Microsoft Research, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81553917956",
      "orcid": "0000-0002-2337-9610"
    },
    {
      "name": "Emily Putnam-Hornstein",
      "institution": "University of Southern California, Los Angeles, CA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659365138",
      "orcid": "missing"
    },
    {
      "name": "Andrew Tobin",
      "institution": "College of Creative Arts, Massey University, Wellington, New Zealand",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659365973",
      "orcid": "missing"
    },
    {
      "name": "Rhema Vaithianathan",
      "institution": "Auckland University of Technology, Auckland, New Zealand",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659365490",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian Y Lim, and Mohan Kankanhalli. 2018. Trends and trajectories for explainable, accountable and intelligible systems: An hci research agenda. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 582.  ",
      "doi": "10.1145/3173574.3174156"
    },
    {
      "text": "Alekh Agarwal, Alina Beygelzimer, Miroslav Dud\u00edk, John Langford, and Hanna Wallach. 2018. A reductions approach to fair classification. arXiv preprint arXiv:1803.02453 (2018).",
      "doi": ""
    },
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine Bias. (2016). https://www.propublica.org/article/ machine-bias-risk-assessments-in-criminal-sentencing",
      "doi": ""
    },
    {
      "text": "Toi Aria. 2017. Our data, our way. https://trusteddata.co.nz/massey_ our_data_our_way.pdf",
      "doi": ""
    },
    {
      "text": "Reuben Binns, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. 'It's Reducing a Human Being to a Percentage': Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 377.  ",
      "doi": "10.1145/3173574.3173951"
    },
    {
      "text": "Robert Brauneis and Ellen P Goodman. 2017. Algorithmic transparency for the smart city. (2017).",
      "doi": ""
    },
    {
      "text": "Sarah Brayne. 2017. Big data surveillance: The case of policing. American Sociological Review 82, 5 (2017), 977--1008.",
      "doi": ""
    },
    {
      "text": "Joel Brockner and Batia Wiesenfeld. 2005. How, when, and why does outcome favorability interact with procedural fairness? (2005).",
      "doi": ""
    },
    {
      "text": "Joel Brockner and BatiaMWiesenfeld. 1996. An integrative framework for explaining reactions to decisions: interactive effects of outcomes and procedures. Psychological bulletin 120, 2 (1996), 189.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. 2018. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In Conference on Fairness, Accountability and Transparency. 134--148.",
      "doi": ""
    },
    {
      "text": "Coalition. 2018. The use of pretrial risk assessment instruments: A shared statement of civil rights concerns. http://civilrightsdocs.info/ pdf/criminal-justice/Pretrial-Risk-Assessment-Full.pdf",
      "doi": ""
    },
    {
      "text": "Jason A Colquitt. 2001. On the dimensionality of organizational justice: A construct validation of a measure. Journal of applied psychology 86, 3 (2001), 386.",
      "doi": ""
    },
    {
      "text": "Nicholas Diakopoulos. {n. d.}. Algorithmic-Accountability: the investigation of Black Boxes. ({n. d.}).",
      "doi": ""
    },
    {
      "text": "Virginia Eubanks. 2018. Automating inequality: How high-tech tools profile, police, and punish the poor. St. Martin's Press. ",
      "doi": "10.5555/3208509"
    },
    {
      "text": "Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 259--268.  ",
      "doi": "10.1145/2783258.2783311"
    },
    {
      "text": "Andrew Guthrie Ferguson. 2017. The Rise of Big Data Policing: Surveillance, Race, and the Future of Law Enforcement. NYU Press.",
      "doi": ""
    },
    {
      "text": "Nina Grgic-Hlaca, Elissa M Redmiles, Krishna P Gummadi, and Adrian Weller. 2018. Human perceptions of fairness in algorithmic decision making: A case study of criminal risk prediction. arXiv preprint arXiv:1802.09548 (2018).  ",
      "doi": "10.1145/3178876.3186138"
    },
    {
      "text": "Bernard E Harcourt. 2014. Risk as a proxy for race: The dangers of risk assessment. Fed. Sent'g Rep. 27 (2014), 237.",
      "doi": ""
    },
    {
      "text": "George E Higgins, Scott E Wolfe, Margaret Mahoney, and Nelseta M Walters. 2009. Race, Ethnicity, and Experience: Modeling the Public's Perceptions of Justice, Satisfaction, and Attitude Toward the Courts. Journal of Ethnicity in Criminal Justice 7, 4 (2009), 293--310.",
      "doi": ""
    },
    {
      "text": "Dan Hurley. 2018. Can an Algorithm Tell When Kids Are in Danger? https://www.nytimes.com/2018/01/02/magazine/can-an-algorithm-tell-when-kids-are-in-danger.html",
      "doi": ""
    },
    {
      "text": "David Jackson and Gary Marx. 2017. Data mining program designed to predict child abuse proves unreliable, DCFS says. http://www.chicagotribune.com/news/watchdog/ct-dcfs-eckerd-met-20171206-story.html",
      "doi": ""
    },
    {
      "text": "Robert Jungk and Norbert M\u00fcllert. 1987. Future Workshops: How to create desirable futures. Institute for Social Inventions London.",
      "doi": ""
    },
    {
      "text": "Niki Kilbertus, Mateo Rojas Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing, and Bernhard Sch\u00f6lkopf. 2017. Avoiding discrimination through causal reasoning. In Advances in Neural Information Processing Systems. 656--666. ",
      "doi": "10.5555/3294771.3294834"
    },
    {
      "text": "Christopher Kingsley and Stefania Di Mauro-Nava. 2017. First, do no harm: Ethical Guidelines for Applying Predictive Tools Within Human Services. MetroLab Network Report (2017).",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 2053951718756684.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee and Su Baykal. {n. d.}. Algorithmic Mediation in Group Decisions: Fairness Perceptions of Algorithmically Mediated vs. Discussion-Based Social Division.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee, Ji Tae Kim, and Leah Lizarondo. 2017. A Human- Centered Approach to Algorithmic Services: Considerations for Fair and Motivating Smart Community Service Management that Allocates Donations to Non-Profit Organizations. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 3365--3376.  ",
      "doi": "10.1145/3025453.3025884"
    },
    {
      "text": "Christopher T Lowenkamp. 2009. The development of an actuarial risk assessment instrument for US Pretrial Services. Fed. Probation 73 (2009), 33.",
      "doi": ""
    },
    {
      "text": "John Monahan, Anne Metz, and Brandon L Garrett. 2018. Judicial Appraisals of Risk Assessment in Sentencing. (2018).",
      "doi": ""
    },
    {
      "text": "Razieh Nabi and Ilya Shpitser. 2018. Fair inference on outcomes. In Proceedings of the... AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence, Vol. 2018. NIH Public Access, 1931.",
      "doi": ""
    },
    {
      "text": "Jedrzej Niklas, Karolina Sztandar-Sztanderska, and Katarzyna Szymielewicz. 2015. Profiling the unemployed in Poland: social and political implications of algorithmic decision making. Fundacja Panoptykon, Warsaw Google Scholar (2015).",
      "doi": ""
    },
    {
      "text": "Executive Office of the President, Cecilia Munoz, Domestic Policy Council Director, Megan (US Chief Technology Officer Smith (Office of Science, Technology Policy)), DJ (Deputy Chief Technology Officer for Data Policy, Chief Data Scientist Patil (Office of Science, and Technology Policy)). 2016. Big data: A report on algorithmic systems, opportunity, and civil rights. Executive Office of the President.",
      "doi": ""
    },
    {
      "text": "Christopher P Parker, Boris B Baltes, and Neil D Christiansen. 1997. Support for affirmative action, justice perceptions, and work attitudes: A study of gender and racial--ethnic group differences. Journal of Applied Psychology 82, 3 (1997), 376.",
      "doi": ""
    },
    {
      "text": "Data Futures Partnership. 2017. A Path to Social Licence: Guidelines for Trusted Data Use. http://datafutures.co.nz/our-work-2/ talking-to-new-zealanders/",
      "doi": ""
    },
    {
      "text": "Angelisa C Plane, Elissa M Redmiles, Michelle L Mazurek, and Michael Carl Tschantz. 2017. Exploring user perceptions of discrimination in online targeted advertising. In USENIX Security. ",
      "doi": "10.5555/3241189.3241263"
    },
    {
      "text": "Dillon Reisman, Jason Schultz, K Crawford, and M Whittaker. 2018. Algorithmic impact assessments: A practical framework for public agency accountability.",
      "doi": ""
    },
    {
      "text": "O'Brien Kirk Roberts, Yvonne H and Peter J Pecora. 2018. Considerations for Implementing Predictive Analytics in Child Welfare. Casey Family Programs (2018).",
      "doi": ""
    },
    {
      "text": "Douglas Schuler and Aki Namioka. 1993. Participatory design: Principles and practices. CRC Press. ",
      "doi": "10.5555/563076"
    },
    {
      "text": "Nicholas Scurich and John Monahan. 2016. Evidence-based sentencing: Public openness and opposition to using gender, age, and race as risk factors for recidivism. Law and Human Behavior 40, 1 (2016), 36.",
      "doi": ""
    },
    {
      "text": "Hetan Shah. 2018. Algorithmic accountability. Phil. Trans. R. Soc. A 376, 2128 (2018), 20170362.",
      "doi": ""
    },
    {
      "text": "Halil Toros and Daniel Flaming. 2018. Prioritizing Homeless Assistance Using Predictive Algorithms: An Evidence-Based Approach. Cityscape 20, 1 (2018), 117--146.",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van Kleek, and Reuben Binns. 2018. Fairness and Accountability Design Needs for Algorithmic Support in High- Stakes Public Sector Decision-Making. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 440.  ",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "AJ Wang. 2018. Procedural Justice and Risk-Assessment Algorithms. (2018).",
      "doi": ""
    },
    {
      "text": "Allison Woodruff, Sarah E Fox, Steven Rousso-Schindler, and Jeffrey Warshaw. 2018. A Qualitative Exploration of Perceptions of Algorithmic Fairness. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 656.  ",
      "doi": "10.1145/3173574.3174230"
    },
    {
      "text": "Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. 2016. Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment. arXiv preprint arXiv:1610.08452 (2016).",
      "doi": ""
    }
  ]
}