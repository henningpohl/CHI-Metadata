{
  "doi": "10.1145/3290605.3300830",
  "title": "Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?",
  "published": "2019-05-02",
  "proctitle": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-16",
  "year": 2019,
  "badges": [],
  "abstract": "The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners' needs.",
  "tags": [
    "needfinding",
    "algorithmic bias",
    "empirical study",
    "product teams",
    "ux of machine learning",
    "fair machine learning"
  ],
  "authors": [
    {
      "name": "Kenneth Holstein",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659133171",
      "orcid": "0000-0001-6730-922X"
    },
    {
      "name": "Jennifer Wortman Vaughan",
      "institution": "Microsoft Research, New York, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81758671157",
      "orcid": "missing"
    },
    {
      "name": "Hal Daum\u00e9",
      "institution": "Microsoft Research & University of Maryland, New York City, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100635457",
      "orcid": "missing"
    },
    {
      "name": "Miro Dudik",
      "institution": "Microsoft Research, New York, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659429062",
      "orcid": "missing"
    },
    {
      "name": "Hanna Wallach",
      "institution": "Microsoft Research, New York City, NY, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81315492225",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "ACM. 2018. ACM Conference on Fairness, Accountability, and Transparency (ACM FAT*). https://fatconference.org/ Accessed: 2018-0615.",
      "doi": ""
    },
    {
      "text": "ACM. 2018. FAT/ML. https://www.fatml.org.Accessed: 2018-06--15.",
      "doi": ""
    },
    {
      "text": "Alekh Agarwal, Alina Beygelzimer, Miroslav Dud\u00edk, John Langford, and Hanna Wallach. 2018. A reductions approach to fair classification. In Proceedings of the Thirty-fifth International Conference on Machine Learning (ICML 2018).",
      "doi": ""
    },
    {
      "text": "Oscar Alvarado and Annika Waern. 2018. Towards algorithmic experience: Initial efforts for social media contexts. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 286.  ",
      "doi": "10.1145/3173574.3173860"
    },
    {
      "text": "Saleema Amershi, Max Chickering, Steven M Drucker, Bongshin Lee, Patrice Simard, and Jina Suh. 2015. ModelTracker: Redesigning performance analysis tools for machine learning. In Proceedings of the 2015 CHI Conference on Human Factors in Computing Systems (CHI 2015). ACM, 337--346.  ",
      "doi": "10.1145/2702123.2702509"
    },
    {
      "text": "Evelin Amorim, Marcia Can\u00e7ado, and Adriano Veloso. 2018. Automated essay scoring in the presence of biased ratings. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), Vol. 1. 229--237.",
      "doi": ""
    },
    {
      "text": "Rico Angell, Brittany Johnson, Yuriy Brun, and Alexandra Meliou. 2018. Themis: Automatically testing software for discrimination. In Proceedings of the Demonstrations Track at the 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), Lake Buena Vista, FL, USA.  ",
      "doi": "10.1145/3236024.3264590"
    },
    {
      "text": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias: There's software used across the country to predict future criminals, and it's biased against blacks. ProPublica (2016).",
      "doi": ""
    },
    {
      "text": "Josh Attenberg, Panagiotis G Ipeirotis, and Foster J Provost. 2011. Beat the machine: Challenging workers to find the unknown unknowns. Human Computation 11, 11 (2011), 2--7. ",
      "doi": "10.5555/2908698.2908699"
    },
    {
      "text": "Ryan SJd Baker, Albert T Corbett, Ido Roll, and Kenneth R Koedinger. 2008. Developing a generalizable detector of when students game the system. User Modeling and User-Adapted Interaction 18, 3 (2008), 287--314.  ",
      "doi": "10.1007/s11257-007-9045-6"
    },
    {
      "text": "Solon Barocas and Andrew D Selbst. 2016. Big data's disparate impact. Cal. L. Rev. 104 (2016), 671.",
      "doi": ""
    },
    {
      "text": "BBC. 2013. Google searches expose racial bias, says study of names. BBC News (Feb 2013). https://www.bbc.com/news/technology21322183. Accessed: 2018-09-03.",
      "doi": ""
    },
    {
      "text": "Emily Bender and Batya Friedman. 2018. Data statements for NLP: Toward mitigating system bias and enabling better science. OpenReview Preprint.",
      "doi": ""
    },
    {
      "text": "Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. 2018. Fairness in criminal justice risk assessments: The State of the Art. Sociological Methods & Research (2018).",
      "doi": ""
    },
    {
      "text": "Reuben Binns. 2018. Fairness in machine learning: Lessons from political philosophy. Proceedings of Machine Learning Research 81, 149--159.",
      "doi": ""
    },
    {
      "text": "Reuben Binns, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. \"It's reducing a human being to a percentage\": Perceptions of justice in algorithmic decisions. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 377.  ",
      "doi": "10.1145/3173574.3173951"
    },
    {
      "text": "Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. In Advances in Neural Information Processing Systems (NeurIPS 2016). 4349--4357. ",
      "doi": "10.5555/3157382.3157584"
    },
    {
      "text": "Nigel Bosch, Sidney K D'Mello, Ryan S Baker, Jaclyn Ocumpaugh, Valerie Shute, Matthew Ventura, Lubin Wang, and Weinan Zhao. 2016. Detecting student emotions in computer-enabled classrooms. In Proceedings of the 2016 International Joint Conference on Artificial Intelligence (IJCAI 2016). 4125--4129. ",
      "doi": "10.5555/3061053.3061231"
    },
    {
      "text": "Justin Bozonier. 2015. Test-driven machine learning. Packt Publishing Ltd.",
      "doi": ""
    },
    {
      "text": "Taina Bucher. 2017. The algorithmic imaginary: Exploring the ordinary affects of Facebook algorithms. Information, Communication & Society 20, 1 (2017), 30--44.",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender Shades: Intersectional accuracy disparities in commercial gender classification. In Proceedings of the 2018 Conference on Fairness, Accountability and Transparency (FAT* 2018). 77--91.",
      "doi": ""
    },
    {
      "text": "Joseph Chee Chang, Saleema Amershi, and Ece Kamar. 2017. Revolt: Collaborative crowdsourcing for labeling machine learning datasets. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI 2017). ACM, 2334--2346.  ",
      "doi": "10.1145/3025453.3026044"
    },
    {
      "text": "Irene Chen, Fredrik D Johansson, and David Sontag. 2018. Why is my classifier discriminatory? Advances in Neural Information Processing Systems (NeurIPS 2018). ",
      "doi": "10.5555/3327144.3327272"
    },
    {
      "text": "Nan-Chen Chen, Jina Suh, Johan Verwey, Gonzalo Ramos, Steven Drucker, and Patrice Simard. 2018. AnchorViz: Facilitating classifier error discovery through interactive semantic data exploration. In 23rd International Conference on Intelligent User Interfaces (IUI 2018). ACM, 269--280.  ",
      "doi": "10.1145/3172944.3172950"
    },
    {
      "text": "Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big Data 5, 2 (2017), 153--163.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. 2018. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In ACM Conference on Fairness, Accountability, and Transparency (FAT* 2018). 134--148.",
      "doi": ""
    },
    {
      "text": "Henriette Cramer, Jean Garcia-Gathright, Sravana Reddy, Aaron Springer, and Romain Takeo. In press. Translation, tracks and data: Algorithmic bias in practice. Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA 2019).  ",
      "doi": "10.1145/3290607.3299057"
    },
    {
      "text": "Kate Crawford. 2017. Artificial intelligence with very real biases. http://www.wsj.com/articles/artificial-intelligencewith-veryreal-biases-1508252717. Accessed: 2018-06--15.",
      "doi": ""
    },
    {
      "text": "Mark D\u00edaz, Isaac Johnson, Amanda Lazar, Anne Marie Piper, and Darren Gergle. 2018. Addressing age-related bias in sentiment analysis. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 412.  ",
      "doi": "10.1145/3173574.3173986"
    },
    {
      "text": "Graham Dove, Kim Halskov, Jodi Forlizzi, and John Zimmerman. 2017. UX design innovation: Challenges for working with machine learning as a design material. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI 2017). ACM, 278--288.  ",
      "doi": "10.1145/3025453.3025739"
    },
    {
      "text": "DSSG. 2018. Aequitas: Bias and fairness audit toolkit. http://aequitas.dssg.io. Accessed: 2018-08--29.",
      "doi": ""
    },
    {
      "text": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the Third Innovations in Theoretical Computer Science Conference (ITCS 2012). ACM, 214--226.  ",
      "doi": "10.1145/2090236.2090255"
    },
    {
      "text": "Cynthia Dwork and Christina Ilvento. 2018. Fairness under composition. CoRR arXiv:1806.06122.",
      "doi": ""
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter, Helen M Blau, and Sebastian Thrun. 2017. Dermatologistlevel classification of skin cancer with deep neural networks. Nature 542, 7639 (2017), 115.",
      "doi": ""
    },
    {
      "text": "Kadija Ferryman and Mikaela Pitcan. 2018. Fairness in precision medicine. Data & Society (2018).",
      "doi": ""
    },
    {
      "text": "World Wide Web Foundation. 2017. Algorithmic accountability. World Wide Web Foundation (2017).",
      "doi": ""
    },
    {
      "text": "Batya Friedman and Helen Nissenbaum. 1996. Bias in computer systems. ACM Transactions on Information Systems (TOIS) 14, 3 (1996), 330--347.  ",
      "doi": "10.1145/230538.230561"
    },
    {
      "text": "Sainyam Galhotra, Yuriy Brun, and Alexandra Meliou. 2017. Fairness testing: Testing software for discrimination. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering (FSE 2017). ACM, 498--510.  ",
      "doi": "10.1145/3106237.3106277"
    },
    {
      "text": "Timnit Gebru, Jonathan Krause, Jia Deng, and Li Fei-Fei. 2017. Scalable annotation of fine-grained categories without experts. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI 2017). ACM, 1877--1881.  ",
      "doi": "10.1145/3025453.3025930"
    },
    {
      "text": "Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daum\u00e9 III, and Kate Crawford. 2018. Datasheets for datasets. CoRR arXiv:1803.09010.",
      "doi": ""
    },
    {
      "text": "Dave Gershgorn. 2018. America's biggest body-camera company says facial recognition isn't accurate enough for police. https://qz.com/1351519/facial-recognition-isnt-yet-accurateenough-for-policing-decisions/. Accessed: 2018-08--30.",
      "doi": ""
    },
    {
      "text": "Dave Gershgorn. 2018. If AI is going to be the world's doctor, it needs better textbooks. https://qz.com/1367177/if-ai-is-going-to-be-theworlds-doctor-it-needs-better-textbooks. Accessed: 2018-09--16.",
      "doi": ""
    },
    {
      "text": "Vivian Giang. 2018. The potential hidden bias in automated hiring systems. https://www.fastcompany.com/40566971/the-potentialhidden-bias-in-automated-hiring-systems. Accessed: 2018-09-03.",
      "doi": ""
    },
    {
      "text": "Google. 2018. The UX of AI - Library. https://design.google/ library/ux-ai/. Accessed: 2018-08--28.",
      "doi": ""
    },
    {
      "text": "Google. 2018. The What-If Tool: Code-free probing of machine learning models. https://ai.googleblog.com/2018/09/the-what-if-tool-codefree-probing-of.html. Accessed: 2018-09--18.",
      "doi": ""
    },
    {
      "text": "Ben Green and Lily Hu. 2018. The myth in the methodology: Towards a recontextualization of fairness in machine learning. In the ICML 2018 Debates Workshop.",
      "doi": ""
    },
    {
      "text": "Foad Hamidi, Morgan Klaus Scheuerman, and Stacy M Branham. 2018. Gender recognition or gender reductionism?: The social implications of embedded gender recognition systems. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 8.  ",
      "doi": "10.1145/3173574.3173582"
    },
    {
      "text": "Bruce Hanington and Bella Martin. 2012. Universal methods of design: 100 ways to research complex problems, develop innovative ideas, and design effective solutions. Rockport Publishers.",
      "doi": ""
    },
    {
      "text": "Moritz Hardt, Eric Price, Nati Srebro, et al. 2016. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems (NeurIPS 2016). 3315--3323. ",
      "doi": "10.5555/3157382.3157469"
    },
    {
      "text": "HireVue.com. 2018. Video interview software for recruiting & hiring. https://www.hirevue.com/. Accessed: 2018-08--28.",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Gena Hong, Mera Tegene, Bruce M McLaren, and Vincent Aleven. 2018. The classroom as a dashboard: Co-designing wearable cognitive augmentation for K-12 teachers. In Proceedings of the Eighth International Conference on Learning Analytics and Knowledge (LAK 2018). ACM, 79--88.  ",
      "doi": "10.1145/3170358.3170377"
    },
    {
      "text": "Kenneth Holstein, Bruce M McLaren, and Vincent Aleven. 2017. Intelligent tutors as teachers' aides: Exploring teacher needs for real-time analytics in blended classrooms. In Proceedings of the Seventh International Learning Analytics and Knowledge Conference (LAK 2017). ACM, 257--266.  ",
      "doi": "10.1145/3027385.3027451"
    },
    {
      "text": "Kenneth Holstein, Bruce M McLaren, and Vincent Aleven. 2018. Student learning benefits of a mixed-reality teacher awareness tool in AI-enhanced classrooms. In Proceedings of the International Conference on Artificial Intelligence in Education (AIED 2018). Springer, 154--168.",
      "doi": ""
    },
    {
      "text": "Karen Holtzblatt and Sandra Jones. 1993. Contextual inquiry: A participatory technique for system design. Participatory design: Principles and practices (1993), 177--210.",
      "doi": ""
    },
    {
      "text": "AI Now Institute. 2018. AI Now Institute. https://ainowinstitute.org. Accessed: 2018-08-03.",
      "doi": ""
    },
    {
      "text": "Alankar Jain, Florian Pecune, Yoichi Matsuyama, and Justine Cassell. 2018. A user simulator architecture for socially-aware conversational agents. In Proceedings of the 18th International Conference on Intelligent Virtual Agents (IVA 2018). ACM, 133--140.  ",
      "doi": "10.1145/3267851.3267916"
    },
    {
      "text": "David Janzen and Hossein Saiedian. 2005. Test-driven development concepts, taxonomy, and future direction. Computer 38, 9 (2005), 43--50.  ",
      "doi": "10.1109/MC.2005.314"
    },
    {
      "text": "Yuan Jia, Bin Xu, Yamini Karanam, and Stephen Voida. 2016. Personality-targeted gamification: A survey study on personality traits and motivational affordances. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI 2016). ACM, 2001--2013.  ",
      "doi": "10.1145/2858036.2858515"
    },
    {
      "text": "Nathan Kallus and Angela Zhou. 2018. Residual unfairness in fair machine learning from prejudiced data. CoRR arXiv:1806.02887.",
      "doi": ""
    },
    {
      "text": "Ece Kamar. 2016. Directions in hybrid intelligence: Complementing AI systems with human intelligence.. In Proceedings of the 2016 International Joint Conference on Artificial Intelligence (IJCAI 2016). 4070--4073. ",
      "doi": "10.5555/3061053.3061219"
    },
    {
      "text": "Ece Kamar, Ashish Kapoor, and Eric Horvitz. 2015. Identifying and accounting for task-dependent bias in crowdsourcing. In Third AAAI Conference on Human Computation and Crowdsourcing (HCOMP 2015).",
      "doi": ""
    },
    {
      "text": "Matthew Kay, Cynthia Matuszek, and Sean A Munson. 2015. Unequal representation and gender stereotypes in image search results for occupations. In Proceedings of the 2015 CHI Conference on Human Factors in Computing Systems (CHI 2015). ACM, 3819--3828.  ",
      "doi": "10.1145/2702123.2702520"
    },
    {
      "text": "Mary Beth Kery, Marissa Radensky, Mahima Arya, Bonnie E John, and Brad A Myers. 2018. The story in the notebook: Exploratory data science using a literate programming tool. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 174.  ",
      "doi": "10.1145/3173574.3173748"
    },
    {
      "text": "Niki Kilbertus, Adri\u00e0 Gasc\u00f3n, Matt J Kusner, Michael Veale, Krishna P Gummadi, and Adrian Weller. 2018. Blind justice: Fairness with encrypted sensitive attributes. Proceedings of the Thirty-Fifth International Conference on Machine Learning (ICML 2018).",
      "doi": ""
    },
    {
      "text": "Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent trade-offs in the fair determination of risk scores. Proceedings of the Eighth Innovations in Theoretical Computer Science Conference (ITCS 2017) (2016).",
      "doi": ""
    },
    {
      "text": "Todd Kulesza, Saleema Amershi, Rich Caruana, Danyel Fisher, and Denis Charles. 2014. Structured labeling for facilitating concept evolution in machine learning. In Proceedings of the 2014 CHI Conference on Human Factors in Computing Systems (CHI 2014). ACM, 3075--3084.  ",
      "doi": "10.1145/2556288.2557238"
    },
    {
      "text": "Todd Kulesza, Margaret Burnett, Weng-Keen Wong, and Simone Stumpf. 2015. Principles of explanatory debugging to personalize interactive machine learning. In Proceedings of the 20th International Conference on Intelligent User Interfaces (IUI 2015). ACM, 126--137.  ",
      "doi": "10.1145/2678025.2701399"
    },
    {
      "text": "Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual fairness. In Advances in Neural Information Processing Systems (NeurIPS 2017). 4066--4076. ",
      "doi": "10.5555/3294996.3295162"
    },
    {
      "text": "Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Eric Horvitz. 2017. Identifying Unknown Unknowns in the Open World: Representations and Policies for Guided Exploration.. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2017). ",
      "doi": "10.5555/3298483.3298546"
    },
    {
      "text": "Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. How we analyzed the COMPAS recidivism algorithm. ProPublica (5 2016) 9 (2016).",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 2053951718756684.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee and Su Baykal. 2017. Algorithmic mediation in group decisions: Fairness perceptions of algorithmically mediated vs. discussion-based social division. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work (CSCW 2017). 1035--1048.  ",
      "doi": "10.1145/2998181.2998230"
    },
    {
      "text": "Anqi Liu, Lev Reyzin, and Brian D Ziebart. 2015. Shift-pessimistic active learning using robust bias-aware prediction. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2015). 2764--2770. ",
      "doi": "10.5555/2886521.2886706"
    },
    {
      "text": "Hugo Liu and Push Singh. 2002. MAKEBELIEVE: Using commonsense knowledge to generate stories. In Proceedings of the Fourteenth Innovative Applications of Artificial Intelligence Conference (IAAI 2002). 957--958. ",
      "doi": "10.5555/777092.777241"
    },
    {
      "text": "Lydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed impact of fair machine learning. Proceedings of the Thirty-fifth International Conference on Machine Learning (ICML 2018) (2018).",
      "doi": ""
    },
    {
      "text": "Natasha Lomas. 2018. Accenture wants to beat unfair AI with a professional toolkit. https://techcrun ch.com/2018/06/09/accenturewants-to-beat-unfair-ai-with-a-professional-toolkit/. Accessed: 201806--14.",
      "doi": ""
    },
    {
      "text": "Natasha Lomas. 2018. IBM launches cloud tool to detect AI bias and explain automated decisions. https://techcrunch.com/2018/09/19/ibmlaunches-cloud-tool-to-detect-ai-bias-and-explain-automateddecisions. Accessed: 2018-09--20.",
      "doi": ""
    },
    {
      "text": "Kristian Lum and William Isaac. 2016. To predict and serve? Significance 13, 5 (2016), 14--19.",
      "doi": ""
    },
    {
      "text": "Lingyu Lyu, Mehmed Kantardzic, and Tegjyot Singh Sethi. 2018. Sloppiness mitigation in crowdsourcing: detecting and correcting bias for crowd scoring tasks. International Journal of Data Science and Analytics (2018), 1--21.",
      "doi": ""
    },
    {
      "text": "Christopher J Maclellan, Erik Harpstead, Rony Patel, and Kenneth R Koedinger. 2016. The Apprentice Learner architecture: Closing the loop between learning theory and educational data.. In Proceedings of the 2016 International Conference on Educational Data Mining (EDM 2016). 151--158.",
      "doi": ""
    },
    {
      "text": "John M Malouff and Einar B Thorsteinsson. 2016. Bias in grading: A meta-analysis of experimental research findings. Australian Journal of Education 60, 3 (2016), 245--256.",
      "doi": ""
    },
    {
      "text": "MURAL. 2018. MURAL - Make remote design work. https://mural.co/. Accessed: 2018-08-02.",
      "doi": ""
    },
    {
      "text": "Arvind Narayanan. 2018. 21 fairness definitions and their politics. FAT* 2018 tutorial (2018).",
      "doi": ""
    },
    {
      "text": "Safiya Umoja Noble. 2018. Algorithms of oppression: How search engines reinforce racism. NYU Press.",
      "doi": ""
    },
    {
      "text": "Besmira Nushi, Ece Kamar, Eric Horvitz, and Donald Kossmann. 2017. On human intellect and machine failures: Troubleshooting integrative machine learning systems. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2017). 1017--1025. ",
      "doi": "10.5555/3298239.3298389"
    },
    {
      "text": "US Department of Education (ED). 2018. Family Educational Rights and Privacy Act (FERPA). https://www2.ed.gov/policy/gen/guid/fpco/ferpa/index.html. Accessed: 2018-09-04.",
      "doi": ""
    },
    {
      "text": "Partnership on AI. 2018. The Partnership on AI. https://www.partnershiponai.org. Accessed: 2018-09-03.",
      "doi": ""
    },
    {
      "text": "Julia Powles and Hal Hodson. 2017. Google DeepMind and healthcare in an age of algorithms. Health and Technology 7, 4 (2017), 351--367.",
      "doi": ""
    },
    {
      "text": "pymetrics. 2018. matching talent to opportunity. https://www.pymetrics.com/. Accessed: 2018-08--28.",
      "doi": ""
    },
    {
      "text": "Qualtrics. 2013. Qualtrics. Provo, UT, USA (2013).",
      "doi": ""
    },
    {
      "text": "Emilee Rader and Rebecca Gray. 2015. Understanding user beliefs about algorithmic curation in the Facebook news feed. In Proceedings of the 2015 CHI Conference on Human Factors in Computing Systems (CHI 2015). ACM, 173--182.  ",
      "doi": "10.1145/2702123.2702174"
    },
    {
      "text": "Manish Raghavan, Aleksandrs Slivkins, Jennifer Wortman Vaughan, and Zhiwei Steven Wu. 2018. The externalities of exploration and how data diversity helps exploitation. In Proceedings of the Thirty-first Annual Conference on Learning Theory (COLT 2018).",
      "doi": ""
    },
    {
      "text": "Dillon Reisman, Jason Schultz, K Crawford, and M Whittaker. 2018. Algorithmic impact assessments: A practical framework for public agency accountability. AI Now Institute (2018).",
      "doi": ""
    },
    {
      "text": "Ari Schlesinger, Kenton P O'Hara, and Alex S Taylor. 2018. Let's talk about race: Identity, chatbots, and AI. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 315.  ",
      "doi": "10.1145/3173574.3173889"
    },
    {
      "text": "D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. 2015. Hidden technical debt in machine learning systems. In Advances in Neural Information Processing Systems (NeurIPS 2015). 2503--2511. ",
      "doi": "10.5555/2969442.2969519"
    },
    {
      "text": "Andrew D Selbst, danah boyd, Sorelle Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and abstraction in sociotechnical systems. In ACM Conference on Fairness, Accountability, and Transparency (FAT* 2018).  ",
      "doi": "10.1145/3287560.3287598"
    },
    {
      "text": "Data & Society. 2018. Algorithmic accountability: A primer. Data & Society (2018).",
      "doi": ""
    },
    {
      "text": "Aaron Springer, J. Garcia-Gathright, and Henriette Cramer. 2018. Assessing and addressing algorithmic bias-But before we get there. In Proceedings of the AAAI 2018 Spring Symposium: Designing the User Experience of Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Donald E Stokes. 1997. Pasteur's quadrant: Basic science and technological innovation. Brookings Institution Press.",
      "doi": ""
    },
    {
      "text": "Sarah Tan, Julius Adebayo, Kori Inkpen, and Ece Kamar. 2018. Investigating Human+Machine Complementarity for Recidivism Predictions. CoRR arXiv:1808.09123.",
      "doi": ""
    },
    {
      "text": "Rob Thubron. 2018. IBM secretly used NYPD CCTV footage to train its facial recognition systems. https://www.techspot.com/news/76323ibm-secretly-used-nypd-cctv-footage-train-facial.html. Accessed: 2018-09--16.",
      "doi": ""
    },
    {
      "text": "Kentaro Toyama. 2018. From needs to aspirations in information technology for development. Information Technology for Development 24, 1, 15--36.",
      "doi": ""
    },
    {
      "text": "Melissa A Valentine, Daniela Retelny, Alexandra To, Negar Rahmati, Tulsee Doshi, and Michael S Bernstein. 2017. Flash organizations: Crowdsourcing complex work by structuring crowds as organizations. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI 2017). ACM, 3523--3537.  ",
      "doi": "10.1145/3025453.3025811"
    },
    {
      "text": "Jennifer Wortman Vaughan. 2018. Making better use of the crowd. Journal of Machine Learning Research 18, 193 (2018), 1--46.",
      "doi": ""
    },
    {
      "text": "Michael Veale and Reuben Binns. 2017. Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data. Big Data & Society 4, 2 (2017), 2053951717743530.",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in highstakes public sector decision-making. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 440.  ",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "Sara Wachter-Boettcher. 2017. AI recruiting tools do not eliminate bias. http://time.com/4993431/ai-recruiting-tools-do-not-eliminatebias. Accessed: 2018-09-01.",
      "doi": ""
    },
    {
      "text": "Allison Woodruff, Sarah E Fox, Steven Rousso-Schindler, and Jeffrey Warshaw. 2018. A qualitative exploration of perceptions of algorithmic fairness. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018). ACM, 656.  ",
      "doi": "10.1145/3173574.3174230"
    },
    {
      "text": "Qian Yang. 2018. Machine learning as a UX design material: How can we imagine beyond automation, recommenders, and reminders?. In Proceedings of the AAAI 2018 Spring Symposium: Designing the User Experience of Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Qian Yang, Jina Suh, Nan-Chen Chen, and Gonzalo Ramos. 2018. Grounding interactive machine learning tool design in how nonexperts actually build models. In Proceedings of the 2018 Conference on Designing Interactive Systems (DIS 2018). ACM, 573--584.  ",
      "doi": "10.1145/3196709.3196729"
    },
    {
      "text": "Qian Yang, John Zimmerman, Aaron Steinfeld, Lisa Carey, and James F Antaki. 2016. Investigating the heart pump implant decision process: Opportunities for decision support tools to help. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI 2016). ACM, 4477--4488.  ",
      "doi": "10.1145/2858036.2858373"
    },
    {
      "text": "Maggie Zhang. 2015. Google photos tags two AfricanAmericans as gorillas through facial recognition software. https://tinyurl.com/Forbes-2015-07-01. Accessed: 2018-07--12.",
      "doi": ""
    },
    {
      "text": "Zian Zhao, Michael Madaio, Florian Pecune, Yoichi Matsuyama, and Justine Cassell. 2018. Socially-conditioned task reasoning for a virtual tutoring agent. In Proceedings of the Seventeenth International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2018). 2265--2267. ",
      "doi": "10.5555/3237383.3238143"
    }
  ]
}