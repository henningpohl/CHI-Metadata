{
  "doi": "10.1145/3290605.3300379",
  "title": "The Invisible Potential of Facial Electromyography: A Comparison of EMG and Computer Vision when Distinguishing Posed from Spontaneous Smiles",
  "published": "2019-05-02",
  "proctitle": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-9",
  "year": 2019,
  "badges": [],
  "abstract": "Positive experiences are a success metric in product and service design. Quantifying smiles is a method of assessing them continuously. Smiles are usually a cue of positive affect, but they can also be fabricated voluntarily. Automatic detection is a promising complement to human perception in terms of identifying the differences between smile types. Computer vision (CV) and facial distal electromyography (EMG) have been proven successful in this task. This is the first study to use a wearable EMG that does not obstruct the face to compare the performance of CV and EMG measurements in the task of distinguishing between posed and spontaneous smiles. The results showed that EMG has the advantage of being able to identify covert behavior not available through vision. Moreover, CV appears to be able to identify visible dynamic features that human judges cannot account for. This sheds light on the role of non-observable behavior in distinguishing affect-related smiles from polite positive affect displays.",
  "tags": [
    "computer vision",
    "electromyography",
    "facial expression recognition"
  ],
  "authors": [
    {
      "name": "Monica Perusqu\u00eda-Hern\u00e1ndez",
      "institution": "NTT Communication Science Laboratories, Atsugi, Kanagawa, Japan",
      "img": "/do/10.1145/contrib-87959411957/rel-imgonly/87959411957.png",
      "acmid": "87959411957",
      "orcid": "0000-0002-0486-1743"
    },
    {
      "name": "Saho Ayabe-Kanamura",
      "institution": "University of Tsukuba, Tsukuba, Ibaraki, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81392599013",
      "orcid": "missing"
    },
    {
      "name": "Kenji Suzuki",
      "institution": "University of Tsukuba, Tsukuba, Ibaraki, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100184640",
      "orcid": "missing"
    },
    {
      "name": "Shiro Kumano",
      "institution": "NTT Communication Science Laboratories, Atsugi, Kanagawa, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81416595109",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Tadas Baltrusaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency. 2018. OpenFace 2.0: facial behavior analysis toolkit. In CHI 2019, May 4--9, 2019, Glasgow, Scotland Uk M. Perusqu\u00eda-Hern\u00e1ndez et al. 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018). IEEE, 59--66.",
      "doi": ""
    },
    {
      "text": "Marian Stewart Bartlett, Gwen C. Littlewort, Mark G. Frank, and Kang Lee. 2014. Automatic decoding of facial movements reveals deceptive pain expressions. Current Biology 24, 7 (mar 2014), 738--743.",
      "doi": ""
    },
    {
      "text": "Michael J. Bernstein, Donald F. Sacco, Christina M. Brown, Steven G. Young, and Heather M. Claypool. 2010. A preference for genuine smiles following social exclusion. Journal of Experimental Social Psychology 46, 1 (2010), 196--199.",
      "doi": ""
    },
    {
      "text": "Vinay Bettadapura. 2012. Face expression recognition and analysis: the state of the art. CoRR (2012), 1--27. arXiv:1203.6722",
      "doi": ""
    },
    {
      "text": "John T. Cacioppo and Louis G. Tassinary. 1990. Inferring psychological significance from physiological signals. American Psychologist 45, 1 (1990), 16--28.",
      "doi": ""
    },
    {
      "text": "Rafael A. Calvo and Sidney D. Mello. 2010. Affect detection: an interdisciplinary review of models, methods, and their applications. IEEE Transactions on Affective Computing 1, September (2010), 18--37.  ",
      "doi": "10.1109/T-AFFC.2010.1"
    },
    {
      "text": "Yumiao Chen, Zhongliang Yang, and Jiangping Wang. 2015. Eyebrow emotional expression recognition using surface EMG signals. Neurocomputing 168 (2015), 871--879.  ",
      "doi": "10.1016/j.neucom.2015.05.037"
    },
    {
      "text": "J. F. Cohn and K.L. Schmidt. 2004. The timing of facial motion in posed and spontaneous smiles. International Journal of Wavelets, Multiresolution and Information Processing 2 (2004), 121--132.",
      "doi": ""
    },
    {
      "text": "Pierre Comon. 1994. Independent component analysis, a new concept? Signal Processing 36, 36 (1994). http://mlsp.cs.cmu.edu/courses/ fall2012/lectures/ICA.pdf  ",
      "doi": "10.1016/0165-1684%2894%2990029-9"
    },
    {
      "text": "Mihaly Csikszentmihalyi and Reed Larson. 2014. Validity and reliability of the Experience-Sampling Method. In Flow and the Foundations of Positive Psychology. Springer Netherlands, Dordrecht, 35--54.",
      "doi": ""
    },
    {
      "text": "Amy Dawel, Luke Wright, Jessica Irons, Rachael Dumbleton, Romina Palermo, Richard O'Kearney, and Elinor McKone. 2017. Perceived emotion genuineness: normative ratings for popular facial expression stimuli and the development of perceived-as-genuine and perceived as-fake sets. Behavior Research Methods 49, 4 (2017), 1539--1562.",
      "doi": ""
    },
    {
      "text": "Hamdi Dibeklioglu, Albert Ali Salah, and Theo Gevers. 2015. Recognition of genuine smiles. IEEE Transactions on Multimedia 17, 3 (2015), 279--294.",
      "doi": "10.1109/TMM.2015.2394777"
    },
    {
      "text": "Guillaume-Benjamin Duchenne. 1862. M\u00e9canisme de la Physionomie Humaine. Jules Renouard, Paris.",
      "doi": ""
    },
    {
      "text": "Paul Ekman, Wallace Friesen, and Joseph Hager. 2002. FACS investigator's guide. (2002).",
      "doi": ""
    },
    {
      "text": "Paul Ekman and Erika Rosenberg. 2005. What the face reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS) (second edition ed.). Oxford University Press. 1--20, 453--486 pages.",
      "doi": ""
    },
    {
      "text": "Atsushi Funahashi, Anna Gruebler, Takeshi Aoki, Hideki Kadone, and Kenji Suzuki. 2014. Brief report: the smiles of a child with autism spectrum disorder during an animal-assisted activity may facilitate social positive behaviors - Quantitative analysis with smile-detecting interface. Journal of Autism and Developmental Disorders 44, 3 (2014), 685--693.",
      "doi": ""
    },
    {
      "text": "Reuma Gadassi and Nilly Mor. 2016. Confusing acceptance and mere politeness: Depression and sensitivity to Duchenne smiles. Journal of Behavior Therapy and Experimental Psychiatry 50 (2016), 8--14.",
      "doi": ""
    },
    {
      "text": "Anna Gruebler and Kenji Suzuki. 2014. Design of a Wearable Device for Reading Positive Expressions from Facial EMG Signals. IEEE Transactions on Affective Computing PP, 99 (2014), 1--1.",
      "doi": ""
    },
    {
      "text": "Hui Guo, Xiao-hui Zhang, Jun Liang, and Wen-jing Yan. 2018. The dynamic features of lip corners in genuine and posed smiles. Frontiers in psychology 9, February (2018), 1--11.",
      "doi": ""
    },
    {
      "text": "Mohammed Hoque, Louis Philippe Morency, and Rosalind W. Picard. 2011. Are you friendly or just polite? - Analysis of smiles in spontaneous face-to-face interactions. In Affective Computing and Intelligent Interaction. Lecture Notes in Computer Science, Sidney D'Mello (Ed.). Vol. 6974. Springer Berlin Heidelberg, 135--144. ",
      "doi": "10.5555/2062780.2062799"
    },
    {
      "text": "Aapo Hyv\u00e4rinen and Erkki Oja. 2000. Independent component analysis: algorithms and applications. Neural networks: the official journal of the International Neural Network Society 13, 4--5 (2000), 411--30.",
      "doi": ""
    },
    {
      "text": "Rachael E. Jack, Oliver G.B. Garrod, and Philippe G. Schyns. 2014. Dynamic facial expressions of emotion transmit an evolving hierarchy of signals over time. Current Biology 24, 2 (2014), 187--192.",
      "doi": ""
    },
    {
      "text": "Joris H. Janssen, Paul Tacken, J.J.G. (Gert-Jan) de Vries, Egon L. van den Broek, Joyce H.D.M. Westerink, Pim Haselager, and Wijnand A. IJsselsteijn. 2013. Machines outperform laypersons in recognizing emotions elicited by autobiographical recollection. Human--Computer Interaction 28, 6 (2013), 479--517. ",
      "doi": "10.5555/2508629.2508630"
    },
    {
      "text": "Jussi P.P. Jokinen. 2015. Emotional user experience: traits, events, and states. International Journal of Human Computer Studies 76 (2015), 67--77.  ",
      "doi": "10.1016/j.ijhcs.2014.12.006"
    },
    {
      "text": "Eva G. Krumhuber, Katja U. Likowski, and Peter Weyers. 2014. Facial mimicry of spontaneous and deliberate Duchenne and Non-Duchenne smiles. Journal of Nonverbal Behavior 38, 1 (2014), 1--11.",
      "doi": ""
    },
    {
      "text": "Eva G Krumhuber and Antony S. R. Manstead. 2013. Effects of dynamic aspects of facial expressions: a review. Emotion Review 5, 1 (2013), 41--46.",
      "doi": ""
    },
    {
      "text": "P.J. Lang, M.M. Bradley, and B.N. Cuthbert. 2008. International Affective Picture System (IAPS). Technical Report. University of Florida, Gainesville, FL. arXiv:0005--7916(93)E0016-Z",
      "doi": ""
    },
    {
      "text": "Reed Larson and Mihaly Csikszentmihalyi. 1983. The Experience Sampling Method. New Directions for Methodology of Social & Behavioral Science 15 (1983), 41--56.",
      "doi": ""
    },
    {
      "text": "Ji-Ye Mao, Karel Vredenburg, Paul W. Smith, and Tom Carey. 2005. The state of user-centered design practice. Commun. ACM 48, 3 (2005), 105--109.  ",
      "doi": "10.1145/1047671.1047677"
    },
    {
      "text": "Mohammad Mavadati, Peyten Sanger, Mohammad H Mahoor, and S York Street. 2016. Extended DISFA dataset: investigating posed and spontaneous facial expressions. (2016), 8 pages.",
      "doi": ""
    },
    {
      "text": "Shushi Namba, Russell S. Kabir, Makoto Miyatani, and Takashi Nakao. 2018. Dynamic displays enhance the ability to discriminate genuine and posed facial expressions of emotion. Frontiers in Psychology 9 (2018), 672.",
      "doi": ""
    },
    {
      "text": "Shushi Namba, Shoko Makihara, Russell S. Kabir, Makoto Miyatani, and Takashi Nakao. 2016. Spontaneous facial expressions are different from posed facial expressions: morphological properties and dynamic sequences. (2016), 13 pages.",
      "doi": ""
    },
    {
      "text": "Lindsay M. Oberman, Piotr Winkielman, and Vilayanur S. Ramachandran. 2007. Face to face: blocking facial mimicry can selectively impair recognition of emotional expressions. Social neuroscience 2, 3--4 (2007), 167--78.",
      "doi": ""
    },
    {
      "text": "Lindsay M. Oberman, Piotr Winkielman, and Vilayanur S. Ramachandran. 2009. Slow echo: facial EMG evidence for the delay of spontaneous, but not voluntary, emotional mimicry in children with autism spectrum disorders. 4 (2009), 510--520.",
      "doi": ""
    },
    {
      "text": "Monica Perusqu\u00eda-Hern\u00e1ndez, Saho Ayabe-Kanamura, and Kenji Suzuki. 2018. Human perception and biosignal-based identification of posed and spontaneous smiles. Manuscript in preparation. (2018).",
      "doi": ""
    },
    {
      "text": "Monica Perusqu\u00eda-Hern\u00e1ndez, Masakazu Hirokawa, and Kenji Suzuki. 2017. A wearable device for fast and subtle spontaneous smile recognition. IEEE Transactions on Affective Computing 8, 4 (2017), 522--533.",
      "doi": ""
    },
    {
      "text": "Monica Perusqu\u00eda-Hern\u00e1ndez, Masakazu Hirokawa, and Kenji Suzuki. 2017. Spontaneous and posed smile recognition based on spatial and temporal patterns of facial EMG. In Affective Computing and Intelligent Interaction. 537--541.",
      "doi": ""
    },
    {
      "text": "James A. Russell, Anna Weiss, and Gerald A. Mendelsohn. 1989. Affect Grid: a single-item scale of pleasure and arousal. Journal of Personality and Social Psychology 57, 3 (1989), 493--502.",
      "doi": ""
    },
    {
      "text": "Karen Schmidt, Sharika Bhattacharya, and Rachel Denlinger. 2009. Comparison of deliberate and spontaneous facial movement in smiles and eyebrow raises. Nonverbal Behaviour 33, 1 (2009), 35--45.",
      "doi": ""
    },
    {
      "text": "Karen L. Schmidt, Zara Ambadar, Jeffrey F. Cohn, and L. Ian Reed. 2006. Movement differences between deliberate and spontaneous facial expressions: zygomaticus major action in smiling. Journal of Nonverbal Behavior 30, 1 (2006), 37--52.",
      "doi": ""
    },
    {
      "text": "K. L. Schmidt and J. F. Cohn. 2001. Dynamics of facial expression: normative characteristics and individual differences. In IEEE Proceedings of International Conference on Multimedia and Expo. IEEE, Tokyo, 728--731.",
      "doi": ""
    },
    {
      "text": "Ruiting Song, Harriet Over, and Malinda Carpenter. 2016. Young children discriminate genuine from fake smiles and expect people displaying genuine smiles to be more prosocial. Evolution and Human Behavior 37, 6 (2016), 490--501.",
      "doi": ""
    },
    {
      "text": "Yuji Takano and Kenji Suzuki. 2014. Affective communication aid using wearable devices based on biosignals. In Proceedings of the 2014 conference on Interaction design and children - IDC '14. ACM Press, New York, New York, USA, 213--216.  ",
      "doi": "10.1145/2593968.2610455"
    },
    {
      "text": "Louis G. Tassinary and John T. Cacioppo. 1992. Unobservable Facial Actions and Emotion. Psychological Science 3, 1 (1992), 28--33.",
      "doi": ""
    },
    {
      "text": "Pascal Thibault, Manon Levesque, Pierre Gosselin, and Ursula Hess. 2012. The Duchenne marker is not a universal signal of smile authenticity - but it can be learned! Social Psychology 43, 4 (2012), 215--221. arXiv:arXiv:1011.1669v3",
      "doi": ""
    },
    {
      "text": "Anton van Boxtel. 2010. Facial EMG as a tool for inferring affective states. In Proceedings of Measuring Behavior, AJ Spink, F Grieco, Krips OE, LWS Loijens, LPJJ Noldus, and PH Zimmerman (Eds.). Eindhoven, 104--108.",
      "doi": ""
    },
    {
      "text": "Alessandro Vinciarelli, Maja Pantic, and Herve Bourlard. 2009. Social signal processing: survey of an emerging domain. Image and Vision Computing 27, 12 (2009), 1743--1759.  ",
      "doi": "10.1016/j.imavis.2008.11.007"
    },
    {
      "text": "Shangfei Wang, Chongliang Wu, and Qiang Ji. 2016. Capturing global spatial patterns for distinguishing posed and spontaneous expressions. Computer Vision and Image Understanding 147 (jun 2016), 69--76.  ",
      "doi": "10.1016/j.cviu.2015.08.007"
    },
    {
      "text": "Jiajia Yang and Shangfei Wang. 2017. Capturing spatial and temporal patterns for distinguishing between posed and spontaneous expressions. In Proceedings of the 2017 ACM on Multimedia Conference - MM '17. ACM Press, New York, New York, USA, 469--477.  ",
      "doi": "10.1145/3123266.3123350"
    },
    {
      "text": "Mircea Zloteanu, Eva G. Krumhuber, and Daniel C. Richardson. 2018. Detecting genuine and deliberate displays of surprise in static and dynamic faces. Frontiers in Psychology 9 (2018), 1184.",
      "doi": ""
    }
  ]
}