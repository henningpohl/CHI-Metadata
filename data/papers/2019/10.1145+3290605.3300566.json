{
  "doi": "10.1145/3290605.3300566",
  "title": "Hands Holding Clues for Object Recognition in Teachable Machines",
  "published": "2019-05-02",
  "proctitle": "CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-12",
  "year": 2019,
  "badges": [],
  "abstract": "Camera manipulation confounds the use of object recognition applications by blind people. This is exacerbated when photos from this population are also used to train models, as with teachable machines, where out-of-frame or partially included objects against cluttered backgrounds degrade performance. Leveraging prior evidence on the ability of blind people to coordinate hand movements using proprioception, we propose a deep learning system that jointly models hand segmentation and object localization for object classification. We investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. We confirm the potential of this approach by analyzing existing datasets from people with visual impairments for object recognition. With a new publicly available egocentric dataset and an extensive error analysis, we provide insights into this approach in the context of teachable recognizers.",
  "tags": [
    "object recognition",
    "blind",
    "egocentric",
    "hand",
    "k-shot learning"
  ],
  "authors": [
    {
      "name": "Kyungjun Lee",
      "institution": "University of Maryland, College Park, College Park, MD, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659367064",
      "orcid": "0000-0001-8556-9113"
    },
    {
      "name": "Hernisa Kacorri",
      "institution": "University of Maryland, College Park, College Park, MD, USA",
      "img": "/do/10.1145/contrib-81474702153/rel-imgonly/81474702153.jpg",
      "acmid": "81474702153",
      "orcid": "0000-0002-7798-308X"
    }
  ],
  "references": [
    {
      "text": "Dustin Adams, Sri Kurniawan, Cynthia Herrera, Veronica Kang, and Natalie Friedman. 2016. Blind photographers and VizSnap: A longterm study. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 201--208.  ",
      "doi": "10.1145/2982142.2982169"
    },
    {
      "text": "Dustin Adams, Lourdes Morales, and Sri Kurniawan. 2013. A qualitative study to support a blind photography mobile application. In Proceedings of the 6th International Conference on PErvasive Technologies Related to Assistive Environments. ACM, 25.  ",
      "doi": "10.1145/2504335.2504360"
    },
    {
      "text": "Tousif Ahmed, Roberto Hoyle, Kay Connelly, David Crandall, and Apu Kapadia. 2015. Privacy concerns and behaviors of people with visual impairments. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. ACM, 3523--3532.  ",
      "doi": "10.1145/2702123.2702334"
    },
    {
      "text": "Envision AI. 2018. Enabling vision for the blind. https://www. letsenvision.com",
      "doi": ""
    },
    {
      "text": "Seeing AI. 2017. A free app that narrates the world around you. https: //www.microsoft.com/en-us/seeing-ai",
      "doi": ""
    },
    {
      "text": "VocalEyes AI. 2017. Computer Vision for the blind. http://vocaleyes.ai",
      "doi": ""
    },
    {
      "text": "Aira. 2017. Your Life, Your Schedule, Right Now. https://aira.io",
      "doi": ""
    },
    {
      "text": "Sven Bambach, Stefan Lee, David J Crandall, and Chen Yu. 2015. Lending a hand: Detecting hands and recognizing activities in complex egocentric interactions. In Proceedings of the IEEE International Conference on Computer Vision. 1949--1957.  ",
      "doi": "10.1109/ICCV.2015.226"
    },
    {
      "text": "BeMyEyes. 2015. Lend you eyes to the blind. http://www.bemyeyes. org",
      "doi": ""
    },
    {
      "text": "BeSpecular. 2016. Let blind people see through your eyes. https: //www.bespecular.com",
      "doi": ""
    },
    {
      "text": "Jefrey P Bigham, Chandrika Jayant, Hanjie Ji, Greg Little, Andrew Miller, Robert C Miller, Robin Miller, Aubrey Tatarowicz, Brandyn White, Samual White, et al. 2010. VizWiz: nearly real-time answers to visual questions. In Proceedings of the 23nd annual ACM symposium on User interface software and technology. ACM, 333--342.  ",
      "doi": "10.1145/1866029.1866080"
    },
    {
      "text": "Erin L Brady, Yu Zhong, Meredith Ringel Morris, and Jefrey P Bigham. 2013. Investigating the appropriateness of social network question asking as a resource for blind users. In Proceedings of the 2013 conference on Computer supported cooperative work. ACM, 1225--1236.  ",
      "doi": "10.1145/2441776.2441915"
    },
    {
      "text": "Minjie Cai, Kris Kitani, and Yoichi Sato. 2018. Understanding handobject manipulation by modeling the contextual relationship between actions, grasp types and object attributes. arXiv preprint arXiv:1807.08254 (2018).",
      "doi": ""
    },
    {
      "text": "Minjie Cai, Kris M Kitani, and Yoichi Sato. 2016. Understanding HandObject Manipulation with Grasp Types and Object Attributes.. In Robotics: Science and Systems, Vol. 3.",
      "doi": ""
    },
    {
      "text": "CamFind. 2013. Search the physical world. http://camfndapp.com",
      "doi": ""
    },
    {
      "text": "Claudio Castellini, Tatiana Tommasi, Nicoletta Noceti, Francesca Odone, and Barbara Caputo. 2011. Using object afordances to improve object recognition. IEEE Transactions on Autonomous Mental Development 3, 3 (2011), 207--215.  ",
      "doi": "10.1109/TAMD.2011.2106782"
    },
    {
      "text": "Digit-Eyes. 2010. Identify and organize your world. http://www. digit-eyes.com",
      "doi": ""
    },
    {
      "text": "EyeNote. 2010. Mobile device application to denominate Federal Reserve Notes (U.S. paper currency) as an aid for the blind or visually impaired to increase accessibility. https://www.eyenote.gov",
      "doi": ""
    },
    {
      "text": "EyeSpy. 2015. The worlds best object recognition mobile app. http://www.eyespy.com",
      "doi": ""
    },
    {
      "text": "Alireza Fathi, Yin Li, and James M Rehg. 2012. Learning to recognize daily actions using gaze. In European Conference on Computer Vision. Springer, 314--327.  ",
      "doi": "10.1007/978-3-642-33718-5_23"
    },
    {
      "text": "Alireza Fathi, Xiaofeng Ren, and James M Rehg. 2011. Learning to recognize objects in egocentric activities. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference On. IEEE, 3281--3288.  ",
      "doi": "10.1109/CVPR.2011.5995444"
    },
    {
      "text": "German H Flores and Roberto Manduchi. 2018. WeAllWalk: An Annotated Dataset of Inertial Sensor Time Series from Blind Walkers. ACM Transactions on Accessible Computing (TACCESS) 11, 1 (2018), 4.  ",
      "doi": "10.1145/3161711"
    },
    {
      "text": "Ren\u00e9 Gilster, Constanze Hesse, and Heiner Deubel. 2012. Contact points during multidigit grasping of geometric objects. Experimental brain research 217, 1 (2012), 137--151.",
      "doi": ""
    },
    {
      "text": "Talking Goggles. 2013. A camera with speech. http://www. sparklingapps.com/goggles",
      "doi": ""
    },
    {
      "text": "Nadia Gosselin-Kessiby, John F Kalaska, and Julie Messier. 2009. Evidence for a proprioception-based rapid on-line error correction mechanism for hand orientation during reaching movements in blind subjects. Journal of Neuroscience 29, 11 (2009), 3485--3496.",
      "doi": ""
    },
    {
      "text": "Anhong Guo, Xiang'Anthony' Chen, Haoran Qi, Samuel White, Suman Ghosh, Chieko Asakawa, and Jefrey P Bigham. 2016. Vizlens: A robust and interactive screen reader for interfaces in the real world. In Proceedings of the 29th Annual Symposium on User Interface Software and Technology. ACM, 651--664.  ",
      "doi": "10.1145/2984511.2984518"
    },
    {
      "text": "Danna Gurari, Qing Li, Abigale J Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, and Jefrey P Bigham. 2018. VizWiz Grand Challenge: Answering Visual Questions from Blind People. arXiv preprint arXiv:1802.08218 (2018).",
      "doi": ""
    },
    {
      "text": "Susumu Harada, Daisuke Sato, Dustin W Adams, Sri Kurniawan, Hironobu Takagi, and Chieko Asakawa. 2013. Accessible photo album: enhancing the photo sharing experience for people with visual impairment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2127--2136.  ",
      "doi": "10.1145/2470654.2481292"
    },
    {
      "text": "T. Hollerer and T. Lee. 2007. Handy AR: Markerless Inspection of Augmented Reality Objects Using Fingertip Tracking. In 2007 11th IEEE International Symposium on Wearable Computers(ISWC), Vol. 00. 1--8.  ",
      "doi": "10.1109/ISWC.2007.4373785"
    },
    {
      "text": "Shao Huang, Weiqiang Wang, Shengfeng He, and Rynson WH Lau. 2017. Egocentric hand detection via dynamic region growing. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) 14, 1 (2017), 10.  ",
      "doi": "10.1145/3152129"
    },
    {
      "text": "Matt Huenerfauth and Hernisa Kacorri. 2014. Release of experimental stimuli and questions for evaluating facial expressions in animations of American Sign Language. In Proceedings of the 6th Workshop on the Representation and Processing of Sign Languages: Beyond the Manual Channel, The 9th International Conference on Language Resources and Evaluation (LREC 2014), Reykjavik, Iceland.",
      "doi": ""
    },
    {
      "text": "Laurent Itti and Christof Koch. 2001. Computational modelling of visual attention. Nature reviews neuroscience 2, 3 (2001), 194.",
      "doi": ""
    },
    {
      "text": "Rabia Jafri, Syed Abid Ali, Hamid R Arabnia, and Shameem Fatima. 2014. Computer vision-based object recognition for the visually impaired in an indoors environment: a survey. The Visual Computer 30, 11 (2014), 1197--1222.  ",
      "doi": "10.1007/s00371-013-0886-1"
    },
    {
      "text": "Chandrika Jayant, Hanjie Ji, Samuel White, and Jefrey P Bigham. 2011. Supporting blind photography. In The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility. ACM, 203--210.  ",
      "doi": "10.1145/2049536.2049573"
    },
    {
      "text": "Hernisa Kacorri. 2017. Teachable machines for accessibility. ACM SIGACCESS Accessibility and Computing 119 (2017), 10--18.  ",
      "doi": "10.1145/3167902.3167904"
    },
    {
      "text": "Hernisa Kacorri, Kris M Kitani, Jefrey P Bigham, and Chieko Asakawa. 2017. People with visual impairment training personal object recognizers: Feasibility and challenges. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 5839--5849.  ",
      "doi": "10.1145/3025453.3025899"
    },
    {
      "text": "Hernisa Kacorri, Sergio Mascetti, Andrea Gerino, Dragan Ahmetovic, Hironobu Takagi, and Chieko Asakawa. 2016. Supporting orientation of people with visual impairment: Analysis of large scale usage data. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 151--159. CHI 2019, May 4--9, 2019, Glasgow, Scotland UK  ",
      "doi": "10.1145/2982142.2982178"
    },
    {
      "text": "Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).",
      "doi": ""
    },
    {
      "text": "Roberta L Klatzky, Brian McCloskey, Sally Doherty, James Pellegrino, and Terence Smith. 1987. Knowledge about hand shaping and knowledge about objects. Journal of motor Behavior 19, 2 (1987), 187--213.",
      "doi": ""
    },
    {
      "text": "Marco Leo, G Medioni, M Trivedi, Takeo Kanade, and Giovanni Maria Farinella. 2017. Computer vision for assistive technologies. Computer Vision and Image Understanding 154 (2017), 1--15.  ",
      "doi": "10.1016/j.cviu.2016.09.001"
    },
    {
      "text": "Yin Li, Zhefan Ye, and James M Rehg. 2015. Delving into egocentric actions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 287--295.",
      "doi": ""
    },
    {
      "text": "Jonathan Long, Evan Shelhamer, and Trevor Darrell. 2015. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition. 3431--3440.",
      "doi": ""
    },
    {
      "text": "Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I Jordan. 2015. Learning transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791 (2015).",
      "doi": ""
    },
    {
      "text": "Minghuang Ma, Haoqi Fan, and Kris M Kitani. 2016. Going deeper into frst-person activity recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1894--1903.",
      "doi": ""
    },
    {
      "text": "Shahzad Malik, Chris McDonald, and Gerhard Roth. 2002. Hand tracking for interactive pattern-based augmented reality. In Proceedings of the 1st International Symposium on Mixed and Augmented Reality. IEEE Computer Society, 117. ",
      "doi": "10.5555/850976.854952"
    },
    {
      "text": "Roberto Manduchi and James Coughlan. 2012. (Computer) vision without sight. Commun. ACM 55, 1 (2012), 96--104.  ",
      "doi": "10.1145/2063176.2063200"
    },
    {
      "text": "Sergio Mascetti, Andrea Gerino, Cristian Bernareggi, Silvia D'Acquisto, Mattia Ducci, and James M Coughlan. 2017. JustPoint: Identifying Colors with a Natural User Interface. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 329--330.  ",
      "doi": "10.1145/3132525.3134802"
    },
    {
      "text": "Novi Patricia and Barbara Caputo. 2014. Learning to learn, from transfer learning to domain adaptation: A unifying perspective. In Proceedings of the Computer Vision and Pattern Recognition.  ",
      "doi": "10.1109/CVPR.2014.187"
    },
    {
      "text": "V. I. Pavlovic, T. S. Huang, and R. Sharma. 1997. Visual Interpretation of Hand Gestures for Human-Computer Interaction: A Review. IEEE Transactions on Pattern Analysis & Machine Intelligence 19 (07 1997), 677--695.  ",
      "doi": "10.1109/34.598226"
    },
    {
      "text": "Tomas Pfster, James Charles, and Andrew Zisserman. 2015. Flowing convnets for human pose estimation in videos. In Proceedings of the IEEE International Conference on Computer Vision. 1913--1921.  ",
      "doi": "10.1109/ICCV.2015.222"
    },
    {
      "text": "Uwe Proske and Simon C Gandevia. 2012. The proprioceptive senses: their roles in signaling body shape, body position and movement, and muscle force. Physiological reviews 92, 4 (2012), 1651--1697.",
      "doi": ""
    },
    {
      "text": "Siddharth S Rautaray and Anupam Agrawal. 2015. Vision based hand gesture recognition for human computer interaction: a survey. Artifcial Intelligence Review 43, 1 (2015), 1--54.  ",
      "doi": "10.1007/s10462-012-9356-9"
    },
    {
      "text": "LookTel Recognizer. 2012. Instantly recognize everyday objects. http: //www.looktel.com/recognizer",
      "doi": ""
    },
    {
      "text": "Stefan Reifnger, Frank Wallhof, Markus Ablassmeier, Tony Poitschke, and Gerhard Rigoll. 2007. Static and dynamic hand-gesture recognition for augmented reality applications. In International Conference on Human-Computer Interaction. Springer, 728--737. ",
      "doi": "10.5555/1769590.1769672"
    },
    {
      "text": "Xiaofeng Ren and Chunhui Gu. 2010. Figure-ground segmentation improves handled object recognition in egocentric video. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 3137--3144.",
      "doi": ""
    },
    {
      "text": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifer. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 1135--1144. Kyungjun Lee and Hernisa Kacorri  ",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Andrew Rosenberg and Julia Hirschberg. 2007. V-measure: A conditional entropy-based external cluster evaluation measure. In Proceedings of the 2007 joint conference on empirical methods in natural language processing and computational natural language learning (EMNLP-CoNLL).",
      "doi": ""
    },
    {
      "text": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. 2015. Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115, 3 (2015), 211--252.  ",
      "doi": "10.1007/s11263-015-0816-y"
    },
    {
      "text": "Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra, et al. 2017. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.. In ICCV. 618--626.",
      "doi": ""
    },
    {
      "text": "Charles S SHERRINGTON. 1907. On the proprio-ceptive system, especially in its refex aspect. Brain 29, 4 (1907), 467--482.",
      "doi": ""
    },
    {
      "text": "Kristen Shinohara and Jacob O Wobbrock. 2011. In the shadow of misperception: assistive technology use and social interactions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 705--714.  ",
      "doi": "10.1145/1978942.1979044"
    },
    {
      "text": "Joan Sosa-Garc\u00eda and Francesca Odone. 2017. \"Hands On\" Visual Recognition for Visually Impaired Users. ACM Transactions on Accessible Computing (TACCESS) 10, 3 (2017), 8.  ",
      "doi": "10.1145/3060056"
    },
    {
      "text": "Jeremi Sudol. 2013. LookTel-Computer Vision Applications for the Visually Impaired. Ph.D. Dissertation. UCLA. ",
      "doi": "10.5555/2520388"
    },
    {
      "text": "Christian Szegedy, Vincent Vanhoucke, Sergey Iofe, Jon Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2818--2826.",
      "doi": ""
    },
    {
      "text": "TapTapSee. 2012. Mobile camera application designed specifcally for the blind and visually impaired iOS users. http://www.taptapseeapp. com",
      "doi": ""
    },
    {
      "text": "Marynel V\u00e1zquez and Aaron Steinfeld. 2012. Helping visually impaired users properly aim a camera. In Proceedings of the 14th international ACM SIGACCESS conference on Computers and accessibility. ACM, 95-- 102.  ",
      "doi": "10.1145/2384916.2384934"
    },
    {
      "text": "Aipoly Vision. 2016. Sight for Blind & Visually Impaired. http: //aipoly.com",
      "doi": ""
    },
    {
      "text": "WayAround. 2018. The smart assistant for people who are blind. https://www.wayaround.com",
      "doi": ""
    },
    {
      "text": "John Weissmann and Ralf Salomon. 1999. Gesture recognition for virtual reality applications using data gloves and neural networks. In Neural Networks, 1999. IJCNN'99. International Joint Conference on, Vol. 3. IEEE, 2043--2046.",
      "doi": ""
    },
    {
      "text": "Deyou Xu. 2006. A neural network approach for hand gesture recognition in virtual reality driving training system of SPG. In Pattern Recognition, 2006. ICPR 2006. 18th International Conference on, Vol. 3. IEEE, 519--522.  ",
      "doi": "10.1109/ICPR.2006.109"
    },
    {
      "text": "Hanlu Ye, Meethu Malu, Uran Oh, and Leah Findlater. 2014. Current and future mobile and wearable device use by people with visual impairments. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3123--3132.  ",
      "doi": "10.1145/2556288.2557085"
    },
    {
      "text": "Yifan Zhang, Congqi Cao, Jian Cheng, and Hanqing Lu. 2018. EgoGesture: A New Dataset and Benchmark for Egocentric Hand Gesture Recognition. IEEE Transactions on Multimedia 20, 5 (2018), 1038--1050.",
      "doi": ""
    },
    {
      "text": "Yu Zhong, Pierre J Garrigues, and Jefrey P Bigham. 2013. Real time object scanning using a mobile phone and cloud-based visual search engine. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, 20.  ",
      "doi": "10.1145/2513383.2513443"
    }
  ]
}