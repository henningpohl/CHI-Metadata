{
  "doi": "10.1145/1357054.1357135",
  "title": "Lean and zoom: proximity-aware user interface and content magnification",
  "published": "2008-04-06",
  "proctitle": "CHI '08: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "507-510",
  "year": 2008,
  "badges": [],
  "abstract": "The size and resolution of computer displays has increased dramatically, allowing more information than ever to be rendered on-screen. However, items can now be so small or screens so cluttered that users need to lean forward to properly examine them. This behavior may be detrimental to a user's posture and eyesight. Our Lean and Zoom system detects a user's proximity to the display using a camera and magnifies the on-screen content proportionally. This alleviates dramatic leaning and makes items more readable. Results from a user study indicate people find the technique natural and intuitive. Most participants found on-screen content easier to read, and believed the technique would improve both their performance and comfort.",
  "tags": [
    "semantic zooming",
    "user interfaces",
    "lean",
    "proximity aware",
    "assistive technology",
    "posture",
    "sensors",
    "magnification"
  ],
  "authors": [
    {
      "name": "Chris Harrison",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/do/10.1145/contrib-81350573130/rel-imgonly/pastedgraphic-11.png",
      "acmid": "81350573130",
      "orcid": "0000-0001-5312-3619"
    },
    {
      "name": "Anind K. Dey",
      "institution": "Carnegie Mellon University, Pittsburgh, PA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100327371",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Bobick, A. et al. The KidsRoom: A perceptually-based interactive and immersive story environment. Presence (8)4, 367--391.  ",
      "doi": "10.1162/105474699566297"
    },
    {
      "text": "Grandjean, E. Fitting the Task to the Man. Taylor &amp; Francis, New York, NY, 1988.",
      "doi": ""
    },
    {
      "text": "Igarashi, T. and Hinckley, K. Speed-dependent automatic zooming for browsing large documents. Proceedings of UIST 2000, 139--148.  ",
      "doi": "10.1145/354401.354435"
    },
    {
      "text": "Igarashi, T. and Hughes, J.F. Voice as sound: Using non-verbal voice input for interactive control. Proceedings of UIST 2001, 155--156.  ",
      "doi": "10.1145/502348.502372"
    },
    {
      "text": "Jacob, R. What you look at is what you get: Eye movement-based interaction techniques. Proceedings of CHI'90, 11--18.  ",
      "doi": "10.1145/97243.97246"
    },
    {
      "text": "Vogel, D. and Balakrishnan, R. Interactive public ambient displays: transitioning from implicit to explicit, public to personal, interaction with multiple users. Proceedings of UIST 2004, 137--146.  ",
      "doi": "10.1145/1029632.1029656"
    },
    {
      "text": "Wang, S. et al. Face-tracking as an augmented input in video games: enhancing presence, role-playing and control. Proceedings of CHI 2006, 1097--1106.  ",
      "doi": "10.1145/1124772.1124936"
    }
  ]
}