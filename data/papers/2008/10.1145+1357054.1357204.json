{
  "doi": "10.1145/1357054.1357204",
  "title": "Implicit user-adaptive system engagement in speech and pen interfaces",
  "published": "2008-04-06",
  "proctitle": "CHI '08: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "969-978",
  "year": 2008,
  "badges": [],
  "abstract": "As emphasis is placed on developing mobile, educational, and other applications that minimize cognitive load on users, it is becoming more essential to explore interfaces based on implicit engagement techniques so users can remain focused on their tasks. In this research, data were collected with 12 pairs of students who solved complex math problems using a tutorial system that they engaged over 100 times per session entirely implicitly via speech amplitude or pen pressure cues. Results revealed that users spontaneously, reliably, and substantially adapted these forms of communicative energy to designate and repair an intended interlocutor in a computer-mediated group setting. Furthermore, this behavior was harnessed to achieve system engagement accuracies of 75-86%, with accuracies highest using speech amplitude. However, students had limited awareness of their own adaptations. Finally, while continually using these implicit engagement techniques, students maintained their performance level at solving complex mathematics problems throughout a one-hour session.",
  "tags": [
    "implicit",
    "user-adaptive",
    "speech amplitude",
    "pen pressure",
    "educational interface",
    "system engagement"
  ],
  "authors": [
    {
      "name": "Sharon Oviatt",
      "institution": "Incaa Designs, Seattle, WA, USA",
      "img": "/do/10.1145/contrib-81100656112/rel-imgonly/handbookv1.png",
      "acmid": "81100656112",
      "orcid": "missing"
    },
    {
      "name": "Colin Swindells",
      "institution": "Incaa Designs, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100548789",
      "orcid": "missing"
    },
    {
      "name": "Alex Arthur",
      "institution": "Adapx, Seattle, WA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81318497716",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Arthur, A., Lunsford, R., Wesson, R. and Oviatt, S. Prototyping novel collaborative multimodal systems: Simulation, data collection and analysis tools for the next decade. Proc. of ICMI 2006, ACM Press (2006), 209--216.  ",
      "doi": "10.1145/1180995.1181039"
    },
    {
      "text": "Arthur, A., Swindells, C., Oviatt, S. and Cohen, P. A High-performance dual-wizard infrastructure supporting speech and digital pen input, in submission.",
      "doi": ""
    },
    {
      "text": "Hinckley, K., Guimbretiere, F., Baudisch, P., Sarin, R., Agrawala, M. and Cutrell. E. The springboard: Multiple modes in one spring-loaded control, Proc. of CHI, ACM Press (2006), 181--190.  ",
      "doi": "10.1145/1124772.1124801"
    },
    {
      "text": "Kao. H., Hong, M. and Wah, L. Handwriting pressure: Effects of task complexity, control mode and orthographic difference, Graphonomics: Contemporary Research in Handwriting, ed. by H. Kao, G. van Galen &amp; R. Hoosain, North Holland, 1986, 47--66.",
      "doi": ""
    },
    {
      "text": "Li, Y., Hinckley, K., Guan, Z. and Landay, J. Experimental analysis of mode switching techniques in pen-based user interfaces, Proc. of CHI, ACM Press (2005), 461--470.  ",
      "doi": "10.1145/1054972.1055036"
    },
    {
      "text": "Lindblom, B. Explaining phonetic variation: A sketch of the H and H theory, Speech Production and Speech Modeling, ed. by W. Hardcastle and A. Marchal, Kluwer, Dordrecht (1990), 403--439.",
      "doi": ""
    },
    {
      "text": "Lunsford, R., Oviatt, S. &amp; Coulston, R. Audio-visual cues distinguishing self- from system-directed speech in younger and older adults. Proc. of ICMI, ACM Press (2005), 265--272.  ",
      "doi": "10.1145/1088463.1088494"
    },
    {
      "text": "Lunsford, R., Oviatt, S. and Arthur, A. Toward open-microphone engagement for multiparty interactions, Proc. of ICMI 2006, ACM Press (2006), 273--280.  ",
      "doi": "10.1145/1180995.1181049"
    },
    {
      "text": "Messer, D. The identification of names in maternal speech to infants. Journ. of Psycholinguistic Research, 10 (1), 1981, 69--77.",
      "doi": ""
    },
    {
      "text": "Neti, C., Iyengar, G., Potamianos, G., Senior, A., and Maison, B. Perceptual interfaces for information interaction: Joint processing of audio and visual information for human-computer interaction. Proc. of ICSLP, Chinese Friendship Publishers, (2000), 11--14.",
      "doi": ""
    },
    {
      "text": "Oviatt, S. L., Arthur, A. and Cohen, J. Q uiet interfaces that help students think, Proc. of UIST, ACM Press (2006), 191--200.  ",
      "doi": "10.1145/1166253.1166284"
    },
    {
      "text": "Oviatt, S., MacEachern, M. and Levow, G. Predicting hyperarticulate speech during human-computer error resolution, Speech Communication (1998), 24 (2), 1--23.  ",
      "doi": "10.1016/S0167-6393%2898%2900005-3"
    },
    {
      "text": "Paek, T., Horvitz, E., and Ringger, E. Continuous listening for unconstrained spoken dialog. Proc. of ICSLP, Chinese Friendship Publishers, (2000), 138--141.",
      "doi": ""
    },
    {
      "text": "Ramos, G., Boulos, M. and Balakrishnan, R. Pressure widgets, Proc. of CHI, (2004), 487--494.  ",
      "doi": "10.1145/985692.985754"
    },
    {
      "text": "Saund, E. and Lank, E. Stylus input and editing without prior selection of mode, Proc. of UIST, ACM Press (2003), 213--216.  ",
      "doi": "10.1145/964696.964720"
    },
    {
      "text": "Schroger, E., A neural mechanism for involuntary attention shifts to changes in auditory stimulation. Journ. of Cognitive Neuroscience, 8(6), 1996, 527--539.  ",
      "doi": "10.1162/jocn.1996.8.6.527"
    },
    {
      "text": "Shriberg, E., Stolcke, A. and Baron, D. Observations on overlap: Findings and implications for automatic processing of multi-party conversation. Proc. of Eurospeech, (2001), 1359--1362.",
      "doi": ""
    },
    {
      "text": "van Turnhout, K., Terken, J., Bakx, I. and Eggen, B. Identifying the intended addressee in mixed human-human and human-computer interaction from non-verbal features. Proc. of ICMI, ACM Press (2005), 175--182.  ",
      "doi": "10.1145/1088463.1088495"
    }
  ]
}