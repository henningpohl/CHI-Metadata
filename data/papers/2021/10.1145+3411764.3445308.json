{
  "doi": "10.1145/3411764.3445308",
  "title": "Soliciting Stakeholders\u2019 Fairness Notions in Child Maltreatment Predictive Systems",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-17",
  "year": 2021,
  "badges": [],
  "abstract": "Recent work in fair machine learning has proposed dozens of technical definitions of algorithmic fairness and methods for enforcing these definitions. However, we still lack an understanding of how to develop machine learning systems with fairness criteria that reflect relevant stakeholders\u2019 nuanced viewpoints in real-world contexts. To address this gap, we propose a framework for eliciting stakeholders\u2019 subjective fairness notions. Combining a user interface that allows stakeholders to examine the data and the algorithm\u2019s predictions with an interview protocol to probe stakeholders\u2019 thoughts while they are interacting with the interface, we can identify stakeholders\u2019 fairness beliefs and principles. We conduct a user study to evaluate our framework in the setting of a child maltreatment predictive system. Our evaluations show that the framework allows stakeholders to comprehensively convey their fairness viewpoints. We also discuss how our results can inform the design of predictive systems.",
  "authors": [
    {
      "name": "Hao-Fei Cheng",
      "institution": "GroupLens Research University of Minnesota, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659156442",
      "orcid": "missing"
    },
    {
      "name": "Logan Stapleton",
      "institution": "University of Minnesota, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659700796",
      "orcid": "missing"
    },
    {
      "name": "Ruiqi Wang",
      "institution": "Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659700990",
      "orcid": "missing"
    },
    {
      "name": "Paige Bullock",
      "institution": "Kenyon College, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659702165",
      "orcid": "missing"
    },
    {
      "name": "Alexandra Chouldechova",
      "institution": "Heinz College Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81553917956",
      "orcid": "0000-0002-2337-9610"
    },
    {
      "name": "Zhiwei Steven Steven Wu",
      "institution": "Carnegie Mellon University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "89758804757",
      "orcid": "missing"
    },
    {
      "name": "Haiyi Zhu",
      "institution": "Human Computer Interaction Institute Carnegie Mellon University, United States",
      "img": "/do/10.1145/contrib-81484646857/rel-imgonly/headshot.png",
      "acmid": "81484646857",
      "orcid": "0000-0001-7271-9100"
    }
  ],
  "references": [
    {
      "text": "Alekh Agarwal, Alina Beygelzimer, Miroslav Dud\u00edk, John Langford, and Hanna\u00a0M. Wallach. 2018. A Reductions Approach to Fair Classification. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, Stockholm, Sweden, July 10-15, 2018. 60\u201369. http://proceedings.mlr.press/v80/agarwal18a.html",
      "doi": ""
    },
    {
      "text": "Alekh Agarwal, Miroslav Dud\u00edk, and Zhiwei\u00a0Steven Wu. 2019. Fair Regression: Quantitative Definitions and Reduction-Based Algorithms. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA. 120\u2013129. http://proceedings.mlr.press/v97/agarwal19d.html",
      "doi": ""
    },
    {
      "text": "Yongsu Ahn and Yu-Ru Lin. 2019. Fairsight: Visual analytics for fairness in decision making. IEEE transactions on visualization and computer graphics 26, 1(2019), 1086\u20131095.",
      "doi": ""
    },
    {
      "text": "E.\u00a0P. Apfelbaum, K. Pauker, S.\u00a0R. Sommers, and N. Ambady. 2010. In blind pursuit of racial equality?Psychological Science 21(2010), 1587\u20141592. https://doi.org/10.1177/0956797610384741",
      "doi": ""
    },
    {
      "text": "Edmond Awad, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-Fran\u00e7ois Bonnefon, and Iyad Rahwan. 2018. The Moral Machine experiment. Nature (2018), 59\u201364. Issue 563. https://doi.org/10.1038/s41586-018-0637-6",
      "doi": ""
    },
    {
      "text": "Caroline Balagot, Hector Lemus, Megan Hartrick, Tamera Kohler, and Suzanne\u00a0P Lindsay. 2019. The homeless Coordinated Entry System: the VI-SPDAT and other predictors of establishing eligibility for services for single homeless adults. Journal of Social Distress and the Homeless 28, 2 (2019), 149\u2013157.",
      "doi": ""
    },
    {
      "text": "Geoffrey Barnes and Jordan\u00a0M Hyatt. 2012. Classifying adult probationers by forecasting future offending. (2012).",
      "doi": ""
    },
    {
      "text": "Yahav Bechavod, Christopher Jung, and Zhiwei\u00a0Steven Wu. 2020. Metric-Free Individual Fairness in Online Learning. CoRR abs/2002.05474(2020). https://arxiv.org/abs/2002.05474",
      "doi": ""
    },
    {
      "text": "Rachel\u00a0KE Bellamy, Kuntal Dey, Michael Hind, Samuel\u00a0C Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, A Mojsilovi\u0107, 2019. AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias. IBM Journal of Research and Development 63, 4/5 (2019), 4\u20131.",
      "doi": ""
    },
    {
      "text": "Reuben Binns, Max Van\u00a0Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. 2018. \u2019It\u2019s Reducing a Human Being to a Percentage\u2019: Perceptions of Justice in Algorithmic Decisions. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 377.",
      "doi": "10.1145/3173574.3173951"
    },
    {
      "text": "Anna Brown, Alexandra Chouldechova, Emily Putnam-Hornstein, Andrew Tobin, and Rhema Vaithianathan. 2019. Toward Algorithmic Accountability in Public Services: A Qualitative Study of Affected Community Perspectives on Algorithmic Decision-making in Child Welfare Services. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, CHI 2019, Glasgow, Scotland, UK, May 04-09, 2019. 41. https://doi.org/10.1145/3290605.3300271",
      "doi": "10.1145/3290605.3300271"
    },
    {
      "text": "Ernest\u00a0W. Burgess. 1928. Factors determining success or failure on parole. In The workings of the indeterminate-sentence law and parole system in Illinois, A.\u00a0A. Bruce, A.\u00a0J. Harno, E.\u00a0W. Burgess, and J.\u00a0Landesco(Eds.). Springfield, IL: State Board of Parole, 221\u2013234.",
      "doi": ""
    },
    {
      "text": "\u00c1ngel\u00a0Alexander Cabrera, Will Epperson, Fred Hohman, Minsuk Kahng, Jamie Morgenstern, and Duen\u00a0Horng Chau. 2019. FairVis: Visual analytics for discovering intersectional bias in machine learning. In 2019 IEEE Conference on Visual Analytics Science and Technology (VAST). IEEE, 46\u201356.",
      "doi": ""
    },
    {
      "text": "Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad. 2015. Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1721\u20131730.",
      "doi": "10.1145/2783258.2788613"
    },
    {
      "text": "Kathy Charmaz. 2014. Constructing grounded theory. sage.",
      "doi": ""
    },
    {
      "text": "Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data 5, 2 (2017), 153\u2013163.",
      "doi": ""
    },
    {
      "text": "Sam Corbett-Davies and Sharad Goel. 2018. The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning. CoRR abs/1808.00023(2018). http://arxiv.org/abs/1808.00023",
      "doi": ""
    },
    {
      "text": "Maria De-Arteaga, Riccardo Fogliato, and Alexandra Chouldechova. 2020. A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3313831.3376638"
    },
    {
      "text": "Sarah Dean, Mihaela Curmei, and Benjamin Recht. 2020. Designing Recommender Systems with Reachability in Mind. Workshop on Participatory Approaches to Machine Learning (2020), \u2013.",
      "doi": ""
    },
    {
      "text": "Matthew DeMichele, Peter Baumgartner, Michael Wenger, Kelle Barrick, Megan Comfort, and Shilpi Misra. 2018. The public safety assessment: A re-validation and assessment of predictive utility and differential prediction by race and gender in kentucky. Available at SSRN 3168452(2018).",
      "doi": ""
    },
    {
      "text": "Sarah\u00a0L Desmarais, Samantha\u00a0A Zottola, Sarah\u00a0E Duhart\u00a0Clarke, and Evan\u00a0M Lowder. 2020. Predictive Validity of Pretrial Risk Assessments: A Systematic Review of the Literature. Criminal Justice and Behavior(2020), 0093854820932959.",
      "doi": ""
    },
    {
      "text": "Alan\u00a0J Dettlaff. 2014. The evolving understanding of disproportionality and disparities in child welfare. In Handbook of child maltreatment. Springer, 149\u2013168.",
      "doi": ""
    },
    {
      "text": "Jonathan Dodge, Q.\u00a0Vera Liao, Yunfeng Zhang, Rachel K.\u00a0E. Bellamy, and Casey Dugan. 2019. Explaining Models: An Empirical Study of How Explanations Impact Fairness Judgment. In Proceedings of the 24th International Conference on Intelligent User Interfaces (Marina del Ray, California) (IUI \u201919). ACM, New York, NY, USA, 275\u2013285. https://doi.org/10.1145/3301275.3302310",
      "doi": "10.1145/3301275.3302310"
    },
    {
      "text": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard\u00a0S. Zemel. 2012. Fairness through awareness. In Innovations in Theoretical Computer Science 2012, Cambridge, MA, USA, January 8-10, 2012. 214\u2013226. https://doi.org/10.1145/2090236.2090255",
      "doi": "10.1145/2090236.2090255"
    },
    {
      "text": "Virginia Eubanks. 2018. Automating inequality: How high-tech tools profile, police, and punish the poor. St. Martin\u2019s Press.",
      "doi": "10.5555/3208509"
    },
    {
      "text": "Sorelle\u00a0A Friedler, Carlos Scheidegger, and Suresh Venkatasubramanian. 2016. On the (im) possibility of fairness. (2016). arxiv:1609.07236",
      "doi": ""
    },
    {
      "text": "Jeremy\u00a0D Goldhaber-Fiebert and Lea Prince. 2019. Impact Evaluation of a Predictive Risk Modeling Tool for Allegheny County\u2019s Child Welfare Office. Pittsburgh: Allegheny County(2019).",
      "doi": ""
    },
    {
      "text": "Nina Grgic-Hlaca, Elissa\u00a0M. Redmiles, Krishna\u00a0P. Gummadi, and Adrian Weller. 2018. Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction. In Proceedings of the 2018 World Wide Web Conference(Lyon, France) (WWW \u201918). International World Wide Web Conferences Steering Committee, 903\u2013912. https://doi.org/10.1145/3178876.3186138",
      "doi": "10.1145/3178876.3186138"
    },
    {
      "text": "Nina Grgi\u0107-Hla\u010da, Muhammad\u00a0Bilal Zafar, Krishna\u00a0P. Gummadi, and Adrian Weller. 2018. Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of Opportunity in Supervised Learning. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain. 3315\u20133323. http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning",
      "doi": "10.5555/3157382.3157469"
    },
    {
      "text": "\u00darsula H\u00e9bert-Johnson, Michael\u00a0P. Kim, Omer Reingold, and Guy\u00a0N. Rothblum. 2018. Multicalibration: Calibration for the (Computationally-Identifiable) Masses. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, Stockholm, Sweden, July 10-15, 2018. 1944\u20131953. http://proceedings.mlr.press/v80/hebert-johnson18a.html",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Jennifer\u00a0Wortman Vaughan, Hal\u00a0Daum\u00e9 III, Miroslav Dud\u00edk, and Hanna\u00a0M. Wallach. 2019. Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, CHI 2019, Glasgow, Scotland, UK, May 04-09, 2019. 600. https://doi.org/10.1145/3290605.3300830",
      "doi": "10.1145/3290605.3300830"
    },
    {
      "text": "Christina Ilvento. 2020. Metric Learning for Individual Fairness. In 1st Symposium on Foundations of Responsible Computing, FORC 2020, June 1-3, 2020, Harvard University, Cambridge, MA, USA (virtual conference)(LIPIcs, Vol.\u00a0156), Aaron Roth(Ed.). Schloss Dagstuhl - Leibniz-Zentrum f\u00fcr Informatik, 2:1\u20132:11. https://doi.org/10.4230/LIPIcs.FORC.2020.2",
      "doi": ""
    },
    {
      "text": "Abby\u00a0Everett Jaques. 2019. Why the Moral Machine Is a Monster. In University of Miami Law School: We Robot Conference. https://robots.law.miami.edu/2019/wp-content/uploads/2019/03/MoralMachineMonster.pdf",
      "doi": ""
    },
    {
      "text": "Will Johnson. 2004. Effectiveness of California\u2019s child welfare structured decision making (SDM) model: a prospective study of the validity of the California Family Risk Assessment. Madison (Wisconsin, USA): Children\u2019s Research Center (2004).",
      "doi": ""
    },
    {
      "text": "Caroline\u00a0M Johnston, Simon Blessenohl, and Phebe Vayanos. [n.d.]. Preference Elicitation and Aggregation to Aid with Patient Triage during the COVID-19 Pandemic. Workshop on Participatory Approaches to Machine Learning ([n.\u00a0d.]).",
      "doi": ""
    },
    {
      "text": "Matthew Joseph, Michael\u00a0J. Kearns, Jamie\u00a0H. Morgenstern, and Aaron Roth. 2016. Fairness in Learning: Classic and Contextual Bandits. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain. 325\u2013333. http://papers.nips.cc/paper/6355-fairness-in-learning-classic-and-contextual-bandits",
      "doi": ""
    },
    {
      "text": "Christopher Jung, Michael\u00a0J. Kearns, Seth Neel, Aaron Roth, Logan Stapleton, and Zhiwei\u00a0Steven Wu. 2021. An Algorithmic Framework for Fairness Elicitation. In Foundations of Responsible Computing (FORC). http://arxiv.org/abs/1905.10660",
      "doi": ""
    },
    {
      "text": "Anson Kahng, Min\u00a0Kyung Lee, Ritesh Noothigattu, Ariel\u00a0D. Procaccia, and Christos-Alexandros Psomas. 2019. Statistical Foundations of Virtual Democracy. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA. 3173\u20133182. http://proceedings.mlr.press/v97/kahng19a.html",
      "doi": ""
    },
    {
      "text": "Faisal Kamiran and Toon Calders. 2012. Data preprocessing techniques for classification without discrimination. Knowledge and Information Systems 33, 1 (2012), 1\u201333.",
      "doi": "10.1007/s10115-011-0463-8"
    },
    {
      "text": "Michael\u00a0J. Kearns, Seth Neel, Aaron Roth, and Zhiwei\u00a0Steven Wu. 2018. Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, Stockholm, Sweden, July 10-15, 2018. 2569\u20132577. http://proceedings.mlr.press/v80/kearns18a.html",
      "doi": ""
    },
    {
      "text": "Danielle\u00a0Leah Kehl and Samuel\u00a0Ari Kessler. 2017. Algorithms in the criminal justice system: Assessing the use of risk assessments in sentencing. (2017).",
      "doi": ""
    },
    {
      "text": "Amir\u00a0E Khandani, Adlar\u00a0J Kim, and Andrew\u00a0W Lo. 2010. Consumer credit-risk models via machine-learning algorithms. Journal of Banking & Finance 34, 11 (2010), 2767\u20132787.",
      "doi": ""
    },
    {
      "text": "Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. 2017. Human decisions and machine predictions. The quarterly journal of economics 133, 1 (2017), 237\u2013293.",
      "doi": ""
    },
    {
      "text": "Jon\u00a0M. Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2017. Inherent Trade-Offs in the Fair Determination of Risk Scores. In 8th Innovations in Theoretical Computer Science Conference, ITCS.",
      "doi": ""
    },
    {
      "text": "Felicitas Kraemer, Kees van Overveld, and Martin Peterson. 2011. Is there an ethics of algorithms?Ethics and Information Technology 13 (2011), 251\u2013\u2013260.",
      "doi": ""
    },
    {
      "text": "Vivian Lai and Chenhao Tan. 2019. On human predictions with explanations and predictions of machine learning models: A case study on deception detection. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 29\u201338.",
      "doi": "10.1145/3287560.3287590"
    },
    {
      "text": "Min\u00a0Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1 (2018), 2053951718756684.",
      "doi": ""
    },
    {
      "text": "Min\u00a0Kyung Lee and Su Baykal. 2017. Algorithmic mediation in group decisions: Fairness perceptions of algorithmically mediated vs. discussion-based social division. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing. ACM, 1035\u20131048.",
      "doi": "10.1145/2998181.2998230"
    },
    {
      "text": "Min\u00a0Kyung Lee, Anuraag Jain, Hea\u00a0Jin Cha, Shashank Ojha, and Daniel Kusbit. 2019. Procedural justice in algorithmic fairness: Leveraging transparency and outcome control for fair algorithmic mediation. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201326.",
      "doi": "10.1145/3359284"
    },
    {
      "text": "Min\u00a0Kyung Lee, Ji\u00a0Tae Kim, and Leah Lizarondo. 2017. A human-centered approach to algorithmic services: Considerations for fair and motivating smart community service management that allocates donations to non-profit organizations. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 3365\u20133376.",
      "doi": "10.1145/3025453.3025884"
    },
    {
      "text": "Min\u00a0Kyung Lee, Daniel Kusbit, Anson Kahng, Ji\u00a0Seong Tae, Xinran Yuan, A.\u00a0D.\u00a0C. Chan, Ritesh Noothigattu, Daniel See, Siheon Lee, Christos-Alexandros Psomas, and Ariel\u00a0D. Procaccia. 2018. WeBuildAI : Participatory Framework for Fair and Efficient Algorithmic Governance. In CSCW.",
      "doi": ""
    },
    {
      "text": "David\u00a0B Marshall and Diana\u00a0J English. 2000. Neural network modeling of risk assessment in child protective services.Psychological Methods 5, 1 (2000), 102.",
      "doi": ""
    },
    {
      "text": "John Monahan. 2017. Risk assessment in sentencing. Academy for Justice, a Report on Scholarship and Criminal Justice Reform (Erik Luna ed., 2017, Forthcoming)(2017).",
      "doi": ""
    },
    {
      "text": "John Monahan, Anne Metz, and Brandon\u00a0L Garrett. 2018. Judicial Appraisals of Risk Assessment in Sentencing. (2018).",
      "doi": ""
    },
    {
      "text": "Arvind Narayanan. 2018. Translation tutorial: 21 fairness definitions and their politics. In Proc. Conf. Fairness Accountability Transp., New York, USA.",
      "doi": ""
    },
    {
      "text": "Jakob Nielsen. 1994. Usability engineering. Morgan Kaufmann.",
      "doi": ""
    },
    {
      "text": "Dino Pedreshi, Salvatore Ruggieri, and Franco Turini. 2008. Discrimination-aware data mining. In Proceedings of the 14th ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 560\u2014568.",
      "doi": "10.1145/1401890.1401959"
    },
    {
      "text": "Geoff Pleiss, Manish Raghavan, Felix Wu, Jon\u00a0M. Kleinberg, and Kilian\u00a0Q. Weinberger. 2017. On Fairness and Calibration. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA. 5684\u20135693. http://papers.nips.cc/paper/7151-on-fairness-and-calibration",
      "doi": ""
    },
    {
      "text": "Edmond Awad Sohan Dsouza Iyad Rahwan Pradeep\u00a0Ravikumar Ritesh\u00a0Noothigattu, Snehalkumar \u2018Neil\u2019 S.\u00a0Gaikwadand Ariel\u00a0D. Procaccia.2018. A voting-based system for ethical decision making. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI).",
      "doi": ""
    },
    {
      "text": "Samantha Robertson and Niloufar Salehi. 2020. What If I Don\u2019t Like Any Of The Choices? The Limits of Preference Elicitation for Participatory Algorithm Design. (2020). arxiv:2007.06718",
      "doi": ""
    },
    {
      "text": "Debjani Saha, Candice Schumann, Duncan\u00a0C. McElfresh, John\u00a0P. Dickerson, Michelle\u00a0L. Mazurek, and Michael\u00a0Carl Tschantz. 2020. Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, Vienna, Austria, July 12\u201318, 2020.",
      "doi": ""
    },
    {
      "text": "Nripsuta\u00a0Ani Saxena, Karen Huang, Evan DeFilippis, Goran Radanovic, David\u00a0C. Parkes, and Yang Liu. 2019. How Do Fairness Definitions Fare?: Examining Public Attitudes Towards Algorithmic Definitions of Fairness. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. ACM, 99\u2014106.",
      "doi": "10.1145/3306618.3314248"
    },
    {
      "text": "Nicholas Scurich and John Monahan. 2016. Evidence-based sentencing: Public openness and opposition to using gender, age, and race as risk factors for recidivism.Law and Human Behavior 40, 1 (2016), 36.",
      "doi": ""
    },
    {
      "text": "Hetan Shah. 2018. Algorithmic accountability. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 376, 2128 (2018), 20170362.",
      "doi": ""
    },
    {
      "text": "Vernon\u00a0C Smith, Adam Lange, and Daniel\u00a0R Huston. 2012. Predictive modeling to forecast student outcomes and drive effective interventions in online community college courses.Journal of Asynchronous Learning Networks 16, 3 (2012), 51\u201361.",
      "doi": ""
    },
    {
      "text": "Megha Srivastava, Hoda Heidari, and Andreas Krause. 2019. Mathematical notions vs. human perception of fairness: A descriptive approach to fairness for machine learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2459\u20132468.",
      "doi": "10.1145/3292500.3330664"
    },
    {
      "text": "Rhema Vaithianathan, Nan Jiang, Tim Maloney, Parma Nand, and Emily Putnam-Hornstein. 2017. Developing Predictive Risk Models to Support Child Maltreatment Hotline Screening Decisions. https://www.alleghenycountyanalytics.us/wp-content/uploads/2017/04/Developing-Predictive-Risk-Models-package-with-cover-1-to-post-1.pdf",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van\u00a0Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in high-stakes public sector decision-making. In Proceedings of the 2018 chi conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "Sahil Verma and Julia Rubin. 2018. Fairness definitions explained. In 2018 IEEE/ACM International Workshop on Software Fairness (FairWare). IEEE, 1\u20137.",
      "doi": "10.1145/3194770.3194776"
    },
    {
      "text": "AJ Wang. 2018. Procedural Justice and Risk-Assessment Algorithms. (2018).",
      "doi": ""
    },
    {
      "text": "Jiaxuan Wang, Jeeheh Oh, Haozhu Wang, and Jenna Wiens. 2018. Learning credible models. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2417\u20132426.",
      "doi": "10.1145/3219819.3220070"
    },
    {
      "text": "Ruotong Wang, F\u00a0Maxwell Harper, and Haiyi Zhu. 2020. Factors Influencing Perceived Fairness in Algorithmic Decision-Making: Algorithm Outcomes, Development Procedures, and Individual Differences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201314.",
      "doi": "10.1145/3313831.3376813"
    },
    {
      "text": "James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda Vi\u00e9gas, and Jimbo Wilson. 2019. The what-if tool: Interactive probing of machine learning models. IEEE transactions on visualization and computer graphics 26, 1(2019), 56\u201365.",
      "doi": ""
    },
    {
      "text": "Meredith Whittaker, Kate Crawford, Roel Dobbe, Genevieve Fried, Elizabeth Kaziunas, Varoon Mathur, Sarah\u00a0Mysers West, Rashida Richardson, Jason Schultz, and Oscar Schwartz. 2018. AI now report 2018. AI Now Institute at New York University.",
      "doi": ""
    },
    {
      "text": "Pak-Hang Wong. 2020. Democratizing Algorithmic Fairness. Philosophy & Technology 33 (2020), 225\u2013244. https://doi.org/10.1145/3290605.3300830",
      "doi": ""
    },
    {
      "text": "Allison Woodruff, Sarah\u00a0E Fox, Steven Rousso-Schindler, and Jeffrey Warshaw. 2018. A qualitative exploration of perceptions of algorithmic fairness. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 656.",
      "doi": "10.1145/3173574.3174230"
    },
    {
      "text": "Bowen Yu, Ye Yuan, Loren Terveen, Zhiwei\u00a0Steven Wu, Jodi Forlizzi, and Haiyi Zhu. 2020. Keeping Designers in the Loop: Communicating Inherent Algorithmic Trade-offs Across Multiple Objectives. In Proceedings of the 2020 ACM Designing Interactive Systems Conference. 1245\u20131257.",
      "doi": "10.1145/3357236.3395528"
    },
    {
      "text": "Muhammad\u00a0Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna\u00a0P. Gummadi. 2017. Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment. In Proceedings of the 26th International Conference on World Wide Web, WWW. ACM, 1171\u20131180.",
      "doi": "10.1145/3038912.3052660"
    },
    {
      "text": "Haiyi Zhu, Bowen Yu, Aaron Halfaker, and Loren Terveen. 2018. Value-sensitive algorithm design: Method, case study, and lessons. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 194.",
      "doi": "10.1145/3274463"
    }
  ]
}