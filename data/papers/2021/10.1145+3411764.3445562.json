{
  "doi": "10.1145/3411764.3445562",
  "title": "Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-16",
  "year": 2021,
  "badges": [],
  "abstract": "This paper addresses an under-explored problem of AI-assisted decision-making: when objective performance information of the machine learning model underlying a decision aid is absent or scarce, how do people decide their reliance on the model? Through three randomized experiments, we explore the heuristics people may use to adjust their reliance on machine learning models when performance feedback is limited. We find that the level of agreement between people and a model on decision-making tasks that people have high confidence in significantly affects reliance on the model if people receive no information about the model\u2019s performance, but this impact will change after aggregate-level model performance information becomes available. Furthermore, the influence of high confidence human-model agreement on people\u2019s reliance on a model is moderated by people\u2019s confidence in cases where they disagree with the model. We discuss potential risks of these heuristics, and provide design implications on promoting appropriate reliance on AI.",
  "tags": [
    "human-AI interaction",
    "appropriate reliance",
    "Machine learning"
  ],
  "authors": [
    {
      "name": "Zhuoran Lu",
      "institution": "Purdue University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659702293",
      "orcid": "0000-0002-1079-2043"
    },
    {
      "name": "Ming Yin",
      "institution": "Purdue University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81438595973",
      "orcid": "0000-0002-7364-139X"
    }
  ],
  "references": [
    {
      "text": "Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul\u00a0N Bennett, Kori Inkpen, 2019. Guidelines for human-ai interaction. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3290605.3300233"
    },
    {
      "text": "Ricardo Baeza-Yates. 2018. Bias on the web. Commun. ACM 61, 6 (2018), 54\u201361.",
      "doi": "10.1145/3209581"
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Walter\u00a0S Lasecki, Daniel\u00a0S Weld, and Eric Horvitz. 2019. Beyond Accuracy: The Role of Mental Models in Human-AI Team Performance. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 2\u201311.",
      "doi": ""
    },
    {
      "text": "Gagan Bansal, Besmira Nushi, Ece Kamar, Daniel\u00a0S Weld, Walter\u00a0S Lasecki, and Eric Horvitz. 2019. Updates in human-ai teams: Understanding and addressing the performance/compatibility tradeoff. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol.\u00a033. 2429\u20132437.",
      "doi": "10.1609/aaai.v33i01.33012429"
    },
    {
      "text": "Gagan Bansal, Tongshuang Wu, Joyce Zhu, Raymond Fok, Besmira Nushi, Ece Kamar, Marco\u00a0Tulio Ribeiro, and Daniel\u00a0S Weld. 2020. Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance. (2020). arxiv:2006.14779",
      "doi": ""
    },
    {
      "text": "Joy Buolamwini and Timnit Gebru. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on fairness, accountability and transparency. 77\u201391.",
      "doi": ""
    },
    {
      "text": "Carrie\u00a0J Cai, Jonas Jongejan, and Jess Holbrook. 2019. The effects of example-based explanations in a machine learning interface. In Proceedings of the 24th International Conference on Intelligent User Interfaces. 258\u2013262.",
      "doi": "10.1145/3301275.3302289"
    },
    {
      "text": "Eric\u00a0T Chancey, James\u00a0P Bliss, Yusuke Yamani, and Holly\u00a0AH Handley. 2017. Trust and the compliance\u2013reliance paradigm: The effects of risk, error bias, and reliability on trust and dependence. Human factors 59, 3 (2017), 333\u2013345.",
      "doi": ""
    },
    {
      "text": "Hao-Fei Cheng, Ruotong Wang, Zheng Zhang, Fiona O\u2019Connell, Terrance Gray, F\u00a0Maxwell Harper, and Haiyi Zhu. 2019. Explaining decision-making algorithms through UI: Strategies to help non-expert stakeholders. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3290605.3300789"
    },
    {
      "text": "Stephen\u00a0R Dixon, Christopher\u00a0D Wickens, and Jason\u00a0S McCarley. 2007. On the independence of compliance and reliance: Are automation false alarms worse than misses?Human factors 49, 4 (2007), 564\u2013572.",
      "doi": ""
    },
    {
      "text": "David Dunning. 2014. We are all confident idiots. Pacific Standard 7(2014), 46\u201354.",
      "doi": ""
    },
    {
      "text": "Mary\u00a0T Dzindolet, Scott\u00a0A Peterson, Regina\u00a0A Pomranky, Linda\u00a0G Pierce, and Hall\u00a0P Beck. 2003. The role of trust in automation reliance. International journal of human-computer studies 58, 6 (2003), 697\u2013718.",
      "doi": "10.1016/S1071-5819%2803%2900038-7"
    },
    {
      "text": "Mary\u00a0T Dzindolet, Linda\u00a0G Pierce, Hall\u00a0P Beck, and Lloyd\u00a0A Dawe. 1999. Misuse and disuse of automated aids. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, Vol.\u00a043. SAGE Publications Sage CA: Los Angeles, CA, 339\u2013339.",
      "doi": ""
    },
    {
      "text": "Philipp Ecken and Richard Pibernik. 2016. Hit or miss: what leads experts to take advice for long-term judgments?Management Science 62, 7 (2016), 2002\u20132021.",
      "doi": ""
    },
    {
      "text": "Andre Esteva, Brett Kuprel, Roberto\u00a0A Novoa, Justin Ko, Susan\u00a0M Swetter, Helen\u00a0M Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 7639 (2017), 115\u2013118.",
      "doi": ""
    },
    {
      "text": "Raymond Fisman, Sheena\u00a0S Iyengar, Emir Kamenica, and Itamar Simonson. 2006. Gender differences in mate selection: Evidence from a speed dating experiment. The Quarterly Journal of Economics 121, 2 (2006), 673\u2013697.",
      "doi": ""
    },
    {
      "text": "SM Fleming and ND Daw. 2016. Self-evaluation of decision performance: A general Bayesian framework for metacognitive computation. Psychol Rev 124(2016), 1\u201359.",
      "doi": ""
    },
    {
      "text": "Jorge Galindo and Pablo Tamayo. 2000. Credit risk assessment using statistical and machine learning: basic methodology and risk modeling applications. Computational Economics 15, 1-2 (2000), 107\u2013143.",
      "doi": "10.1023/A%3A1008699112516"
    },
    {
      "text": "Ji Gao and John\u00a0D Lee. 2006. Extending the decision field theory to model operators\u2019 reliance on automation in supervisory control situations. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 36, 5 (2006), 943\u2013959.",
      "doi": "10.1109/TSMCA.2005.855783"
    },
    {
      "text": "Ji Gao, John\u00a0D Lee, and Yi Zhang. 2006. A dynamic model of interaction between reliance on automation and cooperation in multi-operator multi-automation situations. International Journal of Industrial Ergonomics 36, 5(2006), 511\u2013526.",
      "doi": ""
    },
    {
      "text": "Efstathios\u00a0D Gennatas, Jerome\u00a0H Friedman, Lyle\u00a0H Ungar, Romain Pirracchio, Eric Eaton, Lara\u00a0G Reichmann, Yannet Interian, Jos\u00e9\u00a0Marcio Luna, Charles\u00a0B Simone, Andrew Auerbach, 2020. Expert-augmented machine learning. Proceedings of the National Academy of Sciences 117, 9 (2020), 4571\u20134577.",
      "doi": ""
    },
    {
      "text": "Ben Green and Yiling Chen. 2019. The principles and limits of algorithm-in-the-loop decision making. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201324.",
      "doi": "10.1145/3359152"
    },
    {
      "text": "Dale\u00a0W Griffin and Lee Ross. 1991. Subjective construal, social inference, and human misunderstanding. In Advances in experimental social psychology. Vol.\u00a024. Elsevier, 319\u2013359.",
      "doi": ""
    },
    {
      "text": "Christoph Hube, Besnik Fetahu, and Ujwal Gadiraju. 2019. Understanding and mitigating worker biases in the crowdsourced collection of subjective judgments. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3290605.3300637"
    },
    {
      "text": "Sarfaraz Hussein, Kunlin Cao, Qi Song, and Ulas Bagci. 2017. Risk Stratification of Lung Nodules Using 3D CNN-Based Multi-task Learning. In Information Processing in Medical Imaging, Marc Niethammer, Martin Styner, Stephen Aylward, Hongtu Zhu, Ipek Oguz, Pew-Thian Yap, and Dinggang Shen(Eds.). Springer International Publishing, Cham, 249\u2013260.",
      "doi": ""
    },
    {
      "text": "H Kaur, A Williams, and WS Lasecki. 2019. Building shared mental models between humans and ai for effective collaboration. (2019).",
      "doi": ""
    },
    {
      "text": "Yea-Seul Kim, Paula Kayongo, Madeleine Grunde-McLaughlin, and Jessica Hullman. 2020. Bayesian-Assisted Inference from Visualized Data. (2020). arxiv:2008.00142",
      "doi": ""
    },
    {
      "text": "Gang Kou, Yi Peng, and Guoxun Wang. 2014. Evaluation of clustering algorithms for financial risk analysis using MCDM methods. Information Sciences 275(2014), 1\u201312.",
      "doi": ""
    },
    {
      "text": "Justin Kruger and David Dunning. 1999. Unskilled and unaware of it: how difficulties in recognizing one\u2019s own incompetence lead to inflated self-assessments.Journal of personality and social psychology 77, 6(1999), 1121.",
      "doi": ""
    },
    {
      "text": "Vivian Lai and Chenhao Tan. 2019. On human predictions with explanations and predictions of machine learning models: A case study on deception detection. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 29\u201338.",
      "doi": "10.1145/3287560.3287590"
    },
    {
      "text": "John\u00a0D Lee and Katrina\u00a0A See. 2004. Trust in automation: Designing for appropriate reliance. Human factors 46, 1 (2004), 50\u201380.",
      "doi": ""
    },
    {
      "text": "Moshe Leshno, Vladimir\u00a0Ya Lin, Allan Pinkus, and Shimon Schocken. 1993. Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural networks 6, 6 (1993), 861\u2013867.",
      "doi": ""
    },
    {
      "text": "Varda Liberman, Julia\u00a0A Minson, Christopher\u00a0J Bryan, and Lee Ross. 2012. Na\u00efve realism and capturing the \u201cwisdom of dyads\u201d. Journal of Experimental Social Psychology 48, 2 (2012), 507\u2013512.",
      "doi": ""
    },
    {
      "text": "Duri Long and Brian Magerko. 2020. What is AI Literacy? Competencies and Design Considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3313831.3376727"
    },
    {
      "text": "Maria Madsen and Shirley Gregor. 2000. Measuring human-computer trust. In 11th australasian conference on information systems, Vol.\u00a053. Citeseer, 6\u20138.",
      "doi": ""
    },
    {
      "text": "Gary Marks and Norman Miller. 1987. Ten years of research on the false-consensus effect: An empirical and theoretical review.Psychological bulletin 102, 1 (1987), 72.",
      "doi": ""
    },
    {
      "text": "Charles Marx, Flavio Calmon, and Berk Ustun. 2020. Predictive multiplicity in classification. In International Conference on Machine Learning. PMLR, 6765\u20136774.",
      "doi": ""
    },
    {
      "text": "Stephanie\u00a0M Merritt. 2011. Affective processes in human\u2013automation interactions. Human Factors 53, 4 (2011), 356\u2013370.",
      "doi": ""
    },
    {
      "text": "Julia\u00a0A Minson, Varda Liberman, and Lee Ross. 2011. Two to tango: Effects of collaboration and disagreement on dyadic judgment. Personality and Social Psychology Bulletin 37, 10 (2011), 1325\u20131338.",
      "doi": ""
    },
    {
      "text": "Margaret Mitchell, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa\u00a0Deborah Raji, and Timnit Gebru. 2019. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency. 220\u2013229.",
      "doi": "10.1145/3287560.3287596"
    },
    {
      "text": "Mahsan Nourani, Samia Kabir, Sina Mohseni, and Eric\u00a0D Ragan. 2019. The Effects of Meaningful and Meaningless Explanations on Trust and Perceived System Accuracy in Intelligent Systems. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, Vol.\u00a07. 97\u2013105.",
      "doi": ""
    },
    {
      "text": "Besmira Nushi, Ece Kamar, and E. Horvitz. 2018. Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing System Failure. In HCOMP.",
      "doi": ""
    },
    {
      "text": "Raja Parasuraman and Victor Riley. 1997. Humans and automation: Use, misuse, disuse, abuse. Human factors 39, 2 (1997), 230\u2013253.",
      "doi": ""
    },
    {
      "text": "Raja Parasuraman and Christopher\u00a0D Wickens. 2008. Humans: Still vital after all these years of automation. Human factors 50, 3 (2008), 511\u2013520.",
      "doi": ""
    },
    {
      "text": "Niccolo Pescetelli, Geraint Rees, and Bahador Bahrami. 2016. The perceptual and social components of metacognition.Journal of Experimental Psychology: General 145, 8 (2016), 949.",
      "doi": ""
    },
    {
      "text": "Niccolo Pescetelli and Nick Yeung. 2018. The role of decision confidence in advice-taking and trust formation. (2018). arxiv:1809.10453",
      "doi": ""
    },
    {
      "text": "Forough Poursabzi-Sangdeh, Daniel\u00a0G Goldstein, Jake\u00a0M Hofman, Jennifer\u00a0Wortman Vaughan, and Hanna Wallach. 2018. Manipulating and measuring model interpretability. (2018). arxiv:1802.07810",
      "doi": ""
    },
    {
      "text": "Marco\u00a0Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \u201d Why should i trust you?\u201d Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 1135\u20131144.",
      "doi": "10.1145/2939672.2939778"
    },
    {
      "text": "Victor Riley. 1996. Operator reliance on automation: Theory and data. Automation and human performance: Theory and applications (1996), 19\u201335.",
      "doi": ""
    },
    {
      "text": "Lee Ross, David Greene, and Pamela House. 1977. The \u201cfalse consensus effect\u201d: An egocentric bias in social perception and attribution processes. Journal of experimental social psychology 13, 3 (1977), 279\u2013301.",
      "doi": ""
    },
    {
      "text": "Julian Sanchez, Arthur\u00a0D Fisk, and Wendy\u00a0A Rogers. 2004. Reliability and age-related effects on trust and reliance of a decision support aid. In Proceedings of the Human Factors and Ergonomics Society Annual Meeting, Vol.\u00a048. Sage Publications Sage CA: Los Angeles, CA, 586\u2013589.",
      "doi": ""
    },
    {
      "text": "Julian Sanchez, Wendy\u00a0A Rogers, Arthur\u00a0D Fisk, and Ericka Rovira. 2014. Understanding reliance on automation: effects of error type, error distribution, age and experience. Theoretical issues in ergonomics science 15, 2 (2014), 134\u2013160.",
      "doi": ""
    },
    {
      "text": "James Schaffer, John O\u2019Donovan, James Michaelis, Adrienne Raglin, and Tobias H\u00f6llerer. 2019. I can do better than your AI: expertise and explanations. In Proceedings of the 24th International Conference on Intelligent User Interfaces. 240\u2013251.",
      "doi": "10.1145/3301275.3302308"
    },
    {
      "text": "Kelly\u00a0E See, Elizabeth\u00a0W Morrison, Naomi\u00a0B Rothman, and Jack\u00a0B Soll. 2011. The detrimental effects of power on confidence, advice taking, and accuracy. Organizational behavior and human decision processes 116, 2(2011), 272\u2013285.",
      "doi": ""
    },
    {
      "text": "Keng Siau and Weiyu Wang. 2018. Building trust in artificial intelligence, machine learning, and robotics. Cutter Business Technology Journal 31, 2 (2018), 47\u201353.",
      "doi": ""
    },
    {
      "text": "Aaron Van\u00a0den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. In Advances in neural information processing systems. 2643\u20132651.",
      "doi": ""
    },
    {
      "text": "Kees Van\u00a0Dongen and Peter-Paul Van\u00a0Maanen. 2013. A framework for explaining reliance on decision aids. International Journal of Human-Computer Studies 71, 4 (2013), 410\u2013424.",
      "doi": "10.1016/j.ijhcs.2012.10.018"
    },
    {
      "text": "Lyn\u00a0M Van\u00a0Swol and Janet\u00a0A Sniezek. 2005. Factors affecting the acceptance of expert advice. British journal of social psychology 44, 3 (2005), 443\u2013461.",
      "doi": ""
    },
    {
      "text": "Mei Wang, Weihong Deng, Jiani Hu, Xunqiang Tao, and Yaohai Huang. 2019. Racial faces in the wild: Reducing racial bias by information maximization adaptation network. In Proceedings of the IEEE International Conference on Computer Vision. 692\u2013702.",
      "doi": ""
    },
    {
      "text": "Xinxi Wang and Ye Wang. 2014. Improving content-based and hybrid music recommendation using deep learning. In Proceedings of the 22nd ACM international conference on Multimedia. 627\u2013636.",
      "doi": "10.1145/2647868.2654940"
    },
    {
      "text": "Andrew Ward, L Ross, E Reed, E Turiel, and T Brown. 1997. Naive realism in everyday life: Implications for social conflict and misunderstanding. Values and knowledge(1997), 103\u2013135.",
      "doi": ""
    },
    {
      "text": "Fumeng Yang, Zhuanyi Huang, Jean Scholtz, and Dustin\u00a0L Arendt. 2020. How do visual explanations foster end users\u2019 appropriate trust in machine learning?. In Proceedings of the 25th International Conference on Intelligent User Interfaces. 189\u2013201.",
      "doi": "10.1145/3377325.3377480"
    },
    {
      "text": "Ilan Yaniv. 2004. Receiving other people\u2019s advice: Influence and benefit. Organizational behavior and human decision processes 93, 1 (2004), 1\u201313.",
      "doi": ""
    },
    {
      "text": "Ming Yin, Jennifer Wortman\u00a0Vaughan, and Hanna Wallach. 2019. Understanding the effect of accuracy on trust in machine learning models. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201312.",
      "doi": "10.1145/3290605.3300509"
    },
    {
      "text": "Yunfeng Zhang, Q\u00a0Vera Liao, and Rachel\u00a0KE Bellamy. 2020. Effect of Confidence and Explanation on Accuracy and Trust Calibration in AI-Assisted Decision Making. (2020). arxiv:2001.02114",
      "doi": ""
    },
    {
      "text": "Zijian Zhang, Jaspreet Singh, Ujwal Gadiraju, and Avishek Anand. 2019. Dissonance between human and machine understanding. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201323.",
      "doi": "10.1145/3359158"
    }
  ]
}