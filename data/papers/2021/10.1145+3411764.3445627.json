{
  "doi": "10.1145/3411764.3445627",
  "title": "Towards Understanding Perceptual Differences between Genuine and Face-Swapped Videos",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2021,
  "badges": [],
  "abstract": "In this paper, we report on perceptual experiments indicating that there are distinct and quantitatively measurable differences in the way we visually perceive genuine versus face-swapped videos.  Recent progress in deep learning has made face-swapping techniques a powerful tool for creative purposes, but also a means for unethical forgeries. Currently, it remains unclear why people are misled, and which indicators they use to recognize potential manipulations. Here, we conduct three perceptual experiments focusing on a wide range of aspects: the conspicuousness of artifacts, the viewing behavior using eye tracking, the recognition accuracy for different video lengths, and the assessment of emotions.  Our experiments show that responses differ distinctly when watching manipulated as opposed to original faces, from which we derive perceptual cues to recognize face swaps. By investigating physiologically measurable signals, our findings yield valuable insights that may also be useful for advanced algorithmic detection.",
  "tags": [
    "human perception",
    "face swapping",
    "video manipulation",
    "eye tracking"
  ],
  "authors": [
    {
      "name": "Leslie W\u00f6hler",
      "institution": "Institut f\u00fcr Computergraphik TU Braunschweig, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659343239",
      "orcid": "missing"
    },
    {
      "name": "Martin Zembaty",
      "institution": "Institut f\u00fcr Computergraphik TU Braunschweig, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659700661",
      "orcid": "missing"
    },
    {
      "name": "Susana Castillo",
      "institution": "Institut f\u00fcr Computergraphik TU Braunschweig, Germany",
      "img": "/do/10.1145/contrib-81488651280/rel-imgonly/20220908_121359.png",
      "acmid": "81488651280",
      "orcid": "missing"
    },
    {
      "name": "Marcus Magnor",
      "institution": "Institut f\u00fcr Computergraphik TU Braunschweig, Germany",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100477906",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Laura Abbruzzese, Nadia Magnani, Ian\u00a0Hamilton Robertson, and Mauro Mancuso. 2019. Age and gender differences in emotion recognition. Frontiers in psychology 10 (2019), 2371. https://doi.org/10.3389/fpsyg.2019.02371",
      "doi": ""
    },
    {
      "text": "Darius Afchar, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. 2018. Mesonet: a compact facial video forgery detection network. In IEEE International Workshop on Information Forensics and Security (WIFS). IEEE, New York, NY, USA, 1\u20137. https://doi.org/10.1109/WIFS.2018.8630761",
      "doi": ""
    },
    {
      "text": "Shruti Agarwal, Hany Farid, Yuming Gu, Mingming He, Koki Nagano, and Hao Li. 2019. Protecting World Leaders Against Deep Fakes. In IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshop (CVPRW). IEEE, New York, NY, USA, 38\u201345.",
      "doi": ""
    },
    {
      "text": "Robert R. Althoff and Neal J. Cohen. 1999. Eye-Movement-Based Memory Effect: A Reprocessing Effect in Face Perception. Journal of Experimental Psychology: Learning, Memory, and Cognition 25, 4 (7 1999), 997\u20131010. https://doi.org/10.1037/0278-7393.25.4.997",
      "doi": ""
    },
    {
      "text": "Lisa\u00a0Feldman Barrett, Batja Mesquita, and Maria Gendron. 2011. Context in emotion perception. Current Directions in Psychological Science 20, 5 (2011), 286\u2013290. https://doi.org/10.1177/0963721411422522",
      "doi": ""
    },
    {
      "text": "Elina Birmingham and Alan Kingstone. 2009. Human social attention. Progress in brain research 176 (2009), 309\u2013320. https://doi.org/10.1016/S0079-6123(09)17618-5",
      "doi": ""
    },
    {
      "text": "Dario Bombari, Fred\u00a0W Mast, and Janek\u00a0S Lobmaier. 2009. Featural, Configural, and Holistic Face-Processing Strategies Evoke Different Scan Patterns. Perception 38, 10 (2009), 1508\u20131521. https://doi.org/10.1068/p6117",
      "doi": ""
    },
    {
      "text": "Isabelle Boutet, Chantal\u00a0L Lemieux, Marc-Andr\u00e9 Goulet, and Charles\u00a0A Collin. 2017. Faces elicit different scanning patterns depending on task demands. Attention, Perception, & Psychophysics 79, 4 (2017), 1050\u20131063. https://doi.org/10.3758/s13414-017-1284-y",
      "doi": ""
    },
    {
      "text": "Julie\u00a0N Buchan, Martin Par\u00e9, and Kevin\u00a0G Munhall. 2007. Spatial statistics of gaze fixations during dynamic face processing. Social Neuroscience 2, 1 (2007), 1\u201313. https://doi.org/10.1080/17470910601043644",
      "doi": ""
    },
    {
      "text": "Martin \u010cad\u00edk, Robert Herzog, Rafa\u0142 Mantiuk, Rados\u0142aw Mantiuk, Karol Myszkowski, and Hans-Peter Seidel. 2013. Learning to predict localized distortions in rendered images. In Computer Graphics Forum, Vol.\u00a032. Wiley Online Library, Hoboken, New Jersey, USA, 401\u2013410. https://doi.org/10.1111/cgf.12248",
      "doi": ""
    },
    {
      "text": "Manuel\u00a0G. Calvo and Lauri Nummenmaa. 2009. Eye-movement assessment of the time course in facial expression recognition: Neurophysiological implications. Cognitive, Affective, & Behavioral Neuroscience 9, 4(2009), 398\u2013411. https://doi.org/10.3758/CABN.9.4.398",
      "doi": ""
    },
    {
      "text": "Pilar Carrera-Levillain and Jose-Miguel Fernandez-Dols. 1994. Neutral faces in context: Their emotional meaning and their function. Journal of Nonverbal Behavior 18, 4 (1994), 281\u2013299. https://doi.org/10.1007/BF02172290",
      "doi": ""
    },
    {
      "text": "Susana Castillo, Tilke Judd, and Diego Gutierrez. 2011. Using eye-tracking to assess different image retargeting methods. In ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization (APVG). ACM, New York, NY, USA, 7\u201314. https://doi.org/10.1145/2077451.2077453",
      "doi": "10.1145/2077451.2077453"
    },
    {
      "text": "Susana Castillo, Christian Wallraven, and Douglas Cunningham. 2014. The Semantic Space for Facial Communication. Computer Animation and Virtual Worlds 25, 3-4 (May 2014), 223\u2013231. https://doi.org/10.1002/cav.1593",
      "doi": "10.1002/cav.1593"
    },
    {
      "text": "BBC\u00a0News Daniel\u00a0Thomas. 2020. Deepfakes: A threat to democracy or just a bit of fun?BBC. Retrieved September 16, 2020 from https://www.bbc.com/news/business-51204954",
      "doi": ""
    },
    {
      "text": "DeepFaceLab. 2019. DeepFaceLab. https://github.com/iperov/DeepFaceLab Accessed: 2020-01-06.",
      "doi": ""
    },
    {
      "text": "DeepFakes. 2019. DeepFakes. https://github.com/deepfakes/faceswap Accessed: 2020-01-06.",
      "doi": ""
    },
    {
      "text": "Tom Dobber, Nadia Metoui, Damian Trilling, Natali Helberger, and Claes de Vreese. 2020. Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?The International Journal of Press/Politics 0 (2020), 1940161220944364. https://doi.org/10.1177/1940161220944364",
      "doi": ""
    },
    {
      "text": "Howard\u00a0E Egeth and Steven Yantis. 1997. Visual attention: Control, representation, and time course. Annual review of psychology 48, 1 (1997), 269\u2013297. https://doi.org/10.1146/annurev.psych.48.1.2699",
      "doi": ""
    },
    {
      "text": "Hedwig Eisenbarth and Georg\u00a0W Alpers. 2011. Happy mouth and sad eyes: scanning emotional facial expressions. Emotion 11, 4 (2011), 860. https://doi.org/10.1037/a0022758",
      "doi": ""
    },
    {
      "text": "Paul Ekman, E\u00a0Richard Sorenson, and Wallace\u00a0V Friesen. 1969. Pan-cultural elements in facial displays of emotion. Science 164, 3875 (1969), 86\u201388. https://doi.org/10.1126/science.164.3875.86",
      "doi": ""
    },
    {
      "text": "Ulrich Engelke, Daniel\u00a0P Darcy, Grant\u00a0H Mulliken, Sebastian Bosse, Maria\u00a0G Martini, Sebastian Arndt, Jan-Niklas Antons, Kit\u00a0Yan Chan, Naeem Ramzan, and Kjell Brunnstr\u00f6m. 2016. Psychophysiology-based QoE assessment: A survey. IEEE Journal of Selected Topics in Signal Processing 11, 1(2016), 6\u201321. https://doi.org/10.1109/JSTSP.2016.2609843",
      "doi": ""
    },
    {
      "text": "FaceSwap. 2019. FaceSwap. https://github.com/MarekKowalski/FaceSwap Accessed: 2020-01-06.",
      "doi": ""
    },
    {
      "text": "Steven Fernandes, Sunny Raj, Eddy Ortiz, Iustina Vintila, Margaret Salter, Gordana Urosevic, and Sumit Jha. 2019. Predicting Heart Rate Variations of Deepfake Videos using Neural ODE. In IEEE International Conference on Computer Vision Workshops (CVPRW). IEEE, New York, NY, USA, 1721\u20131729. https://doi.org/10.1109/ICCVW.2019.00213",
      "doi": ""
    },
    {
      "text": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in Neural Information Processing Systems (NeurIPS). ACM, New York, NY, USA, 2672\u20132680. https://doi.org/10.5555/2969033.2969125",
      "doi": ""
    },
    {
      "text": "GoogleAIBlog. 2019. Contributing Data to Deepfake Detection Research. https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html",
      "doi": ""
    },
    {
      "text": "D. G\u00fcera and E.\u00a0J. Delp. 2018. Deepfake video detection using recurrent neural networks. In IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, New York, NY, USA, 1\u20136. https://doi.org/10.1109/AVSS.2018.8639163",
      "doi": ""
    },
    {
      "text": "Tianchu Guo, Yongchao Liu, Hui Zhang, Xiabing Liu, Youngjun Kwak, Byung In\u00a0Yoo, Jae-Joon Han, and Changkyu Choi. 2019. A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone. In IEEE International Conference on Computer Vision Workshops (ICCVW). IEEE, New York, NY, USA, 1131\u20131139. https://doi.org/10.1109/ICCVW.2019.00144",
      "doi": ""
    },
    {
      "text": "Parul Gupta, Komal Chugh, Abhinav Dhall, and Ramanathan Subramanian. 2020. The eyes know it: FakeET-An Eye-tracking Database to Understand Deepfake Perception. In International Conference on Multimodal Interaction (ICIM). ACM, New York, NY, USA, 519\u2013527. https://doi.org/10.1145/3382507.3418857",
      "doi": "10.1145/3382507.3418857"
    },
    {
      "text": "Roy\u00a0S Hessels, Jeroen\u00a0S Benjamins, Tim\u00a0HW Cornelissen, and Ignace\u00a0TC Hooge. 2018. A validation of automatically-generated Areas-of-Interest in videos of a face for eye-tracking research. Frontiers in psychology 9 (2018), 1367. https://doi.org/10.3389/fpsyg.2018.01367",
      "doi": ""
    },
    {
      "text": "Stephen\u00a0J Hinde, Tim\u00a0J Smith, and Iain\u00a0D Gilchrist. 2018. Does narrative drive dynamic attention to a prolonged stimulus?Cognitive research: principles and implications 3, 1(2018), 45. https://doi.org/10.1186/s41235-018-0140-5",
      "doi": ""
    },
    {
      "text": "Janet Hui-wen Hsiao and Garrison Cottrell. 2008. Two fixations suffice in face recognition. Psychological science 19, 10 (2008), 998\u20131006. https://doi.org/10.1111/j.1467-9280.2008.02191.x",
      "doi": ""
    },
    {
      "text": "Derek\u00a0M Isaacowitz, Corinna\u00a0E L\u00f6ckenhoff, Richard\u00a0D Lane, Ron Wright, Lee Sechrest, Robert Riedel, and Paul\u00a0T Costa. 2007. Age differences in recognition of emotion in lexical stimuli and facial expressions. Psychology and aging 22, 1 (2007), 147. https://doi.org/10.1037/0882-7974.22.1.147",
      "doi": ""
    },
    {
      "text": "Stephen\u00a0W Janik, A\u00a0Rodney Wellens, Myron\u00a0L Goldberg, and Louis\u00a0F Dell\u2019Osso. 1978. Eyes as the center of focus in the visual examination of human faces. Perceptual and Motor Skills 47, 3 (1978), 857\u2013858. https://doi.org/10.2466/pms.1978.47.3.857",
      "doi": ""
    },
    {
      "text": "Liming Jiang, Ren Li, Wayne Wu, Chen Qian, and Chen\u00a0Change Loy. 2020. DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery Detection. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, New York, NY, USA, 2886\u20132895. https://doi.org/10.1109/CVPR42600.2020.00296",
      "doi": ""
    },
    {
      "text": "Tilke Judd, Krista Ehinger, Fr\u00e9do Durand, and Antonio Torralba. 2009. Learning to predict where humans look. In IEEE International Conference on Computer Vision (ICCV). IEEE, New York, NY, USA, 2106\u20132113. https://doi.org/10.1109/ICCV.2009.5459462",
      "doi": ""
    },
    {
      "text": "Kathrin Kaulard, Douglas\u00a0W. Cunningham, Heinrich\u00a0H. B\u00fclthoff, and Christian Wallraven. 2012. The MPI Facial Expression Database \u2014 A Validated Database of Emotional and Conversational Facial Expressions. PLoS ONE 7, 3 (03 2012), e32321. https://doi.org/10.1371/journal.pone.0032321",
      "doi": ""
    },
    {
      "text": "Davis\u00a0E. King. 2009. Dlib-ml: A Machine Learning Toolkit. Journal of Machine Learning Research 10 (2009), 1755\u20131758. http://www.dlib.net.",
      "doi": "10.5555/1577069.1755843"
    },
    {
      "text": "I. Korshunova, W. Shi, J. Dambre, and L. Theis. 2017. Fast face-swap using convolutional neural networks. In IEEE International Conference on Computer Vision (ICCV). IEEE, New York, NY, USA, 3677\u20133685. https://doi.org/10.1109/ICCV.2017.397",
      "doi": ""
    },
    {
      "text": "Kyle Krafka, Aditya Khosla, Petr Kellnhofer, Harini Kannan, Suchendra Bhandarkar, Wojciech Matusik, and Antonio Torralba. 2016. Eye Tracking for Everyone. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, New York, NY, USA, 2176\u20132184. https://doi.org/10.1109/CVPR.2016.239.",
      "doi": ""
    },
    {
      "text": "Charissa\u00a0R Lansing and George\u00a0W McConkie. 2003. Word identification and eye fixation locations in visual and visual-plus-auditory presentations of spoken sentences. Perception & psychophysics 65, 4 (2003), 536\u2013552. https://doi.org/10.3758/BF03194581",
      "doi": ""
    },
    {
      "text": "Steven M.\u00a0Gillespie Laura J.\u00a0Wells and Pia Rotshtein. 2016. Identification of emotional facial expressions: Effects of expression, intensity, and sex on eye gaze. PloS ONE 11, 12 (2016). https://doi.org/10.1371/journal.pone.0168307",
      "doi": ""
    },
    {
      "text": "Yuezun Li, Ming-Ching Chang, and Siwei Lyu. 2018. In ictu oculi: Exposing ai created fake videos by detecting eye blinking. In IEEE International Workshop on Information Forensics and Security (WIFS). IEEE, New York, NY, USA, 1\u20137. https://doi.org/10.1109/WIFS.2018.8630787",
      "doi": ""
    },
    {
      "text": "Yuezun Li and Siwei Lyu. 2019. Exposing DeepFake Videos By Detecting Face Warping Artifacts. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Vol.\u00a02. IEEE, New York, NY, USA, 46\u201352.",
      "doi": ""
    },
    {
      "text": "Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu. 2020. Celeb-DF: A Large-Scale Challenging Dataset for DeepFake Forensics. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, New York, NY, USA, 3207\u20133216. https://doi.org/10.1109/CVPR42600.2020.00327",
      "doi": ""
    },
    {
      "text": "Tsoey\u00a0Wun Man and Peter\u00a0J Hills. 2016. Eye-tracking the own-gender bias in face recognition: Other-gender faces are viewed differently to own-gender faces. Visual Cognition 24, 9-10 (2016), 447\u2013458. https://doi.org/10.1080/13506285.2017.1301614",
      "doi": ""
    },
    {
      "text": "Albert Mehrabian. 2008. Communication without words. Communication theory 6(2008), 193\u2013200.",
      "doi": ""
    },
    {
      "text": "I Mertens, H Siegmund, and O-J Gr\u00fcsser. 1993. Gaze motor asymmetries in the perception of faces during a memory task. Neuropsychologia 31, 9 (1993), 989\u2013998. https://doi.org/10.1016/0028-3932(93)90154-R",
      "doi": ""
    },
    {
      "text": "Xiongkuo Min, Guangtao Zhai, Zhongpai Gao, and Chunjia Hu. 2014. Influence of compression artifacts on visual attention. In IEEE International Conference on Multimedia and Expo (ICME). IEEE, New York, NY, USA, 1\u20136. https://doi.org/10.1109/ICME.2014.6890189",
      "doi": ""
    },
    {
      "text": "Parag\u00a0K Mital, Tim\u00a0J Smith, Robin\u00a0L Hill, and John\u00a0M Henderson. 2011. Clustering of gaze during dynamic scene viewing is predicted by motion. Cognitive computation 3, 1 (2011), 5\u201324. https://doi.org/10.1007/s12559-010-9074-z",
      "doi": ""
    },
    {
      "text": "Nora\u00a0A Murphy and Derek\u00a0M Isaacowitz. 2010. Age effects and gaze patterns in recognising emotional expressions: An in-depth look at gaze measures and covariates. Cognition and Emotion 24, 3 (2010), 436\u2013452. https://doi.org/10.1080/02699930802664623",
      "doi": ""
    },
    {
      "text": "Joao\u00a0C Neves, Ruben Tolosana, Ruben Vera-Rodriguez, Vasco Lopes, Hugo Proen\u00e7a, and Julian Fierrez. 2020. GANprintR: Improved Fakes and Evaluation of the State of the Art in Face Manipulation Detection. IEEE Journal of Selected Topics in Signal Processing 14, 5(2020), 1038\u20131048. https://doi.org/10.1109/JSTSP.2020.3007250",
      "doi": ""
    },
    {
      "text": "Yuval Nirkin, Yosi Keller, and Tal Hassner. 2019. FSGAN: Subject Agnostic Face Swapping and Reenactment. In IEEE International Conference on Computer Vision (ICCV). IEEE, New York, NY, USA, 7183\u20137192. https://doi.org/10.1109/ICCV.2019.00728",
      "doi": ""
    },
    {
      "text": "Y. Nirkin, I. Masi, A.\u00a0T. Tuan, T. Hassner, and G. Medioni. 2018. On face segmentation, face swapping, and face perception. In IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018). IEEE, New York, NY, USA, 98\u2013105. https://doi.org/10.1109/FG.2018.00024",
      "doi": ""
    },
    {
      "text": "Manfred Nusseck, Douglas\u00a0W. Cunningham, Christian Wallraven, and Heinrich\u00a0H. B\u00fclthoff. 2008. The contribution of different facial regions to the recognition of conversational expressions. Journal of Vision 8, 8 (06 2008), 1\u20131. https://doi.org/10.1167/8.8.1 arXiv:https://arvojournals.org/arvo/content_public/journal/jov/933530/jov-8-8-1.pdf",
      "doi": ""
    },
    {
      "text": "Effie\u00a0J Pereira, Elina Birmingham, and Jelena Ristic. 2020. The eyes do not have it after all? Attention is not automatically biased towards faces and eyes. Psychological research 84, 5 (2020), 1407\u20131423. https://doi.org/10.1007/s00426-018-1130-4",
      "doi": ""
    },
    {
      "text": "Rista\u00a0C Plate, Adrienne Wood, Kristina Woodard, and Seth\u00a0D Pollak. 2019. Probabilistic learning of emotion categories. Journal of Experimental Psychology: General 148, 10 (2019), 1814. https://doi.org/10.1037/xge0000529",
      "doi": ""
    },
    {
      "text": "Andreas R\u00f6ssler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie\u00dfner. 2018. FaceForensics: A Large-scale Video Dataset for Forgery Detection in Human Faces. CoRR abs/1803.09179(2018). arxiv:1803.09179",
      "doi": ""
    },
    {
      "text": "Andreas R\u00f6ssler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie\u00dfner. 2019. FaceForensics++: Learning to Detect Manipulated Facial Images. In IEEE International Conference on Computer Vision (ICCV). IEEE, New York, NY, USA, 1\u201311. https://doi.org/10.1109/ICCV.2019.00009",
      "doi": ""
    },
    {
      "text": "Guillaume\u00a0A Rousselet, Marc J-M Mac\u00e9, and Mich\u00e8le Fabre-Thorpe. 2003. Is it an animal? Is it a human face? Fast processing in upright and inverted natural scenes. Journal of Vision 3, 6 (2003), 5\u20135. https://doi.org/10.1167/3.6.5",
      "doi": ""
    },
    {
      "text": "Hannah Scott, Jonathan\u00a0P Batten, and Gustav Kuhn. 2019. Why are you looking at me? It\u2019s because I\u2019m talking, but mostly because I\u2019m staring or not doing much. Attention, Perception, & Psychophysics 81, 1 (2019), 109\u2013118. https://doi.org/10.3758/s13414-018-1588-6",
      "doi": ""
    },
    {
      "text": "Jan-Philipp Tauscher, Maryam Mustafa, and Marcus Magnor. 2017. Comparative analysis of three different modalities for perception of artifacts in videos. ACM Transactions on Applied Perception (TAP) 14, 4 (Sep 2017), 1\u201312. https://doi.org/10.1145/3129289",
      "doi": "10.1145/3129289"
    },
    {
      "text": "Cristian Vaccari and Andrew Chadwick. 2020. Deepfakes and disinformation: exploring the impact of synthetic political video on deception, uncertainty, and trust in news. Social Media+ Society 6, 1 (2020), 2056305120903408. https://doi.org/10.1177/2056305120903408",
      "doi": ""
    },
    {
      "text": "Goedele Van\u00a0Belle, Meike Ramon, Philippe Lef\u00e8vre, and Bruno Rossion. 2010. Fixation patterns during recognition of personally familiar and unfamiliar faces. Frontiers in Psychology 1 (2010), 20. https://doi.org/10.3389/fpsyg.2010.00020",
      "doi": ""
    },
    {
      "text": "Melissa L-H V\u00f5, Tim\u00a0J Smith, Parag\u00a0K Mital, and John\u00a0M Henderson. 2012. Do the eyes really have it? Dynamic allocation of attention when viewing moving faces. Journal of vision 12, 13 (2012), 3\u20133. https://doi.org/10.1167/12.13.3",
      "doi": ""
    },
    {
      "text": "Christian Wallraven, Heinrich\u00a0H. B\u00fclthoff, Douglas\u00a0W. Cunningham, Jan Fischer, and Dirk Bartz. 2007. Evaluation of Real-World and Computer-Generated Stylized Facial Expressions. ACM Transactions on Applied Perception (TAP) 4, 3 (Nov. 2007), 16\u2013es. https://doi.org/10.1145/1278387.1278390",
      "doi": ""
    },
    {
      "text": "Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew Owens, and Alexei\u00a0A Efros. 2020. CNN-generated images are surprisingly easy to spot... for now. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Vol.\u00a07. IEEE, New York, NY, USA, 8692\u20138701. https://doi.org/10.1109/CVPR42600.2020.00872",
      "doi": ""
    },
    {
      "text": "Wenguan Wang, Jianbing Shen, Jianwen Xie, Ming-Ming Cheng, Haibin Ling, and Ali Borji. 2019. Revisiting video saliency prediction in the deep learning era. IEEE Transactions on Pattern Analysis and Machine Intelligence 43, 1(2019), 220\u2013237. https://doi.org/10.1109/TPAMI.2019.2924417",
      "doi": "10.1109/TPAMI.2019.2924417"
    },
    {
      "text": "Leslie W\u00f6hler, Jann-Ole Henningson, Susana Castillo, and Marcus Magnor. 2020. PEFS: A Validated Dataset for Perceptual Experiments on Face Swap Portrait Videos. In International Conference on Computer Animation and Social Agents (CASA). Springer, Springer, Cham, 120\u2013127. https://doi.org/10.1007/978-3-030-63426-1_13",
      "doi": ""
    },
    {
      "text": "Xin Yang, Yuezun Li, and Siwei Lyu. 2019. Exposing deep fakes using inconsistent head poses. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, New York, NY, USA, 8261\u20138265. https://doi.org/10.1109/ICASSP.2019.8683164",
      "doi": ""
    },
    {
      "text": "Gregory Zelinsky. 2013. Understanding scene understanding. Frontiers in Psychology 4 (2013), 954. https://doi.org/10.3389/fpsyg.2013.00954",
      "doi": ""
    },
    {
      "text": "Xucong Zhang, Yusuke Sugano, Mario Fritz, and Andreas Bulling. 2017. It\u2019s written all over your face: Full-face appearance-based gaze estimation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). IEEE, New York, NY, USA, 51\u201360. https://doi.org/10.1109/CVPRW.2017.284",
      "doi": ""
    },
    {
      "text": "Fabian Zimmermann and Matthias Kohring. 2020. Mistrust, disinforming news, and vote choice: A panel survey on the origins and consequences of believing disinformation in the 2017 German parliamentary election. Political Communication 37, 2 (2020), 215\u2013237. https://doi.org/10.1080/10584609.2019.1686095",
      "doi": ""
    }
  ]
}