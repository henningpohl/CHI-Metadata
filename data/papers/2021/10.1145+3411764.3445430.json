{
  "doi": "10.1145/3411764.3445430",
  "title": "Acceptability of Speech and Silent Speech Input Methods in Private and Public",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2021,
  "badges": [],
  "abstract": "Silent speech input converts non-acoustic features like tongue and lip movements into text. It has been demonstrated as a promising input method on mobile devices and has been explored for a variety of audiences and contexts where the acoustic signal is unavailable (e.g., people with speech disorders) or unreliable (e.g., noisy environment). Though the method shows promise, very little is known about peoples\u2019 perceptions regarding using it. In this work, first, we conduct two user studies to explore users\u2019 attitudes towards the method with a particular focus on social acceptance and error tolerance. Results show that people perceive silent speech as more socially acceptable than speech input and are willing to tolerate more errors with it to uphold privacy and security. We then conduct a third study to identify a suitable method for providing real-time feedback on silent speech input. Results show users find an abstract feedback method effective and significantly more private and secure than a commonly used video feedback method.",
  "tags": [
    "speech",
    "voice assistant",
    "silent speech",
    "social acceptance",
    "contactless interaction",
    "input and interaction"
  ],
  "authors": [
    {
      "name": "Laxmi Pandey",
      "institution": "Human-Computer Interaction Group University of California, Merced, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659373659",
      "orcid": "missing"
    },
    {
      "name": "Khalad Hasan",
      "institution": "University of British Columbia, Canada",
      "img": "/do/10.1145/contrib-81484647407/rel-imgonly/khalad_hasan.jpg",
      "acmid": "81484647407",
      "orcid": "missing"
    },
    {
      "name": "Ahmed Sabbir Arif",
      "institution": "Human-Computer Interaction Group University of California, Merced, United States",
      "img": "/do/10.1145/contrib-81460652875/rel-imgonly/1632569177136_sq_col_sm.jpg",
      "acmid": "81460652875",
      "orcid": "0000-0002-8384-4764"
    }
  ],
  "references": [
    {
      "text": "Ossama Abdel-Hamid, Abdel-rahman Mohamed, Hui Jiang, Li Deng, Gerald Penn, and Dong Yu. 2014. Convolutional Neural Networks for Speech Recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing 22, 10 (Oct. 2014), 1533\u20131545. https://doi.org/10.1109/TASLP.2014.2339736 Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing.",
      "doi": "10.1109/TASLP.2014.2339736"
    },
    {
      "text": "Triantafyllos Afouras, Joon\u00a0Son Chung, and Andrew Zisserman. 2018. Deep Lip Reading: A Comparison of Models and an Online Application. arXiv:1806.06053 [cs] (June 2018). http://arxiv.org/abs/1806.06053 arXiv:1806.06053.",
      "doi": ""
    },
    {
      "text": "David Ahlstr\u00f6m, Khalad Hasan, and Pourang Irani. 2014. Are You Comfortable Doing That? Acceptance Studies of around-Device Gestures in and for Public Settings. In Proceedings of the 16th International Conference on Human-Computer Interaction with Mobile Devices & Services (Toronto, ON, Canada) (MobileHCI \u201914). Association for Computing Machinery, New York, NY, USA, 193\u2013202. https://doi.org/10.1145/2628363.2628381",
      "doi": "10.1145/2628363.2628381"
    },
    {
      "text": "Fouad Alallah, Ali Neshati, Yumiko Sakamoto, Khalad Hasan, Edward Lank, Andrea Bunt, and Pourang Irani. 2018. Performer vs. Observer: Whose Comfort Level Should We Consider When Examining the Social Acceptability of Input Modalities for Head-Worn Display?. In Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology (Tokyo, Japan) (VRST \u201918). Association for Computing Machinery, New York, NY, USA, Article 10, 9\u00a0pages. https://doi.org/10.1145/3281505.3281541",
      "doi": "10.1145/3281505.3281541"
    },
    {
      "text": "Fouad Alallah, Ali Neshati, Nima Sheibani, Yumiko Sakamoto, Andrea Bunt, Pourang Irani, and Khalad Hasan. 2018. Crowdsourcing vs Laboratory-Style Social Acceptability Studies? Examining the Social Acceptability of Spatial User Interactions for Head-Worn Displays. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI \u201918). Association for Computing Machinery, New York, NY, USA, 1\u20137. https://doi.org/10.1145/3173574.3173884",
      "doi": "10.1145/3173574.3173884"
    },
    {
      "text": "Ohoud Alharbi, Ahmed\u00a0Sabbir Arif, Wolfgang Stuerzlinger, Mark\u00a0D. Dunlop, and Andreas Komninos. 2019. WiseType: A Tablet Keyboard with Color-Coded Visualization and Various Editing Options for Error Correction. In Proceedings of the 45th Graphics Interface Conference on Proceedings of Graphics Interface 2019 (Kingston, Canada) (GI\u201919). Canadian Human-Computer Communications Society, Waterloo, CAN, Article 4, 10\u00a0pages. https://doi.org/10.20380/GI2019.04",
      "doi": "10.20380/GI2019.04"
    },
    {
      "text": "Cyril Allauzen and Michael Riley. 2011. Bayesian Language Model Interpolation for Mobile Speech Input. In Interspeech 2011. 1429\u20131432.",
      "doi": ""
    },
    {
      "text": "Ibrahim Almajai, Stephen Cox, Richard Harvey, and Yuxuan Lan. 2016. Improved Speaker Independent Lip Reading Using Speaker Adaptive Training and Deep Neural Networks. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2722\u20132726. https://doi.org/10.1109/ICASSP.2016.7472172 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "Ahmed\u00a0Sabbir Arif and Wolfgang Stuerzlinger. 2010. Predicting the Cost of Error Correction in Character-Based Text Entry Technologies. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Atlanta, Georgia, USA) (CHI \u201910). Association for Computing Machinery, New York, NY, USA, 5\u201314. https://doi.org/10.1145/1753326.1753329",
      "doi": "10.1145/1753326.1753329"
    },
    {
      "text": "Ahmed\u00a0Sabbir Arif and Wolfgang Stuerzlinger. 2010. Predicting the Cost of Error Correction in Character-Based Text Entry Technologies. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI \u201910). ACM, New York, NY, USA, 5\u201314. https://doi.org/10.1145/1753326.1753329",
      "doi": "10.1145/1753326.1753329"
    },
    {
      "text": "Ahmed\u00a0Sabbir Arif and Wolfgang Stuerzlinger. 2014. User Adaptation to a Faulty Unistroke-Based Text Entry Technique by Switching to an Alternative Gesture Set. In Proceedings of Graphics Interface 2014 (Montreal, Quebec, Canada) (GI \u201914). Canadian Information Processing Society, CAN, 183\u2013192.",
      "doi": "10.5555/2619648.2619679"
    },
    {
      "text": "Ahmed\u00a0Sabbir Arif and Wolfgang Stuerzlinger. 2014. User Adaptation to a Faulty Unistroke-Based Text Entry Technique by Switching to an Alternative Gesture Set. In Proceedings of Graphics Interface 2014(GI \u201914). Canadian Information Processing Society, Toronto, Ont., Canada, Canada, 183\u2013192. http://dl.acm.org/citation.cfm?id=2619648.2619679",
      "doi": "10.5555/2619648.2619679"
    },
    {
      "text": "Yannis\u00a0M. Assael, Brendan Shillingford, Shimon Whiteson, and Nando de Freitas. 2016. LipNet: End-to-End Sentence-level Lipreading. arXiv:1611.01599 [cs] (Dec. 2016). http://arxiv.org/abs/1611.01599 arXiv:1611.01599.",
      "doi": ""
    },
    {
      "text": "Mauro Avila\u00a0Soto and Markus Funk. [n.d.]. Look, a guidance drone! Assessing the Social Acceptability of Companion Drones for Blind Travelers in Public Spaces. In Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility (New York, NY, USA, 2018-10-08) (ASSETS \u201918). Association for Computing Machinery, 417\u2013419. https://doi.org/10.1145/3234695.3241019",
      "doi": "10.1145/3234695.3241019"
    },
    {
      "text": "Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and Yoshua Bengio. 2016. End-to-End Attention-Based Large Vocabulary Speech Recognition. arXiv:1508.04395 [cs] (March 2016). http://arxiv.org/abs/1508.04395 arXiv:1508.04395.",
      "doi": ""
    },
    {
      "text": "Monique\u00a0Faye Baier and Michael Burmester. 2019. Not Just About the User: Acceptance of Speech Interaction in Public Spaces. In Proceedings of Mensch Und Computer 2019 (Hamburg, Germany) (MuC\u201919). Association for Computing Machinery, New York, NY, USA, 349\u2013359. https://doi.org/10.1145/3340764.3340801",
      "doi": "10.1145/3340764.3340801"
    },
    {
      "text": "Brandon Ballinger, Cyril Allauzen, Alexander Gruenstein, and Johan Schalkwyk. 2010. On-Demand Language Model Interpolation for Mobile Speech Input. In Interspeech. 1812\u20131815.",
      "doi": ""
    },
    {
      "text": "Jess Bartels, D. Andreasen, P. Ehirim, Hui Mao, and P. Kennedy. 2008. Neurotrophic Electrode: Method of Assembly and Implantation into Human Motor Speech Cortex. Journal of Neuroscience Methods(2008). https://doi.org/10.1016/j.jneumeth.2008.06.030",
      "doi": ""
    },
    {
      "text": "Helen\u00a0L. Bear and Richard Harvey. 2019. Alternative Visual Units for an Optimized Phoneme-Based Lipreading System. 18 (2019), 3870. https://doi.org/10.3390/app9183870",
      "doi": ""
    },
    {
      "text": "Tara\u00a0S. Behrend, David\u00a0J. Sharek, Adam\u00a0W. Meade, and Eric\u00a0N. Wiebe. 2011. The Viability of Crowdsourcing for Survey Research. Behavior Research Methods 43, 3 (March 2011), 800. https://doi.org/10.3758/s13428-011-0081-0",
      "doi": ""
    },
    {
      "text": "Godfred\u00a0O Boateng, Torsten\u00a0B Neilands, Edward\u00a0A Frongillo, Hugo\u00a0R Melgar-Qui\u00f1onez, and Sera\u00a0L Young. 2018. Best Practices for Developing and Validating Scales for Health, Social, and Behavioral Research: A Primer. Frontiers in public health 6 (2018), 149.",
      "doi": ""
    },
    {
      "text": "John Brooke. 1996. SUS: A Quick and Dirty Usability Scale. Usability evaluation in industry(1996), 189.",
      "doi": ""
    },
    {
      "text": "Christopher\u00a0Ralph Brown. 2008. Automatic Pruning of Grammars in a Multi-Application Speech Recognition Interface. https://patents.google.com/patent/US20080059195/en",
      "doi": ""
    },
    {
      "text": "Jonathan\u00a0S. Brumberg, Alfonso Nieto-Castanon, Philip\u00a0R. Kennedy, and Frank\u00a0H. Guenther. 2010. Brain-Computer Interfaces for Speech Communication. Speech Communication 52, 4 (April 2010), 367\u2013379. https://doi.org/10.1016/j.specom.2010.01.001",
      "doi": "10.1016/j.specom.2010.01.001"
    },
    {
      "text": "Joon\u00a0Son Chung and Andrew Zisserman. 2016. Out of Time: Automated Lip Sync in the Wild. In ACCV Workshops. https://doi.org/10.1007/978-3-319-54427-4_19",
      "doi": ""
    },
    {
      "text": "Joon\u00a0Son Chung and Andrew Zisserman. 2017. Lip Reading in Profile. In BMVC. https://doi.org/10.5244/C.31.155",
      "doi": ""
    },
    {
      "text": "Joon\u00a0Son Chung and Andrew Zisserman. 2017. Lip Reading in the Wild. In Computer Vision \u2013 ACCV 2016(Lecture Notes in Computer Science), Shang-Hong Lai, Vincent Lepetit, Ko\u00a0Nishino, and Yoichi Sato(Eds.). Springer International Publishing, Cham, 87\u2013103. https://doi.org/10.1007/978-3-319-54184-6_6",
      "doi": ""
    },
    {
      "text": "Joon\u00a0Son Chung and Andrew Zisserman. 2018. Learning to Lip Read Words by Watching Videos. Computer Vision and Image Understanding 173 (Aug. 2018), 76\u201385. https://doi.org/10.1016/j.cviu.2018.02.001",
      "doi": ""
    },
    {
      "text": "Leigh Clark, Philip Doyle, Diego Garaialde, Emer Gilmartin, Stephan Schl\u00f6gl, Jens Edlund, Matthew Aylett, Jo\u00e3o Cabral, Cosmin Munteanu, Justin Edwards, and et al.2019. The State of Speech in HCI: Trends, Themes and Challenges. Interacting with Computers 31, 4 (Jun 2019), 349\u2013371. https://doi.org/10.1093/iwc/iwz016",
      "doi": ""
    },
    {
      "text": "Charles\u00a0S. DaSalla, Hiroyuki Kambara, Yasuharu Koike, and Makoto Sato. 2009. Spatial Filtering and Single-Trial Classification of Eeg During Vowel Speech Imagery. In Proceedings of the 3rd International Convention on Rehabilitation Engineering & Assistive Technology(i-CREATe \u201909). Association for Computing Machinery, New York, NY, USA, 1\u20134. https://doi.org/10.1145/1592700.1592731",
      "doi": "10.1145/1592700.1592731"
    },
    {
      "text": "B. Denby, Y. Oussar, G. Dreyfus, and M. Stone. 2006. Prospects for a Silent Speech Interface Using Ultrasound Imaging. In 2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, Vol.\u00a01. I\u2013I. https://doi.org/10.1109/ICASSP.2006.1660033 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "B. Denby and M. Stone. 2004. Speech Synthesis from Real Time Ultrasound Images of the Tongue. In 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing, Vol.\u00a01. I\u2013685. https://doi.org/10.1109/ICASSP.2004.1326078 ISSN: 1520-6149.",
      "doi": ""
    },
    {
      "text": "Li Deng and Xuedong Huang. 2004. Challenges in Adopting Speech Recognition. Commun. ACM 47, 1 (Jan. 2004), 69\u201375. https://doi.org/10.1145/962081.962108",
      "doi": ""
    },
    {
      "text": "Tamara Denning, Zakariya Dehlawi, and Tadayoshi Kohno. [n.d.]. In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies. Association for Computing Machinery, 2377\u20132386. https://doi.org/10.1145/2556288.2557352",
      "doi": ""
    },
    {
      "text": "Alan Dix, Janet\u00a0E. Finlay, Gregory\u00a0D. Abowd, and Russell Beale. 2003. Human-Computer Interaction (3rd Edition). Prentice-Hall, Inc., USA.",
      "doi": "10.5555/1203012"
    },
    {
      "text": "Aarthi Easwara\u00a0Moorthy and Kim-Phuong\u00a0L. Vu. 2014. Voice Activated Personal Assistant: Acceptability of Use in the Public Space. In Human Interface and the Management of Information. Information and Knowledge in Applications and Services(Lecture Notes in Computer Science), Sakae Yamamoto (Ed.). Springer International Publishing, Cham, 324\u2013334. https://doi.org/10.1007/978-3-319-07863-2_32",
      "doi": "10.1007/978-3-319-07863-2_32"
    },
    {
      "text": "Christos Efthymiou and M. Halvey. 2016. Evaluating the Social Acceptability of Voice Based Smartwatch Search. In AIRS. https://doi.org/10.1007/978-3-319-48051-0_20",
      "doi": ""
    },
    {
      "text": "M.\u00a0J. Fagan, S.\u00a0R. Ell, J.\u00a0M. Gilbert, E. Sarrazin, and P.\u00a0M. Chapman. 2008. Development of a (silent) Speech Recognition System for Patients Following Laryngectomy. Medical Engineering & Physics 30, 4 (May 2008), 419\u2013425. https://doi.org/10.1016/j.medengphy.2007.05.003",
      "doi": ""
    },
    {
      "text": "Victoria\u00a0M. Florescu, L. Crevier-Buchman, B. Denby, T. Hueber, Antonia Colazo-Simon, Claire Pillot-Loiseau, P. Roussel-Ragot, C. Gendrot, and S. Quattrocchi. 2010. Silent Vs Vocalized Articulation for a Portable Ultrasound-Based Silent Speech Interface. In INTERSPEECH.",
      "doi": ""
    },
    {
      "text": "Masaaki Fukumoto. 2018. Silentvoice: Unnoticeable Voice Input by Ingressive Speech. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology(UIST \u201918). Association for Computing Machinery, New York, NY, USA, 237\u2013246. https://doi.org/10.1145/3242587.3242603",
      "doi": "10.1145/3242587.3242603"
    },
    {
      "text": "Shabnam Ghaffarzadegan, Hynek Bo\u0159il, and John\u00a0H. Hansen. 2017. Deep Neural Network Training for Whispered Speech Recognition Using Small Databases and Generative Model Sampling. International Journal of Speech Technology 20, 4 (Dec. 2017), 1063\u20131075. https://doi.org/10.1007/s10772-017-9461-x",
      "doi": "10.1007/s10772-017-9461-x"
    },
    {
      "text": "Shabnam Ghaffarzadegan, Hynek Bo\u0159il, and John H.\u00a0L. Hansen. 2016. Generative Modeling of Pseudo-Whisper for Robust Whispered Speech Recognition. IEEE/ACM Transactions on Audio, Speech, and Language Processing 24, 10 (Oct. 2016), 1705\u20131720. https://doi.org/10.1109/TASLP.2016.2580944 Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing.",
      "doi": "10.1109/TASLP.2016.2580944"
    },
    {
      "text": "J.\u00a0M. Gilbert, S.\u00a0I. Rybchenko, R. Hofe, S.\u00a0R. Ell, M.\u00a0J. Fagan, R.\u00a0K. Moore, and P. Green. 2010. Isolated Word Recognition of Silent Speech Using Magnetic Implants and Sensors. Medical Engineering & Physics 32, 10 (Dec. 2010), 1189\u20131197. https://doi.org/10.1016/j.medengphy.2010.08.011",
      "doi": ""
    },
    {
      "text": "Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech Recognition with Deep Recurrent Neural Networks. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. 6645\u20136649. https://doi.org/10.1109/ICASSP.2013.6638947 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "\u0110or\u0111e\u00a0T. Grozdi\u0107 and Slobodan\u00a0T. Jovi\u010di\u0107. 2017. Whispered Speech Recognition Using Deep Denoising Autoencoder and Inverse Filtering. IEEE/ACM Transactions on Audio, Speech, and Language Processing 25, 12 (Dec. 2017), 2313\u20132322. https://doi.org/10.1109/TASLP.2017.2738559 Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing.",
      "doi": "10.1109/TASLP.2017.2738559"
    },
    {
      "text": "Anja\u00a0S. G\u00f6ritz, Kathrin Borchert, and Matthias Hirth. 2019. Using Attention Testing to Select Crowdsourced Workers and Research Participants. Social Science Computer Review (June 2019), 0894439319848726. https://doi.org/10.1177/0894439319848726 Publisher: SAGE Publications Inc.",
      "doi": ""
    },
    {
      "text": "Sandra\u00a0G Hart. 2006. NASA-task Load Index (NASA-TLX); 20 Years Later. In Proceedings of the human factors and ergonomics society annual meeting, Vol.\u00a050. Sage publications Sage CA: Los Angeles, CA, 904\u2013908.",
      "doi": "10.1177/154193120605000909"
    },
    {
      "text": "Hideki Hashimoto, Yoshifumi Nagata, Shigenobu Seto, Yoichi Takebayashi, Hideaki Shinchi, and Koji Yamaguchi. 1997. Speech Recognition Interface System Suitable for Window Systems and Speech Mail Systems. https://patents.google.com/patent/US5632002/en",
      "doi": ""
    },
    {
      "text": "Yanzhang He, Tara\u00a0N. Sainath, Rohit Prabhavalkar, Ian McGraw, Raziel Alvarez, Ding Zhao, David Rybach, Anjuli Kannan, Yonghui Wu, Ruoming Pang, Qiao Liang, Deepti Bhatia, Yuan Shangguan, Bo Li, Golan Pundak, Khe\u00a0Chai Sim, Tom Bagby, Shuo-yiin Chang, Kanishka Rao, and Alexander Gruenstein. 2019. Streaming End-to-End Speech Recognition for Mobile Devices. In ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 6381\u20136385. https://doi.org/10.1109/ICASSP.2019.8682336 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "Panikos Heracleous and Norihiro Hagita. 2011. Automatic Recognition of Speech Without Any Audio Information. In 2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2392\u20132395. https://doi.org/10.1109/ICASSP.2011.5946965 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "Panikos Heracleous, Tomomi Kaino, H. Saruwatari, and K. Shikano. 2007. Unvoiced Speech Recognition Using Tissue-Conductive Acoustic Sensor. EURASIP J. Adv. Signal Process.(2007). https://doi.org/10.1155/2007/94068",
      "doi": ""
    },
    {
      "text": "Tatsuya Hirahara, Makoto Otani, Shota Shimizu, Tomoki Toda, Keigo Nakamura, Yoshitaka Nakajima, and Kiyohiro Shikano. 2010. Silent-Speech Enhancement Using Body-Conducted Vocal-Tract Resonance Signals. Speech Communication 52, 4 (April 2010), 301\u2013313. https://doi.org/10.1016/j.specom.2009.12.001",
      "doi": "10.1016/j.specom.2009.12.001"
    },
    {
      "text": "Matthew\u00a0B. Hoy. 2018. Alexa, Siri, Cortana, and More: An Introduction to Voice Assistants. Medical Reference Services Quarterly 37, 1 (Jan. 2018), 81\u201388. https://doi.org/10.1080/02763869.2018.1404391 Publisher: Routledge _eprint: https://doi.org/10.1080/02763869.2018.1404391.",
      "doi": ""
    },
    {
      "text": "T. Hueber, G. Aversano, G. Chollet, B. Denby, G. Dreyfus, Y. Oussar, P. Roussel, and M. Stone. 2007. Eigentongue Feature Extraction for an Ultrasound-Based Silent Speech Interface. In 2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP \u201907, Vol.\u00a01. I\u20131245\u2013I\u20131248. https://doi.org/10.1109/ICASSP.2007.366140 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "Thomas Hueber, Elie-Laurent Benaroya, G\u00e9rard Chollet, Bruce Denby, G\u00e9rard Dreyfus, and Maureen Stone. 2010. Development of a Silent Speech Interface Driven by Ultrasound and Optical Images of the Tongue and Lips. Speech Communication 52, 4 (April 2010), 288\u2013300. https://doi.org/10.1016/j.specom.2009.11.004",
      "doi": "10.1016/j.specom.2009.11.004"
    },
    {
      "text": "Charles Jorgensen and Sorin Dusan. 2010. Speech Interfaces Based Upon Surface Electromyography. Speech Communication 52, 4 (April 2010), 354\u2013366. https://doi.org/10.1016/j.specom.2009.11.003",
      "doi": "10.1016/j.specom.2009.11.003"
    },
    {
      "text": "C. Jorgensen, D.D. Lee, and S. Agabont. 2003. Sub Auditory Speech Recognition Based on Emg Signals. In Proceedings of the International Joint Conference on Neural Networks, 2003., Vol.\u00a04. 3128\u20133133 vol.4. https://doi.org/10.1109/IJCNN.2003.1224072 ISSN: 1098-7576.",
      "doi": ""
    },
    {
      "text": "S. Jou, Tanja Schultz, Matthias Walliczek, F. Kraft, and Alexander\u00a0H. Waibel. 2006. Towards Continuous Speech Recognition Using Surface Electromyography. In INTERSPEECH.",
      "doi": ""
    },
    {
      "text": "Szu-Chen Jou and et al. 2004. Adaptation for Soft Whisper Recognition Using a Throat Microphone.",
      "doi": ""
    },
    {
      "text": "Arnav Kapur, Shreyas Kapur, and Pattie Maes. 2018. Alterego: A Personalized Wearable Silent Speech Interface. In 23rd International Conference on Intelligent User Interfaces(IUI \u201918). Association for Computing Machinery, New York, NY, USA, 43\u201353. https://doi.org/10.1145/3172944.3172977",
      "doi": "10.1145/3172944.3172977"
    },
    {
      "text": "Naoki Kimura, Michinari Kono, and Jun Rekimoto. 2019. SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI \u201919). Association for Computing Machinery, New York, NY, USA, 1\u201311. https://doi.org/10.1145/3290605.3300376",
      "doi": "10.1145/3290605.3300376"
    },
    {
      "text": "Peter\u00a0F. King. 2003. Server Based Speech Recognition User Interface for Wireless Devices. https://patents.google.com/patent/US6532446B1/en",
      "doi": ""
    },
    {
      "text": "Marion Koelle, Swamy Ananthanarayan, and Susanne Boll. 2020. Social Acceptability in HCI: A Survey of Methods, Measures, and Design Strategies. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI \u201920). Association for Computing Machinery, New York, NY, USA, 1\u201319. https://doi.org/10.1145/3313831.3376162",
      "doi": "10.1145/3313831.3376162"
    },
    {
      "text": "Marion Koelle, Abdallah El\u00a0Ali, Vanessa Cobus, Wilko Heuten, and Susanne\u00a0CJ Boll. 2017. All about Acceptability? Identifying Factors for the Adoption of Data Glasses. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 295\u2013300. https://doi.org/10.1145/3025453.3025749",
      "doi": "10.1145/3025453.3025749"
    },
    {
      "text": "Marion Koelle, Matthias Kranz, and Andreas M\u00f6ller. 2015. Don\u2019t Look at Me That Way! Understanding User Attitudes Towards Data Glasses Usage. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services (Copenhagen, Denmark) (MobileHCI \u201915). Association for Computing Machinery, New York, NY, USA, 362\u2013372. https://doi.org/10.1145/2785830.2785842",
      "doi": "10.1145/2785830.2785842"
    },
    {
      "text": "Andreas Komninos, Emma Nicol, and Mark Dunlop. 2020. Investigating Error Injection to Enhance the Effectiveness of Mobile Text Entry Studies of Error Behaviour. arxiv:2003.06318\u00a0[cs.HC]",
      "doi": ""
    },
    {
      "text": "DoYoung Lee, Youryang Lee, Yonghwan Shin, and Ian Oakley. 2018. Designing Socially Acceptable Hand-to-Face Input. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (Berlin, Germany) (UIST \u201918). Association for Computing Machinery, New York, NY, USA, 711\u2013723. https://doi.org/10.1145/3242587.3242642",
      "doi": "10.1145/3242587.3242642"
    },
    {
      "text": "Xin Lei, A. Senior, A. Gruenstein, and Jeffrey\u00a0Scott Sorensen. 2013. Accurate and Compact Large Vocabulary Speech Recognition on Mobile Devices. In INTERSPEECH.",
      "doi": ""
    },
    {
      "text": "Ning Li, Tuoyang Zhou, Yingwei Zhou, Chen Guo, Deqiang Fu, Xiaoqing Li, and Zijing Guo. 2019. Research on Human-Computer Interaction Mode of Speech Recognition Based on Environment Elements of Command and Control System. In 2019 5th International Conference on Big Data and Information Analytics (BigDIA). 170\u2013175. https://doi.org/10.1109/BigDIA.2019.8802812",
      "doi": ""
    },
    {
      "text": "Andr\u00e9s Lucero and Akos Vetek. [n.d.]. NotifEye: using interactive glasses to deal with notifications while walking in public. In Proceedings of the 11th Conference on Advances in Computer Entertainment Technology (New York, NY, USA, 2014-11-11) (ACE \u201914). Association for Computing Machinery, 1\u201310. https://doi.org/10.1145/2663806.2663824",
      "doi": "10.1145/2663806.2663824"
    },
    {
      "text": "Patrick\u00a0J. Lynch. 1994. Visual Design for the User Interface, Part 1: Design Fundamentals. Journal of Biocommunication 21 (1994), 22\u201322. http://trantor.sheridanc.on.ca/sys32a1/manual/appendix/gui1.html",
      "doi": ""
    },
    {
      "text": "Gustavo L\u00f3pez, Luis Quesada, and Luis\u00a0A. Guerrero. 2018. Alexa Vs. Siri Vs. Cortana Vs. Google Assistant: A Comparison of Speech-Based Natural User Interfaces. In Advances in Human Factors and Systems Interaction(Advances in Intelligent Systems and Computing), Isabel\u00a0L. Nunes (Ed.). Springer International Publishing, Cham, 241\u2013250. https://doi.org/10.1007/978-3-319-60366-7_23",
      "doi": ""
    },
    {
      "text": "I.\u00a0Scott MacKenzie and R.\u00a0William Soukoreff. [n.d.]. Phrase sets for evaluating text entry techniques. In CHI \u201903 Extended Abstracts on Human Factors in Computing Systems (New York, NY, USA, 2003-04-05) (CHI EA \u201903). Association for Computing Machinery, 754\u2013755. https://doi.org/10.1145/765891.765971",
      "doi": "10.1145/765891.765971"
    },
    {
      "text": "L. Maier-Hein, F. Metze, T. Schultz, and A. Waibel. 2005. Session Independent Non-Audible Speech Recognition Using Surface Electromyography. In IEEE Workshop on Automatic Speech Recognition and Understanding, 2005.331\u2013336. https://doi.org/10.1109/ASRU.2005.1566521",
      "doi": ""
    },
    {
      "text": "Ian McGraw, Rohit Prabhavalkar, Raziel Alvarez, Montse\u00a0Gonzalez Arenas, Kanishka Rao, David Rybach, Ouais Alsharif, Ha\u015fim Sak, Alexander Gruenstein, Fran\u00e7oise Beaufays, and Carolina Parada. 2016. Personalized Speech Recognition on Mobile Devices. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 5955\u20135959. https://doi.org/10.1109/ICASSP.2016.7472820 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "I. Mcloughlin, J. Li, and Yan Song. 2013. Reconstruction of Continuous Voiced Speech from Whispers. In INTERSPEECH.",
      "doi": ""
    },
    {
      "text": "Calkin\u00a0S. Montero, Jason Alexander, Mark\u00a0T. Marshall, and Sriram Subramanian. [n.d.]. Would you do that? understanding social acceptance of gestural interfaces. In Proceedings of the 12th international conference on Human computer interaction with mobile devices and services (New York, NY, USA, 2010-09-07) (MobileHCI \u201910). Association for Computing Machinery, 275\u2013278. https://doi.org/10.1145/1851600.1851647",
      "doi": "10.1145/1851600.1851647"
    },
    {
      "text": "Aarthi\u00a0Easwara Moorthy and Kim-Phuong\u00a0L. Vu. 2015. Privacy Concerns for Use of Voice Activated Personal Assistant in the Public Space. International Journal of Human\u2013Computer Interaction 31, 4 (April 2015), 307\u2013335. https://doi.org/10.1080/10447318.2014.986642 Publisher: Taylor & Francis _eprint: https://doi.org/10.1080/10447318.2014.986642.",
      "doi": ""
    },
    {
      "text": "Y. Nakajima, H. Kashioka, K. Shikano, and N. Campbell. 2003. Non-Audible Murmur Recognition Input Interface Using Stethoscopic Microphone Attached to the Skin. In 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP \u201903)., Vol.\u00a05. V\u2013708. https://doi.org/10.1109/ICASSP.2003.1200069 ISSN: 1520-6149.",
      "doi": ""
    },
    {
      "text": "Y. Nakajima, H. Kashioka, K. Shikano, and N. Campbell. 2003. Non-Audible Murmur Recognition Input Interface Using Stethoscopic Microphone Attached to the Skin. In 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP \u201903)., Vol.\u00a05. V\u2013708. https://doi.org/10.1109/ICASSP.2003.1200069 ISSN: 1520-6149.",
      "doi": ""
    },
    {
      "text": "NASA. 1986. NASA Task Load Index (TLX) V 1.0: Paper and Pencil Package. Technical Report. Human Performance Research Group, NASA Ames Research Center, Moffett Field, CA, USA.",
      "doi": ""
    },
    {
      "text": "Chalapathy Neti, Gerasimos Potamianos, Juergen Luettin, Iain Matthews, and Herve Glotin. 2000. Audio-Visual Speech Recognition. (2000), 86.",
      "doi": ""
    },
    {
      "text": "L.C. Ng, G.C. Burnett, J.F. Holzrichter, and T.J. Gable. 2000. Denoising of Human Speech Using Combined Acoustic and Em Sensor Signal Processing. In 2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100), Vol.\u00a01. 229\u2013232 vol.1. https://doi.org/10.1109/ICASSP.2000.861925 ISSN: 1520-6149.",
      "doi": ""
    },
    {
      "text": "Sanjay\u00a0A. Patil and John H.\u00a0L. Hansen. 2010. The Physiological Microphone (pmic): A Competitive Alternative for Speaker Assessment in Stress Detection and Speaker Verification. Speech Communication 52, 4 (April 2010), 327\u2013340. https://doi.org/10.1016/j.specom.2009.11.006",
      "doi": "10.1016/j.specom.2009.11.006"
    },
    {
      "text": "Dr\u00a0Marta Perez\u00a0Garcia, Sarita Saffon\u00a0Lopez, and Hector Donis. 2018. Everybody is Talking About Virtual Assistants, But How are People Really Using Them?. In Proceedings of the 32nd International BCS Human Computer Interaction Conference 32. 1\u20135.",
      "doi": "10.14236/ewic/HCI2018.96"
    },
    {
      "text": "Stavros Petridis and Maja Pantic. 2016. Deep Complementary Bottleneck Features for Visual Speech Recognition. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2304\u20132308. https://doi.org/10.1109/ICASSP.2016.7472088 ISSN: 2379-190X.",
      "doi": ""
    },
    {
      "text": "J.W. Picone. 1993. Signal Modeling Techniques in Speech Recognition. Proc. IEEE 81, 9 (Sept. 1993), 1215\u20131247. https://doi.org/10.1109/5.237532 Conference Name: Proceedings of the IEEE.",
      "doi": ""
    },
    {
      "text": "Anne Porbadnigk, Marek Wester, Jan Calliess, and Tanja Schultz. 2009. EEG-based Speech Recognition - Impact of Temporal Effects. In BIOSIGNALS. https://doi.org/10.5220/0001554303760381",
      "doi": ""
    },
    {
      "text": "Anne Porbadnigk, Marek Wester, Jan Calliess, and Tanja Schultz. 2009. EEG-Based Speech Recognition - Impact of Temporal Effects. In BIOSIGNALS. https://doi.org/10.5220/0001554303760381",
      "doi": ""
    },
    {
      "text": "G. Potamianos, C. Neti, G. Gravier, A. Garg, and A.W. Senior. 2003. Recent Advances in the Automatic Recognition of Audiovisual Speech. Proc. IEEE 91, 9 (Sept. 2003), 1306\u20131326. https://doi.org/10.1109/JPROC.2003.817150 Conference Name: Proceedings of the IEEE.",
      "doi": ""
    },
    {
      "text": "Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, Jan Silovsky, Georg Stemmer, and Karel Vesely. 2011. The Kaldi Speech Recognition Toolkit. https://infoscience.epfl.ch/record/192584 Conference Name: IEEE 2011 Workshop on Automatic Speech Recognition and Understanding Number: CONF Publisher: IEEE Signal Processing Society.",
      "doi": ""
    },
    {
      "text": "S. Prabhakar, S. Pankanti, and A.K. Jain. 2003. Biometric Recognition: Security and Privacy Concerns. IEEE Security Privacy 1, 2 (March 2003), 33\u201342. https://doi.org/10.1109/MSECP.2003.1193209 Conference Name: IEEE Security Privacy.",
      "doi": "10.1109/MSECP.2003.1193209"
    },
    {
      "text": "Halley Profita, Reem Albaghli, Leah Findlater, Paul Jaeger, and Shaun\u00a0K. Kane. 2016. The AT Effect: How Disability Affects the Perceived Social Acceptability of Head-Mounted Display Use. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (San Jose, California, USA) (CHI \u201916). Association for Computing Machinery, New York, NY, USA, 4884\u20134895. https://doi.org/10.1145/2858036.2858130",
      "doi": "10.1145/2858036.2858130"
    },
    {
      "text": "Halley\u00a0P. Profita. [n.d.]. Designing wearable computing technology for acceptability and accessibility. 114 ([n.\u00a0d.]), 44\u201348. https://doi.org/10.1145/2904092.2904101",
      "doi": ""
    },
    {
      "text": "T.F. Quatieri, K. Brady, D. Messing, J.P. Campbell, W.M. Campbell, M.S. Brandstein, C.J. Weinstein, J.D. Tardelli, and P.D. Gatewood. 2006. Exploiting Nonacoustic Sensors for Speech Encoding. IEEE Transactions on Audio, Speech, and Language Processing 14, 2 (March 2006), 533\u2013544. https://doi.org/10.1109/TSA.2005.855838 Conference Name: IEEE Transactions on Audio, Speech, and Language Processing.",
      "doi": "10.1109/TSA.2005.855838"
    },
    {
      "text": "Stuart Reeves, Steve Benford, Claire O\u2019Malley, and Mike Fraser. 2005. Designing the Spectator Experience. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Portland, Oregon, USA) (CHI \u201905). Association for Computing Machinery, New York, NY, USA, 741\u2013750. https://doi.org/10.1145/1054972.1055074",
      "doi": "10.1145/1054972.1055074"
    },
    {
      "text": "Julie Rico and Stephen Brewster. [n.d.]. Gestures all around us: user differences in social acceptability perceptions of gesture based interfaces. In Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services (New York, NY, USA, 2009-09-15) (MobileHCI \u201909). Association for Computing Machinery, 1\u20132. https://doi.org/10.1145/1613858.1613936",
      "doi": "10.1145/1613858.1613936"
    },
    {
      "text": "Julie Rico and Stephen Brewster. 2010. Usable Gestures for Mobile Interfaces: Evaluating Social Acceptability. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Atlanta, Georgia, USA) (CHI \u201910). Association for Computing Machinery, New York, NY, USA, 887\u2013896. https://doi.org/10.1145/1753326.1753458",
      "doi": "10.1145/1753326.1753458"
    },
    {
      "text": "Julie Rico and Stephen Brewster. 2010. Usable Gestures for Mobile Interfaces: Evaluating Social Acceptability. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Atlanta, Georgia, USA) (CHI \u201910). Association for Computing Machinery, New York, NY, USA, 887\u2013896. https://doi.org/10.1145/1753326.1753458",
      "doi": "10.1145/1753326.1753458"
    },
    {
      "text": "Judy Robertson and Maurits Kaptein. [n.d.]. Modern Statistical Methods for HCI. Springer.",
      "doi": "10.5555/2927492"
    },
    {
      "text": "Sami Ronkainen, Jonna H\u00e4kkil\u00e4, Saana Kaleva, Ashley Colley, and Jukka Linjama. 2007. Tap Input as an Embedded Interaction Method for Mobile Devices. In Proceedings of the 1st International Conference on Tangible and Embedded Interaction (Baton Rouge, Louisiana) (TEI \u201907). Association for Computing Machinery, New York, NY, USA, 263\u2013270. https://doi.org/10.1145/1226969.1227023",
      "doi": "10.1145/1226969.1227023"
    },
    {
      "text": "Sherry Ruan, Jacob\u00a0O. Wobbrock, Kenny Liou, Andrew Ng, and James\u00a0A. Landay. 2018. Comparing Speech and Keyboard Text Entry for Short Messages in Two Languages on Touchscreen Phones. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, 4 (Jan. 2018), 159:1\u2013159:23. https://doi.org/10.1145/3161187",
      "doi": "10.1145/3161187"
    },
    {
      "text": "A. Rubin, V. Praneetvatakul, Shirley Gherson, C. Moyer, and R. Sataloff. 2006. Laryngeal Hyperfunction During Whispering: Reality or Myth?Journal of voice : official journal of the Voice Foundation (2006). https://doi.org/10.1016/J.JVOICE.2004.10.007",
      "doi": ""
    },
    {
      "text": "Himanshu Sahni, Abdelkareem Bedri, Gabriel Reyes, Pavleen Thukral, Zehua Guo, Thad Starner, and Maysam Ghovanloo. 2014. The Tongue and Ear Interface: A Wearable System for Silent Speech Recognition. In Proceedings of the 2014 ACM International Symposium on Wearable Computers(ISWC \u201914). Association for Computing Machinery, New York, NY, USA, 47\u201354. https://doi.org/10.1145/2634317.2634322",
      "doi": "10.1145/2634317.2634322"
    },
    {
      "text": "Tanja Schultz and Michael Wand. 2010. Modeling Coarticulation in Emg-Based Continuous Speech Recognition. Speech Communication 52, 4 (April 2010), 341\u2013353. https://doi.org/10.1016/j.specom.2009.12.002",
      "doi": "10.1016/j.specom.2009.12.002"
    },
    {
      "text": "Mike Schuster. 2010. Speech Recognition for Mobile Devices at Google. In PRICAI 2010: Trends in Artificial Intelligence(Lecture Notes in Computer Science), Byoung-Tak Zhangand Mehmet\u00a0A. Orgun (Eds.). Springer, Berlin, Heidelberg, 8\u201310. https://doi.org/10.1007/978-3-642-15246-7_3",
      "doi": ""
    },
    {
      "text": "Marcos Serrano, Barrett\u00a0M. Ens, and Pourang\u00a0P. Irani. 2014. Exploring the Use of Hand-to-Face Input for Interacting with Head-Worn Displays. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Toronto, Ontario, Canada) (CHI \u201914). Association for Computing Machinery, New York, NY, USA, 3181\u20133190. https://doi.org/10.1145/2556288.2556984",
      "doi": "10.1145/2556288.2556984"
    },
    {
      "text": "R.\u00a0V. Shannon, F. Zeng, V. Kamath, J. Wygonski, and M. Ekelid. 1995. Speech Recognition with Primarily Temporal Cues. Science (1995). https://doi.org/10.1126/science.270.5234.303",
      "doi": ""
    },
    {
      "text": "Themos Stafylakis and Georgios Tzimiropoulos. 2017. Combining Residual Networks with Lstms for Lipreading. INTERSPEECH (2017). https://doi.org/10.21437/INTERSPEECH.2017-85",
      "doi": ""
    },
    {
      "text": "Ke Sun, Chun Yu, Weinan Shi, Lan Liu, and Yuanchun Shi. 2018. Lip-Interact: Improving Mobile Device Interaction with Silent Speech Commands. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology(UIST \u201918). Association for Computing Machinery, New York, NY, USA, 581\u2013593. https://doi.org/10.1145/3242587.3242599",
      "doi": "10.1145/3242587.3242599"
    },
    {
      "text": "P. Suppes, B. Han, and Z. Lu. 1998. Brain-Wave Recognition of Sentences.Proceedings of the National Academy of Sciences of the United States of America (1998). https://doi.org/10.1073/pnas.95.26.15861",
      "doi": ""
    },
    {
      "text": "P. Suppes, Z. Lu, and B. Han. 1997. Brain Wave Recognition of Words.Proceedings of the National Academy of Sciences of the United States of America (1997). https://doi.org/10.1073/pnas.94.26.14965",
      "doi": ""
    },
    {
      "text": "Ingo\u00a0R. Titze, Brad\u00a0H. Story, Gregory\u00a0C. Burnett, John\u00a0F. Holzrichter, Lawrence\u00a0C. Ng, and Wayne\u00a0A. Lea. 1999. Comparison Between Electroglottography and Electromagnetic Glottography. The Journal of the Acoustical Society of America 107, 1 (Dec. 1999), 581\u2013588. https://doi.org/10.1121/1.428324 Publisher: Acoustical Society of America.",
      "doi": ""
    },
    {
      "text": "Ying-Chao Tung, Chun-Yen Hsu, Han-Yu Wang, Silvia Chyou, Jhe-Wei Lin, Pei-Jung Wu, Andries Valstar, and Mike\u00a0Y. Chen. 2015. User-Defined Game Input for Smart Glasses in Public Space. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (Seoul, Republic of Korea) (CHI \u201915). Association for Computing Machinery, New York, NY, USA, 3327\u20133336. https://doi.org/10.1145/2702123.2702214",
      "doi": "10.1145/2702123.2702214"
    },
    {
      "text": "Michael Wand and Tanja Schultz. 2011. Session-Independent Emg-Based Speech Recognition. In BIOSIGNALS. https://doi.org/10.5220/0003169702950300",
      "doi": ""
    },
    {
      "text": "Dean Weber. 2001. Interactive User Interface Using Speech Recognition and Natural Language Processing. https://patentscope.wipo.int/search/en/detail.jsf?docId=WO2001026093",
      "doi": ""
    },
    {
      "text": "Dean Weber. 2002. Object Interactive User Interface Using Speech Recognition and Natural Language Processing. https://patents.google.com/patent/US6434524B1/en",
      "doi": ""
    },
    {
      "text": "Dean Weber. 2002. Object Interactive User Interface Using Speech Recognition and Natural Language Processing. https://patents.google.com/patent/US6434524B1/en",
      "doi": ""
    },
    {
      "text": "D. Zaykovskiy. 2006. Survey of the Speech Recognition Techniques for Mobile Devices.",
      "doi": ""
    },
    {
      "text": "You Zhang, Jeffery\u00a0J. Faneuff, William Hidden, James\u00a0T. Hotary, Steven\u00a0C. Lee, and Vasu Iyengar. 2010. Automobile Speech-Recognition Interface. https://patents.google.com/patent/US7826945B2/en",
      "doi": ""
    },
    {
      "text": "Yu Zhong, T.\u00a0V. Raman, Casey Burkhardt, Fadi Biadsy, and Jeffrey\u00a0P. Bigham. 2014. Justspeak: Enabling Universal Voice Control on Android. In W4A 2014. http://dl.acm.org/citation.cfm?id=2596720",
      "doi": "10.1145/2596695.2596720"
    }
  ]
}