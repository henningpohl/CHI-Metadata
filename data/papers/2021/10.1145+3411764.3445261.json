{
  "doi": "10.1145/3411764.3445261",
  "title": "The Landscape and Gaps in Open Source Fairness Toolkits",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2021,
  "badges": [
    "Best Paper"
  ],
  "abstract": "With the surge in literature focusing on the assessment and mitigation of unfair outcomes in algorithms, several open source \u2018fairness toolkits\u2019 recently emerged to make such methods widely accessible. However, little studied are the differences in approach and capabilities of existing fairness toolkits, and their fit-for-purpose in commercial contexts. Towards this, this paper identifies the gaps between the existing open source fairness toolkit capabilities and the industry practitioners\u2019 needs. Specifically, we undertake a comparative assessment of the strengths and weaknesses of six prominent open source fairness toolkits, and investigate the current landscape and gaps in fairness toolkits through an exploratory focus group, a semi-structured interview, and an anonymous survey of data science/machine learning (ML) practitioners. We identify several gaps between the toolkits\u2019 capabilities and practitioner needs, highlighting areas requiring attention and future directions towards tooling that better support \u2018fairness in practice.\u2019",
  "tags": [
    "bias",
    "bias mitigation",
    "open source toolkits",
    "bias detection",
    "algorithm auditing",
    "fairness",
    "algorithmic fairness",
    "fairness toolkits"
  ],
  "authors": [
    {
      "name": "Michelle Seng Ah Lee",
      "institution": "Department of Computer Science & Technology, University of Cambridge, Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659681738",
      "orcid": "0000-0001-7725-2503"
    },
    {
      "name": "Jat Singh",
      "institution": "Department of Computer Science & Technology, University of Cambridge, Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659320789",
      "orcid": "0000-0002-5102-6564"
    }
  ],
  "references": [
    {
      "text": "Yasemin Acar, Michael Backes, Sascha Fahl, Simson Garfinkel, Doowon Kim, Michelle\u00a0L Mazurek, and Christian Stransky. 2017. Comparing the usability of cryptographic APIs. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE, IEEE, 154\u2013171.",
      "doi": ""
    },
    {
      "text": "Saleema Amershi, Max Chickering, Steven\u00a0M Drucker, Bongshin Lee, Patrice Simard, and Jina Suh. 2015. Modeltracker: Redesigning performance analysis tools for machine learning. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. 337\u2013346.",
      "doi": "10.1145/2702123.2702509"
    },
    {
      "text": "Aaron Bangor, Philip\u00a0T Kortum, and James\u00a0T Miller. 2008. An empirical evaluation of the system usability scale. Intl. Journal of Human\u2013Computer Interaction 24, 6(2008), 574\u2013594.",
      "doi": ""
    },
    {
      "text": "Rachel\u00a0KE Bellamy, Kuntal Dey, Michael Hind, Samuel\u00a0C Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, A Mojsilovi\u0107, 2019. AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias. IBM Journal of Research and Development 63, 4/5 (2019), 4\u20131.",
      "doi": ""
    },
    {
      "text": "Elettra Bietti. 2020. From ethics washing to ethics bashing: a view on tech ethics from within moral philosophy. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 210\u2013219.",
      "doi": "10.1145/3351095.3372860"
    },
    {
      "text": "Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan\u00a0Natesan Ramamurthy, and Kush\u00a0R Varshney. 2017. Optimized pre-processing for discrimination prevention. In Advances in Neural Information Processing Systems. 3992\u20134001.",
      "doi": ""
    },
    {
      "text": "Nan-Chen Chen, Jina Suh, Johan Verwey, Gonzalo Ramos, Steven Drucker, and Patrice Simard. 2018. AnchorViz: Facilitating classifier error discovery through interactive semantic data exploration. In 23rd International Conference on Intelligent User Interfaces. 269\u2013280.",
      "doi": "10.1145/3172944.3172950"
    },
    {
      "text": "Aisling\u00a0Ni Chonaire and Jannna\u00a0Ter Meer. 2020. The perception of fairness of algorithms and proxy information in financial services: A report for the Centre for Data Ethics and Innovation. The Behavioural Insights Team(2020).",
      "doi": ""
    },
    {
      "text": "Kate Crawford. 2017. Artificial intelligence with very real biases. The Wall Street Journal. Retrieved from https://www. wsj. com/articles/artificial-intelligencewith-very-real-biases-1508252717(2017).",
      "doi": ""
    },
    {
      "text": "Jeffrey Dastin. 2018. Amazon scraps secret AI recruiting tool that showed bias against women. Reuters, October 2018.",
      "doi": ""
    },
    {
      "text": "Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference. ACM, 214\u2013226.",
      "doi": "10.1145/2090236.2090255"
    },
    {
      "text": "Michael Feldman, Sorelle\u00a0A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 259\u2013268.",
      "doi": "10.1145/2783258.2783311"
    },
    {
      "text": "Avi Feller, Emma Pierson, Sam Corbett-Davies, and Sharad Goel. 2016. A computer program used for bail and sentencing decisions was labeled biased against blacks. It\u2019s actually not that clear. The Washington Post (2016).",
      "doi": ""
    },
    {
      "text": "Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. In Advances in neural information processing systems. 3315\u20133323.",
      "doi": ""
    },
    {
      "text": "Rasmus Hauch. 2020. Denmark introduces mandatory legislation for AI and data ethics. 2021.ai (2020). https://2021.ai/denmark-introduces-mandatory-legislation-ai-data-ethics/",
      "doi": ""
    },
    {
      "text": "Douglas\u00a0D Heckathorn. 2011. Comment: Snowball versus respondent-driven sampling. Sociological methodology 41, 1 (2011), 355\u2013366.",
      "doi": ""
    },
    {
      "text": "Hoda Heidari, Michele Loi, Krishna\u00a0P Gummadi, and Andreas Krause. 2018. A moral framework for understanding of fair ml through economic models of equality of opportunity. arXiv preprint arXiv:1809.03400(2018).",
      "doi": ""
    },
    {
      "text": "Kenneth Holstein, Jennifer Wortman\u00a0Vaughan, Hal Daum\u00e9\u00a0III, Miro Dudik, and Hanna Wallach. 2019. Improving fairness in machine learning systems: What do industry practitioners need?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201316.",
      "doi": "10.1145/3290605.3300830"
    },
    {
      "text": "Ben Hutchinson and Margaret Mitchell. 2019. 50 Years of Test (Un) fairness: Lessons for Machine Learning. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 49\u201358.",
      "doi": "10.1145/3287560.3287600"
    },
    {
      "text": "Anna Jobin, Marcello Ienca, and Effy Vayena. 2019. The global landscape of AI ethics guidelines. Nature Machine Intelligence 1, 9 (2019), 389\u2013399.",
      "doi": ""
    },
    {
      "text": "Faisal Kamiran, Asim Karim, and Xiangliang Zhang. 2012. Decision theory for discrimination-aware classification. In 2012 IEEE 12th International Conference on Data Mining. IEEE, 924\u2013929.",
      "doi": "10.1109/ICDM.2012.45"
    },
    {
      "text": "Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2012. Fairness-aware classifier with prejudice remover regularizer. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 35\u201350.",
      "doi": ""
    },
    {
      "text": "Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei\u00a0Steven Wu. 2018. Preventing fairness gerrymandering: Auditing and learning for subgroup fairness. In International Conference on Machine Learning. PMLR, 2564\u20132572.",
      "doi": ""
    },
    {
      "text": "Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent trade-offs in the fair determination of risk scores. arXiv preprint arXiv:1609.05807(2016).",
      "doi": ""
    },
    {
      "text": "Todd Kulesza, Margaret Burnett, Weng-Keen Wong, and Simone Stumpf. 2015. Principles of explanatory debugging to personalize interactive machine learning. In Proceedings of the 20th international conference on intelligent user interfaces. 126\u2013137.",
      "doi": "10.1145/2678025.2701399"
    },
    {
      "text": "Matt\u00a0J. Kusner, Joshua\u00a0R. Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual Fairness. arXiv e-prints, Article arXiv:1703.06856 (March 2017), arXiv:1703.06856\u00a0pages. arxiv:1703.06856\u00a0[stat.ML]",
      "doi": ""
    },
    {
      "text": "Min\u00a0Kyung Lee and Su Baykal. 2017. Algorithmic mediation in group decisions: Fairness perceptions of algorithmically mediated vs. discussion-based social division. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing. 1035\u20131048.",
      "doi": "10.1145/2998181.2998230"
    },
    {
      "text": "Michelle Seng\u00a0Ah Lee, Luciano Floridi, and Jatinder Singh. 2020. From fairness metrics to key ethics indicators (KEIs): a context-aware approach to algorithmic ethics in an unequal society. Available on SSRN (2020). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3679975",
      "doi": ""
    },
    {
      "text": "Microsoft and contributors. 2019. Fairlearn. https://fairlearn.github.io/",
      "doi": ""
    },
    {
      "text": "Brad\u00a0A Myers and Jeffrey Stylos. 2016. Improving API usability. Commun. ACM 59, 6 (2016), 62\u201369.",
      "doi": "10.1145/2896587"
    },
    {
      "text": "Arvind Narayanan. 2018. Tutorial: 21 Definitions of Fairness and their Politics. YouTube. https://www.youtube.com/watch?v=jIXIuYdnyyk",
      "doi": ""
    },
    {
      "text": "Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian\u00a0Q Weinberger. 2017. On fairness and calibration. In Advances in Neural Information Processing Systems. 5680\u20135689.",
      "doi": ""
    },
    {
      "text": "Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby Stevens, Ari Anisfeld, Kit\u00a0T Rodolfa, and Rayid Ghani. 2018. Aequitas: A bias and fairness audit toolkit. arXiv preprint arXiv:1811.05577(2018).",
      "doi": ""
    },
    {
      "text": "Kacper Sokol, Raul Santos-Rodriguez, and Peter Flach. 2019. FAT Forensics: A Python toolbox for algorithmic fairness, accountability and transparency. arXiv preprint arXiv:1909.05167(2019).",
      "doi": ""
    },
    {
      "text": "Aaron Springer, Jean Garcia-Gathright, and Henriette Cramer. 2018. Assessing and Addressing Algorithmic Bias-But Before We Get There.... In AAAI Spring Symposia.",
      "doi": ""
    },
    {
      "text": "Megha Srivastava, Hoda Heidari, and Andreas Krause. 2019. Mathematical notions vs. human perception of fairness: A descriptive approach to fairness for machine learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2459\u20132468.",
      "doi": "10.1145/3292500.3330664"
    },
    {
      "text": "Roger Taylor. 2020. AI Barometer Report. Centre for Data Ethics and Innovation(2020). https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/894170/CDEI_AI_Barometer.pdf",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van\u00a0Kleek, and Reuben Binns. 2018. Fairness and accountability design needs for algorithmic support in high-stakes public sector decision-making. In Proceedings of the 2018 chi conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "Sahil Verma and Julia Rubin. 2018. Fairness definitions explained. In 2018 IEEE/ACM International Workshop on Software Fairness (FairWare). IEEE, 1\u20137.",
      "doi": "10.1145/3194770.3194776"
    },
    {
      "text": "Neil Vigdor. 2019. Apple card investigated after gender discrimination complaints. The New York Times (2019).",
      "doi": ""
    },
    {
      "text": "Matthijs Vincent and ManyOthers. 2019. scikit-fairness. https://github.com/koaning/scikit-fairness",
      "doi": ""
    },
    {
      "text": "Sandra Wachter, Brent Mittelstadt, and Chris Russell. 2020. Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and AI. Available at SSRN (2020).",
      "doi": ""
    },
    {
      "text": "Stephen Walli, Dave Gynn, and Bruno\u00a0von Rotz. 2005. The growth of open source software in organizations. Publication Report. Optaros Inc(2005).",
      "doi": ""
    },
    {
      "text": "James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda Vi\u00e9gas, and Jimbo Wilson. 2019. The what-if tool: Interactive probing of machine learning models. IEEE transactions on visualization and computer graphics 26, 1(2019), 56\u201365.",
      "doi": ""
    },
    {
      "text": "Allison Woodruff, Sarah\u00a0E Fox, Steven Rousso-Schindler, and Jeffrey Warshaw. 2018. A qualitative exploration of perceptions of algorithmic fairness. In Proceedings of the 2018 chi conference on human factors in computing systems. 1\u201314.",
      "doi": "10.1145/3173574.3174230"
    },
    {
      "text": "Brian\u00a0Hu Zhang, Blake Lemoine, and Margaret Mitchell. 2018. Mitigating unwanted biases with adversarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. 335\u2013340.",
      "doi": "10.1145/3278721.3278779"
    },
    {
      "text": "Minhaz Zibran. 2008. What makes APIs difficult to use. International Journal of Computer Science and Network Security (IJCSNS) 8, 4(2008), 255\u2013261.",
      "doi": ""
    }
  ]
}