{
  "doi": "10.1145/3411764.3445708",
  "title": "Understanding Conversational and Expressive Style in a Multimodal Embodied Conversational Agent",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-10",
  "year": 2021,
  "badges": [],
  "abstract": "Embodied conversational agents have changed the ways we can interact with machines. However, these systems often do not meet users\u2019 expectations. A limitation is that the agents are monotonic in behavior and do not adapt to an interlocutor. We present SIVA (a Socially Intelligent Virtual Agent), an expressive, embodied conversational agent that can recognize human behavior during open-ended conversations and automatically align its responses to the conversational and expressive style of the other party. SIVA leverages multimodal inputs to produce rich and perceptually valid responses (lip syncing and facial expressions) during the conversation. We conducted a user study (N=30) in which participants rated SIVA as being more empathetic and believable than the control (agent without style matching). Based on almost 10 hours of interaction, participants who preferred interpersonal involvement evaluated SIVA as significantly more animate than the participants who valued consideration and independence.",
  "tags": [
    "facial expressive style",
    "conversational style",
    "social dialogue",
    "multi-modality",
    "emotional expressions",
    "Embodied agents",
    "social behavior"
  ],
  "authors": [
    {
      "name": "Deepali Aneja",
      "institution": "Adobe Research, United States",
      "img": "/do/10.1145/contrib-99658959915/rel-imgonly/deepalianeja.jpg",
      "acmid": "99658959915",
      "orcid": "missing"
    },
    {
      "name": "Rens Hoegen",
      "institution": "University of Southern California, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658975099",
      "orcid": "missing"
    },
    {
      "name": "Daniel McDuff",
      "institution": "Microsoft Research, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81490688111",
      "orcid": "missing"
    },
    {
      "name": "Mary Czerwinski",
      "institution": "Microsoft Research, United States",
      "img": "/do/10.1145/contrib-81100280834/rel-imgonly/marycz.jpg",
      "acmid": "81100280834",
      "orcid": "0000-0003-0881-401X"
    }
  ],
  "references": [
    {
      "text": "Deepali Aneja, Daniel McDuff, and Shital Shah. 2019. A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities. In Proceedings of the 2019 on International Conference on Multimodal Interaction. ACM.",
      "doi": "10.1145/3340555.3353744"
    },
    {
      "text": "Christoph Bartneck, Dana Kuli\u0107, Elizabeth Croft, and Susana Zoghbi. 2009. Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots. International journal of social robotics 1, 1 (2009), 71\u201381.",
      "doi": ""
    },
    {
      "text": "\u0160tefan Be\u0148u\u0161. 2014. Social aspects of entrainment in spoken interaction. Cognitive Computation 6, 4 (2014), 802\u2013813.",
      "doi": ""
    },
    {
      "text": "Timothy Bickmore and Justine Cassell. 2000. how about this weather? social dialogue with embodied conversational agents. In Proc. AAAI Fall Symposium on Socially Intelligent Agents.",
      "doi": ""
    },
    {
      "text": "Timothy Bickmore and Justine Cassell. 2001. Relational agents: a model and implementation of building user trust. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 396\u2013403.",
      "doi": "10.1145/365024.365304"
    },
    {
      "text": "Dan Bohus, Sean Andrist, and Mihai Jalobeanu. 2017. Rapid development of multimodal interactive systems: a demonstration of platform for situated intelligence. In Proceedings of the 19th ACM International Conference on Multimodal Interaction. ACM, 493\u2013494.",
      "doi": "10.1145/3136755.3143021"
    },
    {
      "text": "Daniel\u00a0C Burnett, Mark\u00a0R Walker, and Andrew Hunt. 2004. Speech synthesis markup language (ssml) version 1.0. W3C recommendation 7(2004).",
      "doi": ""
    },
    {
      "text": "Justine Cassell. 2000. Embodied conversational interface agents. Commun. ACM 43, 4 (2000), 70\u201378.",
      "doi": "10.1145/332051.332075"
    },
    {
      "text": "Justine Cauell, Tim Bickmore, Lee Campbell, and Hannes Vilhj\u00e1lmsson. 2000. Designing embodied conversational agents. Embodied conversational agents(2000), 29\u201363.",
      "doi": ""
    },
    {
      "text": "Celso\u00a0M de Melo, Jonathan Gratch, and Peter\u00a0J Carnevale. 2014. Humans versus computers: Impact of emotion expressions on people\u2019s decision making. IEEE Transactions on Affective Computing 6, 2 (2014), 127\u2013136.",
      "doi": "10.1109/TAFFC.2014.2332471"
    },
    {
      "text": "Donald\u00a0M Decker 1999. Handbook of the International Phonetic Association: A guide to the use of the International Phonetic Alphabet. Cambridge University Press.",
      "doi": ""
    },
    {
      "text": "David DeVault, Ron Artstein, Grace Benn, Teresa Dey, Ed Fast, Alesia Gainer, Kallirroi Georgila, Jon Gratch, Arno Hartholt, Margaux Lhommet, 2014. SimSensei Kiosk: A virtual human interviewer for healthcare decision support. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems. International Foundation for Autonomous Agents and Multiagent Systems, 1061\u20131068.",
      "doi": ""
    },
    {
      "text": "Pif Edwards, Chris Landreth, Eugene Fiume, and Karan Singh. 2016. JALI: an animator-centric viseme model for expressive lip synchronization. ACM Transactions on Graphics (TOG) 35, 4 (2016), 127.",
      "doi": "10.1145/2897824.2925984"
    },
    {
      "text": "Kathleen\u00a0Kara Fitzpatrick, Alison Darcy, and Molly Vierhile. 2017. Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial. JMIR mental health 4, 2 (2017).",
      "doi": ""
    },
    {
      "text": "Wallace\u00a0V Friesen, Paul Ekman, 1983. EMFACS-7: Emotional facial action coding system. Unpublished manuscript, University of California at San Francisco 2, 36(1983), 1.",
      "doi": ""
    },
    {
      "text": "Epic Games. 2007. Unreal engine. Online: https://www. unrealengine. com(2007).",
      "doi": ""
    },
    {
      "text": "Tom Geller. 2008. Overcoming the uncanny valley. IEEE computer graphics and applications 28, 4 (2008), 11\u201317.",
      "doi": "10.1109/MCG.2008.79"
    },
    {
      "text": "Sandra\u00a0G Hart and Lowell\u00a0E Staveland. 1988. Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research. In Advances in psychology. Vol.\u00a052. Elsevier, 139\u2013183.",
      "doi": ""
    },
    {
      "text": "Ursula Hess and Sylvie Blairy. 2001. Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy. International journal of psychophysiology 40, 2 (2001), 129\u2013141.",
      "doi": ""
    },
    {
      "text": "Rens Hoegen, Deepali Aneja, Daniel McDuff, and Mary Czerwinski. 2019. An end-to-end conversational style matching agent. In Proceedings of the 19th ACM International Conference on Intelligent Virtual Agents. 111\u2013118.",
      "doi": "10.1145/3308532.3329473"
    },
    {
      "text": "Mohammed\u00a0Ehsan Hoque, Matthieu Courgeon, Jean-Claude Martin, Bilge Mutlu, and Rosalind\u00a0W Picard. 2013. Mach: My automated conversation coach. In Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing. ACM, 697\u2013706.",
      "doi": "10.1145/2493432.2493502"
    },
    {
      "text": "David Huggins-Daines, Mohit Kumar, Arthur Chan, Alan\u00a0W Black, Mosur Ravishankar, and Alexander\u00a0I Rudnicky. 2006. Pocketsphinx: A free, real-time continuous speech recognition system for hand-held devices. In Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on, Vol.\u00a01. IEEE, I\u2013I.",
      "doi": ""
    },
    {
      "text": "David Ireland, Christina Atay, Jacki Liddle, Dana Bradford, Helen Lee, Olivia Rushin, Thomas Mullins, Dan Angus, Janet Wiles, Simon McBride, 2016. Hello Harlie: Enabling Speech Monitoring Through Chat-Bot Conversations.Studies in health technology and informatics 227 (2016), 55\u201360.",
      "doi": ""
    },
    {
      "text": "Liliana Laranjo, Adam\u00a0G Dunn, Huong\u00a0Ly Tong, Ahmet\u00a0Baki Kocaballi, Jessica Chen, Rabia Bashir, Didi Surian, Blanca Gallego, Farah Magrabi, Annie\u00a0YS Lau, 2018. Conversational agents in healthcare: a systematic review. Journal of the American Medical Informatics Association 25, 9(2018), 1248\u20131258.",
      "doi": ""
    },
    {
      "text": "Rivka Levitan, Stefan Benus, Ramiro\u00a0H G\u00e1lvez, Agust\u00edn Gravano, Florencia Savoretti, Marian Trnka, Andreas Weise, and Julia Hirschberg. 2016. Implementing Acoustic-Prosodic Entrainment in a Conversational Avatar.. In INTERSPEECH, Vol.\u00a016. 1166\u20131170.",
      "doi": ""
    },
    {
      "text": "Yoichi Matsuyama, Arjun Bhardwaj, Ran Zhao, Oscar Romeo, Sushma Akoju, and Justine Cassell. 2016. Socially-aware animated intelligent personal assistant agent. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. 224\u2013227.",
      "doi": ""
    },
    {
      "text": "Adam\u00a0S Miner, Arnold Milstein, Stephen Schueller, Roshini Hegde, Christina Mangurian, and Eleni Linos. 2016. Smartphone-based conversational agents and responses to questions about mental health, interpersonal violence, and physical health. JAMA internal medicine 176, 5 (2016), 619\u2013625.",
      "doi": ""
    },
    {
      "text": "Tetsuo Ono, Michita Imai, and Hiroshi Ishiguro. 2001. A model of embodied communications with gestures between human and robots. In Proceedings of the Annual Meeting of the Cognitive Science Society, Vol.\u00a023.",
      "doi": ""
    },
    {
      "text": "Pierre Philip, Jean-Arthur Micoulaud-Franchi, Patricia Sagaspe, Etienne De\u00a0Sevin, J\u00e9r\u00f4me Olive, St\u00e9phanie Bioulac, and Alain Sauteraud. 2017. Virtual human as a new diagnostic tool, a proof of concept study in the field of major depressive disorders. Scientific Reports 7(2017), 42656.",
      "doi": ""
    },
    {
      "text": "Isabella Poggi, Catherine Pelachaud, Fiorella de Rosis, Valeria Carofiglio, and Berardina De\u00a0Carolis. 2005. Greta. a believable embodied conversational agent. In Multimodal intelligent information presentation. Springer, 3\u201325.",
      "doi": ""
    },
    {
      "text": "Laurel\u00a0D Riek and Peter Robinson. 2008. Real-time empathy: Facial mimicry on a robot. In Workshop on Affective Interaction in Natural Environments (AFFINE) at the International ACM Conference on Multimodal Interfaces (ICMI 08). ACM. Citeseer.",
      "doi": ""
    },
    {
      "text": "William\u00a0T Rogers. 1978. The contribution of kinesic illustrators toward the comprehension of verbal behavior within utterances. Human communication research 5, 1 (1978), 54\u201362.",
      "doi": ""
    },
    {
      "text": "Magdalena Rychlowska, Antony\u00a0SR Manstead, and Job van\u00a0der Schalk. 2019. The Many Faces of Smiles. In The Social Nature of Emotion Expression. Springer, 227\u2013245.",
      "doi": ""
    },
    {
      "text": "Lauren\u00a0E Scissors, Alastair\u00a0J Gill, Kathleen Geraghty, and Darren Gergle. 2009. In CMC we trust: The role of similarity. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 527\u2013536.",
      "doi": "10.1145/1518701.1518783"
    },
    {
      "text": "Lauren\u00a0E Scissors, Alastair\u00a0J Gill, and Darren Gergle. 2008. Linguistic mimicry and trust in text-based CMC. In Proceedings of the 2008 ACM conference on Computer supported cooperative work. ACM, 277\u2013280.",
      "doi": "10.1145/1460563.1460608"
    },
    {
      "text": "Yoshihiro Sejima, Yutaka Ishii, and Tomio Watanabe. 2011. A virtual audience system for enhancing embodied interaction based on conversational activity. In Symposium on Human Interface. Springer, 180\u2013189.",
      "doi": ""
    },
    {
      "text": "Shital Shah, Debadeepta Dey, Chris Lovett, and Ashish Kapoor. 2018. Airsim: High-fidelity visual and physical simulation for autonomous vehicles. In Field and service robotics. Springer, 621\u2013635.",
      "doi": ""
    },
    {
      "text": "Ameneh Shamekhi, Mary Czerwinski, Gloria Mark, Margeigh Novotny, and Gregory\u00a0A Bennett. 2016. An exploratory study toward the preferred conversational style for compatible virtual agents. In International Conference on Intelligent Virtual Agents. Springer, 40\u201350.",
      "doi": ""
    },
    {
      "text": "Ameneh Shamekhi, Mary Czerwinski, Gloria Mark, Margeigh Novotny, and Gregory\u00a0A Bennett. 2016. An exploratory study toward the preferred conversational style for compatible virtual agents. In Proc.\u00a0Int.\u00a0Conf.\u00a0on Intelligent Virtual Agents(Los Angeles). Springer, 40\u201350.",
      "doi": ""
    },
    {
      "text": "Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A neural network approach to context-sensitive generation of conversational responses. In Proc. of NAACL-HLT.",
      "doi": ""
    },
    {
      "text": "Eszter Strupka, Oliver Niebuhr, and Kerstin Fischer. 2016. Influence of robot gender and speaker gender on prosodic entrainment in HRI. In Interactive Session at the IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN 2016), New York City.",
      "doi": ""
    },
    {
      "text": "Hiroki Tanaka, Hiroyoshi Adachi, Norimichi Ukita, Manabu Ikeda, Hiroaki Kazui, Takashi Kudo, and Satoshi Nakamura. 2017. Detecting dementia through interactive computer avatars. IEEE journal of translational engineering in health and medicine 5 (2017), 1\u201311.",
      "doi": ""
    },
    {
      "text": "Hiroki Tanaka, Hideki Negoro, Hidemi Iwasaka, and Satoshi Nakamura. 2017. Embodied conversational agents for multimodal automated social skills training in people with autism spectrum disorders. PloS one 12, 8 (2017), e0182151.",
      "doi": ""
    },
    {
      "text": "Deborah Tannen. 1987. Conversational style. In Psycholinguistic models of production, Hans\u00a0W Dechert and Manfred Raupach (Eds.). Ablex, Norwood, NJ.",
      "doi": ""
    },
    {
      "text": "Deborah Tannen. 2005. Conversational style: Analyzing talk among friends (new ed.). Oxford University Press, New York.",
      "doi": ""
    },
    {
      "text": "Paul Thomas, Mary Czerwinski, Daniel McDuff, Nick Craswell, and Gloria Mark. 2018. Style and Alignment in Information-Seeking Conversation. In Proceedings of the 2018 Conference on Human Information Interaction&Retrieval. ACM, 42\u201351.",
      "doi": "10.1145/3176349.3176388"
    }
  ]
}