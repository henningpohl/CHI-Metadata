{
  "doi": "10.1145/3411764.3445423",
  "title": "The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-14",
  "year": 2021,
  "badges": [],
  "abstract": "Machine learning classifiers for human-facing tasks such as comment toxicity and misinformation often score highly on metrics such as ROC AUC but are received poorly in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are used to measure technical performance; however, human-computer interaction observes that evaluation of human-facing systems should account for people\u2019s reactions to the system. In this paper, we introduce a transformation that more closely aligns machine learning classification metrics with the values and methods of user-facing performance measures. The disagreement deconvolution takes in any multi-annotator (e.g., crowdsourced) dataset, disentangles stable opinions from noise by estimating intra-annotator consistency, and compares each test set prediction to the individual stable opinions from each annotator. Applying the disagreement deconvolution to existing social computing datasets, we find that current metrics dramatically overstate the performance of many human-facing machine learning tasks: for example, performance on a comment toxicity task is corrected from .95 to .73 ROC AUC.",
  "tags": [],
  "authors": [
    {
      "name": "Mitchell L. Gordon",
      "institution": "Computer Science Department, Stanford University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "87959139657",
      "orcid": "missing"
    },
    {
      "name": "Kaitlyn Zhou",
      "institution": "Computer Science Department, Stanford University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659021434",
      "orcid": "missing"
    },
    {
      "name": "Kayur Patel",
      "institution": "Apple Inc., United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81350576909",
      "orcid": "missing"
    },
    {
      "name": "Tatsunori Hashimoto",
      "institution": "Computer Science Department, Stanford University, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659324555",
      "orcid": "missing"
    },
    {
      "name": "Michael S. Bernstein",
      "institution": "Computer Science Department, Stanford University, United States",
      "img": "/do/10.1145/contrib-81405591691/rel-imgonly/msb-casbs-headshot-small.jpeg",
      "acmid": "81405591691",
      "orcid": "0000-0001-8020-9434"
    }
  ],
  "references": [
    {
      "text": "Ali Alkhatib and Michael Bernstein. 2019. Street-level algorithms: A theory at the gaps between policy and decisions. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3290605.3300760"
    },
    {
      "text": "Saleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and Thomas Zimmermann. 2019. Software engineering for machine learning: A case study. In 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 291\u2013300.",
      "doi": "10.1109/ICSE-SEIP.2019.00042"
    },
    {
      "text": "Saleema Amershi, Maya Cakmak, William\u00a0Bradley Knox, and Todd Kulesza. 2014. Power to the people: The role of humans in interactive machine learning. Ai Magazine 35, 4 (2014), 105\u2013120.",
      "doi": ""
    },
    {
      "text": "Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul\u00a0N Bennett, Kori Inkpen, 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3290605.3300233"
    },
    {
      "text": "Alexandry Augustin, Matteo Venanzi, J Hare, A Rogers, and NR Jennings. 2017. Bayesian aggregation of categorical distributions with applications in crowdsourcing. AAAI Press/International Joint Conferences on Artificial Intelligence.",
      "doi": ""
    },
    {
      "text": "Jutta Backhaus, Klaus Junghanns, Andreas Broocks, Dieter Riemann, and Fritz Hohagen. 2002. Test\u2013retest reliability and validity of the Pittsburgh Sleep Quality Index in primary insomnia. Journal of psychosomatic research 53, 3 (2002), 737\u2013740.",
      "doi": ""
    },
    {
      "text": "Barbara\u00a0A Bailar. 1968. Recent research in reinterview procedures. J. Amer. Statist. Assoc. 63, 321 (1968), 41\u201363.",
      "doi": ""
    },
    {
      "text": "Paul\u00a0M Barrett. 2020. Who Moderates the Social Media Giants?Center for Business (2020).",
      "doi": ""
    },
    {
      "text": "Md\u00a0Momen Bhuiyan, Amy\u00a0X. Zhang, Connie\u00a0Moon Sehat, and Tanushree Mitra. 2020. Investigating Differences in Crowdsourced News Credibility Assessment: Raters, Tasks, and Expert Criteria. Proc. ACM Hum.-Comput. Interact. 4, CSCW2, Article 93 (Oct. 2020), 26\u00a0pages.",
      "doi": "10.1145/3415164"
    },
    {
      "text": "Reuben Binns, Michael Veale, Max Van\u00a0Kleek, and Nigel Shadbolt. 2017. Like trainer, like bot? Inheritance of bias in algorithmic content moderation. In International conference on social informatics. Springer, 405\u2013415.",
      "doi": ""
    },
    {
      "text": "Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. 2019. Nuanced metrics for measuring unintended bias with real data for text classification. In Companion Proceedings of The 2019 World Wide Web Conference. 491\u2013500.",
      "doi": "10.1145/3308560.3317593"
    },
    {
      "text": "Geoffery\u00a0C. Bowker and Susan\u00a0Leigh Star. 2000. Sorting Things out: Classification and Its Consequences. MIT Press, Cambridge, MA, USA.",
      "doi": ""
    },
    {
      "text": "Jonathan Bragg, Mausam, and Daniel\u00a0S. Weld. 2018. Sprout: Crowd-Powered Task Design for Crowdsourcing. In Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology (Berlin, Germany) (UIST \u201918). Association for Computing Machinery, New York, NY, USA, 165\u2013176.",
      "doi": "10.1145/3242587.3242598"
    },
    {
      "text": "Chris Callison-Burch. 2009. Fast, cheap, and creative: Evaluating translation quality using Amazon\u2019s Mechanical Turk. In Proceedings of the 2009 conference on empirical methods in natural language processing. 286\u2013295.",
      "doi": ""
    },
    {
      "text": "Robyn Caplan and Tarleton Gillespie. 2020. Tiered governance and demonetization: The shifting terms of labor and compensation in the platform economy. Social Media+ Society 6, 2 (2020), 2056305120936636.",
      "doi": ""
    },
    {
      "text": "Stevie Chancellor, Jessica\u00a0Annette Pater, Trustin Clear, Eric Gilbert, and Munmun De\u00a0Choudhury. 2016. # thyghgapp: Instagram content moderation and lexical variation in pro-eating disorder communities. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing. 1201\u20131213.",
      "doi": "10.1145/2818048.2819963"
    },
    {
      "text": "Joseph\u00a0Chee Chang, Saleema Amershi, and Ece Kamar. 2017. Revolt: Collaborative crowdsourcing for labeling machine learning datasets. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 2334\u20132346.",
      "doi": "10.1145/3025453.3026044"
    },
    {
      "text": "Weiwei Cheng, Eyke H\u00fcllermeier, and Krzysztof\u00a0J Dembczynski. 2010. Bayes optimal multilabel classification via probabilistic classifier chains. In Proceedings of the 27th international conference on machine learning (ICML-10). 279\u2013286.",
      "doi": ""
    },
    {
      "text": "Zhendong Chu, Jing Ma, and Hongning Wang. 2020. Learning from Crowds by Modeling Common Confusions. arxiv:cs.LG/2012.13052",
      "doi": ""
    },
    {
      "text": "John Joon\u00a0Young Chung, Jean\u00a0Y Song, Sindhu Kutty, Sungsoo Hong, Juho Kim, and Walter\u00a0S Lasecki. 2019. Efficient elicitation approaches to estimate collective crowd answers. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201325.",
      "doi": ""
    },
    {
      "text": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. 2009. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09.",
      "doi": ""
    },
    {
      "text": "Michael\u00a0A DeVito, Jeremy Birnholtz, Jeffery\u00a0T Hancock, Megan French, and Sunny Liu. 2018. How people form folk theories of social media feeds and what it means for how we study self-presentation. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1\u201312.",
      "doi": "10.1145/3173574.3173694"
    },
    {
      "text": "Anca Dumitrache. 2015. Crowdsourcing disagreement for collecting semantic annotation. In European Semantic Web Conference. Springer, 701\u2013710.",
      "doi": "10.1007/978-3-319-18818-8_43"
    },
    {
      "text": "Anca Dumitrache, Lora Aroyo, and Chris Welty. 2017. Crowdsourcing ground truth for medical relation extraction. (2017). arXiv:1701.02185",
      "doi": ""
    },
    {
      "text": "Anca Dumitrache, Lora Aroyo, and Chris Welty. 2018. Capturing ambiguity in crowdsourcing frame disambiguation. (2018). arXiv:1805.00270",
      "doi": ""
    },
    {
      "text": "Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy Vuong, Karrie Karahalios, Kevin Hamilton, and Christian Sandvig. 2015. \u201cI always assumed that I wasn\u2019t really that close to [her]\u201d Reasoning about Invisible Algorithms in News Feeds. In Proceedings of the 33rd annual ACM conference on human factors in computing systems. 153\u2013162.",
      "doi": "10.1145/2702123.2702556"
    },
    {
      "text": "Jerry\u00a0Alan Fails and Dan\u00a0R Olsen\u00a0Jr. 2003. Interactive machine learning. In Proceedings of the 8th international conference on Intelligent user interfaces. 39\u201345.",
      "doi": "10.1145/604045.604056"
    },
    {
      "text": "G\u00f6sta Forsman and Irwin Schreiner. 2004. The design and analysis of reinterview: an overview. Measurement errors in surveys(2004), 279\u2013301.",
      "doi": ""
    },
    {
      "text": "Matt Gardner, Yoav Artzi, Victoria Basmova, Jonathan Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, 2020. Evaluating nlp models via contrast sets. (2020). arXiv:2004.02709",
      "doi": ""
    },
    {
      "text": "Timnit Gebru. 2020. Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (Virtual Event, CA, USA) (KDD \u201920). Association for Computing Machinery, New York, NY, USA, 3609.",
      "doi": "10.1145/3394486.3409559"
    },
    {
      "text": "Spiros\u00a0V Georgakopoulos, Sotiris\u00a0K Tasoulis, Aristidis\u00a0G Vrahatis, and Vassilis\u00a0P Plagianakos. 2018. Convolutional neural networks for toxic comment classification. In Proceedings of the 10th Hellenic Conference on Artificial Intelligence. 1\u20136.",
      "doi": "10.1145/3200947.3208069"
    },
    {
      "text": "Tarleton Gillespie. 2018. Custodians of the Internet: Platforms, content moderation, and the hidden decisions that shape social media. Yale University Press.",
      "doi": ""
    },
    {
      "text": "Louis Guttman. 1945. A basis for analyzing test-retest reliability. Psychometrika 10, 4 (1945), 255\u2013282.",
      "doi": ""
    },
    {
      "text": "Louis Guttman. 1946. The test-retest reliability of qualitative data. Psychometrika 11, 2 (1946), 81\u201395.",
      "doi": ""
    },
    {
      "text": "Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems. 159\u2013166.",
      "doi": "10.1145/302979.303030"
    },
    {
      "text": "Pei-Yun Hsueh, Prem Melville, and Vikas Sindhwani. 2009. Data quality from crowdsourcing: a study of annotation selection criteria. In Proceedings of the NAACL HLT 2009 workshop on active learning for natural language processing. 27\u201335.",
      "doi": ""
    },
    {
      "text": "Maurice Jakesch, Moran Koren, Anna Evtushenko, and Mor Naaman. 2019. The Role of Source and Expressive Responding in Political News Evaluation. (2019).",
      "doi": ""
    },
    {
      "text": "Jogsaw. [n.d.]. Jigsaw Unintended Bias in Toxicity Classification. https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview",
      "doi": ""
    },
    {
      "text": "Charles\u00a0D Jones. [n.d.]. Accuracy of 1970 Census Population and Housing Characteristics as Measured by Reinterviews.",
      "doi": ""
    },
    {
      "text": "Jeremy Kahn. 2020. Can Facebook\u2019s new A.I. banish Pepe the Frog?https://fortune.com/2020/05/12/facebook-a-i-hate-speech-covid-19-misinformation/",
      "doi": ""
    },
    {
      "text": "Sanjay Kairam and Jeffrey Heer. 2016. Parting crowds: Characterizing divergent interpretations in crowdsourced annotation tasks. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing. 1637\u20131648.",
      "doi": "10.1145/2818048.2820016"
    },
    {
      "text": "Kian Kenyon-Dean, Eisha Ahmed, Scott Fujimoto, Jeremy Georges-Filteau, Christopher Glasz, Barleen Kaur, Auguste Lalande, Shruti Bhanderi, Robert Belfer, Nirmal Kanagasabai, 2018. Sentiment analysis: It\u2019s complicated!. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 1886\u20131895.",
      "doi": ""
    },
    {
      "text": "John Le, Andy Edmonds, Vaughn Hester, and Lukas Biewald. 2010. Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution. In SIGIR 2010 workshop on crowdsourcing for search evaluation, Vol.\u00a02126. 22\u201332.",
      "doi": ""
    },
    {
      "text": "Tong Liu, Akash Venkatachalam, Pratik Sanjay\u00a0Bongale, and Christopher Homan. 2019. Learning to predict population-level label distributions. In Companion Proceedings of The 2019 World Wide Web Conference. 1111\u20131120.",
      "doi": "10.1145/3308560.3317082"
    },
    {
      "text": "Elizabeth Lucas, Cecilia\u00a0O Alm, and Reynold Bailey. 2019. Understanding Human and Predictive Moderation of Online Science Discourse. In 2019 IEEE Western New York Image and Signal Processing Workshop (WNYISPW). IEEE, 1\u20135.",
      "doi": ""
    },
    {
      "text": "Kaitlin Mahar, Amy\u00a0X. Zhang, and David Karger. 2018. Squadbox: A Tool to Combat Email Harassment Using Friendsourced Moderation. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal QC, Canada) (CHI \u201918). Association for Computing Machinery, New York, NY, USA, 1\u201313.",
      "doi": "10.1145/3173574.3174160"
    },
    {
      "text": "VK\u00a0Chaithanya Manam and Alexander\u00a0J Quinn. 2018. Wingit: Efficient refinement of unclear task instructions. In Sixth AAAI Conference on Human Computation and Crowdsourcing.",
      "doi": ""
    },
    {
      "text": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2019. A survey on bias and fairness in machine learning. (2019). arXiv:1908.09635",
      "doi": ""
    },
    {
      "text": "Josh Andres Zahra Ashktorab Narendra Nath Joshi Michael Desmond Aabhas Sharma Kristina Brimijoin Qian Pan Evelyn Duesterwald Casey\u00a0Dugan Michael\u00a0Muller, Christine\u00a0Wolf. 2021. Designing Ground Truth and the Social Life of Labels. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (2021).",
      "doi": ""
    },
    {
      "text": "Tanushree Mitra and Eric Gilbert. 2015. Credbank: A large-scale social media corpus with associated credibility annotations.",
      "doi": ""
    },
    {
      "text": "Kayur Patel, James Fogarty, James\u00a0A Landay, and Beverly\u00a0L Harrison. 2008. Examining Difficulties Software Developers Encounter in the Adoption of Statistical Machine Learning.. In AAAI. 1563\u20131566.",
      "doi": ""
    },
    {
      "text": "Ellie Pavlick and Tom Kwiatkowski. 2019. Inherent disagreements in human textual inferences. Transactions of the Association for Computational Linguistics 7 (2019), 677\u2013694.",
      "doi": ""
    },
    {
      "text": "Joshua\u00a0C Peterson, Ruairidh\u00a0M Battleday, Thomas\u00a0L Griffiths, and Olga Russakovsky. 2019. Human uncertainty makes classification more robust. In Proceedings of the IEEE International Conference on Computer Vision. 9617\u20139626.",
      "doi": ""
    },
    {
      "text": "Danny Pfeffermann and Calyampudi\u00a0Radhakrishna Rao. 2009. Sample surveys: design, methods and applications. Elsevier.",
      "doi": ""
    },
    {
      "text": "Alexander Ratner, Stephen\u00a0H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher R\u00e9. 2017. Snorkel: Rapid training data creation with weak supervision. In Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases, Vol.\u00a011. NIH Public Access, 269.",
      "doi": "10.14778/3157794.3157797"
    },
    {
      "text": "Sarah\u00a0T. Roberts. 2020. Fewer Humans Are Moderating Facebook Content. That\u2019s Worrying.https://slate.com/technology/2020/04/coronavirus-facebook-content-moderation-automated.html",
      "doi": ""
    },
    {
      "text": "Bj\u00f6rn Ross, Michael Rist, Guillermo Carbonell, Benjamin Cabrera, Nils Kurowsky, and Michael Wojatzki. 2017. Measuring the reliability of hate speech annotations: The case of the european refugee crisis. (2017). arXiv:1701.08118",
      "doi": ""
    },
    {
      "text": "Joni Salminen, Fabio Veronesi, Hind Almerekhi, Soon-Gvo Jung, and Bernard\u00a0J Jansen. 2018. Online Hate Interpretation Varies by Country, But More by Individual: A Statistical Analysis Using Crowdsourced Ratings. In 2018 Fifth International Conference on Social Networks Analysis, Management and Security (SNAMS). IEEE, 88\u201394.",
      "doi": ""
    },
    {
      "text": "Christian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric Langbort. 2014. Auditing algorithms: Research methods for detecting discrimination on internet platforms. Data and discrimination: converting critical concerns into productive inquiry 22(2014).",
      "doi": ""
    },
    {
      "text": "Mike Schaekermann, Joslin Goh, Kate Larson, and Edith Law. 2018. Resolvable vs. irresolvable disagreement: A study on worker deliberation in crowd work. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201319.",
      "doi": "10.1145/3274423"
    },
    {
      "text": "Victor\u00a0S Sheng, Foster Provost, and Panagiotis\u00a0G Ipeirotis. 2008. Get another label? improving data quality and data mining using multiple, noisy labelers. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 614\u2013622.",
      "doi": "10.1145/1401890.1401965"
    },
    {
      "text": "Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news detection on social media: A data mining perspective. ACM SIGKDD explorations newsletter 19, 1 (2017), 22\u201336.",
      "doi": "10.1145/3137597.3137600"
    },
    {
      "text": "Harini Suresh and John\u00a0V Guttag. 2019. A framework for understanding unintended consequences of machine learning. (2019). arXiv:1901.10002",
      "doi": ""
    },
    {
      "text": "Keith Trnka, John McCaw, Debra Yarrington, Kathleen\u00a0F McCoy, and Christopher Pennington. 2009. User interaction with word prediction: The effects of prediction quality. ACM Transactions on Accessible Computing (TACCESS) 1, 3 (2009), 1\u201334.",
      "doi": "10.1145/1497302.1497307"
    },
    {
      "text": "Joseph\u00a0D Tucker, Suzanne Day, Weiming Tang, and Barry Bayus. 2019. Crowdsourcing in medical research: concepts and applications. PeerJ 7(2019), e6762.",
      "doi": ""
    },
    {
      "text": "Betty van Aken, Julian Risch, Ralf Krestel, and Alexander L\u00f6ser. 2018. Challenges for toxic comment classification: An in-depth error analysis. (2018). arXiv:1809.07572",
      "doi": ""
    },
    {
      "text": "Alex\u00a0Hai Wang. 2010. Detecting spam bots in online social networking sites: a machine learning approach. In IFIP Annual Conference on Data and Applications Security and Privacy. Springer, 335\u2013342.",
      "doi": ""
    },
    {
      "text": "Jing Wang and Xin Geng. [n.d.]. Classification with Label Distribution Learning.",
      "doi": ""
    },
    {
      "text": "Zeerak Waseem. 2016. Are you a racist or am i seeing things? annotator influence on hate speech detection on twitter. In Proceedings of the first workshop on NLP and computational social science. 138\u2013142.",
      "doi": ""
    },
    {
      "text": "Jacob\u00a0O Wobbrock, Andrew\u00a0D Wilson, and Yang Li. 2007. Gestures without libraries, toolkits or training: a $1 recognizer for user interface prototypes. In Proceedings of the 20th annual ACM symposium on User interface software and technology. 159\u2013168.",
      "doi": "10.1145/1294211.1294238"
    },
    {
      "text": "Biqiao Zhang, Georg Essl, and Emily Mower\u00a0Provost. 2017. Predicting the distribution of emotion perception: capturing inter-rater variability. In Proceedings of the 19th ACM International Conference on Multimodal Interaction. 51\u201359.",
      "doi": "10.1145/3136755.3136792"
    },
    {
      "text": "Xinyi Zhou and Reza Zafarani. 2018. Fake news: A survey of research, detection methods, and opportunities. (2018). arXiv:1812.00315",
      "doi": ""
    }
  ]
}