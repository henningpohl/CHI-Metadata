{
  "doi": "10.1145/3411764.3445291",
  "title": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-14",
  "year": 2021,
  "badges": [],
  "abstract": "Crowdwork can enable invaluable opportunities for people with disabilities, not least the work flexibility and the ability to work from home, especially during the current Covid-19 pandemic. This paper investigates how engagement in crowdwork tasks is affected by individual disabilities and the resulting implications for HCI. We first surveyed 1,000 Amazon Mechanical Turk (AMT) workers to identify demographics of crowdworkers who identify as having various disabilities within the AMT ecosystem\u2014including vision, hearing, cognition/mental, mobility, reading and motor impairments. Through a second focused survey and follow-up interviews, we provide insights into how respondents cope with crowdwork tasks. We found that standard task factors, such as task completion time and presentation, often do not account for the needs of users with disabilities, resulting in anxiety and a feeling of depression on occasion. We discuss how to alleviate barriers to enable effective interaction for crowdworkers with disabilities.",
  "tags": [
    "crowdwork",
    "MTurk",
    "AMT",
    "accessibility",
    "crowdsourcing",
    "disability"
  ],
  "authors": [
    {
      "name": "Stephen Uzor",
      "institution": "Department of Engineering University of Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81479664548",
      "orcid": "missing"
    },
    {
      "name": "Jason T. Jacques",
      "institution": "Department of Engineering University of Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658722807",
      "orcid": "missing"
    },
    {
      "name": "John J Dudley",
      "institution": "Department of Engineering University of Cambridge, United Kingdom",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659277381",
      "orcid": "missing"
    },
    {
      "name": "Per Ola Kristensson",
      "institution": "Department of Engineering University of Cambridge, United Kingdom",
      "img": "/do/10.1145/contrib-81100362804/rel-imgonly/pokristensson2013small.jpg",
      "acmid": "81100362804",
      "orcid": "0000-0002-7139-871X"
    }
  ],
  "references": [
    {
      "text": "Harini Alagarai\u00a0Sampath, Rajeev Rajeshuni, and Bipin Indurkhya. 2014. Cognitively inspired task design to improve user performance on crowdsourcing platforms. In Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI \u201914. ACM Press, Toronto, Ontario, Canada, 3665\u20133674. https://doi.org/10.1145/2556288.2557155",
      "doi": "10.1145/2556288.2557155"
    },
    {
      "text": "Amazon. 2020 (accessed September 11, 2020). Amazon Mechanical Turk. https://www.mturk.com/",
      "doi": ""
    },
    {
      "text": "Daniel Archambault, Helen\u00a0C. Purchase, and Tobias Hobfeld. 2017. Evaluation in the Crowd: An Introduction. In Evaluation in the Crowd. Crowdsourcing and Human-Centered Experiments, Daniel Archambault, Helen Purchase, and Tobias Hobfeld(Eds.). Vol.\u00a010264. Springer International Publishing, Cham, 1\u20135. https://doi.org/10.1007/978-3-319-66435-4_1",
      "doi": ""
    },
    {
      "text": "Giorgio Brajnik, Yeliz Yesilada, and Simon Harper. 2010. Testability and validity of WCAG 2.0: the expertise effect. In Proceedings of the 12th international ACM SIGACCESS conference on Computers and accessibility - ASSETS \u201910. ACM Press, Orlando, Florida, USA, 43. https://doi.org/10.1145/1878803.1878813",
      "doi": "10.1145/1878803.1878813"
    },
    {
      "text": "Giorgio Brajnik, Yeliz Yesilada, and Simon Harper. 2012. Is accessibility conformance an elusive property? A study of validity and reliability of WCAG 2.0. ACM Transactions on Accessible Computing 4, 2 (March 2012), 1\u201328. https://doi.org/10.1145/2141943.2141946",
      "doi": "10.1145/2141943.2141946"
    },
    {
      "text": "Matthew\u00a0W. Brault. 2012. Americans With Disabilities: 2010. https://www2.census.gov/library/publications/2012/demo/p70-131.pdf",
      "doi": ""
    },
    {
      "text": "Alice\u00a0M. Brawley and Cynthia\u00a0L.S. Pury. 2016. Work experiences on MTurk: Job satisfaction, turnover, and information sharing. Computers in Human Behavior 54 (Jan. 2016), 531\u2013546. https://doi.org/10.1016/j.chb.2015.08.031",
      "doi": ""
    },
    {
      "text": "Robin Brewer, Meredith\u00a0Ringel Morris, and Anne\u00a0Marie Piper. 2016. \u201dWhy would anybody do this?\u201d: Understanding Older Adults\u2019 Motivations and Challenges in Crowd Work. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, San Jose California USA, 2246\u20132257. https://doi.org/10.1145/2858036.2858198",
      "doi": "10.1145/2858036.2858198"
    },
    {
      "text": "US\u00a0Census Bureau. 2020. U.S. Census Bureau QuickFacts: United States. https://www.census.gov/quickfacts/fact/table/US/PST045219",
      "doi": ""
    },
    {
      "text": "Roc\u00edo Calvo, Shaun\u00a0K. Kane, and Amy Hurst. 2014. Evaluating the accessibility of crowdsourcing tasks on Amazon\u2019s mechanical turk. In Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility - ASSETS \u201914. ACM Press, Rochester, New York, USA, 257\u2013258. https://doi.org/10.1145/2661334.2661401",
      "doi": "10.1145/2661334.2661401"
    },
    {
      "text": "Krista Casler, Lydia Bickel, and Elizabeth Hackett. 2013. Separate but equal? A comparison of participants and data gathered via Amazon\u2019s MTurk, social media, and face-to-face behavioral testing. Computers in Human Behavior 29, 6 (Nov. 2013), 2156\u20132160. https://doi.org/10.1016/j.chb.2013.05.009",
      "doi": "10.1016/j.chb.2013.05.009"
    },
    {
      "text": "Jesse Chandler and Danielle Shapiro. 2016. Conducting Clinical Research Using Crowdsourced Convenience Samples. Annual Review of Clinical Psychology 12, 1 (March 2016), 53\u201381. https://doi.org/10.1146/annurev-clinpsy-021815-093623",
      "doi": ""
    },
    {
      "text": "Yanto Chandra and Liang Shang. 2019. Inductive Coding. In Qualitative Research Using R: A Systematic Approach. Springer Singapore, Singapore, 91\u2013106. https://doi.org/10.1007/978-981-13-3170-1_8",
      "doi": ""
    },
    {
      "text": "Cint. 2020 (accessed September 11, 2020). The Cint Platform. https://www.cint.com/platform-market-research-technology",
      "doi": ""
    },
    {
      "text": "Clickworker. 2020 (accessed September 11, 2020). Clickworker Website. https://www.clickworker.com/",
      "doi": ""
    },
    {
      "text": "Microsoft Corporation. 2003. The Wide Range of Abilities and Its Impact on Computer Technology. Technical Report. Forrester Research Inc.https://www.microsoft.com/en-us/download/details.aspx?id=18446",
      "doi": ""
    },
    {
      "text": "Djellel Difallah, Elena Filatova, and Panos Ipeirotis. 2018. Demographics and Dynamics of Mechanical Turk Workers. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining - WSDM \u201918. ACM Press, Marina Del Rey, CA, USA, 135\u2013143. https://doi.org/10.1145/3159652.3159661",
      "doi": "10.1145/3159652.3159661"
    },
    {
      "text": "Jennifer Fereday and Eimear Muir-Cochrane. 2006. Demonstrating Rigor Using Thematic Analysis: A Hybrid Approach of Inductive and Deductive Coding and Theme Development. International Journal of Qualitative Methods 5, 1 (March 2006), 80\u201392. https://doi.org/10.1177/160940690600500107",
      "doi": ""
    },
    {
      "text": "Avi Fleischer, Alan\u00a0D. Mead, and Jialin Huang. 2015. Inattentive Responding in MTurk and Other Online Samples. Industrial and Organizational Psychology 8, 2 (June 2015), 196\u2013202. https://doi.org/10.1017/iop.2015.25",
      "doi": ""
    },
    {
      "text": "D.\u00a0Jake Follmer, Rayne\u00a0A. Sperling, and Hoi\u00a0K. Suen. 2017. The Role of MTurk in Education Research: Advantages, Issues, and Future Directions. Educational Researcher 46, 6 (Aug. 2017), 329\u2013334. https://doi.org/10.3102/0013189X17725519",
      "doi": ""
    },
    {
      "text": "Kar\u00ebn Fort, Gilles Adda, and K.\u00a0Bretonnel Cohen. 2011. Amazon Mechanical Turk: Gold Mine or Coal Mine?Computational Linguistics 37, 2 (June 2011), 413\u2013420. https://doi.org/10.1162/COLI_a_00057",
      "doi": ""
    },
    {
      "text": "Ujwal Gadiraju, Ricardo Kawase, and Stefan Dietze. 2014. A taxonomy of microtasks on the web. In Proceedings of the 25th ACM conference on Hypertext and social media - HT \u201914. ACM Press, Santiago, Chile, 218\u2013223. https://doi.org/10.1145/2631775.2631819",
      "doi": "10.1145/2631775.2631819"
    },
    {
      "text": "Ujwal Gadiraju, Sebastian M\u00fcller, Martin N\u00f6llenburg, Dietmar Saupe, Sebastian Egger-Lampl, Daniel Archambault, and Brian Fisher. 2017. Crowdsourcing Versus the Laboratory: Towards Human-Centered Experiments Using the Crowd. In Evaluation in the Crowd. Crowdsourcing and Human-Centered Experiments, Daniel Archambault, Helen Purchase, and Tobias Hobfeld(Eds.). Vol.\u00a010264. Springer International Publishing, Cham, 6\u201326. https://doi.org/10.1007/978-3-319-66435-4_2",
      "doi": ""
    },
    {
      "text": "Neha Gupta, David Martin, Benjamin\u00a0V. Hanrahan, and Jacki O\u2019Neill. 2014. Turk-Life in India. In Proceedings of the 18th International Conference on Supporting Group Work - GROUP \u201914. ACM Press, Sanibel Island, Florida, USA, 1\u201311. https://doi.org/10.1145/2660398.2660403",
      "doi": "10.1145/2660398.2660403"
    },
    {
      "text": "Kotaro Hara, Abigail Adams, Kristy Milland, Saiph Savage, Chris Callison-Burch, and Jeffrey\u00a0P. Bigham. 2018. A Data-Driven Analysis of Workers\u2019 Earnings on Amazon Mechanical Turk. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI \u201918. ACM Press, Montreal QC, Canada, 1\u201314. https://doi.org/10.1145/3173574.3174023",
      "doi": "10.1145/3173574.3174023"
    },
    {
      "text": "Kotaro Hara, Abigail Adams, Kristy Milland, Saiph Savage, Benjamin\u00a0V. Hanrahan, Jeffrey\u00a0P. Bigham, and Chris Callison-Burch. 2019. Worker Demographics and Earnings on Amazon Mechanical Turk: An Exploratory Analysis. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, Glasgow Scotland Uk, 1\u20136. https://doi.org/10.1145/3290607.3312970",
      "doi": ""
    },
    {
      "text": "Kotaro Hara, Vicki Le, and Jon Froehlich. 2013. Combining crowdsourcing and google street view to identify street-level accessibility problems. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI \u201913. ACM Press, Paris, France, 631. https://doi.org/10.1145/2470654.2470744",
      "doi": "10.1145/2470654.2470744"
    },
    {
      "text": "David\u00a0J. Hauser and Norbert Schwarz. 2016. Attentive Turkers: MTurk participants perform better on online attention checks than do subject pool participants. Behavior Research Methods 48, 1 (March 2016), 400\u2013407. https://doi.org/10.3758/s13428-015-0578-z",
      "doi": ""
    },
    {
      "text": "Isabell Hensel, Jochen Koch, and Eva Kocher. 2016. Crowdworking als Phanomen der Koordination digitaler Erwerbsarbeit - Eine interdisziplinare Perspektive. Industrielle Beziehungen2 (2016), 162\u2013186. https://doi.org/10.1688/IndB-2016-02-Hensel",
      "doi": ""
    },
    {
      "text": "Matthias Hirth, Jason Jacques, Peter Rodgers, Ognjen Scekic, and Michael Wybrow. 2017. Crowdsourcing Technology to Support Academic Research. In Evaluation in the Crowd. Crowdsourcing and Human-Centered Experiments, Daniel Archambault, Helen Purchase, and Tobias Hobfeld(Eds.). Vol.\u00a010264. Springer International Publishing, Cham, 70\u201395. https://doi.org/10.1007/978-3-319-66435-4_4",
      "doi": ""
    },
    {
      "text": "Paul Hitlin. 2016. Research in the Crowdsourcing Age, a Case Study: How Scholars, Companies and Workers are Using Mechanical Turk, a \u201dgig Economy\u201d Platform, for Tasks Computers Can\u2019t Handle. Pew Research Center.",
      "doi": ""
    },
    {
      "text": "Hwajung Hong, Svetlana Yarosh, Jennifer\u00a0G. Kim, Gregory\u00a0D. Abowd, and Rosa\u00a0I. Arriaga. 2013. Investigating the use of circles in social networks to support independence of individuals with autism. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI \u201913. ACM Press, Paris, France, 3207. https://doi.org/10.1145/2470654.2466439",
      "doi": "10.1145/2470654.2466439"
    },
    {
      "text": "J Howe. 2006. The Rise of Crowdsourcing. Wired Magazine 14, 6 (2006). https://www.wired.com/2006/06/crowds/",
      "doi": ""
    },
    {
      "text": "Panos Ipeirotis. 2009 (accessed September 11, 2020). Turker Demographics vs Internet Demographics. https://www.behind-the-enemy-lines.com/2009/03/turker-demographics-vs-internet.html",
      "doi": ""
    },
    {
      "text": "Jason\u00a0T. Jacques and Per\u00a0Ola Kristensson. 2017. Design Strategies for Efficient Access to Mobile Device Users via Amazon Mechanical Turk. In Proceedings of the First ACM Workshop on Mobile Crowdsensing Systems and Applications - CrowdSenSys \u201917. ACM Press, Delft, Netherlands, 25\u201330. https://doi.org/10.1145/3139243.3139247",
      "doi": ""
    },
    {
      "text": "Jason\u00a0T. Jacques and Per\u00a0Ola Kristensson. 2019. Crowdworker Economics in the Gig Economy. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI \u201919. ACM Press, Glasgow, Scotland Uk, 1\u201310. https://doi.org/10.1145/3290605.3300621",
      "doi": ""
    },
    {
      "text": "Shashank Khanna, Aishwarya Ratan, James Davis, and William Thies. 2010. Evaluating and improving the usability of Mechanical Turk for low-income workers in India. In Proceedings of the First ACM Symposium on Computing for Development - ACM DEV \u201910. ACM Press, London, United Kingdom, 1. https://doi.org/10.1145/1926180.1926195",
      "doi": "10.1145/1926180.1926195"
    },
    {
      "text": "Aniket Kittur, Ed\u00a0H. Chi, and Bongwon Suh. 2008. Crowdsourcing user studies with Mechanical Turk. In Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems - CHI \u201908. ACM Press, Florence, Italy, 453. https://doi.org/10.1145/1357054.1357127",
      "doi": ""
    },
    {
      "text": "Masatomo Kobayashi, Tatsuya Ishihara, Akihiro Kosugi, Hironobu Takagi, and Chieko Asakawa. 2013. Question-Answer Cards for an Inclusive Micro-tasking Framework for the Elderly. In Human-Computer Interaction - INTERACT 2013, David Hutchison, Takeo Kanade, Josef Kittler, Jon\u00a0M. Kleinberg, Friedemann Mattern, John\u00a0C. Mitchell, Moni Naor, Oscar Nierstrasz, C.\u00a0Pandu\u00a0Rangan, Bernhard Steffen, Madhu Sudan, Demetri Terzopoulos, Doug Tygar, Moshe\u00a0Y. Vardi, Gerhard Weikum, Paula Kotze, Gary Marsden, Gitte Lindgaard, Janet Wesson, and Marco Winckler (Eds.). Vol.\u00a08119. Springer Berlin Heidelberg, Berlin, Heidelberg, 590\u2013607. https://doi.org/10.1007/978-3-642-40477-1_38",
      "doi": ""
    },
    {
      "text": "Siou\u00a0Chew Kuek and Cecilia Paradi-Guildford. 2015. The Global Opportunity in Online Outsourcing. Technical Report. World Bank Group. http://documents1.worldbank.org/curated/en/138371468000900555/pdf/ACS14228-ESW-white-cover-P149016-Box391478B-PUBLIC-World-Bank-Global-OO-Study-WB-Rpt-FinalS.pdf",
      "doi": ""
    },
    {
      "text": "Leib Litman, Jonathan Robinson, and Cheskie Rosenzweig. 2015. The relationship between motivation, monetary compensation, and data quality among US- and India-based workers on Mechanical Turk. Behavior Research Methods 47, 2 (June 2015), 519\u2013528. https://doi.org/10.3758/s13428-014-0483-x",
      "doi": ""
    },
    {
      "text": "Eric Loepp and Jarrod\u00a0T. Kelly. 2020. Distinction without a difference? An assessment of MTurk Worker types. Research & Politics 7, 1 (Jan. 2020), 205316801990118. https://doi.org/10.1177/2053168019901185",
      "doi": ""
    },
    {
      "text": "Emily\u00a0M. Lund, Michael\u00a0R. Nadorff, Kate Galbraith, and Katie\u00a0B. Thomas. 2018. Using Amazon Mechanical Turk to Recruit Participants With Disabilities. SAGE Research Methods Cases in Psychology(2018). https://doi.org/10.4135/9781526437280",
      "doi": ""
    },
    {
      "text": "Adam Marcus and Aditya Parameswaran. 2015. Crowdsourced Data Management: Industry and Academic Perspectives. Foundations and Trends in Databases 6, 1-2 (2015), 1\u2013161. https://doi.org/10.1561/1900000044",
      "doi": "10.1561/1900000044"
    },
    {
      "text": "David Martin, Benjamin\u00a0V. Hanrahan, Jacki O\u2019Neill, and Neha Gupta. 2014. Being a turker. In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing - CSCW \u201914. ACM Press, Baltimore, Maryland, USA, 224\u2013235. https://doi.org/10.1145/2531602.2531663",
      "doi": "10.1145/2531602.2531663"
    },
    {
      "text": "Winter Mason and Siddharth Suri. 2012. Conducting behavioral research on Amazon\u2019s Mechanical Turk. Behavior Research Methods 44, 1 (March 2012), 1\u201323. https://doi.org/10.3758/s13428-011-0124-6",
      "doi": ""
    },
    {
      "text": "A. Moghaddam. 2006. Coding issues in grounded theory. Issues in Educational Research 16 (01 2006), 47\u201358.",
      "doi": ""
    },
    {
      "text": "Gabriele Paolacci and Jesse Chandler. 2014. Inside the Turk: Understanding Mechanical Turk as a Participant Pool. Current Directions in Psychological Science 23, 3 (June 2014), 184\u2013188. https://doi.org/10.1177/0963721414531598",
      "doi": ""
    },
    {
      "text": "Gabriele Paolacci, Jesse Chandler, and Panagiotis\u00a0G. Ipeirotis. 2010. Running experiments on Amazon Mechanical Turk. Decision Making 5, 5 (2010), 411\u2013419.",
      "doi": ""
    },
    {
      "text": "Prolific. 2020 (accessed September 11, 2020). Prolific. https://www.prolific.co/",
      "doi": ""
    },
    {
      "text": "Elissa\u00a0M. Redmiles, Sean Kross, and Michelle\u00a0L. Mazurek. 2019. How Well Do My Results Generalize? Comparing Security and Privacy Survey Results from MTurk, Web, and Telephone Samples. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, San Francisco, CA, USA, 1326\u20131343. https://doi.org/10.1109/SP.2019.00014",
      "doi": ""
    },
    {
      "text": "Mireia Ribera, Merce Porras, Marc Boldu, Miquel Termens, Andreu Sule, and Pilar Paris. 2009. Web Content Accessibility Guidelines 2.0: A further step towards accessible digital information. Program 43, 4 (Sept. 2009), 392\u2013406. https://doi.org/10.1108/00330330910998048",
      "doi": ""
    },
    {
      "text": "Joel Ross, Lilly Irani, M.\u00a0Six Silberman, Andrew Zaldivar, and Bill Tomlinson. 2010. Who are the crowdworkers?: shifting demographics in mechanical turk. In Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA \u201910. ACM Press, Atlanta, Georgia, USA, 2863. https://doi.org/10.1145/1753846.1753873",
      "doi": "10.1145/1753846.1753873"
    },
    {
      "text": "Shruti Sannon and Dan Cosley. 2019. Privacy, Power, and Invisible Labor on Amazon Mechanical Turk. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI \u201919. ACM Press, Glasgow, Scotland Uk, 1\u201312. https://doi.org/10.1145/3290605.3300512",
      "doi": "10.1145/3290605.3300512"
    },
    {
      "text": "Kathryn Sharpe\u00a0Wessling, Joel Huber, and Oded Netzer. 2017. MTurk Character Misrepresentation: Assessment and Solutions. Journal of Consumer Research 44, 1 (June 2017), 211\u2013230. https://doi.org/10.1093/jcr/ucx053",
      "doi": ""
    },
    {
      "text": "Scott\u00a0M. Smith, Catherine\u00a0A. Roster, Linda\u00a0L. Golden, and Gerald\u00a0S. Albaum. 2016. A multi-group analysis of online survey respondent data quality: Comparing a regular USA consumer panel to MTurk samples. Journal of Business Research 69, 8 (Aug. 2016), 3139\u20133148. https://doi.org/10.1016/j.jbusres.2015.12.002",
      "doi": ""
    },
    {
      "text": "Rion Snow, Daniel Jurafsky, and Andrew\u00a0Y. Ng. 2020 (accessed September 11, 2020). Cheap and Fast - But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks.",
      "doi": ""
    },
    {
      "text": "Alexander Sorokin and David Forsyth. 2008. Utility data annotation with Amazon Mechanical Turk. In 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops.",
      "doi": ""
    },
    {
      "text": "Neil Stewart, Christoph Ungemach, Adam J.\u00a0L. Harris, Daniel\u00a0M. Bartels, Ben\u00a0R. Newell, Gabriele Paolaccik, and Jesse Chandler. 2015. The average laboratory samples a population of 7,300 Amazon Mechanical Turk workers. Judgment and Decision Making 10, 5 (2015), 479\u2013491.",
      "doi": ""
    },
    {
      "text": "Saiganesh Swaminathan, Kotaro Hara, and Jeffrey\u00a0P. Bigham. 2017. The Crowd Work Accessibility Problem. In Proceedings of the 14th Web for All Conference on The Future of Accessible Work - W4A \u201917. ACM Press, Perth, Western Australia, Australia, 1\u20134. https://doi.org/10.1145/3058555.3058569",
      "doi": "10.1145/3058555.3058569"
    },
    {
      "text": "Kathryn Zyskowski, Meredith\u00a0Ringel Morris, Jeffrey\u00a0P. Bigham, Mary\u00a0L. Gray, and Shaun\u00a0K. Kane. 2015. Accessible Crowdwork?: Understanding the Value in and Challenge of Microtask Employment for People with Disabilities. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing - CSCW \u201915. ACM Press, Vancouver, BC, Canada, 1682\u20131693. https://doi.org/10.1145/2675133.2675158",
      "doi": "10.1145/2675133.2675158"
    }
  ]
}