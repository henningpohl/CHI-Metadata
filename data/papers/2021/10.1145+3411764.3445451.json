{
  "doi": "10.1145/3411764.3445451",
  "title": "LineChaser: A Smartphone-Based Navigation System for Blind People to Stand in Lines",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-13",
  "year": 2021,
  "badges": [],
  "abstract": "Standing in line is one of the most common social behaviors in public spaces but can be challenging for blind people. We propose an assistive system named LineChaser, which navigates a blind user to the end of a line and continuously reports the distance and direction to the last person in the line so that they can be followed. LineChaser uses the RGB camera in a smartphone to detect nearby pedestrians, and the built-in infrared depth sensor to estimate their position. Via pedestrian position estimations, LineChaser determines whether nearby pedestrians are standing in line, and uses audio and vibration signals to notify the user when they should start/stop moving forward. In this way, users can stay correctly positioned while maintaining social distance. We have conducted a usability study with 12 blind participants. LineChaser allowed blind participants to successfully navigate lines, significantly increasing their confidence in standing in lines.",
  "tags": [
    "line detection",
    "visual impairment",
    "pedestrian detection",
    "orientation and mobility"
  ],
  "authors": [
    {
      "name": "Masaki Kuribayashi",
      "institution": "Waseda University, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659701839",
      "orcid": "0000-0001-8412-223X"
    },
    {
      "name": "Seita Kayukawa",
      "institution": "Waseda University, Japan",
      "img": "/do/10.1145/contrib-99659261707/rel-imgonly/_____1_.jpg",
      "acmid": "99659261707",
      "orcid": "0000-0002-0678-1157"
    },
    {
      "name": "Hironobu Takagi",
      "institution": "IBM Research - Tokyo, Japan",
      "img": "/do/10.1145/contrib-81408594028/rel-imgonly/1428.jpeg",
      "acmid": "81408594028",
      "orcid": "0000-0003-3087-3251"
    },
    {
      "name": "Chieko Asakawa",
      "institution": "IBM Research IBM, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100044475",
      "orcid": "0000-0002-5447-1305"
    },
    {
      "name": "Shigeo Morishima",
      "institution": "Waseda Research Institute for Science and Engineering, Japan",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100066959",
      "orcid": "0000-0001-8859-6539"
    }
  ],
  "references": [
    {
      "text": "Japan\u00a0Tourism Agency. 2020. Manual For Welcoming People With disabilities and Elderlies. Retrieved in December 28, 2020 from https://www.mlit.go.jp/common/001226565.pdf.",
      "doi": ""
    },
    {
      "text": "Dragan Ahmetovic, Federico Avanzini, Adriano Barat\u00e8, Cristian Bernareggi, Gabriele Galimberti, Luca\u00a0A Ludovico, Sergio Mascetti, and Giorgio Presti. 2019. Sonification of rotation instructions to support navigation of people with visual impairment. In 2019 IEEE International Conference on Pervasive Computing and Communications (PerCom. IEEE, Los Alamitos, CA, USA, 1\u201310. https://doi.org/10.1109/PERCOM.2019.8767407",
      "doi": ""
    },
    {
      "text": "Aipoly. 2020. Aipoly Vision. Sight for Blind and Visually Impaired.Retrieved in December 27, 2020 from http://aipoly.com.",
      "doi": ""
    },
    {
      "text": "Aira. 2020. Aira. Retrieved in December 27, 2020 from https://aira.io/.",
      "doi": ""
    },
    {
      "text": "Aaron Bangor, Philip Kortum, and James Miller. 2009. Determining what individual SUS scores mean: Adding an adjective rating scale. Journal of usability studies 4, 3 (2009), 114\u2013123. https://doi.org/10.5555/2835587.2835589",
      "doi": "10.5555/2835587.2835589"
    },
    {
      "text": "BeMyEyes. 2020. BeMyEyes. Retrieved in December 27, 2020 from https://www.bemyeyes.com/.",
      "doi": ""
    },
    {
      "text": "Jeffrey\u00a0R Blum, Mathieu Bouchard, and Jeremy\u00a0R Cooperstock. 2011. What\u2019s around me? Spatialized audio augmented reality for blind users with a smartphone. In International Conference on Mobile and Ubiquitous Systems: Computing, Networking, and Services. Springer, New York, NY, USA, 49\u201362. https://doi.org/10.1007/978-3-642-30973-1_5",
      "doi": ""
    },
    {
      "text": "Nicholas\u00a0A Bradley and Mark\u00a0D Dunlop. 2002. Investigating context-aware clues to assist navigation for visually impaired people. In Proceedings of Workshop on Building Bridges: Interdisciplinary Context-Sensitive Computing, University of Glasgow. Strathprints, GBR, 5\u201310.",
      "doi": ""
    },
    {
      "text": "John Brooke 1996. SUS-A quick and dirty usability scale. Usability evaluation in industry 189, 194 (1996), 4\u20137.",
      "doi": ""
    },
    {
      "text": "Envision\u00a0Technologies B.V.2020. Envision AI. Enabling vision for the blind.Retrieved in December 27, 2020 from https://www.letsenvision.com.",
      "doi": ""
    },
    {
      "text": "Hsuan-Eng Chen, Yi-Ying Lin, Chien-Hsing Chen, and I-Fang Wang. 2015. BlindNavi: A navigation app for the visually impaired smartphone user. In Proceedings of the 33rd annual ACM conference extended abstracts on human factors in computing systems. ACM, New York, NY, USA, 19\u201324. https://doi.org/10.1145/2702613.2726953",
      "doi": "10.1145/2702613.2726953"
    },
    {
      "text": "Sakmongkon Chumkamon, Peranitti Tuvaphanthaphiphat, and Phongsak Keeratiwintakorn. 2008. A blind navigation system using RFID for indoor environments. In 2008 5th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, Vol.\u00a02. IEEE, Los Alamitos, CA, USA, 765\u2013768. https://doi.org/10.1109/ECTICON.2008.4600543.",
      "doi": ""
    },
    {
      "text": "Giovanni Ciaffoni. 2020. Ariadne GPS - Mobility and ,ap exploration for all. Retrieved in December 27, 2020 from https://www.ariadnegps.eu/.",
      "doi": ""
    },
    {
      "text": "Cloudsight. 2020. TapTapSee. Mobile camera application designed specifically for the blind and visually impaired iOS users.Retrieved in December 27, 2020 from http://www.taptapseeapp.com.",
      "doi": ""
    },
    {
      "text": "Navid Fallah, Ilias Apostolopoulos, Kostas Bekris, and Eelke Folmer. 2012. The user as a sensor: navigating users with visual impairments in indoor spaces using tactile landmarks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 425\u2013432. https://doi.org/10.1145/2207676.2207735",
      "doi": "10.1145/2207676.2207735"
    },
    {
      "text": "Alexander Fiannaca, Ilias Apostolopoulous, and Eelke Folmer. 2014. Headlock: a wearable navigation aid that helps blind cane users traverse large open spaces. In Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility. ACM, New York, NY, USA, 19\u201326. https://doi.org/10.1145/2661334.2661453",
      "doi": "10.1145/2661334.2661453"
    },
    {
      "text": "Dieter Fox, Wolfram Burgard, and Sebastian Thrun. 1997. The dynamic window approach to collision avoidance. IEEE Robotics & Automation Magazine 4, 1 (1997), 23\u201333. https://doi.org/10.1109/100.580977",
      "doi": "10.5555/895623"
    },
    {
      "text": "Aura Ganz, Siddhesh\u00a0Rajan Gandhi, Carole Wilson, and Gary Mullett. 2010. INSIGHT: RFID and Bluetooth enabled automated space for the blind and visually impaired. In 2010 Annual International Conference of the IEEE Engineering in Medicine and Biology. IEEE, Los Alamitos, CA, USA, 331\u2013334. https://doi.org/10.1109/IEMBS.2010.5627670",
      "doi": ""
    },
    {
      "text": "Giuseppe Ghiani, Barbara Leporini, and Fabio Patern\u00f2. 2009. Vibrotactile feedback to aid blind users of mobile guides. Journal of Visual Languages & Computing 20, 5 (2009), 305\u2013317. https://doi.org/10.1016/j.jvlc.2009.07.004",
      "doi": "10.1016/j.jvlc.2009.07.004"
    },
    {
      "text": "Nicholas\u00a0A. Giudice. 2020. COVID-19 and blindness: Why the new touchless, physically-distant world sucks for people with visual impairment. Retrieved in December 27, 2020 from https://medium.com/@nicholas.giudice/covid-19-and-blindness-why-the-new-touchless-physically-distant-world-sucks-for-people-with-2c8dbd21de63.",
      "doi": ""
    },
    {
      "text": "Nicholas\u00a0A Giudice, Benjamin\u00a0A Guenther, Nicholas\u00a0A Jensen, and Kaitlyn\u00a0N Haase. 2020. Cognitive mapping without vision: Comparing wayfinding performance after learning from digital touchscreen-based multimodal maps vs. embossed tactile overlays. Frontiers in Human Neuroscience 14 (2020), 87. https://doi.org/10.3389/fnhum.2020.00087",
      "doi": ""
    },
    {
      "text": "Nicholas\u00a0A Giudice, William\u00a0E Whalen, Timothy\u00a0H Riehle, Shane\u00a0M Anderson, and Stacy\u00a0A Doore. 2019. Evaluation of an accessible, real-time, and infrastructure-free indoor navigation system by users who are blind in the mall of america. Journal of Visual Impairment & Blindness 113, 2 (2019), 140\u2013155. https://doi.org/10.1177/0145482X19840918",
      "doi": ""
    },
    {
      "text": "Google. 2020. Google Maps. Retrieved in December 27, 2020 from https://maps.google.com.",
      "doi": ""
    },
    {
      "text": "William Grussenmeyer, Jesel Garcia, and Fang Jiang. 2016. Feasibility of using haptic directions through maps with a tablet and smart watch for people who are blind and visually impaired. In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services. ACM, New York, NY, USA, 83\u201389. https://doi.org/10.1145/2935334.2935367",
      "doi": "10.1145/2935334.2935367"
    },
    {
      "text": "Jo\u00e3o Guerreiro, Daisuke Sato, Saki Asakawa, Huixu Dong, Kris\u00a0M Kitani, and Chieko Asakawa. 2019. CaBot: Designing and Evaluating an Autonomous Navigation Robot for Blind People. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 68\u201382. https://doi.org/10.1145/3308561.3353771",
      "doi": "10.1145/3308561.3353771"
    },
    {
      "text": "Rabia Jafri, Rodrigo\u00a0Louzada Campos, Syed\u00a0Abid Ali, and Hamid\u00a0R Arabnia. 2017. Visual and infrared sensor data-based obstacle detection for the visually impaired using the Google project tango tablet development kit and the unity engine. IEEE Access 6(2017), 443\u2013454. https://doi.org/10.1109/ACCESS.2017.2766579",
      "doi": ""
    },
    {
      "text": "Robert\u00a0K Katzschmann, Brandon Araki, and Daniela Rus. 2018. Safe local navigation for visually impaired users with a time-of-flight and haptic feedback device. IEEE Transactions on Neural Systems and Rehabilitation Engineering 26, 3(2018), 583\u2013593. https://doi.org/10.1109/TNSRE.2018.2800665",
      "doi": ""
    },
    {
      "text": "Seita Kayukawa, Keita Higuchi, Jo\u00e3o Guerreiro, Shigeo Morishima, Yoichi Sato, Kris Kitani, and Chieko Asakawa. 2019. BBeep: A sonic collision avoidance system for blind travellers and nearby pedestrians. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3290605.3300282",
      "doi": "10.1145/3290605.3300282"
    },
    {
      "text": "Seita Kayukawa, Tatsuya Ishihara, Hironobu Takagi, Shigeo Morishima, and Chieko Asakawa. 2020. BlindPilot: A Robotic Local Navigation System That Leads Blind People to a Landmark Object. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 1\u20139. https://doi.org/10.1145/3334480.3382925",
      "doi": "10.1145/3334480"
    },
    {
      "text": "Seita Kayukawa, Tatsuya Ishihara, Hironobu Takagi, Shigeo Morishima, and Chieko Asakawa. 2020. Guiding Blind Pedestrians in Public Spaces by Understanding Walking Behavior of Nearby Pedestrians. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 3 (2020), 1\u201322. https://doi.org/10.1145/3411825",
      "doi": "10.1145/3411825"
    },
    {
      "text": "Seita Kayukawa, Hironobu Takagi, Jo\u00e3o Guerreiro, Shigeo Morishima, and Chieko Asakawa. 2020. Smartphone-Based Assistance for Blind People to Stand in Lines. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 1\u20138. https://doi.org/10.1145/3334480.3382954",
      "doi": "10.1145/3334480.3382954"
    },
    {
      "text": "Jee-Eun Kim, Masahiro Bessho, Shinsuke Kobayashi, Noboru Koshizuka, and Ken Sakamura. 2016. Navigating Visually Impaired Travelers in a Large Train Station Using Smartphone and Bluetooth Low Energy. In Proceedings of the 31st Annual ACM Symposium on Applied Computing. ACM, New York, NY, USA, 604\u2013611. https://doi.org/10.1145/2851613.2851716",
      "doi": "10.1145/2851613.2851716"
    },
    {
      "text": "Eunjeong Ko, Jin\u00a0Sun Ju, and Eun\u00a0Yi Kim. 2011. Situation-based indoor wayfinding system for the visually impaired. In The proceedings of the 13th international ACM SIGACCESS conference on Computers and accessibility. ACM, New York, NY, USA, 35\u201342. https://doi.org/10.1145/2049536.2049545",
      "doi": "10.1145/2049536.2049545"
    },
    {
      "text": "Bing Li, J\u00a0Pablo Munoz, Xuejian Rong, Jizhong Xiao, Yingli Tian, and Aries Arditi. 2016. ISANA: wearable context-aware indoor assistive navigation with obstacle avoidance for the blind. In European Conference on Computer Vision. Springer, New York, NY, USA, 448\u2013462. https://doi.org/10.1007/978-3-319-48881-3_31",
      "doi": ""
    },
    {
      "text": "Jack\u00a0M Loomis, Yvonne Lippa, Roberta\u00a0L Klatzky, and Reginald\u00a0G Golledge. 2002. Spatial updating of locations specified by 3-D sound and spatial language.Journal of Experimental Psychology: Learning, Memory, and Cognition 28, 2(2002), 335. https://doi.org/10.1037/0278-7393.28.2.335",
      "doi": ""
    },
    {
      "text": "Manuel Martinez, Angela Constantinescu, Boris Schauerte, Daniel Koester, and Rainer Stiefelhagen. 2014. Cognitive evaluation of haptic and audio feedback in short range navigation tasks. In International Conference on Computers for Handicapped Persons. Springer, New York, NY, USA, 128\u2013135. https://doi.org/10.1007/978-3-319-08599-9_20",
      "doi": ""
    },
    {
      "text": "Microsoft. 2020. Seeing AI. A free app that narrates the world around you. Retrieved in December 27, 2020 from https://www.microsoft.com/en-us/seeing-ai.",
      "doi": ""
    },
    {
      "text": "Microsoft. 2020. SoundScape. Retrieved in December 27, 2020 from https://www.microsoft.com/en-us/research/product/soundscape/.",
      "doi": ""
    },
    {
      "text": "MIPsoft. 2020. Blindsquare.",
      "doi": ""
    },
    {
      "text": "Masayuki Murata, Dragan Ahmetovic, Daisuke Sato, Hironobu Takagi, Kris\u00a0M Kitani, and Chieko Asakawa. 2018. Smartphone-based indoor localization for blind navigation across building complexes. In 2018 IEEE International Conference on Pervasive Computing and Communications (PerCom). IEEE, Los Alamitos, CA, USA, 1\u201310. https://doi.org/10.1109/PERCOM.2018.8444593",
      "doi": ""
    },
    {
      "text": "Madoka Nakajima and Shinichiro Haruyama. 2013. New indoor navigation system for visually impaired people using visible light communication. EURASIP Journal on Wireless Communications and Networking 2013, 1(2013), 37. https://doi.org/10.1186/1687-1499-2013-37",
      "doi": ""
    },
    {
      "text": "Yasushi Nakauchi and Reid Simmons. 2002. A social robot that stands in line. Autonomous Robots 12, 3 (2002), 313\u2013324. https://doi.org/10.1023/A:1015273816637",
      "doi": "10.1023/A%3A1015273816637"
    },
    {
      "text": "Orcam. 2020. Help People who are Blind or Partially Sighted - OrCam.Retrieved in December 27, 2020 from https://www.orcam.com/en/.",
      "doi": ""
    },
    {
      "text": "Manoj Penmetcha, Arabinda Samantaray, and Byung-Cheol Min. 2017. Smartresponse: Emergency and non-emergency response for smartphone based indoor localization applications. In International Conference on Human-Computer Interaction. Springer, New York, NY, USA, 398\u2013404. https://doi.org/10.1007/978-3-319-58753-0_57",
      "doi": ""
    },
    {
      "text": "Benjamin Poppinga, Charlotte Magnusson, Martin Pielot, and Kirsten Rassmus-Gr\u00f6hn. 2011. TouchOver map: audio-tactile exploration of interactive maps. In Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services. ACM, New York, NY, USA, 545\u2013550. https://doi.org/10.1145/2037373.2037458",
      "doi": "10.1145/2037373.2037458"
    },
    {
      "text": "Giorgio Presti, Dragan Ahmetovic, Mattia Ducci, Cristian Bernareggi, Luca Ludovico, Adriano Barat\u00e8, Federico Avanzini, and Sergio Mascetti. 2019. WatchOut: Obstacle sonification for people with visual impairment or blindness. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 402\u2013413. https://doi.org/10.1145/3308561.3353779",
      "doi": "10.1145/3308561.3353779"
    },
    {
      "text": "Joseph Redmon and Ali Farhadi. 2018. YOLOv3: An Incremental Improvement. arxiv:1804.02767\u00a0[cs.CV]",
      "doi": ""
    },
    {
      "text": "Timothy\u00a0H Riehle, Shane\u00a0M Anderson, Patrick\u00a0A Lichter, Nicholas\u00a0A Giudice, Suneel\u00a0I Sheikh, Robert\u00a0J Knuesel, Daniel\u00a0T Kollmann, and Daniel\u00a0S Hedin. 2012. Indoor magnetic navigation for the blind. In 2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE, Los Alamitos, CA, USA, 1972\u20131975. https://doi.org/10.1109/EMBC.2012.6346342",
      "doi": ""
    },
    {
      "text": "Jean-Paul Rodrigue, Claude Comtois, and Brian Slack. 2016. The geography of transport systems. Routledge, Abingdon, Oxfordshire, UK.",
      "doi": ""
    },
    {
      "text": "Alberto Rodr\u00edguez, J\u00a0Javier Yebes, Pablo\u00a0F Alcantarilla, Luis\u00a0M Bergasa, Javier Almaz\u00e1n, and Andr\u00e9s Cela. 2012. Assisting the visually impaired: obstacle detection and warning system by acoustic feedback. Sensors 12, 12 (2012), 17476\u201317496. https://doi.org/10.3390/s121217476",
      "doi": ""
    },
    {
      "text": "David\u00a0A Ross and Bruce\u00a0B Blasch. 2000. Wearable interfaces for orientation and wayfinding. In Proceedings of the fourth international ACM conference on Assistive technologies. ACM, New York, NY, USA, 193\u2013200. https://doi.org/10.1145/354324.354380",
      "doi": "10.1145/354324.354380"
    },
    {
      "text": "Daisuke Sato, Uran Oh, Jo\u00e3o Guerreiro, Dragan Ahmetovic, Kakuya Naito, Hironobu Takagi, Kris\u00a0M Kitani, and Chieko Asakawa. 2019. NavCog3 in the wild: Large-scale blind indoor navigation assistant with semantic features. ACM Transactions on Accessible Computing (TACCESS) 12, 3 (2019), 14. https://doi.org/10.1145/3340319",
      "doi": "10.1145/3340319"
    },
    {
      "text": "Hsueh-Cheng Wang, Robert\u00a0K Katzschmann, Santani Teng, Brandon Araki, Laura Giarr\u00e9, and Daniela Rus. 2017. Enabling independent navigation for visually impaired people through a wearable vision-based feedback system. In 2017 IEEE international conference on robotics and automation (ICRA). IEEE, Los Alamitos, CA, USA, 6533\u20136540. https://doi.org/10.1109/ICRA.2017.7989772",
      "doi": ""
    },
    {
      "text": "Richard Welsh. 1981. Foundations of orientation and mobility. Technical Report. American Foundation for the Blind.",
      "doi": ""
    },
    {
      "text": "Michele\u00a0A Williams, Amy Hurst, and Shaun\u00a0K Kane. 2013. \u201d Pray before you step out\u201d describing personal and situational blind navigation behaviors. In Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 1\u20138. https://doi.org/10.1145/2513383.2513449",
      "doi": "10.1145/2513383.2513449"
    },
    {
      "text": "Koji Yatani, Nikola Banovic, and Khai Truong. 2012. SpaceSense: representing geographical information to visually impaired people using spatial tactile feedback. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 415\u2013424. https://doi.org/10.1145/2207676.2207734",
      "doi": "10.1145/2207676.2207734"
    },
    {
      "text": "Chris Yoon, Ryan Louie, Jeremy Ryan, MinhKhang Vu, Hyegi Bang, William Derksen, and Paul Ruvolo. 2019. Leveraging Augmented Reality to Create Apps for People with Visual Disabilities: A Case Study in Indoor Navigation. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM, New York, NY, USA, 210\u2013221. https://doi.org/10.1145/3308561.3353788",
      "doi": "10.1145/3308561.3353788"
    }
  ]
}