{
  "doi": "10.1145/3411764.3445304",
  "title": "Human-AI Interaction in Human Resource Management: Understanding Why Employees Resist Algorithmic Evaluation at Workplaces and How to Mitigate Burdens",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-15",
  "year": 2021,
  "badges": [],
  "abstract": "Recently, Artificial Intelligence (AI) has been used to enable efficient decision-making in managerial and organizational contexts, ranging from employment to dismissal. However, to avoid employees\u2019 antipathy toward AI, it is important to understand what aspects of AI employees like and/or dislike. In this paper, we aim to identify how employees perceive current human resource (HR) teams and future algorithmic management. Specifically, we explored what factors negatively influence employees\u2019 perceptions of AI making work performance evaluations. Through in-depth interviews with 21 workers, we found that 1) employees feel six types of burdens (i.e., emotional, mental, bias, manipulation, privacy, and social) toward AI's introduction to human resource management (HRM), and that 2) these burdens could be mitigated by incorporating transparency, interpretability, and human intervention to algorithmic decision-making. Based on our findings, we present design efforts to alleviate employees\u2019 burdens. To leverage AI for HRM in fair and trustworthy ways, we call for the HCI community to design human-AI collaboration systems with various HR stakeholders.",
  "tags": [
    "Interpretability",
    "Algorithmic management",
    "Human-AI collaboration",
    "Transparency",
    "User burden",
    "Trust",
    "Explainable AI (XAI)",
    "Adoption",
    "Algorithmic fairness",
    "Artificial intelligence (AI)",
    "Human resource management (HRM)",
    "Algorithm aversion",
    "Fair and responsible AI"
  ],
  "authors": [
    {
      "name": "Hyanghee Park",
      "institution": "Human-Computer Interaction+Design Lab., Seoul National University, Republic of Korea",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659063493",
      "orcid": "0000-0002-4607-2988"
    },
    {
      "name": "Daehwan Ahn",
      "institution": "OID Dept., The Wharton School, University of Pennsylvania, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659702252",
      "orcid": "missing"
    },
    {
      "name": "Kartik Hosanagar",
      "institution": "OID Dept., The Wharton School, University of Pennsylvania, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100528978",
      "orcid": "missing"
    },
    {
      "name": "Joonhwan Lee",
      "institution": "Human-Computer Interaction+Design Lab., Seoul National University, Republic of Korea",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81502746040",
      "orcid": "0000-0002-3115-4024"
    }
  ],
  "references": [
    {
      "text": "Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian Y. Lim, and Mohan Kankanhalli. 2018. Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI \u201918), 582:1\u2013582:18. https://doi.org/10.1145/3173574.3174156",
      "doi": "10.1145/3173574.3174156"
    },
    {
      "text": "Ashraf Abdul, Christian von der Weth, Mohan Kankanhalli, and Brian Y. Lim. 2020. COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1\u201314.",
      "doi": ""
    },
    {
      "text": "David Alvarez-Melis and Tommi S. Jaakkola. 2018. On the robustness of interpretability methods. arXiv preprint arXiv:1806.08049.",
      "doi": ""
    },
    {
      "text": "Saleema Amershi, Kori Inkpen, Jaime Teevan, Ruth Kikin-Gil, Eric Horvitz, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, and Paul N. Bennett. 2019. Guidelines for Human-AI Interaction. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI \u201919, 1\u201313. https://doi.org/10.1145/3290605.3300233",
      "doi": ""
    },
    {
      "text": "Josh Andres, Christine T. Wolf, Sergio Cabrero Barros, Erick Oduor, Rahul Nair, Alexander Kj\u00e6rum, Anders Bech Tharsgaard, and Bo Schwartz Madsen. 2020. Scenario-based XAI for Humanitarian Aid Forecasting. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems (CHI EA \u201920), 1\u20138. https://doi.org/10.1145/3334480.3382903",
      "doi": ""
    },
    {
      "text": "Human Resources Professionals Association (HRPA). A new age of opportunities: what does artificial intelligence mean for HR professionals?. Retrieved April 20, 2020 from https://www.hrpa.ca/Documents/Public/Thought-Leadership/HRPA-Report-Artificial-Intelligence-20171031.PDF",
      "doi": ""
    },
    {
      "text": "Jonah Berger. 2020. The Catalyst: How to Change Anyone's Mind. Simon & Schuster.",
      "doi": ""
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2013. Successful qualitative research: A practical guide for beginners. sage.",
      "doi": ""
    },
    {
      "text": "Andrew Burt. 2019. The AI transparency paradox. Harv. Bus. Rev.(Dec. 13, 2019), https://bit.ly/369LKvq.",
      "doi": ""
    },
    {
      "text": "Peter Cappelli, Prasanna Tambe, and Valery Yakubovich. 2019. Artificial intelligence in human resources management: challenges and a path forward. Available at SSRN 3263878.",
      "doi": ""
    },
    {
      "text": "John M. Carroll. 1996. Becoming social: expanding scenario-based approaches in HCI. Behaviour & Information Technology 15, 4: 266\u2013275.",
      "doi": ""
    },
    {
      "text": "Stephen Cave and Kanta Dihal. 2019. Hopes and fears for intelligent machines in fiction and reality. Nature Machine Intelligence 1, 2: 74\u201378.",
      "doi": ""
    },
    {
      "text": "Hyojin Chin, Lebogang Wame Molefi, and Mun Yong Yi. 2020. Empathy Is All You Need: How a Conversational Agent Should Respond to Verbal Abuse. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920), 1\u201313. https://doi.org/10.1145/3313831.3376461",
      "doi": "10.1145/3313831.3376461"
    },
    {
      "text": "Eun Kyoung Choe, Marisa E Duarte, Hyewon Suh, Wanda Pratt, and Julie A Kientz. 2019. Communicating Bad News: Insights for the Design of Consumer Health Technologies. JMIR Human Factors 6, 2: e8885. https://doi.org/10.2196/humanfactors.8885",
      "doi": ""
    },
    {
      "text": "Committee of Ministers Council of Europe. Declaration by the Committee of Ministers on the manipulative capabilities of algorithmic processes. Retrieved September 13, 2020 from https://search.coe.int/cm/pages/result_details.aspx?objectid=090000168092dd4b",
      "doi": ""
    },
    {
      "text": "Eric Corbett and Astrid Weber. 2016. What can I say?: addressing user experience challenges of a mobile voice user interface for accessibility. In Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services, 72\u201382.",
      "doi": "10.1145/2935334.2935386"
    },
    {
      "text": "Anupam Datta, Shayak Sen, and Yair Zick. 2016. Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems. In 2016 IEEE symposium on security and privacy (SP), 598\u2013617.",
      "doi": ""
    },
    {
      "text": "Berkeley J. Dietvorst, Joseph P. Simmons, and Cade Massey. 2018. Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them. Management Science 64, 3: 1155\u20131170.",
      "doi": "10.1287/mnsc.2016.2643"
    },
    {
      "text": "Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608.",
      "doi": ""
    },
    {
      "text": "Graham Dove, Kim Halskov, Jodi Forlizzi, and John Zimmerman. 2017. UX design innovation: Challenges for working with machine learning as a design material. In Proceedings of the 2017 chi conference on human factors in computing systems, 278\u2013288.",
      "doi": "10.1145/3025453.3025739"
    },
    {
      "text": "Aaron Doyle, Randy Lippert, and David Lyon. 2013. Eyes everywhere: The global growth of camera surveillance. Routledge.",
      "doi": ""
    },
    {
      "text": "Patrick van Esch, J. Stewart Black, and Joseph Ferolie. 2019. Marketing AI recruitment: The next phase in job application and selection. Computers in Human Behavior 90: 215\u2013222. https://doi.org/10.1016/j.chb.2018.09.009",
      "doi": ""
    },
    {
      "text": "Sarah E. Fox, Vera Khovanskaya, Clara Crivellaro, Niloufar Salehi, Lynn Dombrowski, Chinmay Kulkarni, Lilly Irani, and Jodi Forlizzi. 2020. Worker-Centered Design: Expanding HCI Methods for Supporting Labor. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, 1\u20138. https://doi.org/10.1145/3334480.3375157",
      "doi": ""
    },
    {
      "text": "Lex Fridman, Bryan Reimer, Bruce Mehler, and William T. Freeman. 2018. Cognitive load estimation in the wild. In Proceedings of the 2018 chi conference on human factors in computing systems, 1\u20139.",
      "doi": ""
    },
    {
      "text": "Kurt Gray and Daniel M. Wegner. 2012. Feeling robots and human zombies: Mind perception and the uncanny valley. Cognition 125, 1: 125\u2013130.",
      "doi": ""
    },
    {
      "text": "Miriam Greis, Jessica Hullman, Michael Correll, Matthew Kay, and Orit Shaer. 2017. Designing for Uncertainty in HCI: When Does Uncertainty Help? In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA \u201917), 593\u2013600. https://doi.org/10.1145/3027063.3027091",
      "doi": "10.1145/3027063.3027091"
    },
    {
      "text": "Sara Hajian, Francesco Bonchi, and Carlos Castillo. 2016. Algorithmic bias: From discrimination discovery to fairness-aware data mining. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 2125\u20132126.",
      "doi": "10.1145/2939672.2945386"
    },
    {
      "text": "John R. Hollenbeck, Raymond A. Noe, and Barry A. Gerhart. 2018. Human resource management: Gaining a competitive advantage. McGraw-Hill Education.",
      "doi": ""
    },
    {
      "text": "Kartik Hosanagar and Vivian Jair. 2018. We need transparency in algorithms, but too much can backfire. Harvard Business Review.",
      "doi": ""
    },
    {
      "text": "Becky Inkster, Shubhankar Sarda, and Vinod Subramanian. 2018. An Empathy-Driven, Conversational Artificial Intelligence Agent (Wysa) for Digital Mental Well-Being: Real-World Data Evaluation Mixed-Methods Study. JMIR mHealth and uHealth 6, 11: e12106. https://doi.org/10.2196/12106",
      "doi": ""
    },
    {
      "text": "Lucas D. Introna. 2000. Workplace surveillance, privacy and distributive justice. ACM SIGCAS Computers and Society 30, 4: 33\u201339.",
      "doi": "10.1145/572260.572267"
    },
    {
      "text": "Qiong Jia, Yue Guo, Rong Li, Yurong Li, and Yuwei Chen. 2018. A conceptual artificial intelligence application framework in human resource management. In Proceedings of the International Conference on Electronic Business, 106\u2013114.",
      "doi": ""
    },
    {
      "text": "Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, and Jennifer Wortman Vaughan. 2020. Interpreting Interpretability: Understanding Data Scientists\u2019 Use of Interpretability Tools for Machine Learning. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1\u201314.",
      "doi": "10.1145/3313831.3376219"
    },
    {
      "text": "Caitlin Kelleher and Wint Hnin. 2019. Predicting cognitive load in future code puzzles. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, 1\u201312.",
      "doi": "10.1145/3290605.3300487"
    },
    {
      "text": "Katherine C. Kellogg, Melissa A. Valentine, and Angele Christin. 2020. Algorithms at work: The new contested terrain of control. Academy of Management Annals 14, 1: 366\u2013410.",
      "doi": ""
    },
    {
      "text": "Young-Ho Kim, Jae Ho Jeon, Eun Kyoung Choe, Bongshin Lee, KwonHyun Kim, and Jinwook Seo. 2016. TimeAware: Leveraging framing effects to enhance personal productivity. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, 272\u2013283.",
      "doi": "10.1145/2858036.2858428"
    },
    {
      "text": "Ren\u00e9 F. Kizilcec. 2016. How much information? Effects of transparency on trust in an algorithmic interface. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, 2390\u20132395.",
      "doi": "10.1145/2858036.2858402"
    },
    {
      "text": "Rafal Kocielnik, Saleema Amershi, and Paul N. Bennett. 2019. Will You Accept an Imperfect AI?: Exploring Designs for Adjusting End-user Expectations of AI Systems. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI \u201919, 1\u201314. https://doi.org/10.1145/3290605.3300641",
      "doi": ""
    },
    {
      "text": "Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236.",
      "doi": ""
    },
    {
      "text": "Colin Lecher. 2019. How Amazon automatically tracks and fires warehouse workers for \u2018productivity.\u2019 The Verge. Retrieved February 5, 2020 from https://www.theverge.com/2019/4/25/18516004/amazon-warehouse-fulfillment-centers-productivity-firing-terminations",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5, 1: 205395171875668. https://doi.org/10.1177/2053951718756684",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee and Su Baykal. 2017. Algorithmic Mediation in Group Decisions: Fairness Perceptions of Algorithmically Mediated vs. Discussion-Based Social Division. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing - CSCW \u201917, 1035\u20131048. https://doi.org/10.1145/2998181.2998230",
      "doi": "10.1145/2998181.2998230"
    },
    {
      "text": "Min Kyung Lee, Anuraag Jain, Hea Jin Cha, Shashank Ojha, and Daniel Kusbit. 2019. Procedural justice in algorithmic fairness: Leveraging transparency and outcome control for fair algorithmic mediation. Proceedings of the ACM on Human-Computer Interaction 3, CSCW: 1\u201326.",
      "doi": "10.1145/3359284"
    },
    {
      "text": "Min Kyung Lee, Sara Kiesler, Jodi Forlizzi, and Paul Rybski. 2012. Ripple Effects of an Embedded Social Agent: A Field Study of a Social Robot in the Workplace. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \u201912), 695\u2013704. https://doi.org/10.1145/2207676.2207776",
      "doi": "10.1145/2207676.2207776"
    },
    {
      "text": "Min Kyung Lee, Daniel Kusbit, Anson Kahng, Ji Tae Kim, Xinran Yuan, Allissa Chan, Daniel See, Ritesh Noothigattu, Siheon Lee, and Alexandros Psomas. 2019. WeBuildAI: Participatory framework for algorithmic governance. Proceedings of the ACM on Human-Computer Interaction 3, CSCW: 1\u201335.",
      "doi": ""
    },
    {
      "text": "Min Kyung Lee, Daniel Kusbit, Evan Metsky, and Laura Dabbish. 2015. Working with machines: The impact of algorithmic and data-driven management on human workers. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, 1603\u20131612.",
      "doi": "10.1145/2702123.2702548"
    },
    {
      "text": "Bruno Lepri, Nuria Oliver, Emmanuel Letouz\u00e9, Alex Pentland, and Patrick Vinck. 2018. Fair, transparent, and accountable algorithmic decision-making processes. Philosophy & Technology 31, 4: 611\u2013627.",
      "doi": ""
    },
    {
      "text": "Q. Vera Liao, Daniel Gruen, and Sarah Miller. 2020. Questioning the AI: Informing Design Practices for Explainable AI User Experiences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1\u201315.",
      "doi": "10.1145/3313831.3376590"
    },
    {
      "text": "Brian Y. Lim, Oshrat Ayalon, and Eran Toch. 2017. Reducing Communication Uncertainty with Social Intelligibility: Challenges and Opportunities. In CHI 2017 Workshop on Designing for Uncertainty in HCI.",
      "doi": ""
    },
    {
      "text": "Bingjie Liu and S. Shyam Sundar. 2018. Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot. Cyberpsychology, Behavior, and Social Networking 21, 10: 625\u2013636. https://doi.org/10.1089/cyber.2018.0110",
      "doi": ""
    },
    {
      "text": "Jennifer Liu. 2019. A.I. is changing how much workers trust their managers\u2014and that could be a good thing. CNBC. Retrieved February 5, 2020 from https://www.cnbc.com/2019/10/15/ai-is-changing-how-much-workers-trust-their-managerswhy-thats-good.html",
      "doi": ""
    },
    {
      "text": "Duri Long and Brian Magerko. 2020. What is AI Literacy? Competencies and Design Considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI \u201920), 1\u201316. https://doi.org/10.1145/3313831.3376727",
      "doi": "10.1145/3313831.3376727"
    },
    {
      "text": "Michael A. Madaio, Luke Stark, Jennifer Wortman Vaughan, and Hanna Wallach. 2020. Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1\u201314.",
      "doi": "10.1145/3313831.3376445"
    },
    {
      "text": "Lena Mamykina, Arlene M. Smaldone, and Suzanne R. Bakken. 2015. Adopting the sensemaking perspective for chronic disease self-management. Journal of biomedical informatics 56: 406\u2013417.",
      "doi": "10.1016/j.jbi.2015.06.006"
    },
    {
      "text": "Michael McCahill and Clive Norris. 1999. Watching the workers: Crime, CCTV and the Workplace. In Invisible Crimes. Springer, 208\u2013231.",
      "doi": ""
    },
    {
      "text": "Paul K. McClure. 2018. \u201cYou're Fired,\u201d Says the Robot: The Rise of Automation in the Workplace, Technophobes, and Fears of Unemployment. Social Science Computer Review 36, 2: 139\u2013156. https://doi.org/10.1177/0894439317698637",
      "doi": "10.1177/0894439317698637"
    },
    {
      "text": "S. L. McGovern, Vinod Pandey, Steve Gill, Tim Aldrich, Chad Myers, Chirag Desai, and Mayank Gera. 2018. The new age: artificial intelligence for human resource opportunities and functions. London: Ernst & Young LLP.",
      "doi": ""
    },
    {
      "text": "Sameep Mehta, Rakesh Pimplikar, Amit Singh, Lav R. Varshney, and Karthik Visweswariah. 2013. Efficient multifaceted screening of job applicants. In Proceedings of the 16th International Conference on Extending Database Technology, 661\u2013671.",
      "doi": "10.1145/2452376.2452453"
    },
    {
      "text": "David Alvarez Melis and Tommi Jaakkola. 2018. Towards robust interpretability with self-explaining neural networks. In Advances in Neural Information Processing Systems, 7775\u20137784.",
      "doi": ""
    },
    {
      "text": "Seumas Miller and John Weckert. 2000. Privacy, the Workplace and the Internet. Journal of Business Ethics 28, 3: 255\u2013265.",
      "doi": ""
    },
    {
      "text": "Tim Miller. 2019. Explanation in artificial intelligence: Insights from the social sciences. Artificial Intelligence 267: 1\u201338.",
      "doi": ""
    },
    {
      "text": "Smitha Milli, Ludwig Schmidt, Anca D. Dragan, and Moritz Hardt. 2019. Model reconstruction from model explanations. In Proceedings of the Conference on Fairness, Accountability, and Transparency, 1\u20139.",
      "doi": "10.1145/3287560.3287562"
    },
    {
      "text": "Christoph Molnar. 2020. Interpretable Machine Learning. Lulu. com.",
      "doi": ""
    },
    {
      "text": "Changhoon Oh, Taeyoung Lee, Yoojung Kim, SoHyun Park, Saebom Kwon, and Bongwon Suh. 2017. Us vs. them: Understanding artificial intelligence technophobia over the google deepmind challenge match. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 2523\u20132534.",
      "doi": "10.1145/3025453.3025539"
    },
    {
      "text": "Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael Wellman. 2016. Towards the science of security and privacy in machine learning. arXiv preprint arXiv:1611.03814.",
      "doi": ""
    },
    {
      "text": "Lewis Petrinovich, Patricia O'Neill, and Matthew Jorgensen. 1993. An empirical study of moral intuitions: Toward an evolutionary ethics. Journal of personality and social psychology 64, 3: 467.",
      "doi": ""
    },
    {
      "text": "Valery Petrushin. 1999. Emotion in speech: Recognition and application to call centers. In Proceedings of artificial neural networks in engineering, 22.",
      "doi": ""
    },
    {
      "text": "Manish Raghavan, Solon Barocas, Jon Kleinberg, and Karen Levy. 2020. Mitigating bias in algorithmic hiring: evaluating claims and practices. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 469\u2013481.",
      "doi": "10.1145/3351095.3372828"
    },
    {
      "text": "Byron Reeves and Clifford Ivar Nass. 1996. The media equation: How people treat computers, television, and new media like real people and places. Cambridge University Press, New York, NY, US.",
      "doi": "10.5555/236605"
    },
    {
      "text": "Neil M. Richards and Jonathan H. King. 2016. Big data and the future for privacy. In Research handbook on digital transformations. Edward Elgar Publishing.",
      "doi": ""
    },
    {
      "text": "Eric Rosenbaum. 2019. IBM artificial intelligence can predict with 95% accuracy which workers are about to quit their jobs. CNBC. Retrieved September 15, 2020 from https://www.cnbc.com/2019/04/03/ibm-ai-can-predict-with-95-percent-accuracy-which-employees-will-quit.html",
      "doi": ""
    },
    {
      "text": "Lenny Roth. 2004. Workplace Surveillance. NSW Parliamentary Library Research Service.",
      "doi": ""
    },
    {
      "text": "Daniel B. Shank, Christopher Graves, Alexander Gott, Patrick Gamez, and Sophia Rodriguez. 2019. Feeling our way to machine minds: People's emotions when perceiving mind in artificial intelligence. Computers in Human Behavior 98: 256\u2013266.",
      "doi": "10.1016/j.chb.2019.04.001"
    },
    {
      "text": "Donghee Shin and Yong Jin Park. 2019. Role of fairness, accountability, and transparency in algorithmic affordance. Computers in Human Behavior 98: 277\u2013284.",
      "doi": "10.1016/j.chb.2019.04.019"
    },
    {
      "text": "Ben Shneiderman. 2020. Human-centered artificial intelligence: Reliable, safe & trustworthy. International Journal of Human\u2013Computer Interaction 36, 6: 495\u2013504.",
      "doi": ""
    },
    {
      "text": "Hyewon Suh, Nina Shahriaree, Eric B. Hekler, and Julie A. Kientz. 2016. Developing and validating the user burden scale: A tool for assessing user burden in computing systems. In Proceedings of the 2016 CHI conference on human factors in computing systems, 3988\u20133999.",
      "doi": ""
    },
    {
      "text": "S. Shyam Sundar and Jinyoung Kim. 2019. Machine Heuristic: When We Trust Computers More Than Humans with Our Personal Information. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI \u201919), 538:1\u2013538:9. https://doi.org/10.1145/3290605.3300768",
      "doi": "10.1145/3290605.3300768"
    },
    {
      "text": "Prasanna Tambe, Peter Cappelli, and Valery Yakubovich. 2019. Artificial Intelligence in Human Resources Management: Challenges and a Path Forward. California Management Review 61, 4: 15\u201342. https://doi.org/10.1177/0008125619867910",
      "doi": ""
    },
    {
      "text": "Omer Tene and Jules Polonetsky. 2012. Big data for all: Privacy and user control in the age of analytics. Nw. J. Tech. & Intell. Prop. 11: xxvii.",
      "doi": ""
    },
    {
      "text": "Michael Veale, Max Van Kleek, and Reuben Binns. 2018. Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI \u201918, 1\u201314. https://doi.org/10.1145/3173574.3174014",
      "doi": "10.1145/3173574.3174014"
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian Y. Lim. 2019. Designing Theory-Driven User-Centric Explainable AI. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI \u201919, 1\u201315. https://doi.org/10.1145/3290605.3300831",
      "doi": "10.1145/3290605.3300831"
    },
    {
      "text": "Karl E. Weick. 1995. Sensemaking in organizations. Sage.",
      "doi": ""
    },
    {
      "text": "Adrian Weller. 2017. Challenges for transparency. arXiv preprint arXiv:1708.01870.",
      "doi": ""
    },
    {
      "text": "Jacob O. Wobbrock, Htet Htet Aung, Brandon Rothrock, and Brad A. Myers. 2005. Maximizing the guessability of symbolic input. In CHI \u201905 Extended Abstracts on Human Factors in Computing Systems (CHI EA \u201905), 1869\u20131872. https://doi.org/10.1145/1056808.1057043",
      "doi": ""
    },
    {
      "text": "Christine T. Wolf. 2019. Explainability scenarios: towards scenario-based XAI design. In Proceedings of the 24th International Conference on Intelligent User Interfaces (IUI \u201919), 252\u2013257. https://doi.org/10.1145/3301275.3302317",
      "doi": "10.1145/3301275.3302317"
    },
    {
      "text": "Matthew S. Wood and Steven J. Karau. 2009. Preserving employee dignity during the termination interview: An empirical examination. Journal of business ethics 86, 4: 519\u2013534.",
      "doi": ""
    },
    {
      "text": "Allison Woodruff, Sarah E. Fox, Steven Rousso-Schindler, and Jeffrey Warshaw. 2018. A qualitative exploration of perceptions of algorithmic fairness. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 656.",
      "doi": "10.1145/3173574.3174230"
    },
    {
      "text": "Qixue Xiao, Kang Li, Deyue Zhang, and Weilin Xu. 2018. Security risks in deep learning implementations. In 2018 IEEE Security and Privacy Workshops (SPW), 123\u2013128.",
      "doi": ""
    },
    {
      "text": "Qian Yang, Aaron Steinfeld, Carolyn Ros\u00e9, and John Zimmerman. 2020. Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. 13.",
      "doi": ""
    },
    {
      "text": "Qian Yang, Aaron Steinfeld, and John Zimmerman. 2019. Unremarkable ai: Fitting intelligent decision support into critical, clinical decision-making processes. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, 1\u201311.",
      "doi": "10.1145/3290605.3300468"
    },
    {
      "text": "Jason C. Yip, Kiley Sobel, Xin Gao, Allison Marie Hishikawa, Alexis Lim, Laura Meng, Romaine Flor Ofiana, Justin Park, and Alexis Hiniker. 2019. Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI \u201919, 1\u201315. https://doi.org/10.1145/3290605.3300303",
      "doi": "10.1145/3290605.3300303"
    },
    {
      "text": "Shoshana Zuboff. 2015. Big other: surveillance capitalism and the prospects of an information civilization. Journal of Information Technology 30, 1: 75\u201389.",
      "doi": ""
    },
    {
      "text": "2018. The man who was fired by a machine. BBC News. Retrieved September 15, 2020 from https://www.bbc.com/news/technology-44561838",
      "doi": ""
    },
    {
      "text": "2018. Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. Retrieved April 9, 2020 from https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G",
      "doi": ""
    },
    {
      "text": "2020. Chinese construction firms using AI to keep tabs on workers. South China Morning Post. Retrieved August 15, 2020 from https://www.scmp.com/news/china/science/article/3091738/chinese-construction-firms-using-ai-monitor-workers-safety-also",
      "doi": ""
    },
    {
      "text": "Ideal AI Resume Screening Software | Increase Quality of Hire | Demo Today. Ideal. Retrieved April 9, 2020 from https://ideal.com/product/screening/",
      "doi": ""
    },
    {
      "text": "Interview Mocha Reviews and Pricing - 2020. Retrieved April 9, 2020 from https://www.capterra.com/p/132140/Interview-Mocha/#about",
      "doi": ""
    },
    {
      "text": "Amazon's sexist AI recruiting tool: how did it go so wrong? Retrieved April 9, 2020 from https://becominghuman.ai/amazons-sexist-ai-recruiting-tool-how-did-it-go-so-wrong-e3d14816d98e",
      "doi": ""
    },
    {
      "text": "From Fear to Enthusiasm. Oracle & Future Workplace: 18.",
      "doi": ""
    },
    {
      "text": "Union Accuses Amazon of Breaking Federal Law by Firing Activist - Bloomberg. Retrieved February 5, 2020 from https://www.bloomberg.com/news/articles/2019-03-20/union-accuses-amazon-of-breaking-federal-law-by-firing-activist",
      "doi": ""
    },
    {
      "text": "Your Raise Is Now Based on Next Year's Performance - Bloomberg. Retrieved September 17, 2020 from https://www.bloomberg.com/news/articles/2018-07-09/your-raise-is-now-based-on-next-year-s-performance",
      "doi": ""
    }
  ]
}