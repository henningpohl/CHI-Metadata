{
  "doi": "10.1145/3411764.3445188",
  "title": "Expanding Explainability: Towards Social Transparency in AI systems",
  "published": "2021-05-07",
  "proctitle": "CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
  "pages": "1-19",
  "year": 2021,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "As AI-powered systems increasingly mediate consequential decision-making, their explainability is critical for end-users to take informed and accountable actions. Explanations in human-human interactions are socially-situated. AI systems are often socio-organizationally embedded. However, Explainable AI (XAI) approaches have been predominantly algorithm-centered. We take a developmental step towards socially-situated XAI by introducing and exploring Social Transparency (ST), a sociotechnically informed perspective that incorporates the socio-organizational context into explaining AI-mediated decision-making. To explore ST conceptually, we conducted interviews with 29 AI users and practitioners grounded in a speculative design scenario. We suggested constitutive design elements of ST and developed a conceptual framework to unpack ST\u2019s effect and implications at the technical, decision-making, and organizational level. The framework showcases how ST can potentially calibrate trust in AI, improve decision-making, facilitate organizational collective actions, and cultivate holistic explainability. Our work contributes to the discourse of Human-Centered XAI by expanding the design space of XAI.",
  "tags": [
    "explanations",
    "human-AI interaction",
    "Artificial Intelligence",
    "socio-organizational context",
    "sociotechnical",
    "Explainable AI",
    "social transparency"
  ],
  "authors": [
    {
      "name": "Upol Ehsan",
      "institution": "Computer Science Georgia Institute of Technology, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659184377",
      "orcid": "missing"
    },
    {
      "name": "Q. Vera Liao",
      "institution": "IBM Research, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659248963",
      "orcid": "0000-0003-4543-7196"
    },
    {
      "name": "Michael Muller",
      "institution": "AI Interactions IBM Research, United States",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81332517372",
      "orcid": "0000-0001-7860-163X"
    },
    {
      "name": "Mark O. Riedl",
      "institution": "Georgia Tech, United States",
      "img": "/do/10.1145/contrib-81100096537/rel-imgonly/mark-aiide10-panel.jpg",
      "acmid": "81100096537",
      "orcid": "missing"
    },
    {
      "name": "Justin D. Weisz",
      "institution": "IBM Research AI, United States",
      "img": "/do/10.1145/contrib-81311482644/rel-imgonly/jweisz-20-sm.jpg",
      "acmid": "81311482644",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian\u00a0Y Lim, and Mohan Kankanhalli. 2018. Trends and trajectories for explainable, accountable and intelligible systems: An hci research agenda. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1\u201318.",
      "doi": "10.1145/3173574.3174156"
    },
    {
      "text": "Ashraf Abdul, Christian von\u00a0der Weth, Mohan Kankanhalli, and Brian\u00a0Y. Lim. 2020. COGAM: Measuring and Moderating Cognitive Load in Machine Learning Model Explanations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI \u201920). Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi.org/10.1145/3313831.3376615",
      "doi": "10.1145/3313831.3376615"
    },
    {
      "text": "Mark\u00a0S Ackerman, Juri Dachtera, Volkmar Pipek, and Volker Wulf. 2013. Sharing knowledge and expertise: The CSCW view of knowledge management. Computer Supported Cooperative Work (CSCW) 22, 4-6 (2013), 531\u2013573.",
      "doi": "10.1007/s10606-013-9192-8"
    },
    {
      "text": "P Agre. 1997. Toward a critical technical practice: Lessons learned in trying to reform AI in Bowker. G., Star, S., Turner, W., and Gasser, L., eds, Social Science, Technical Systems and Cooperative Work: Beyond the Great Divide, Erlbaum (1997).",
      "doi": ""
    },
    {
      "text": "Philip Agre and Philip\u00a0E Agre. 1997. Computation and human experience. Cambridge University Press.",
      "doi": "10.5555/522884"
    },
    {
      "text": "Ahmed Alqaraawi, Martin Schuessler, Philipp Wei\u00df, Enrico Costanza, and Nadia Berthouze. 2020. Evaluating saliency map explanations for convolutional neural networks: a user study. In Proceedings of the 25th International Conference on Intelligent User Interfaces. 275\u2013285.",
      "doi": "10.1145/3377325.3377519"
    },
    {
      "text": "Alejandro\u00a0Barredo Arrieta, Natalia D\u00edaz-Rodr\u00edguez, Javier Del\u00a0Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc\u00eda, Sergio Gil-L\u00f3pez, Daniel Molina, Richard Benjamins, 2020. Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion 58(2020), 82\u2013115.",
      "doi": "10.1016/j.inffus.2019.12.012"
    },
    {
      "text": "Vijay Arya, Rachel\u00a0KE Bellamy, Pin-Yu Chen, Amit Dhurandhar, Michael Hind, Samuel\u00a0C Hoffman, Stephanie Houde, Q\u00a0Vera Liao, Ronny Luss, Aleksandra Mojsilovi\u0107, 2019. One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques. CoRR abs/1909.03012(2019). arxiv:1909.03012http://arxiv.org/abs/1909.03012",
      "doi": ""
    },
    {
      "text": "John\u00a0R Austin. 2003. Transactive memory in organizational groups: the effects of content, consensus, specialization, and accuracy on group performance.Journal of applied psychology 88, 5 (2003), 866.",
      "doi": ""
    },
    {
      "text": "David\u00a0P Brandon and Andrea\u00a0B Hollingshead. 2004. Transactive memory systems in organizations: Matching tasks, expertise, and people. Organization science 15, 6 (2004), 633\u2013644.",
      "doi": ""
    },
    {
      "text": "Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology. Qualitative research in psychology 3, 2 (2006), 77\u2013101.",
      "doi": ""
    },
    {
      "text": "Zana Bu\u00e7inca, Phoebe Lin, Krzysztof\u00a0Z. Gajos, and Elena\u00a0L. Glassman. 2020. Proxy Tasks and Subjective Measures Can Be Misleading in Evaluating Explainable AI Systems. In Proceedings of the 25th International Conference on Intelligent User Interfaces (Cagliari, Italy) (IUI \u201920). Association for Computing Machinery, New York, NY, USA, 454\u2013464. https://doi.org/10.1145/3377325.3377498",
      "doi": "10.1145/3377325.3377498"
    },
    {
      "text": "Carrie\u00a0J Cai, Jonas Jongejan, and Jess Holbrook. 2019. The effects of example-based explanations in a machine learning interface. In Proceedings of the 24th International Conference on Intelligent User Interfaces. 258\u2013262.",
      "doi": "10.1145/3301275.3302289"
    },
    {
      "text": "Diogo\u00a0V Carvalho, Eduardo\u00a0M Pereira, and Jaime\u00a0S Cardoso. 2019. Machine learning interpretability: A survey on methods and metrics. Electronics 8, 8 (2019), 832.",
      "doi": ""
    },
    {
      "text": "Hao-Fei Cheng, Ruotong Wang, Zheng Zhang, Fiona O\u2019Connell, Terrance Gray, F\u00a0Maxwell Harper, and Haiyi Zhu. 2019. Explaining decision-making algorithms through UI: Strategies to help non-expert stakeholders. In Proceedings of the 2019 chi conference on human factors in computing systems. 1\u201312.",
      "doi": "10.1145/3290605.3300789"
    },
    {
      "text": "EunJeong Cheon and Norman\u00a0Makoto Su. 2016. Integrating roboticist values into a Value Sensitive Design framework for humanoid robots. In 2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI). IEEE, 375\u2013382.",
      "doi": ""
    },
    {
      "text": "EunJeong Cheon and Norman\u00a0Makoto Su. 2018. Futuristic autobiographies: Weaving participant narratives to elicit values around robots. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction. 388\u2013397.",
      "doi": "10.1145/3171221.3171244"
    },
    {
      "text": "Laura Dabbish, Colleen Stuart, Jason Tsay, and Jim Herbsleb. 2012. Social coding in GitHub: transparency and collaboration in an open software repository. In Proceedings of the ACM 2012 conference on computer supported cooperative work. 1277\u20131286.",
      "doi": "10.1145/2145204.2145396"
    },
    {
      "text": "Ben Dattner, Tomas Chamorro-Premuzic, Richard Buchband, and Lucinda Schettler. 2019. The Legal and Ethical Implications of Using AI in Hiring. Harvard Business Review (25 April 2019). Retrieved 26-August-2019 from https://hbr.org/2019/04/the-legal-and-ethical-implications-of-using-ai-in-hiring",
      "doi": ""
    },
    {
      "text": "Daniel\u00a0Clement Dennett. 1989. The intentional stance. MIT press.",
      "doi": ""
    },
    {
      "text": "Berkeley\u00a0J Dietvorst, Joseph\u00a0P Simmons, and Cade Massey. 2015. Algorithm aversion: People erroneously avoid algorithms after seeing them err.Journal of Experimental Psychology: General 144, 1 (2015), 114.",
      "doi": ""
    },
    {
      "text": "Jonathan Dodge, Q\u00a0Vera Liao, Yunfeng Zhang, Rachel\u00a0KE Bellamy, and Casey Dugan. 2019. Explaining models: an empirical study of how explanations impact fairness judgment. In Proceedings of the 24th International Conference on Intelligent User Interfaces. 275\u2013285.",
      "doi": "10.1145/3301275.3302310"
    },
    {
      "text": "Finale Doshi-Velez and Been Kim. 2017. Towards A Rigorous Science of Interpretable Machine Learning. stat 1050(2017), 2.",
      "doi": ""
    },
    {
      "text": "Paul Dourish. 2004. Where the action is: the foundations of embodied interaction. MIT press.",
      "doi": "10.5555/513034"
    },
    {
      "text": "Paul Dourish, Janet Finlay, Phoebe Sengers, and Peter Wright. 2004. Reflective HCI: Towards a critical technical practice. In CHI\u201904 extended abstracts on Human factors in computing systems. 1727\u20131728.",
      "doi": ""
    },
    {
      "text": "Upol Ehsan and Mark\u00a0O Riedl. 2020. Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach. arXiv preprint arXiv:2002.01092(2020).",
      "doi": ""
    },
    {
      "text": "Upol Ehsan, Pradyumna Tambwekar, Larry Chan, Brent Harrison, and Mark\u00a0O. Riedl. 2019. Automated Rationale Generation: A Technique for Explainable AI and Its Effects on Human Perceptions. In Proceedings of the 24th International Conference on Intelligent User Interfaces (Marina del Ray, California) (IUI \u201919). Association for Computing Machinery, New York, NY, USA, 263\u2013274. https://doi.org/10.1145/3301275.3302316",
      "doi": "10.1145/3301275.3302316"
    },
    {
      "text": "Thomas Erickson and Wendy\u00a0A Kellogg. 2003. Social translucence: using minimalist visualisations of social activity to support collective interaction. In Designing information spaces: The social navigation approach. Springer, 17\u201341.",
      "doi": ""
    },
    {
      "text": "Bhavya Ghai, Q\u00a0Vera Liao, Yunfeng Zhang, Rachel Bellamy, and Klaus Mueller. 2021. Explainable Active Learning (XAL): Toward AI Explanations as Interfaces for Machine Teachers. Proceedings of the ACM on Human-Computer InteractionCSCW (2021).",
      "doi": ""
    },
    {
      "text": "Eric Gilbert. 2012. Designing Social Translucence over Social Networks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Austin, Texas, USA) (CHI \u201912). Association for Computing Machinery, New York, NY, USA, 2731\u20132740. https://doi.org/10.1145/2207676.2208670",
      "doi": "10.1145/2207676.2208670"
    },
    {
      "text": "Leilani\u00a0H Gilpin, David Bau, Ben\u00a0Z Yuan, Ayesha Bajwa, Michael Specter, and Lalana Kagal. 2018. Explaining explanations: An overview of interpretability of machine learning. In 2018 IEEE 5th International Conference on data science and advanced analytics (DSAA). IEEE, 80\u201389.",
      "doi": ""
    },
    {
      "text": "Ben Green and Salom\u00e9 Viljoen. 2020. Algorithmic realism: expanding the boundaries of algorithmic thought. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 19\u201331.",
      "doi": "10.1145/3351095.3372840"
    },
    {
      "text": "Jonathan Grudin. 1988. Why CSCW Applications Fail: Problems in the Design and Evaluationof Organizational Interfaces. In Proceedings of the 1988 ACM Conference on Computer-Supported Cooperative Work (Portland, Oregon, USA) (CSCW \u201988). Association for Computing Machinery, New York, NY, USA, 85\u201393. https://doi.org/10.1145/62266.62273",
      "doi": "10.1145/62266.62273"
    },
    {
      "text": "David Gunning. 2017. Explainable artificial intelligence (xai). Defense Advanced Research Projects Agency (DARPA), nd Web 2 (2017), 2.",
      "doi": ""
    },
    {
      "text": "Carl Gutwin and Saul Greenberg. 2002. A descriptive framework of workspace awareness for real-time groupware. Computer supported cooperative work 11, 3-4 (2002), 411\u2013446.",
      "doi": ""
    },
    {
      "text": "Carl Gutwin, Reagan Penner, and Kevin Schneider. 2004. Group awareness in distributed software development. In Proceedings of the 2004 ACM conference on Computer supported cooperative work. 72\u201381.",
      "doi": "10.1145/1031607.1031621"
    },
    {
      "text": "Karen Hao. 2019. AI is sending people to jail \u2013 and getting it wrong. MIT Technology Review (21 January 2019). Retrieved 26-August-2019 from https://www.technologyreview.com/s/612775/algorithms- criminal-justice-ai/",
      "doi": ""
    },
    {
      "text": "Fritz Heider. 1958. The psychology of interpersonal relations Wiley. New York (1958).",
      "doi": ""
    },
    {
      "text": "Denis\u00a0J Hilton. 1996. Mental models and causal explanation: Judgements of probable cause and explanatory relevance. Thinking & Reasoning 2, 4 (1996), 273\u2013308.",
      "doi": ""
    },
    {
      "text": "Michael Hind, Dennis Wei, Murray Campbell, Noel\u00a0CF Codella, Amit Dhurandhar, Aleksandra Mojsilovi\u0107, Karthikeyan Natesan\u00a0Ramamurthy, and Kush\u00a0R Varshney. 2019. TED: Teaching AI to explain its decisions. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 123\u2013129.",
      "doi": "10.1145/3306618.3314273"
    },
    {
      "text": "Robert\u00a0R Hoffman and Gary Klein. 2017. Explaining explanation, part 1: theoretical foundations. IEEE Intelligent Systems 32, 3 (2017), 68\u201373.",
      "doi": "10.1109/MIS.2017.54"
    },
    {
      "text": "Andrea\u00a0B Hollingshead and David\u00a0P Brandon. 2003. Potential benefits of communication in transactive memory systems. Human communication research 29, 4 (2003), 607\u2013615.",
      "doi": ""
    },
    {
      "text": "Sungsoo\u00a0Ray Hong, Jessica Hullman, and Enrico Bertini. 2020. Human Factors in Model Interpretability: Industry Practices, Challenges, and Needs. Proceedings of the ACM on Human-Computer Interaction 4, CSCW1(2020), 1\u201326.",
      "doi": "10.1145/3392878"
    },
    {
      "text": "Shih-Wen Huang and Wai-Tat Fu. 2013. Don\u2019t hide in the crowd! Increasing social transparency between peer workers improves crowdsourcing outcomes. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 621\u2013630.",
      "doi": "10.1145/2470654.2470743"
    },
    {
      "text": "David Hume. 2000. An enquiry concerning human understanding: A critical edition. Vol.\u00a03. Oxford University Press.",
      "doi": ""
    },
    {
      "text": "Edwin Hutchins. 1991. The social organization of distributed cognition.(1991).",
      "doi": ""
    },
    {
      "text": "Andrew\u00a0JI Jones, Alexander Artikis, and Jeremy Pitt. 2013. The design of intelligent socio-technical systems. Artificial Intelligence Review 39, 1 (2013), 5\u201320.",
      "doi": "10.5555/2440640.2440707"
    },
    {
      "text": "Daniel Kahneman, Stewart\u00a0Paul Slovic, Paul Slovic, and Amos Tversky. 1982. Judgment under uncertainty: Heuristics and biases. Cambridge university press.",
      "doi": ""
    },
    {
      "text": "Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler, Aaron Tam, Corinne Bintz, Daniella Raz, and PM Krafft. 2020. Toward situated interventions for algorithmic equity: lessons from the field. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 45\u201355.",
      "doi": "10.1145/3351095.3372874"
    },
    {
      "text": "Harmanpreet Kaur, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, and Jennifer Wortman\u00a0Vaughan. 2020. Interpreting Interpretability: Understanding Data Scientists\u2019 Use of Interpretability Tools for Machine Learning. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI \u201920). Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi.org/10.1145/3313831.3376219",
      "doi": "10.1145/3313831.3376219"
    },
    {
      "text": "Jennifer\u00a0G Kim, Ha-Kyung Kong, Hwajung Hong, and Karrie Karahalios. 2020. Enriched Social Translucence in Medical Crowdfunding. In Proceedings of the 2020 ACM Designing Interactive Systems Conference. 1465\u20131477.",
      "doi": "10.1145/3357236.3395520"
    },
    {
      "text": "Roderick\u00a0M Kramer. 1999. Trust and distrust in organizations: Emerging perspectives, enduring questions. Annual review of psychology 50, 1 (1999), 569\u2013598.",
      "doi": ""
    },
    {
      "text": "Vivian Lai, Han Liu, and Chenhao Tan. 2020. \u201d Why is\u2019 Chicago\u2019deceptive?\u201d Towards Building Model-Driven Tutorials for Humans. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3313831.3376873"
    },
    {
      "text": "Min\u00a0Kyung Lee, Daniel Kusbit, Anson Kahng, Ji\u00a0Tae Kim, Xinran Yuan, Allissa Chan, Daniel See, Ritesh Noothigattu, Siheon Lee, Alexandros Psomas, and Ariel\u00a0D. Procaccia. 2019. WeBuildAI: Participatory Framework for Algorithmic Governance. Proc. ACM Hum.-Comput. Interact. 3, CSCW, Article 181 (Nov. 2019), 35\u00a0pages. https://doi.org/10.1145/3359283",
      "doi": "10.1145/3359283"
    },
    {
      "text": "Paul\u00a0M Leonardi. 2014. Social media, knowledge sharing, and innovation: Toward a theory of communication visibility. Information systems research 25, 4 (2014), 796\u2013816.",
      "doi": ""
    },
    {
      "text": "Paul\u00a0M Leonardi. 2015. Ambient awareness and knowledge acquisition: using social media to learn \u2018who knows what\u2019and \u2018who knows whom\u2019. Mis Quarterly 39, 4 (2015), 747\u2013762.",
      "doi": "10.25300/MISQ/2015/39.4.1"
    },
    {
      "text": "David\u00a0K Lewis. 1986. Causal explanation. (1986).",
      "doi": ""
    },
    {
      "text": "Q\u00a0Vera Liao, Daniel Gruen, and Sarah Miller. 2020. Questioning the AI: Informing Design Practices for Explainable AI User Experiences. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM.",
      "doi": "10.1145/3313831.3376590"
    },
    {
      "text": "Brian\u00a0Y. Lim and Anind\u00a0K. Dey. 2010. Toolkit to Support Intelligibility in Context-Aware Applications. In Proceedings of the 12th ACM International Conference on Ubiquitous Computing (Copenhagen, Denmark) (UbiComp \u201910). Association for Computing Machinery, New York, NY, USA, 13\u201322. https://doi.org/10.1145/1864349.1864353",
      "doi": ""
    },
    {
      "text": "Brian\u00a0Y Lim, Anind\u00a0K Dey, and Daniel Avrahami. 2009. Why and why not explanations improve the intelligibility of context-aware intelligent systems. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. 2119\u20132128.",
      "doi": "10.1145/1518701.1519023"
    },
    {
      "text": "Brian\u00a0Y Lim, Qian Yang, Ashraf\u00a0M Abdul, and Danding Wang. 2019. Why these Explanations? Selecting Intelligibility Types for Explanation Goals.. In IUI Workshops.",
      "doi": ""
    },
    {
      "text": "Zachary\u00a0C Lipton. 2018. The mythos of model interpretability. Queue 16, 3 (2018), 31\u201357.",
      "doi": "10.1145/3236386.3241340"
    },
    {
      "text": "Tyler\u00a0J. Loftus, Patrick\u00a0J. Tighe, Amanda\u00a0C. Filiberto, Philip\u00a0A. Efron, Scott\u00a0C. Brakenridge, Alicia\u00a0M. Mohr, Parisa Rashidi, Jr Upchurch, Gilbert\u00a0R., and Azra Bihorac. 2020. Artificial Intelligence and Surgical Decision-making. JAMA Surgery 155, 2 (02 2020), 148\u2013158. https://doi.org/10.1001/jamasurg.2019.4917",
      "doi": ""
    },
    {
      "text": "Tania Lombrozo. 2011. The instrumental value of explanations. Philosophy Compass 6, 8 (2011), 539\u2013551.",
      "doi": ""
    },
    {
      "text": "Tania Lombrozo. 2012. Explanation and abductive inference.(2012).",
      "doi": ""
    },
    {
      "text": "Erin\u00a0E Makarius, Debmalya Mukherjee, Joseph\u00a0D Fox, and Alexa\u00a0K Fox. 2020. Rising with the machines: A sociotechnical framework for bringing artificial intelligence into the organization. Journal of Business Research 120 (2020), 262\u2013273.",
      "doi": ""
    },
    {
      "text": "David\u00a0W McDonald, Stephanie Gokhman, and Mark Zachry. 2012. Building for social translucence: a domain analysis and prototype system. In Proceedings of the ACM 2012 conference on computer supported cooperative work. 637\u2013646.",
      "doi": "10.1145/2145204.2145301"
    },
    {
      "text": "Miriam\u00a0J Metzger and Andrew\u00a0J Flanagin. 2013. Credibility and trust of information in online environments: The use of cognitive heuristics. Journal of pragmatics 59(2013), 210\u2013220.",
      "doi": ""
    },
    {
      "text": "Miriam\u00a0J Metzger, Andrew\u00a0J Flanagin, and Ryan\u00a0B Medders. 2010. Social and heuristic approaches to credibility evaluation online. Journal of communication 60, 3 (2010), 413\u2013439.",
      "doi": ""
    },
    {
      "text": "Tim Miller. 2019. Explanation in artificial intelligence: Insights from the social sciences. Artificial Intelligence 267 (2019), 1\u201338.",
      "doi": ""
    },
    {
      "text": "Brent Mittelstadt, Chris Russell, and Sandra Wachter. 2019. Explaining explanations in AI. In Proceedings of the conference on fairness, accountability, and transparency. 279\u2013288.",
      "doi": "10.1145/3287560.3287574"
    },
    {
      "text": "Shakir Mohamed, Marie-Therese Png, and William Isaac. 2020. Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence. Philosophy & Technology(2020), 1\u201326.",
      "doi": ""
    },
    {
      "text": "Sina Mohseni, Niloofar Zarei, and Eric\u00a0D. Ragan. 2018. A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems. ACM Trans. Interact. Intell. Syst.iv(2018). https://doi.org/10.1145/3387166arxiv:1811.11839",
      "doi": ""
    },
    {
      "text": "Richard\u00a0L Moreland and L Thompson. 2006. Transactive memory: Learning who knows what in work groups and organizations. Small groups: Key readings 327 (2006).",
      "doi": ""
    },
    {
      "text": "Michael Muller and Q\u00a0Vera Liao. 2017. Exploring AI Ethics and Values through Participatory Design Fictions. Human Computer Interaction Consortium(2017).",
      "doi": ""
    },
    {
      "text": "John Murawski. 2019. Mortgage Providers Look to AI to Process Home Loans Faster. Wall Street Journal (18 March 2019). Retrieved 16-September-2020 from https://www.wsj.com/articles/mortgage-providers-look-to-ai-to-process-home-loans-faster-11552899212",
      "doi": ""
    },
    {
      "text": "Bonnie\u00a0A Nardi, Steve Whittaker, and Heinrich Schwarz. 2002. NetWORKers and their activity in intensional networks. Computer Supported Cooperative Work (CSCW) 11, 1-2 (2002), 205\u2013242. https://doi.org/10.1023/A:1015241914483",
      "doi": "10.1023/A%3A1015241914483"
    },
    {
      "text": "Duyen\u00a0T Nguyen, Laura\u00a0A Dabbish, and Sara Kiesler. 2015. The perverse effects of social transparency on online advice taking. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing. 207\u2013217.",
      "doi": "10.1145/2675133.2675253"
    },
    {
      "text": "DJ Pangburn. 2019. Schools are using software to help pick who gets in. What could go wrong?Fast Company (17 May 2019). Retrieved 16-September-2020 from https://www.fastcompany.com/90342596/schools-are-quietly-turning-to-ai-to-help-pick-who-gets-in-what-could-go-wrong",
      "doi": ""
    },
    {
      "text": "Forough Poursabzi-Sangdeh, Daniel\u00a0G Goldstein, Jake\u00a0M Hofman, Jennifer\u00a0Wortman Vaughan, and Hanna Wallach. 2018. Manipulating and measuring model interpretability. arXiv preprint arXiv:1802.07810(2018).",
      "doi": ""
    },
    {
      "text": "Emilee Rader, Kelley Cotter, and Janghee Cho. 2018. Explanations as mechanisms for supporting algorithmic transparency. In Proceedings of the 2018 CHI conference on human factors in computing systems. 1\u201313.",
      "doi": "10.1145/3173574.3173677"
    },
    {
      "text": "Gabri\u00eblle Ras, Marcel van Gerven, and Pim Haselager. 2018. Explanation methods in deep learning: Users, values, concerns and challenges. In Explainable and Interpretable Models in Computer Vision and Machine Learning. Springer, 19\u201336.",
      "doi": ""
    },
    {
      "text": "Paul Resnick, Ko Kuwabara, Richard Zeckhauser, and Eric Friedman. 2000. Reputation systems. Commun. ACM 43, 12 (2000), 45\u201348.",
      "doi": "10.1145/355112.355122"
    },
    {
      "text": "Mary\u00a0Beth Rosson and John\u00a0M Carroll. 2009. Scenario based design. Human-computer interaction. boca raton, FL(2009), 145\u2013162.",
      "doi": ""
    },
    {
      "text": "Selma \u0160abanovi\u0107. 2010. Robots in society, society in robots. International Journal of Social Robotics 2, 4 (2010), 439\u2013450.",
      "doi": ""
    },
    {
      "text": "Javier S\u00e1nchez-Monedero, Lina Dencik, and Lilian Edwards. 2020. What does it mean to\u2019solve\u2019the problem of discrimination in hiring? social, technical and legal perspectives from the UK on automated hiring systems. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 458\u2013468.",
      "doi": "10.1145/3351095.3372849"
    },
    {
      "text": "Andrew\u00a0D Selbst, Danah Boyd, Sorelle\u00a0A Friedler, Suresh Venkatasubramanian, and Janet Vertesi. 2019. Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency. 59\u201368.",
      "doi": "10.1145/3287560.3287598"
    },
    {
      "text": "Phoebe Sengers, Kirsten Boehner, Shay David, and Joseph\u2019Jofish\u2019 Kaye. 2005. Reflective design. In Proceedings of the 4th decennial conference on Critical computing: between sense and sensibility. 49\u201358.",
      "doi": "10.1145/1094562.1094569"
    },
    {
      "text": "Ben Shneiderman. 2020. Human-centered artificial intelligence: Reliable, safe & trustworthy. International Journal of Human\u2013Computer Interaction 36, 6(2020), 495\u2013504.",
      "doi": ""
    },
    {
      "text": "Alison Smith-Renner, Ron Fan, Melissa Birchfield, Tongshuang Wu, Jordan Boyd-Graber, Daniel\u00a0S Weld, and Leah Findlater. 2020. No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1\u201313.",
      "doi": "10.1145/3313831.3376624"
    },
    {
      "text": "Thilo Spinner, Udo Schlegel, Hanna Sch\u00e4fer, and Mennatallah El-Assady. 2019. explAIner: A visual analytics framework for interactive and explainable machine learning. IEEE transactions on visualization and computer graphics 26, 1(2019), 1064\u20131074. https://doi.org/10.1109/TVCG.2019.2934629",
      "doi": ""
    },
    {
      "text": "Susan\u00a0Leigh Star and Anselm Strauss. 1999. Layers of silence, arenas of voice: The ecology of visible and invisible work. Computer supported cooperative work (CSCW) 8, 1-2 (1999), 9\u201330.",
      "doi": ""
    },
    {
      "text": "Anselm Strauss and Juliet Corbin. 1994. Grounded theory methodology. Handbook of qualitative research 17, 1 (1994), 273\u2013285.",
      "doi": ""
    },
    {
      "text": "H\u00a0Colleen Stuart, Laura Dabbish, Sara Kiesler, Peter Kinnaird, and Ruogu Kang. 2012. Social transparency in networked information exchange: a theoretical framework. In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work. 451\u2013460.",
      "doi": "10.1145/2145204.2145275"
    },
    {
      "text": "Simone Stumpf, Adrian Bussone, and Dympna O\u2019sullivan. 2016. Explanations considered harmful? user interactions with machine learning systems. In ACM SIGCHI Workshop on Human-Centered Machine Learning.",
      "doi": ""
    },
    {
      "text": "Lucy Suchman. 1995. Making work visible. Commun. ACM 38, 9 (1995), 56\u201364.",
      "doi": "10.1145/223248.223263"
    },
    {
      "text": "Lucy\u00a0A Suchman. 1987. Plans and situated actions: The problem of human-machine communication. Cambridge university press.",
      "doi": "10.5555/38407"
    },
    {
      "text": "S\u00a0Shyam Sundar. 2008. The MAIN model: A heuristic approach to understanding technology effects on credibility. MacArthur Foundation Digital Media and Learning Initiative.",
      "doi": ""
    },
    {
      "text": "Harini Suresh and John\u00a0V Guttag. 2019. A framework for understanding unintended consequences of machine learning. arXiv preprint arXiv:1901.10002(2019).",
      "doi": ""
    },
    {
      "text": "Jennifer\u00a0Wortman Vaughan and Hanna Wallach. 2020. A human-centered agenda for intelligible machine learning. Machines We Trust: Getting Along with Artificial Intelligence (2020).",
      "doi": ""
    },
    {
      "text": "Danding Wang, Qian Yang, Ashraf Abdul, and Brian\u00a0Y Lim. 2019. Designing theory-driven user-centric explainable AI. In Proceedings of the 2019 CHI conference on human factors in computing systems. 1\u201315.",
      "doi": "10.1145/3290605.3300831"
    },
    {
      "text": "Daniel\u00a0M Wegner, Ralph Erber, and Paula Raymond. 1991. Transactive memory in close relationships.Journal of personality and social psychology 61, 6(1991), 923.",
      "doi": ""
    },
    {
      "text": "Karl\u00a0E Weick and Karlene\u00a0H Roberts. 1993. Collective mind in organizations: Heedful interrelating on flight decks. Administrative science quarterly(1993), 357\u2013381.",
      "doi": ""
    },
    {
      "text": "Daniel\u00a0S. Weld and Gagan Bansal. 2019. The Challenge of Crafting Intelligible Intelligence. Commun. ACM 62, 6 (May 2019), 70\u201379. https://doi.org/10.1145/3282486",
      "doi": "10.1145/3282486"
    },
    {
      "text": "Daniel\u00a0A Wilkenfeld and Tania Lombrozo. 2015. Inference to the best explanation (IBE) versus explaining for the best inference (EBI). Science & Education 24, 9-10 (2015), 1059\u20131077.",
      "doi": ""
    },
    {
      "text": "Christine Wolf and Jeanette Blomberg. 2019. Evaluating the promise of human-algorithm collaborations in everyday work practices. Proceedings of the ACM on Human-Computer Interaction 3, CSCW(2019), 1\u201323.",
      "doi": "10.1145/3359245"
    },
    {
      "text": "Fumeng Yang, Zhuanyi Huang, Jean Scholtz, and Dustin\u00a0L Arendt. 2020. How do visual explanations foster end users\u2019 appropriate trust in machine learning?. In Proceedings of the 25th International Conference on Intelligent User Interfaces. 189\u2013201.",
      "doi": "10.1145/3377325.3377480"
    },
    {
      "text": "Qian Yang, Aaron Steinfeld, and John Zimmerman. 2019. Unremarkable ai: Fitting intelligent decision support into critical, clinical decision-making processes. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1\u201311.",
      "doi": "10.1145/3290605.3300468"
    },
    {
      "text": "Qian Yang, John Zimmerman, Aaron Steinfeld, Lisa Carey, and James\u00a0F Antaki. 2016. Investigating the heart pump implant decision process: opportunities for decision support tools to help. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. 4477\u20134488.",
      "doi": "10.1145/2858036.2858373"
    },
    {
      "text": "Youngjin Yoo and Prasert Kanawattanachai. 2001. Developments of transactive memory systems and collective mind in virtual teams. International Journal of Organizational Analysis 9, 2 (2001), 187\u2013208.",
      "doi": ""
    },
    {
      "text": "Yunfeng Zhang, Q.\u00a0Vera Liao, and Rachel K.\u00a0E. Bellamy. 2020. Effect of Confidence and Explanation on Accuracy and Trust Calibration in AI-Assisted Decision Making. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (Barcelona, Spain) (FAT* \u201920). Association for Computing Machinery, New York, NY, USA, 295\u2013305. https://doi.org/10.1145/3351095.3372852",
      "doi": "10.1145/3351095.3372852"
    },
    {
      "text": "Haiyi Zhu, Bowen Yu, Aaron Halfaker, and Loren Terveen. 2018. Value-sensitive algorithm design: Method, case study, and lessons. Proceedings of the ACM on Human-Computer Interaction 2, CSCW(2018), 1\u201323.",
      "doi": "10.1145/3274463"
    }
  ]
}