{
  "doi": "10.1145/2702123.2702387",
  "title": "VocalSketch: Vocally Imitating Audio Concepts",
  "published": "2015-04-18",
  "proctitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
  "pages": "43-46",
  "year": 2015,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "A natural way of communicating an audio concept is to imitate it with one's voice. This creates an approximation of the imagined sound (e.g. a particular owl's hoot), much like how a visual sketch approximates a visual concept (e.g a drawing of the owl). If a machine could understand vocal imitations, users could communicate with software in this natural way, enabling new interactions (e.g. programming a music synthesizer by imitating the desired sound with one's voice). In this work, we collect thousands of crowd-sourced vocal imitations of a large set of diverse sounds, along with data on the crowd's ability to correctly label these vocal imitations. The resulting data set will help the research community understand which audio concepts can be effectively communicated with this approach. We have released the data set so the community can study the related issues and build systems that leverage vocal imitation as an interaction modality.",
  "authors": [
    {
      "name": "Mark Cartwright",
      "institution": "Northwestern University, Evanston, IL, USA",
      "img": "/do/10.1145/contrib-81549144856/rel-imgonly/headshot_square.jpg",
      "acmid": "81549144856",
      "orcid": "missing"
    },
    {
      "name": "Bryan Pardo",
      "institution": "Northwestern University, Evanston, IL, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81452611845",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "1. Blancas, D. S., and Janer, J. Sound retrieval from voice imitation queries in collaborative databases. In Proc. of Audio Engineering Society 53rd Int'l Conf. (2014).",
      "doi": ""
    },
    {
      "text": "2. Cartwright, M., and Pardo, B. Synthassist: Querying an audio synthesizer by vocal imitation. In Conference on New Interfaces for Musical Expression (2014).",
      "doi": ""
    },
    {
      "text": "3. Eitz, M., Hays, J., and Alexa, M. How do humans sketch objects? ACM Trans. Graph. 31, 4 (2012), 44.  ",
      "doi": "10.1145/2185520.2185540"
    },
    {
      "text": "4. Ekman, I., and Rinott, M. Using vocal sketching for designing sonic interactions. In Proc. of the 8th ACM Conf. on Designing Interactive Systems (2010).  ",
      "doi": "10.1145/1858171.1858195"
    },
    {
      "text": "5. Fritts, L. University of iowa musical instrument samples, 2012. http://theremin.music.uiowa.edu/MIS.html.",
      "doi": ""
    },
    {
      "text": "6. Ghias, A., Logan, J., Chamberlin, D., and Smith, B. C. Query by humming: musical information retrieval in an audio database. In Proc. of the Third ACM Int'l Conference on Multimedia (1995).  ",
      "doi": "10.1145/217279.215273"
    },
    {
      "text": "7. Gillet, O., and Richard, G. Drum loops retrieval from spoken queries. Journal of Intelligent Information Systems 24, 2--3 (2005), 159--177.  ",
      "doi": "10.1007/s10844-005-0321-9"
    },
    {
      "text": "8. Janer Mestres, J. Singing-driven interfaces for sound synthesizers. PhD thesis, Universitat Pompeu Fabra, 2008.",
      "doi": ""
    },
    {
      "text": "9. Lemaitre, G., Dessein, A., Susini, P., and Aura, K. Vocal imitations and the identification of sound events. Ecological Psychology 23, 4 (2011), 267--307.",
      "doi": ""
    },
    {
      "text": "10. Lemaitre, G., and Rocchesso, D. On the effectiveness of vocal imitations and verbal descriptions of sounds. The Journal of the Acoustical Society of America 135, 2 (2014), 862--873.",
      "doi": ""
    },
    {
      "text": "11. Marcell, M. M., Borella, D., Greene, M., Kerr, E., and Rogers, S. Confrontation naming of environmental sounds. Journal of Clinical and Experimental Neuropsychology 22, 6 (2000), 830--864.",
      "doi": ""
    },
    {
      "text": "12. Smaragdis, P., and Mysore, G. J. Separation by \"humming\": User-guided sound extraction from monophonic mixtures. In Proc. of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (2009).",
      "doi": ""
    },
    {
      "text": "13. Stowell, D. Making music through real-time voice timbre analysis: machine learning and timbral control. PhD thesis, Queen Mary University of London, 2010.",
      "doi": ""
    },
    {
      "text": "14. Sundaram, S., and Narayanan, S. Vector-based representation and clustering of audio using onomatopoeia words. In Proc. of AAAI (2006).",
      "doi": ""
    }
  ]
}