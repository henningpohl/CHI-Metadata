{
  "doi": "10.1145/2702123.2702464",
  "title": "Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices",
  "published": "2015-04-18",
  "proctitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
  "pages": "3001-3009",
  "year": 2015,
  "badges": [],
  "abstract": "This paper presents Cyclops, a single-piece wearable device that sees its user's whole body postures through an ego-centric view of the user that is obtained through a fisheye lens at the center of the user's body, allowing it to see only the user's limbs and interpret body postures effectively. Unlike currently available body gesture input systems that depend on external cameras or distributed motion sensors across the user's body, Cyclops is a single-piece wearable device that is worn as a pendant or a badge. The main idea proposed in this paper is the observation of limbs from a central location of the body. Owing to the ego-centric view, Cyclops turns posture recognition into a highly controllable computer vision problem. This paper demonstrates a proof-of-concept device, and an algorithm for recognizing static and moving bodily gestures based on motion history images (MHI) and a random decision forest (RDF). Four example applications of interactive bodily workout, a mobile racing game that involves hands and feet, a full-body virtual reality system, and interaction with a tangible toy are presented. The experiment on the bodily workout demonstrates that, from a database of 20 body workout gestures that were collected from 20 participants, Cyclops achieved a recognition rate of 79% using MHI and simple template matching, which increased to 92% with the more advanced machine learning approach of RDF.",
  "authors": [
    {
      "name": "Liwei Chan",
      "institution": "National Taiwan University, Taipei, Taiwan Roc",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99659142992",
      "orcid": "missing"
    },
    {
      "name": "Chi-Hao Hsieh",
      "institution": "Computer Science, Taipei, Taiwan Roc",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658698628",
      "orcid": "missing"
    },
    {
      "name": "Yi-Ling Chen",
      "institution": "National Taiwan University, Taipei, Taiwan Roc",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658701655",
      "orcid": "missing"
    },
    {
      "name": "Shuo Yang",
      "institution": "Computer Science, Taipei, Taiwan Roc",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "99658701283",
      "orcid": "missing"
    },
    {
      "name": "Da-Yuan Huang",
      "institution": "National Taiwan University, Taipei, Taiwan Roc",
      "img": "/do/10.1145/contrib-81551198756/rel-imgonly/81551198756.jpg",
      "acmid": "81551198756",
      "orcid": "missing"
    },
    {
      "name": "Rong-Hao Liang",
      "institution": "National Taiwan University, Taipei, Taiwan Roc",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81321494894",
      "orcid": "0000-0003-3239-8749"
    },
    {
      "name": "Bing-Yu Chen",
      "institution": "National Taiwan University, Taipei, Taiwan Roc",
      "img": "/do/10.1145/contrib-81100108039/rel-imgonly/rchen.jpg",
      "acmid": "81100108039",
      "orcid": "0000-0003-0169-7682"
    }
  ],
  "references": [
    {
      "text": "Ahad, M. A. R., Tan, J. K., Kim, H., and Ishikawa, S. Motion history image: Its variants and applications. Mach. Vision Appl. 23, 2 (Mar. 2012), 255--281.  ",
      "doi": "10.1007/s00138-010-0298-4"
    },
    {
      "text": "Bailly, G., M\u00fcller, J., Rohs, M., Wigdor, D., and Kratz, S. Shoesense: A new perspective on gestural interaction and wearable applications. In Proc. ACM CHI '12 (2012), 1239--1248.  ",
      "doi": "10.1145/2207676.2208576"
    },
    {
      "text": "Bobick, A. F., and Davis, J. W. The recognition of human movement using temporal templates. IEEE Trans. Pattern Anal. Mach. Intell. 23, 3 (Mar. 2001), 257--267.  ",
      "doi": "10.1109/34.910878"
    },
    {
      "text": "Chan, L., Liang, R.-H., Tsai, M.-C., Cheng, K.-Y., Su, C.-H., Chen, M. Y., Cheng, W.-H., and Chen, B.-Y. Fingerpad: Private and subtle interaction using fingertips. In Proc. ACM UIST '13 (2013), 255--260.  ",
      "doi": "10.1145/2501988.2502016"
    },
    {
      "text": "Chen, K.-Y., Lyons, K., White, S., and Patel, S. utrack: 3d input using two magnetic sensors. In Proc. ACM UIST '13 (2013), 237--244.  ",
      "doi": "10.1145/2501988.2502035"
    },
    {
      "text": "Cohn, G., Morris, D., Patel, S., and Tan, D. Humantenna: Using the body as an antenna for real-time whole-body interaction. In Proc. ACM CHI '12 (2012), 1901--1910.  ",
      "doi": "10.1145/2207676.2208330"
    },
    {
      "text": "Cola\u00e7o, A., Kirmani, A., Yang, H. S., Gong, N.-W., Schmandt, C., and Goyal, V. K. Mime: Compact, low power 3d gesture sensing for interaction with head mounted displays. In Proc. ACM UIST '13 (2013), 227--236.  ",
      "doi": "10.1145/2501988.2502042"
    },
    {
      "text": "Criminisi, A., and Shotton, J. Decision Forests for Computer Vision and Medical Image Analysis. Springer, 2013. ",
      "doi": ""
    },
    {
      "text": "Dernbach, S., Das, B., Krishnan, N. C., Thomas, B., and Cook, D. Simple and complex activity recognition through smart phones. In IEEE IE '02 (June 2012), 214--221.  ",
      "doi": "10.1109/IE.2012.39"
    },
    {
      "text": "Fanello, S. R., Keskin, C., Izadi, S., Kohli, P., Kim, D., Sweeney, D., Criminisi, A., Shotton, J., Kang, S. B., and Paek, T. Learning to be a depth camera for close-range human capture and interaction. ACM Trans. Graph. 33, 4 (July 2014), 86:1--86:11.  ",
      "doi": "10.1145/2601097.2601223"
    },
    {
      "text": "Gustafson, S., Bierwirth, D., and Baudisch, P. Imaginary interfaces: Spatial interaction with empty hands and without visual feedback. In Proc. ACM UIST '10 (2010), 3--12.  ",
      "doi": "10.1145/1866029.1866033"
    },
    {
      "text": "Harrison, C., Benko, H., and Wilson, A. D. Omnitouch: Wearable multitouch interaction everywhere. In Proc. ACM UIST '11 (2011), 441--450.  ",
      "doi": "10.1145/2047196.2047255"
    },
    {
      "text": "Harrison, C., Tan, D., and Morris, D. Skinput: Appropriating the body as an input surface. In Proc. ACM CHI '10 (2010), 453--462.  ",
      "doi": "10.1145/1753326.1753394"
    },
    {
      "text": "Junker, H., Amft, O., Lukowicz, P., and Tr\u00f6ster, G. Gesture spotting with body-worn inertial sensors to detect user activities. Pattern Recogn. 41, 6 (June 2008), 2010--2024.  ",
      "doi": "10.1016/j.patcog.2007.11.016"
    },
    {
      "text": "Keally, M., Zhou, G., Xing, G., Wu, J., and Pyles, A. Pbn: Towards practical activity recognition using smartphone-based body sensor networks. In Proc. ACM SenSys '11 (2011), 246--259.  ",
      "doi": "10.1145/2070942.2070968"
    },
    {
      "text": "Kim, D., Hilliges, O., Izadi, S., Butler, A. D., Chen, J., Oikonomidis, I., and Olivier, P. Digits: Freehand 3d interactions anywhere using a wrist-worn gloveless sensor. In Proc. ACM UIST '12 (2012), 167--176.  ",
      "doi": "10.1145/2380116.2380139"
    },
    {
      "text": "Kwapisz, J. R., Weiss, G. M., and Moore, S. A. Activity recognition using cell phone accelerometers. SIGKDD Explor. Newsl. 12, 2 (Mar. 2011), 74--82.  ",
      "doi": "10.1145/1964897.1964918"
    },
    {
      "text": "Lee, J., and Ha, I. Real-time motion capture for a human body using accelerometers. Robotica 19, 6 (Sept. 2001), 601--610.  ",
      "doi": "10.1017/S0263574701003319"
    },
    {
      "text": "Lin, S.-Y., Su, C.-H., Cheng, K.-Y., Liang, R.-H., Kuo, T.-H., and Chen, B.-Y. Pub - point upon body: Exploring eyes-free interaction and methods on an arm. In Proc. ACM UIST '11 (2011), 481--488.  ",
      "doi": "10.1145/2047196.2047259"
    },
    {
      "text": "Mayol-Cuevas, W. W., Tordoff, B. J., and Murray, D. W. On the choice and placement of wearable vision sensors. Trans. Sys. Man Cyber. Part A 39, 2 (Mar. 2009), 414--425.  ",
      "doi": "10.1109/TSMCA.2008.2010848"
    },
    {
      "text": "Mistry, P., and Maes, P. Sixthsense: A wearable gestural interface. In Proc. ACM SIGGRAPH ASIA '09 Sketches (2009), 11:1--11:1.  ",
      "doi": "10.1145/1667146.1667160"
    },
    {
      "text": "Mistry, P., Maes, P., and Chang, L. Wuw - wear ur world: A wearable gestural interface. In Proc. ACM CHI EA '09 (2009), 4111--4116.  ",
      "doi": "10.1145/1520340.1520626"
    },
    {
      "text": "Morris, D., Saponas, T. S., Guillory, A., and Kelner, I. Recofit: Using a wearable sensor to find, recognize, and count repetitive exercises. In Proc. ACM CHI '14 (2014), 3225--3234.  ",
      "doi": "10.1145/2556288.2557116"
    },
    {
      "text": "Mujibiya, A., Cao, X., Tan, D. S., Morris, D., Patel, S. N., and Rekimoto, J. The sound of touch: On-body touch and gesture sensing based on transdermal ultrasound propagation. In Proc. ACM ITS '13 (2013), 189--198.  ",
      "doi": "10.1145/2512349.2512821"
    },
    {
      "text": "Ogata, M., Sugiura, Y., Makino, Y., Inami, M., and Imai, M. Senskin: Adapting skin as a soft interface. In Proc. ACM UIST '13 (2013), 539--544.  ",
      "doi": "10.1145/2501988.2502039"
    },
    {
      "text": "Rekimoto, J. Gesturewrist and gesturepad: Unobtrusive wearable interaction devices. In Proc. IEEE ISWC '01 (2001), 21--. ",
      "doi": "10.5555/580581.856565"
    },
    {
      "text": "Saponas, T. S., Tan, D. S., Morris, D., Balakrishnan, R., Turner, J., and Landay, J. A. Enabling always-available input with muscle-computer interfaces. In Proc. ACM UIST '09 (2009), 167--176.  ",
      "doi": "10.1145/1622176.1622208"
    },
    {
      "text": "Sato, M., Poupyrev, I., and Harrison, C. Touche: Enhancing touch interaction on humans, screens, liquids, and everyday objects. In Proc. ACM CHI '12 (2012), 483--492.  ",
      "doi": "10.1145/2207676.2207743"
    },
    {
      "text": "Scott, J., Dearman, D., Yatani, K., and Truong, K. N. Sensing foot gestures from the pocket. In Proc. ACM UIST '10 (2010), 199--208.  ",
      "doi": "10.1145/1866029.1866063"
    },
    {
      "text": "Shiratori, T., Park, H. S., Sigal, L., Sheikh, Y., and Hodgins, J. K. Motion capture from body-mounted cameras. In Proc. ACM SIGGRAPH '11 (2011), 31:1--31:10.  ",
      "doi": "10.1145/1964921.1964926"
    },
    {
      "text": "Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M., Moore, R., Kipman, A., and Blake, A. Real-time human pose recognition in parts from single depth images. In Proc. IEEE CVPR '11 (2011), 1297--1304.  ",
      "doi": "10.1109/CVPR.2011.5995316"
    },
    {
      "text": "Song, J., S\u00f6r\u00f6s, G., Pece, F., Fanello, S. R., Izadi, S., Keskin, C., and Hilliges, O. In-air gestures around unmodified mobile devices. In Proc. ACM UIST '14 (2014), 319--329.  ",
      "doi": "10.1145/2642918.2647373"
    },
    {
      "text": "Sturman, D. J., and Zeltzer, D. A survey of glove-based input. IEEE Comput. Graph. Appl. 14, 1 (Jan. 1994), 30--39.  ",
      "doi": "10.1109/38.250916"
    },
    {
      "text": "Tamaki, E., Miyaki, T., and Rekimoto, J. Brainy hand: An ear-worn hand gesture interaction device. In Proc. ACM CHI EA '09 (2009), 4255--4260.  ",
      "doi": "10.1145/1520340.1520649"
    },
    {
      "text": "Taylor, S., Keskin, C., Hilliges, O., Izadi, S., and Helmes, J. Type-hover-swipe in 96 bytes: A motion sensing mechanical keyboard. In Proc. ACM CHI '14 (2014), 1695--1704.  ",
      "doi": "10.1145/2556288.2557030"
    },
    {
      "text": "Vardy, A., Robinson, J., and Cheng, L.-T. The wristcam as input device. In Proc. IEEE ISWC '99 (1999), 199--202. ",
      "doi": "10.5555/519309.856464"
    }
  ]
}