{
  "doi": "10.1145/2702123.2702159",
  "title": "AudioScope: Smartphones as Directional Microphones in Mobile Audio Augmented Reality Systems",
  "published": "2015-04-18",
  "proctitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
  "pages": "949-952",
  "year": 2015,
  "badges": [],
  "abstract": "Mobile audio augmented reality systems (MAARS) provide a new and engaging modality to present information or to create playful experiences. Using special filters, spatial audio rendering creates the impression that the sound of a virtual source emanates from a certain position in the physical space. So far, most of the implementations of such systems rely on head tracking to create a realistic effect, which requires additional hardware. Recent results indicate that the built-in sensors of a smartphone can be used as source for orientation measurement, reducing deployment to a simple app download. AudioScope presents an alternative interaction technique to create such an experience, using the metaphor of pointing a directional microphone at the environment. In an experiment with 20 users, we compared the time to locate a proximate audio source and the perceived presence in the virtual environment. Results show that there is no significant difference between head-orientation measurement and AudioScope regarding accuracy and perceived presence. This means that MAARS, such as audio guides for museums, do not require special hardware but can run on the visitor's smartphones with standard headphones.",
  "authors": [
    {
      "name": "Florian Heller",
      "institution": "RWTH Aachen University, Aachen, Germany",
      "img": "/do/10.1145/contrib-81416598157/rel-imgonly/heller.jpg",
      "acmid": "81416598157",
      "orcid": "missing"
    },
    {
      "name": "Jan Borchers",
      "institution": "RWTH Aachen University, Aachen, Germany",
      "img": "/do/10.1145/contrib-81100443423/rel-imgonly/borchers_7154.jpg",
      "acmid": "81100443423",
      "orcid": "0000-0003-1509-3257"
    }
  ],
  "references": [
    {
      "text": "Begault, D. R., Wenzel, E. M., and Anderson, M. R. Direct Comparison of the Impact of Head Tracking, Reverberation, and Individualized Head-Related Transfer Functions on the Spatial Perception of a Virtual Speech Source. J. Audio Eng. Soc (2001).",
      "doi": ""
    },
    {
      "text": "Begault, D. R., Wenzel, E. M., Godfroy, M., Miller, J. D., and Anderson, M. R. Applying Spatial Audio to Human Interfaces: 25 Years of NASA Experience. In AES Conference 40 (2010).",
      "doi": ""
    },
    {
      "text": "Billinghurst, M., deo, S., Adams, N., and Lehikoinen, J. Motion-Tracking in Spatial Mobile Audio-Conferencing. In MobileHCI '07 (2007).",
      "doi": ""
    },
    {
      "text": "Brungart, D. S., Simpson, B. D., and Kordik, A. J. The detectability of headtracker latency in virtual audio displays. In ICAD '05.",
      "doi": ""
    },
    {
      "text": "Dicke, C., deo, S., Billinghurst, M., Adams, N., and Lehikoinen, J. Experiments in Mobile Spatial Audio-conferencing: Key-based and Gesture-based Interaction. In MobileHCI '08.  ",
      "doi": "10.1145/1409240.1409251"
    },
    {
      "text": "Heller, F., Kr\u00e4mer, A., and Borchers, J. Simplifying Orientation Measurement for Mobile Audio Augmented Reality Applications. In CHI '14.  ",
      "doi": "10.1145/2556288.2557021"
    },
    {
      "text": "Kajastila, R., and Lokki, T. Eyes-free methods for accessing large auditory menus. In ICAD '10.",
      "doi": ""
    },
    {
      "text": "Loomis, J. M., Hebert, C., and Cicinelli, J. G. Active localization of virtual sounds. The Journal of the Acoustical Society of America (1990).",
      "doi": ""
    },
    {
      "text": "Marentakis, G. N., and Brewster, S. A. Effects of feedback, mobility and index of difficulty on deictic spatial audio target acquisition in the horizontal plane. In CHI '06.  ",
      "doi": "10.1145/1124772.1124826"
    },
    {
      "text": "Mariette, N. Navigation Performance Effects of Render Method and Head-Turn Latency in Mobile Audio Augmented Reality. In Auditory Display. Springer, 2010.  ",
      "doi": "10.1007/978-3-642-12439-6_13"
    },
    {
      "text": "Middlebrooks, J. C. Virtual localization improved by scaling nonindividualized external-ear transfer functions in frequency. The Journal of the Acoustical Society of America (1999).",
      "doi": ""
    },
    {
      "text": "Sander, C., Wefers, F., and Leckschat, D. Scalable Binaural Synthesis on Mobile Devices. In AES Convention 133 (2012).",
      "doi": ""
    },
    {
      "text": "Stahl, C. The roaring navigator: a group guide for the zoo with shared auditory landmark display. In MobileHCI '07.  ",
      "doi": "10.1145/1377999.1378042"
    },
    {
      "text": "Tang, T. J. J., and Li, W. H. An Assistive EyeWear Prototype That Interactively Converts 3D Object Locations into Spatial Audio. In ISWC '14.  ",
      "doi": "10.1145/2634317.2634318"
    },
    {
      "text": "Terrenghi, L., and Zimmermann, A. Tailored audio augmented environments for museums. In IUI '04.  ",
      "doi": "10.1145/964442.964523"
    },
    {
      "text": "Vazquez-Alvarez, Y., Oakley, I., and Brewster, S. Auditory display design for exploration in mobile audio-augmented reality. Pers. and Ubiqu. comp. (2012).  ",
      "doi": "10.1007/s00779-011-0459-0"
    },
    {
      "text": "Wenzel, E. M., Arruda, M., Kistler, D. J., and Wightman, F. L. Localization using nonindividualized head-related transfer functions. The Journal of the Acoustical Society of America (1993).",
      "doi": ""
    },
    {
      "text": "Witmer, B. G., and Singer, M. J. Measuring Presence in Virtual Environments: A Presence Questionnaire. Presence: Teleoper. Virtual Environ. (1998).  ",
      "doi": "10.1162/105474698565686"
    }
  ]
}