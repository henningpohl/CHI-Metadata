{
  "doi": "10.1145/2702123.2702553",
  "title": "Comparing Person- and Process-centric Strategies for Obtaining Quality Data on Amazon Mechanical Turk",
  "published": "2015-04-18",
  "proctitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
  "pages": "1345-1354",
  "year": 2015,
  "badges": [
    "Honorable Mention"
  ],
  "abstract": "In the past half-decade, Amazon Mechanical Turk has radically changed the way many scholars do research. The availability of a massive, distributed, anonymous crowd of individuals willing to perform general human-intelligence micro-tasks for micro-payments is a valuable resource for researchers and practitioners. This paper addresses the challenges of obtaining quality annotations for subjective judgment oriented tasks of varying difficulty. We design and conduct a large, controlled experiment (N=68,000) to measure the efficacy of selected strategies for obtaining high quality data annotations from non-experts. Our results point to the advantages of person-oriented strategies over process-oriented strategies. Specifically, we find that screening workers for requisite cognitive aptitudes and providing training in qualitative coding techniques is quite effective, significantly outperforming control and baseline conditions. Interestingly, such strategies can improve coder annotation accuracy above and beyond common benchmark strategies such as Bayesian Truth Serum (BTS).",
  "authors": [
    {
      "name": "Tanushree Mitra",
      "institution": "Georgia Institute of Technology, Atlanta, GA, USA",
      "img": "/do/10.1145/contrib-81553902156/rel-imgonly/tanu_sm.jpg",
      "acmid": "81553902156",
      "orcid": "0000-0002-9507-6192"
    },
    {
      "name": "Clayton J. Hutto",
      "institution": "Georgia Institute of Technology, Atlanta, GA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81557261156",
      "orcid": "missing"
    },
    {
      "name": "Eric Gilbert",
      "institution": "Georgia Institute of Technology, Atlanta, GA, USA",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81336489255",
      "orcid": "missing"
    }
  ],
  "references": [
    {
      "text": "Andre, P., Kittur, A., and Dow, S.P. Crowd synthesis: extracting categories and clusters from complex data. CSCW 2014, 989--998.  ",
      "doi": "10.1145/2531602.2531653"
    },
    {
      "text": "Berinsky, A.J., Huber, G.A., and Lenz, G.S. Evaluating Online Labor Markets for Experimental Research: Amazon.com's Mechanical Turk. Political Analysis 20, 3 2012, 351--368.",
      "doi": ""
    },
    {
      "text": "Blei, D., Ng, A., and Jordan, M. Latent dirichlet allocation. J. of Machine Learning Res.3, 2003, 993--1022. ",
      "doi": "10.5555/944919.944937"
    },
    {
      "text": "Castillo, C., Mendoza, M., and Poblete, B. Information credibility on twitter. CHI 2011, 675--684.  ",
      "doi": "10.1145/1963405.1963500"
    },
    {
      "text": "Chang, J., Boyd-Graber, J., Gerrish, S., Wang, C., and Blei, D. Reading Tea Leaves: How Humans Interpret Topic Models. NIPS 2009, 288--296. https://www.mturk.com/mturk/help?helpPage=worker",
      "doi": ""
    },
    {
      "text": "Crump, M.J.C., McDonnell, J.V., and Gureckis, T.M. Evaluating Amazon's Mechanical Turk as a Tool for Experimental Beh. Res. PLoS ONE 8, 3 2013.",
      "doi": ""
    },
    {
      "text": "Dalal, N. and Triggs, B. Histograms of oriented gradients for human detection. CVPR 2005, 886--893.  ",
      "doi": "10.1109/CVPR.2005.177"
    },
    {
      "text": "Downs, J.S., Holbrook, M.B., Sheng, S., and Cranor, L.F. Are your participants gaming the system?: screening mechanical turk workers. CHI 2010, 2399--2402.  ",
      "doi": "10.1145/1753326.1753688"
    },
    {
      "text": "Gilbert, E. What if we ask a different question?: social inferences create product ratings faster. CHI 2014.  ",
      "doi": "10.1145/2556288.2557081"
    },
    {
      "text": "Hart, S.G. and Staveland, L.E. Development of NASATLX (Task Load Index): Results of empirical and theoretical research. Adv. in psych. 52, 1988, 139--183.",
      "doi": ""
    },
    {
      "text": "Heer, J. and Bostock, M. Crowdsourcing graphical perception: using mechanical turk to assess visualization design. CHI 2010, 203--212.  ",
      "doi": "10.1145/1753326.1753357"
    },
    {
      "text": "Huang, S.-W. and Fu, W.-T. Don't hide in the crowd!: increasing social transparency between peer workers improves crowdsourcing outcomes. CHI 2013.  ",
      "doi": "10.1145/2470654.2470743"
    },
    {
      "text": "Hutto, C.J. and Gilbert, E. VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. ICWSM 2014, 216--255.",
      "doi": ""
    },
    {
      "text": "Ipeirotis, P.G. Analyzing the amazon mechanical turk marketplace. XRDS: Crossroads17, 2 2010, 16--21.  ",
      "doi": "10.1145/1869086.1869094"
    },
    {
      "text": "Ipeirotis, P.G., Provost, F., and Wang, J. Quality management on Amazon Mechanical Turk. HCOMP 2010.  ",
      "doi": "10.1145/1837885.1837906"
    },
    {
      "text": "Kazai, G., Kamps, J., and Milic-Frayling, N. Worker types and personality traits in crowdsourcing relevance labels. CIKM 2011, 1941--1944.  ",
      "doi": "10.1145/2063576.2063860"
    },
    {
      "text": "Kittur, A., Chi, E.H., and Suh, B. Crowdsourcing user studies with Mechanical Turk. CHI 2008, 453--456.  ",
      "doi": "10.1145/1357054.1357127"
    },
    {
      "text": "Kriplean, T., Bonnar, C., Borning, A., Kinney, B., and Gill, B. Integrating on-demand fact-checking with public dialogue. CSCW 2014, 1188--1199.  ",
      "doi": "10.1145/2531602.2531677"
    },
    {
      "text": "Lasecki, W.S., Gordon, M., Koutra, D., Jung, M.F., Dow, S.P., and Bigham, J.P. Glance: rapidly coding behavioral video with the crowd. UIST 2014, 551--562.  ",
      "doi": "10.1145/2642918.2647367"
    },
    {
      "text": "Lau, J.H., Collier, N., and Baldwin, T. On-line Trend Analysis with Topic Models: #twitter Trends Detection Topic Model Online. COLING 2012, 1519--1534.",
      "doi": ""
    },
    {
      "text": "Little, G., Chilton, L.B., Goldman, M., and Miller, R.C. Exploring iterative and parallel human computation processes. CHI 2010, 68--76.  ",
      "doi": "10.1145/1837885.1837907"
    },
    {
      "text": "MacDonald, P.L. and Gardner, R.C. Type I error rate comparisons of post hoc procedures for I j Chi-Square tables. Ed. and Psych. Meas. 60, 5 2000, 735--754.",
      "doi": ""
    },
    {
      "text": "Mason, W. and Suri, S. Conducting behavioral research on Amazon's Mechanical Turk. Behavior research methods 44, 1 2012, 1--23.",
      "doi": ""
    },
    {
      "text": "Mason, W. and Watts, D.J. Financial incentives and the performance of crowds. ACM SIGKDD Explorations Newsletter 11, 2 (2010), 100--108.  ",
      "doi": "10.1145/1809400.1809422"
    },
    {
      "text": "Morris, M.R., Counts, S., Roseway, A., Hoff, A., and Schwarz, J. Tweeting is believing?: understanding microblog credibility perceptions. CSCW 2012, 441--450.  ",
      "doi": "10.1145/2145204.2145274"
    },
    {
      "text": "Naaman, M., Boase, J., and Lai, C.-H. Is it really about me?: message content in social awareness streams. CSCW 2010, 189--192.  ",
      "doi": "10.1145/1718918.1718953"
    },
    {
      "text": "Paolacci, G., Chandler, J., and Ipeirotis, P.G. Running experiments on Amazon Mechanical Turk. Judgment and Decision Making 5, 5 2010, 411--419.",
      "doi": ""
    },
    {
      "text": "Papageorgiou, C. and Poggio, T. A trainable system for object detection. Int. J. of Computer Vision 38, 1 2000.  ",
      "doi": "10.1023/A%3A1008162616689"
    },
    {
      "text": "Peer, E., Vosgerau, J., and Acquisti, A. Reputation as a sufficient condition for data quality on Amazon Mechanical Turk. Behavior Research Methods, 2013, 1--9.",
      "doi": ""
    },
    {
      "text": "Prelec, D. A Bayesian truth serum for subjective data. Science 306, 5695 2004, 462--466.",
      "doi": ""
    },
    {
      "text": "Qazvinian, V., Rosengren, E., Radev, D.R., and Mei, Q. Rumor has it: Identifying misinformation in microblogs. EMNLP2011, 1589--1599. ",
      "doi": "10.5555/2145432.2145602"
    },
    {
      "text": "Rashtchian, C., Young, P., Hodosh, M., and Hockenmaier, J. Collecting image annotations using Amazon's Mechanical Turk. In Proc. NAACL HLT Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk, 139--147, 2010. ",
      "doi": "10.5555/1866696.1866717"
    },
    {
      "text": "Rosenthal, R. and Rubin, D.B. Multiple contrasts and ordered Bonferroni procedures. J. Ed. Psy. 76, 6 1984.",
      "doi": ""
    },
    {
      "text": "Saldana, J. The Coding Manual for Qualitative Researchers. SAGE Publications, 2009.",
      "doi": ""
    },
    {
      "text": "Shaw, A.D., Horton, J.J., and Chen, D.L. Designing incentives for inexpert human raters. CHI 2011.  ",
      "doi": "10.1145/1958824.1958865"
    },
    {
      "text": "Sheng, V.S., Provost, F., and Ipeirotis, P.G. Get another label? improving data quality and data mining using multiple, noisy labelers. KDD 2008, 614--622.  ",
      "doi": "10.1145/1401890.1401965"
    },
    {
      "text": "Sheshadri, A. and Lease, M. SQUARE: A Benchmark for Research on Computing Crowd Consensus. HCOMP 2013, 156--164.",
      "doi": ""
    },
    {
      "text": "Snow, R., O'Connor, B., Jurafsky, D., and Ng, A.Y. Cheap and Fast - But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks. EMNLP 2008. ",
      "doi": "10.5555/1613715.1613751"
    },
    {
      "text": "Soni, S., Mitra, T., Gilbert, E., and Eisenstein, J. Modeling Factuality Judgments in Social Media Text. In Proc. ACL, 415--420, 2014.",
      "doi": ""
    },
    {
      "text": "Sorokin, A. and Forsyth, D. Utility data annotation with Amazon Mechanical Turk. CVPRW 2008, 1--8.",
      "doi": ""
    },
    {
      "text": "Sun, Y.-A., Roy, S., and Little, G. Beyond Independent Agreement: A Tournament Selection Approach for Quality Assurance of Human Computation Tasks. Human Computation, 2011.",
      "doi": ""
    },
    {
      "text": "Surowiecki, J. The Wisdom of Crowds. Anchor Books, New York, NY, 2004. ",
      "doi": "10.5555/1095645"
    },
    {
      "text": "Wang, Y.-C., Kraut, R., and Levine, J.M. To stay or leave?: the relationship of emotional and informational support to commitment in online health support groups. CSCW 2012, 833--842.  ",
      "doi": "10.1145/2145204.2145329"
    },
    {
      "text": "Willett, W., Heer, J., and Agrawala, M. Strategies for crowdsourcing social data analysis. CHI 2012.  ",
      "doi": "10.1145/2207676.2207709"
    },
    {
      "text": "Zhao, W.X., Jiang, J., Weng, J., et al. Comparing twitter and traditional media using topic models. Advances in Information Retrieval. Springer, 2011, 338--349. ",
      "doi": "10.5555/1996889.1996934"
    }
  ]
}