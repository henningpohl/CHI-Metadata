{
  "doi": "10.1145/1054972.1055004",
  "title": "Conversing with the user based on eye-gaze patterns",
  "published": "2005-04-02",
  "proctitle": "CHI '05: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
  "pages": "221-230",
  "year": 2005,
  "badges": [],
  "abstract": "Motivated by and grounded in observations of eye-gaze patterns in human-human dialogue, this study explores using eye-gaze patterns in managing human-computer dialogue. We developed an interactive system, iTourist, for city trip planning, which encapsulated knowledge of eye-gaze patterns gained from studies of human-human collaboration systems. User study results show that it was possible to sense users' interest based on eye-gaze patterns and manage computer information output accordingly. Study participants could successfully plan their trip with iTourist and positively rated their experience of using it. We demonstrate that eye-gaze could play an important role in managing future multimodal human-computer dialogues.",
  "authors": [
    {
      "name": "Pernilla Qvarfordt",
      "institution": "Link\u00f6pings universitet, Link\u00f6ping, Sweden",
      "img": "/pb-assets/icons/DOs/default-profile-1543932446943.svg",
      "acmid": "81100507433",
      "orcid": "missing"
    },
    {
      "name": "Shumin Zhai",
      "institution": "IBM Almaden Research Center, San Jose, California",
      "img": "/do/10.1145/contrib-81408591988/rel-imgonly/81408591988.jpg",
      "acmid": "81408591988",
      "orcid": "0000-0003-0752-2090"
    }
  ],
  "references": [
    {
      "text": "Allopenna, P.D., Magnuson, J.S. and Tanenhaus, M.K. Tacking the time course of spoken word recognition using eye movements: Evidence for continuous mapping models. Journal of Memory and Language, 38, (1998). 419--439.]]",
      "doi": ""
    },
    {
      "text": "Argyle, M. and Graham, J. The central Europe experiment - Looking at persons and looking at things. Journal of Environmental Psychology and Nonverbal Behaviour, 1, (1977). 6--16.]]",
      "doi": ""
    },
    {
      "text": "Bolt, R.A., Eyes at the interface. Proc. Human Factors in Computer Systems (1982), ACM, 360--362.]]  ",
      "doi": "10.1145/800049.801811"
    },
    {
      "text": "Campbell, C.S. and Maglio, P.P., A robust algorithms for reading detection. Proc. ACM Workshop on Perceptive User Interfaces (2001), 1--7.]]  ",
      "doi": "10.1145/971478.971503"
    },
    {
      "text": "Cooper, R.M. The control of eye fixation by the meaning of spoken language - a new methodology for the real-time investigation of speech perception, memory, and language processing. Cognitive Psychology, 6, (1974). 84--107.]]",
      "doi": ""
    },
    {
      "text": "Edwards, G., A tool for creating eye-aware applications that adapt to changes in user behaviour. Proc. 3rd International ACM Conference on Assistive Technologies (1998), 67--74.]]  ",
      "doi": "10.1145/274497.274511"
    },
    {
      "text": "Goldberg, J.H. and Schryver, J.C. Eye-gaze determination of user intent at the computer interface. In Findlay, J.M., Walker, R. and Kentridge, R.W. (ed). Eye Movement Research -- Mechanisms, Processes and Applications, Elsevier Science, New York (1995).]]",
      "doi": ""
    },
    {
      "text": "Griffin, Z.M. and Bock, K. What the eye says about speaking. Psychological Science, 11, 4 (2000). 274--279.]]",
      "doi": ""
    },
    {
      "text": "Hyrskykari, A., Majaranta, P., Aaltonen, A. and R\u00e4ih\u00e4, K.-J., Design issues of iDICT: A gaze-added translation aid. Proc. ACM Symposium on Eye Tracking Research & Applications (2000), 9--14.]]  ",
      "doi": "10.1145/355017.355019"
    },
    {
      "text": "Hyrskykari, A., Majaranta, P. and R\u00e4ih\u00e4, K.-J., Proactive response to eye movements. Proc. INTERACT - IFIP Conference on Human-Computer Interaction (2003), 129--136.]]",
      "doi": ""
    },
    {
      "text": "Jacob, R.J.K., What you look at is what you get: Eye movement-based interaction techniques. Proc. CHI (1990), ACM, 11--18.]]  ",
      "doi": "10.1145/97243.97246"
    },
    {
      "text": "Kaur, M., Tremaine, M., Huang, N., Wilder, J., Gacovski, Z., Flippo, F. and Mantravadi, C.S., Where is \"it\"? event syncronisation in gaze-speech input systems. Proc. Fifth International Conference on Multimodal Interfaces (2003), 151--157.]]  ",
      "doi": "10.1145/958432.958463"
    },
    {
      "text": "Kendon Some function of gaze direction in social interaction. Acta Psychologica, 32, (1967). 1--25.]]",
      "doi": ""
    },
    {
      "text": "Li, M. and Selker, T., Eye pattern analysis in intelligent virtual agents. Proc. IVA 2001, Lecture Notes in Artificial Intelligence, 2190 (2001), Springer-Verlag.]] ",
      "doi": "10.5555/648034.744237"
    },
    {
      "text": "Maglio, P.P., Barrett, R., Campbell, C.S. and Selker, T., SUITOR: An attentive information system. Proc. International Conference on Intelligent User Interfaces (2000), 169--176.]]  ",
      "doi": "10.1145/325737.325821"
    },
    {
      "text": "Oviatt, S., Mutual disambiguation of recognition errors in a multimodal architecture. Proc. CHI (1999), ACM, 576--583.]]  ",
      "doi": "10.1145/302979.303163"
    },
    {
      "text": "Qvarfordt, P. Eyes on multimodal interaction (Ph.D. Thesis) Department of Computer and Information Science, Linkoping University, Linkoping Studies in Science and Technology Dissertation No. 893 (2004).]]",
      "doi": ""
    },
    {
      "text": "Salvucci, D., Inferring intent in eye-based interfaces: Tracing eye movements with process models. Proc. CHI (1999), ACM, 254--261.]]  ",
      "doi": "10.1145/302979.303055"
    },
    {
      "text": "Sibert, J.L., Gokturk, M. and Lavine, R.A., The reading assistant: Eye gaze triggered auditory prompting for reading remediation. Proc. ACM Symposium on User Interface Software and Technology (2000), 101--107.]]  ",
      "doi": "10.1145/354401.354418"
    },
    {
      "text": "Starker, I. and Bolt, R.A., A gaze-responsive self-disclosing display. Proc. CHI (1990), ACM, 3--9.]]  ",
      "doi": "10.1145/97243.97245"
    },
    {
      "text": "Tanaka, K., A robust selection system using real-time multi-modal user-agent interactions. Proc. 4th International Conference on Intelligent User Interfaces (1999), 105--108.]]  ",
      "doi": "10.1145/291080.291099"
    },
    {
      "text": "Tanenhaus, M.K., Magnuson, J.S., Dahan, D. and Chambers, C. Eye movements and lexical access in spoken-language comprehension: Linking hypothesis between fixations and linguistic processing. Journal of Psycholinguistics Research, 29, 6 (2000). 557--580.]]",
      "doi": ""
    },
    {
      "text": "Tanenhaus, M.K., Spivey-Knowlton, M.J., Eberhard, K.M. and Sedivy, J.C. Integration of visual and linguistic information in spoken language comprehension. Science, 268, 5217 (1995). 1635--1634.]]",
      "doi": ""
    },
    {
      "text": "Velichkovsky, B.M. Communicating attention-gaze position transfer in cooperative problem solving. Pragmatics and Cognition, 3, 2 (1995). 99--224.]]",
      "doi": ""
    },
    {
      "text": "Vertegaal, R., The GAZE Groupware System: Mediating Joint Attention in Multiparty Communication and Collaboration. Proc. CHI (1999), ACM, 294--301.]]  ",
      "doi": "10.1145/302979.303065"
    },
    {
      "text": "Vertegaal, R., Slagter, R., van der Veer, G.C. and Nijholt, A., Eye gaze patterns in conversations: there is more the conversational agents than meets the eyes. Proc. CHI (2001), ACM, 301--308.]]  ",
      "doi": "10.1145/365024.365119"
    },
    {
      "text": "Ware, C. and Mikaelian, H.H., An evaluation of an eye tracker as a device for computer input. Proc. CHI+GI (1987), ACM, 183--188.]]  ",
      "doi": "10.1145/29933.275627"
    },
    {
      "text": "Zhai, S. What's in the Eyes for Attentive Input Communications of the ACM (2003), 34--39.]]  ",
      "doi": "10.1145/636772.636795"
    },
    {
      "text": "Zhai, S., Morimoto, C. and Ihde, S., Manual and gaze input cascaded (MAGIC) pointing. Proc (1999), ACM, 246--253.]]  ",
      "doi": "10.1145/302979.303053"
    },
    {
      "text": "Zhang, Q., Imamiya, A., Go, K. and Gao, X., Overriding errors in speech and gaze multimodal architecture. Proc. 9th International Conference on Intelligent User Interfaces (2004), 346--348.]]  ",
      "doi": "10.1145/964442.964527"
    }
  ]
}