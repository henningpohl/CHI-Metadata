<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Best of CHI | CHI 2013</title><base href="http://chi2013.acm.org/">
<link rel="stylesheet" type="text/css" href="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/css/style_sheet.css" media="screen, print">
<style type="text/css">
<!--
.style1 {color: #660033}
-->
</style>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="stylesheet" type="text/css" media="all" href="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/style.css" />
<link rel="pingback" href="http://chi2013.acm.org/wordpress/xmlrpc.php" />

<!-- This site is optimized with the Yoast WordPress SEO plugin v1.2.7 - http://yoast.com/wordpress/seo/ -->
<link rel="canonical" href="http://chi2013.acm.org/program/best-of-chi/" />
<meta property='og:locale' content='en_us'/>
<meta property='og:title' content='Best of CHI - CHI 2013'/>
<meta property='og:url' content='http://chi2013.acm.org/program/best-of-chi/'/>
<meta property='og:site_name' content='CHI 2013'/>
<meta property='og:type' content='article'/>
<!-- / Yoast WordPress SEO plugin. -->

<link rel="alternate" type="application/rss+xml" title="CHI 2013 &raquo; Feed" href="http://chi2013.acm.org/feed/" />
<link rel="alternate" type="application/rss+xml" title="CHI 2013 &raquo; Comments Feed" href="http://chi2013.acm.org/comments/feed/" />
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-includes/js/jquery/jquery.js?ver=1.7.2'></script>
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-content/plugins/jquery-vertical-accordion-menu/js/jquery.hoverIntent.minified.js?ver=3.4.1'></script>
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-content/plugins/jquery-vertical-accordion-menu/js/jquery.cookie.js?ver=3.4.1'></script>
<script type='text/javascript' src='http://chi2013.acm.org/wordpress/wp-content/plugins/jquery-vertical-accordion-menu/js/jquery.dcjqaccordion.2.9.js?ver=3.4.1'></script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://chi2013.acm.org/wordpress/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://chi2013.acm.org/wordpress/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 3.4.1" />

<!-- Bad Behavior 2.2.13 run time: 1.677 ms -->
<script type="text/javascript">
<!--
function bb2_addLoadEvent(func) {
	var oldonload = window.onload;
	if (typeof window.onload != 'function') {
		window.onload = func;
	} else {
		window.onload = function() {
			oldonload();
			func();
		}
	}
}

bb2_addLoadEvent(function() {
	for ( i=0; i < document.forms.length; i++ ) {
		if (document.forms[i].method == 'post') {
			var myElement = document.createElement('input');
			myElement.setAttribute('type', 'hidden');
			myElement.name = 'bb2_screener_';
			myElement.value = '1690361874 130.225.198.161';
			document.forms[i].appendChild(myElement);
		}
	}
});
// --></script>
		<script src="http://chi2013.acm.org/wordpress/wp-content/uploads/2013/04/findtlc.js"></script>
</head>


					</head>

<body>

<div id="wrapper" style="overflow: visible; "><!--####  wrapper  ###-->

	<div id="top-menu"><!--menu-->
    
    		              <div id="icon_area"><!--icon area-->
                
                
                		<ul>
                        
                        	<li><a href="https://www.facebook.com/acmchi" title="CHI on Facebook"><img src="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/facebook.png" alt="facebook icon"></a></li>
                                <li><a href="http://twitter.com/sig_chi" title="CHI on Twitter"><img src="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/twitter.png" alt="twitter icon"></a></li>
				<li><a href="https://plus.google.com/s/CHI2013" title="CHI on Google+"><img src="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/gplus.png" width="20px" alt="google+ icon"></a></li>
                		</ul>
          		</div><!--icon area-->

	<div id="nav_top"><!--menu top--> 
                <ul id="nav">
					<li class="page_item page-item-2"><a href="http://chi2013.acm.org/">Welcome</a></li>
<li class="page_item page-item-9 current_page_ancestor current_page_parent"><a href="http://chi2013.acm.org/program/">Program</a></li>
<li class="page_item page-item-12"><a href="http://chi2013.acm.org/attending/">Attending</a></li>
<li class="page_item page-item-15"><a href="http://chi2013.acm.org/authors/">Authors</a></li>
<li class="page_item page-item-28"><a href="http://chi2013.acm.org/organizers/">Organizers</a></li>
<li class="page_item page-item-18"><a href="http://chi2013.acm.org/sponsorship/">Sponsorship</a></li>
<li class="page_item page-item-21"><a href="http://chi2013.acm.org/exhibiting/">Exhibiting</a></li>
<li class="page_item page-item-31"><a href="http://chi2013.acm.org/press/">Press</a></li>
<li class="page_item page-item-25"><a href="http://chi2013.acm.org/recruiting/">Recruiting</a></li>
<li class="page_item page-item-64"><a href="http://chi2013.acm.org/communities/">Communities</a></li>
                </ul>
                    
                                   
               <ul id="subnav">
                    <li class="page_item page-item-1428"><a href="http://chi2013.acm.org/program/by-venues/">By venues</a></li>
<li class="page_item page-item-1655"><a href="http://chi2013.acm.org/program/by-day/">By day</a></li>
<li class="page_item page-item-1745 current_page_item"><a href="http://chi2013.acm.org/program/best-of-chi/">Best of CHI</a></li>
<li class="page_item page-item-2105"><a href="http://chi2013.acm.org/program/industry-days/">Industry Days</a></li>
<li class="page_item page-item-2110"><a href="http://chi2013.acm.org/program/mobile-apps/">Mobile Apps</a></li>
<li class="page_item page-item-2404"><a href="http://chi2013.acm.org/program/my-chi/">myCHI</a></li>
<li class="page_item page-item-2043"><a href="http://chi2013.acm.org/program/video-previews/">Video Previews</a></li>
<li class="page_item page-item-2042"><a href="http://chi2013.acm.org/program/3-letter-codes/">3-Letter Codes</a></li>
                </ul>
                     

<!-- testing grandchild code                                       
-->
                   <!-- testing code -->

                    
<!-- end testing code -->

<!--              	 	<ul>
                        
                       <li><a href="index.html" class="active">Welcome</a></li>
                        <li class="grey"><a href="#">Program</a></li>
					   <li class="grey"><a href="#">Attending</a></li>
                       <li class="grey"><a href="#">Authors</a></li>
                       <li class="grey"><a href="#">Sponsorship</a></li>
					    <li class="grey"><a href="#">Exhibiting</a></li>
						<li class="grey"><a href="#">Recruiting</a><a href="#">Organizers</a></li>
						<li class="grey"><a href="#">Press</a></li>
						<div align="left"><a href="#"></a></div>
						 
					
           	  </ul>-->
                     
                     
      </div><!--menu top end--> 
            
	</div><!--menu end-->
  <!--header-->
    <!--header end-->
<div id="banner" style="overflow: visible; "><!--banner-->
        		 <!--img src="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/header1.jpg" alt="" style="overflow: visible; "-->
        		 <img src="http://chi2013.acm.org/wordpress/wp-content/themes/ThemeMatcher_free/images/banner/home.jpg" alt="" style="overflow: visible; ">
  </div><!--banner end-->
  <!-- breadcrumbs -->
<div id="breadcrumbs">
    &gt; <a href="http://chi2013.acm.org/program/">Program</a> &gt; <a href="http://chi2013.acm.org/program/best-of-chi/">Best of CHI</a>     </div>
  <!-- end breadcrumbs -->              
        
        <div id="content_wrapper" style="overflow: visible; "><!-- content wrapper-->
                    
                   <div id="content_laft" style="overflow: visible; opacity: 1; ">		<div id="secondary" class="widget-area" role="complementary">
								<div id="recent-posts-2" class="widget widget_recent_entries">		<h1 class="widget-title">News</h1>		<ul>
				<li><a href="http://chi2013.acm.org/chi-2013-awards/" title="&lt;img src=&quot;http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png&quot;&gt; CHI 2013 Awards"><img src="http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png"> CHI 2013 Awards</a></li>
				<li><a href="http://chi2013.acm.org/what-to-attend-mychi/" title="What to attend: MyCHI">What to attend: MyCHI</a></li>
				<li><a href="http://chi2013.acm.org/watch-the-video-previews/" title="Watch the Video Previews">Watch the Video Previews</a></li>
				</ul>
		</div><div id="text-5" class="widget widget_text"><h1 class="widget-title">3-letter codes</h1>			<div class="textwidget"><label for="tlc">Enter code:</label><input id="tlc" type="text" size="3" onchange="gotoTLC()" /><button onclick="gotoTLC()">Go</button></div>
		</div><div id="search-3" class="widget widget_search"><h1 class="widget-title">Search</h1><form role="search" method="get" id="searchform" action="http://chi2013.acm.org/" >
	<div><label class="screen-reader-text" for="s">Search for:</label>
	<input type="text" value="" name="s" id="s" />
	<input type="submit" id="searchsubmit" value="Search" />
	</div>
	</form></div><div id="nav_menu-2" class="widget widget_nav_menu"><h1 class="widget-title">Communities</h1><div class="menu-communities-container"><ul id="menu-communities" class="menu"><li id="menu-item-77" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-77"><a href="http://chi2013.acm.org/communities/design/">Design</a></li>
<li id="menu-item-76" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-76"><a href="http://chi2013.acm.org/communities/engineering/">Engineering</a></li>
<li id="menu-item-75" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-75"><a href="http://chi2013.acm.org/communities/management/">Management</a></li>
<li id="menu-item-74" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-74"><a href="http://chi2013.acm.org/communities/user-experience/">User Experience</a></li>
<li id="menu-item-88" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-88"><a href="http://chi2013.acm.org/communities/hci-for-kids/">Child-Computer Interaction</a></li>
<li id="menu-item-631" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-631"><a href="http://chi2013.acm.org/communities/digital-arts/">Digital Arts</a></li>
<li id="menu-item-94" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-94"><a href="http://chi2013.acm.org/communities/entertainment/">Games &#038; Entertainment</a></li>
<li id="menu-item-93" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-93"><a href="http://chi2013.acm.org/communities/health/">Health</a></li>
<li id="menu-item-92" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-92"><a href="http://chi2013.acm.org/communities/sustainability/">Sustainability</a></li>
<li id="menu-item-576" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-576"><a href="http://chi2013.acm.org/communities/hci4d/">HCI4D</a></li>
</ul></div></div>		</div><!-- #secondary .widget-area -->                     
                   </div><!--content laft end-->
                
        <!-- c-ao 23jan13 adjustment for page id 1213 to make it wider -->
	<!-- mbl 12feb13 changed test for page id with test for custom field 'wide' -->
        		
		<div id="content_wide" style="overflow:visible; "><!--content wide-->
		                
                		<!--<h1>Welcome to CHI 2013</h1>-->
                        
                        <p class="text" style="overflow: visible; "> 
                          <span class="style1" style="overflow: visible; opacity: 1; ">
<h1 class="page-title TG-pagepage-title TG-page-title">Best of CHI</h1>
								




				<div id="post-1745" class="post-1745 page type-page status-publish hentry" >
									<div class="entry-content">
						<p>These papers, notes and case studies have been selected according to ACM rules for best papers: fewer than 1% of submissions can receive a <strong>Best of CHI award</strong>, and fewer than 5% of submissions can receive an <strong>Honorable Mention</strong>.</p>
<p>CHI 2013 introduces the <strong>RepliCHI award</strong>, which recognizes papers and notes that demonstrate best practices in replicating and extending resesarch results or serve as an example of a highly replicable experiment.</p>
<p>CHI 2013 also presented <a href="http://chi2013.acm.org/program/by-venues/student-competitions/" title="Student Competitions">student competition awards</a> and the <a href="http://chi2013.acm.org/program/by-venues/video-showcase/" title="Video Showcase">video showcase award</a>.</p>
<style>
a { color: rgb(100, 79, 76);}
h3 { margin-bottom: 2px;}
div.chair {font-style: italic;}
.presentation {line-height: 1.4; margin-bottom: 12px; color: rgb(102, 0, 51);}
.presentation .title {font-weight: bold;}
.presentation .authors {font-style: italic;}
.presentation .authorList {display: none;}
.presentation .authorList > span {display: block;}
.presentation .cbStatement {padding: 24px 0px;}
.presentation .abstract {display: none; padding: 24px 0px;}
.presentation .author { font-style: italic;}
.time { background-color: rgb(100, 79, 76); color: rgb(246, 243, 226); padding: 2px 5px;}
span.when { float: right; margin-left: 15px; font-family: sans-serif; font-size: 9pt;}
span.award { display: inline-block; float: left; margin-left: -50px; height: 34px; width: 34px; background-repeat:no-repeat;}
span.best { background-image: url('http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/best.png');}
span.honorable { background-image: url('http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/honorable.png');}
span.repliCHI { clear: left; height: 51px; width: 51px; background-image: url('http://chi2013.acm.org/wordpress/wp-content/uploads/2013/03/repliCHI.png');}
span.room { display: inline-block; float: right; padding-top: 1px; font-family: sans-serif; font-size: 14px; font-weight: normal;}
span.room:before { content: 'Room: ';}
</style>
<p><script type='text/javascript'>
function toggleAll() { var $=jQuery; $('.authors').toggle(); $('.authorList').toggle(); $('.cbStatement').toggle(); $('.abstract').toggle(); }
</script></p>
<p><a href='javascript:toggleAll()'>Show / hide full affiliations and abstracts</a> (May take a few seconds.)</p>
<p><span class='letterCode' style='float:left'>IWC</span>&nbsp;Enter a <a href='http://chi2013.acm.org/3-letter-codes/'>3-letter code</a> in the search box of the CHI 2013 mobile app to go to the corresponding session or presentation. <br/>&nbsp;When clickable, a 3-letter code links to the <a href='http://chi2013.acm.org/previews'>Video Previews</a> web site.</p>
<p><script type="text/javascript">
	function filterCommunity(community) { var $=jQuery; if (community == "all") { $(".presentation").show(); $(".session").show(); } else {$(".presentation").hide(); $(".presentation."+community).show(); $(".session").hide(); $(".session."+community).show()};}
	</script></p>
<table>
<tr>
<td><input type="radio" name="community" onchange="filterCommunity('all')" value="all" checked>All communities</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('design')" value="design">Design (37)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('engineering')" value="engineering">Engineering (19)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('management')" value="management">Management (4)</input></td>
</tr>
<tr>
<td><input type="radio" name="community" onchange="filterCommunity('ux')" value="ux">User Experience (29)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('cci')" value="cci">Child-Computer Interaction (5)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('arts')" value="arts">Digital Arts (6)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('games')" value="games">Games and Entertainment (9)</input></td>
</tr>
<tr>
<td><input type="radio" name="community" onchange="filterCommunity('health')" value="health">Health (8)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('sustainability')" value="sustainability">Sustainability (7)</input></td>
<td><input type="radio" name="community" onchange="filterCommunity('HCI4D')" value="HCI4D">HCI for Development (3)</input></td>
</tr>
</table>
<p><a href="http://chi2013.acm.org/program/best-of-chi/#bestPapers">Best papers and notes</a> | <a href="http://chi2013.acm.org/program/best-of-chi/#bestCaseStudies">Best case study</a> | <a href="http://chi2013.acm.org/program/best-of-chi/#honorablePapers">Honorable papers and notes</a> | <a href="http://chi2013.acm.org/program/best-of-chi/#honorableCaseStudies">Honorable case studies</a> | <a href="http://chi2013.acm.org/program/best-of-chi/#repliCHI">RepliCHI papers and notes</a></p>
<h2 id="bestPapers">Best of CHI Papers and Notes</h2>
<ul>
<li id="PPD"class="presentation health"><a href="http://chi2013.acm.org/previews/#PPD"><span class="letterCode" style="float:right">PPD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PPD">Mon. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470724">Weighted Graph Comparison Techniques for Brain Connectivity Analysis</a></span><br />
<span class="authors">B. Alper (Univ. of California, Santa Barbara, USA), B. Bach, N. Henry Riche, T. Isenberg, J. Fekete</span>
<div class="authorList"><span><span class="author">B. Alper</span> (Univ. of California, Santa Barbara, USA)</span><span><span class="author">B. Bach</span> (INRIA, FR)</span><span><span class="author">N. Henry Riche</span> (Microsoft Research, USA)</span><span><span class="author">T. Isenberg</span> (INRIA, FR)</span><span><span class="author">J. Fekete</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">This paper presents the design and evaluation of two visualizations for comparing weighted graphs. Results have implications for the design of brain connectivity analysis and other graph visualization tools.</span><span class="abstract">The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to  be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not  been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.</span></li>
<li id="PJM"class="presentation "><a href="http://chi2013.acm.org/previews/#PJM"><span class="letterCode" style="float:right">PJM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJM">Tue. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466158">Analyzing User-Generated YouTube Videos to Understand Touchscreen Use by People with Motor Impairments</a></span><br />
<span class="authors">L. Anthony (Univ. of Maryland, Baltimore County, USA), Y. Kim, L. Findlater</span>
<div class="authorList"><span><span class="author">L. Anthony</span> (Univ. of Maryland, Baltimore County, USA)</span><span><span class="author">Y. Kim</span> (Univ. of Maryland, USA)</span><span><span class="author">L. Findlater</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">To inform accessible touchscreen design, we analyzed 187 YouTube videos depicting people with physical disabilities interacting with mobile touchscreen devices. We report on challenges observed and user-initiated adaptations being made.</span><span class="abstract">Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of user-generated content to study user interface design.</span></li>
<li id="PHQ"class="presentation design arts"><a href="http://chi2013.acm.org/previews/#PHQ"><span class="letterCode" style="float:right">PHQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PHQ">Thu. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466451">What is &#8220;Critical&#8221; About Critical Design?</a></span><br />
<span class="authors">J. Bardzell (Indiana Univ. Bloomington, USA), S. Bardzell</span>
<div class="authorList"><span><span class="author">J. Bardzell</span> (Indiana Univ. Bloomington, USA)</span><span><span class="author">S. Bardzell</span> (Indiana Univ. Bloomington, USA)</span></div>
<p><span class="cbStatement">We provide a critique of Critical Design and propose a broader, more practical reframing, based on humanistic scholarship on critical theory and criticism.</span><span class="abstract">Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today’s socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature. </span></li>
<li id="PGZ"class="presentation ux sustainability"><a href="http://chi2013.acm.org/previews/#PGZ"><span class="letterCode" style="float:right">PGZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGZ">Tue. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466155">The Dubuque Electricity Portal: Evaluation of a City-Scale Residential Electricity Consumption Feedback System</a></span><br />
<span class="authors">T. Erickson (IBM T.J. Watson Research Center, USA), M. Li, Y. Kim, A. Deshpande, S. Sahu, T. Chao, P. Sukaviriya, M. Naphade</span>
<div class="authorList"><span><span class="author">T. Erickson</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">M. Li</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">Y. Kim</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">A. Deshpande</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">S. Sahu</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">T. Chao</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">P. Sukaviriya</span> (IBM T.J. Watson Research Center, USA)</span><span><span class="author">M. Naphade</span> (IBM T.J. Watson Research Center, USA)</span></div>
<p><span class="cbStatement">Evaluation of an electricity portal deployed to 765 homes for 20 weeks that used feedback and social techniques to support decreased electricity consumption. Can assist designers of residential feedback  systems.  </span><span class="abstract">This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions ¬ – both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system’s users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.</span></li>
<li id="PSF"class="presentation "><a href="http://chi2013.acm.org/previews/#PSF"><span class="letterCode" style="float:right">PSF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PSF">Wed. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481323">Improving Navigation-Based File Retrieval</a></span><br />
<span class="authors">S. Fitchett (Univ. of Canterbury, NZ), A. Cockburn, C. Gutwin</span>
<div class="authorList"><span><span class="author">S. Fitchett</span> (Univ. of Canterbury, NZ)</span><span><span class="author">A. Cockburn</span> (Univ. of Canterbury, NZ)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">Introduces three interfaces to improve navigation-based file retrieval. Empirical studies show they are subjectively preferred and decrease retrieval times for both new and revisited items.</span><span class="abstract">Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their  predictions to users. We present three design goals aiming to  improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment  standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces  could be combined and deployed in existing file browsers.</span></li>
<li id="PFU"class="presentation "><a href="http://chi2013.acm.org/previews/#PFU"><span class="letterCode" style="float:right">PFU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFU">Wed. 9am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481283">SPRWeb: Preserving Subjective Responses to Website Colour Schemes through Automatic Recolouring</a></span><br />
<span class="authors">D. Flatla (Univ. of Saskatchewan, CA), K. Reinecke, C. Gutwin, K. Gajos</span>
<div class="authorList"><span><span class="author">D. Flatla</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">K. Reinecke</span> (Harvard Univ., USA)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">K. Gajos</span> (Harvard Univ., USA)</span></div>
<p><span class="cbStatement">SPRWeb equalizes website experience for people with colour vision deficiency by improving colour differentiation (like previous recolouring tools), but also maintains the original colour scheme&#8217;s subjective properties (&#8216;warmth&#8217;, &#8216;weight&#8217;, &#8216;activity&#8217;).</span><span class="abstract">Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability &#8211; thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.</span></li>
<li id="PCH"class="presentation "><a href="http://chi2013.acm.org/previews/#PCH"><span class="letterCode" style="float:right">PCH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCH">Mon. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470718">The Efficacy of Human Post-Editing for Language Translation</a></span><br />
<span class="authors">S. Green (Stanford Univ., USA), J. Heer, C. Manning</span>
<div class="authorList"><span><span class="author">S. Green</span> (Stanford Univ., USA)</span><span><span class="author">J. Heer</span> (Stanford Univ., USA)</span><span><span class="author">C. Manning</span> (Stanford Univ., USA)</span></div>
<p><span class="cbStatement">We analyzed human post-editing of machine translation output, a common feature in translator interfaces. We found that machine suggestions reduce human translation time and improved final quality.</span><span class="abstract">Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.</span></li>
<li id="PGX"class="presentation design health sustainability"><a href="http://chi2013.acm.org/previews/#PGX"><span class="letterCode" style="float:right">PGX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PGX">Thu. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466452">Mind the Theoretical Gap: Interpreting, Using, and Developing Behavioral Theory in HCI Research</a></span><br />
<span class="authors">E. Hekler (Arizona State Univ., USA), P. Klasnja, J. Froehlich, M. Buman</span>
<div class="authorList"><span><span class="author">E. Hekler</span> (Arizona State Univ., USA)</span><span><span class="author">P. Klasnja</span> (Univ. of Michigan, USA)</span><span><span class="author">J. Froehlich</span> (Univ. of Maryland, USA)</span><span><span class="author">M. Buman</span> (Arizona State Univ., USA)</span></div>
<p><span class="cbStatement">Are you trying to use behavioral theory in your work?  Our paper will help by providing a context and organizing framework for interpreting, using, and developing behavioral theory. </span><span class="abstract">Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them.</span></li>
<li id="PML"class="presentation design HCI4D"><a href="http://chi2013.acm.org/previews/#PML"><span class="letterCode" style="float:right">PML</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PML">Mon. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470742">Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk</a></span><br />
<span class="authors">L. Irani (Univ. of California, Irvine, USA), M. Silberman</span>
<div class="authorList"><span><span class="author">L. Irani</span> (Univ. of California, Irvine, USA)</span><span><span class="author">M. Silberman</span> (Bureau of Economic Interpretation, USA)</span></div>
<p><span class="cbStatement">With Turkopticon, we contribute an example of a long-term systems building project that reworks employer-worker relations in Amazon Mechanical Turk.  We analyze the system in feminist, infrastrastructural, and political terms.  </span><span class="abstract">As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems. </span></li>
<li id="PCJ"class="presentation design engineering games"><a href="http://chi2013.acm.org/previews/#PCJ"><span class="letterCode" style="float:right">PCJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PCJ">Tue. 9am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466112">IllumiRoom: Peripheral Projected Illusions for Interactive Experiences</a></span><br />
<span class="authors">B. Jones (Univ. of Illinois at Urbana-Champaign, USA), H. Benko, E. Ofek, A. Wilson</span>
<div class="authorList"><span><span class="author">B. Jones</span> (Univ. of Illinois at Urbana-Champaign, USA)</span><span><span class="author">H. Benko</span> (Microsoft Research, USA)</span><span><span class="author">E. Ofek</span> (Microsoft Research, USA)</span><span><span class="author">A. Wilson</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. </span><span class="abstract">IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.</span></li>
<li id="PLB"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/#PLB"><span class="letterCode" style="float:right">PLB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PLB">Thu. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466420">Webzeitgeist: Design Mining the Web</a></span><br />
<span class="authors">R. Kumar (Stanford Univ., USA), A. Satyanarayan, C. Torres, M. Lim, S. Ahmad, S. Klemmer, J. Talton</span>
<div class="authorList"><span><span class="author">R. Kumar</span> (Stanford Univ., USA)</span><span><span class="author">A. Satyanarayan</span> (Stanford Univ., USA)</span><span><span class="author">C. Torres</span> (Stanford Univ., USA)</span><span><span class="author">M. Lim</span> (Stanford Univ., USA)</span><span><span class="author">S. Ahmad</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Klemmer</span> (Stanford Univ., USA)</span><span><span class="author">J. Talton</span> (Intel Corporation, USA)</span></div>
<p><span class="cbStatement">This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.</span><span class="abstract">Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes.  This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.  This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.</span></li>
<li id="PFL"class="presentation engineering"><a href="http://chi2013.acm.org/previews/#PFL"><span class="letterCode" style="float:right">PFL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFL">Wed. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481358">LaserOrigami: Laser-Cutting 3D Objects</a></span><br />
<span class="authors">S. Mueller (Hasso Plattner Institute, DE), B. Kruck, P. Baudisch</span>
<div class="authorList"><span><span class="author">S. Mueller</span> (Hasso Plattner Institute, DE)</span><span><span class="author">B. Kruck</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">LaserOrigami is a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than 3D-printing and unlike traditional laser cutting it requires no manual assembly.</span><span class="abstract">We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. Laser¬Origami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. Laser¬Origami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser’s power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down—when users take out the workpiece, it is already fully assembled. We present the three main design elements of Laser¬Origami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of Laser¬Origami, a process in which user interaction and fabrication alternate step-by-step.</span></li>
<li id="PKZ"class="presentation design management"><a href="http://chi2013.acm.org/previews/#PKZ"><span class="letterCode" style="float:right">PKZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PKZ">Mon. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470745">Labor Dynamics in a Mobile Micro-Task Market</a></span><br />
<span class="authors">M. Musthag (Univ. of Massachusetts, USA), D. Ganesan</span>
<div class="authorList"><span><span class="author">M. Musthag</span> (Univ. of Massachusetts, USA)</span><span><span class="author">D. Ganesan</span> (Univ. of Massachusetts, USA)</span></div>
<p><span class="cbStatement">This paper provides an in-depth exploration of labor dynamics in mobile task markets which require spatial mobility based on a year-long dataset from a leading mobile crowdsourcing platform.  </span><span class="abstract">The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents.    This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform.  We find that a small core group of workers (< 10%) account for a disproportionately large proportion of activity (> 80%) generated in the market. We find that these super agents are more efficient than other agents across several dimensions: a) they are willing to move longer distances to perform tasks, yet they amortize travel across more tasks, b) they work and search for tasks more efficiently, c) they have higher data quality in terms of accepted submissions, and d) they improve in almost all of these efficiency measures over time. We find that super agent efficiency stems from two simple optimizations &#8212; they are 3x more likely than other agents to chain tasks and they pick fewer lower priced tasks than other agents. We compare mobile and online micro-task markets, and discuss differences in demographics, data quality, and time of use, as well as similarities in super agent behavior. We conclude with a discussion of how a mobile micro-task market might leverage some of our results to improve performance.</span></li>
<li id="PTF"class="presentation HCI4D"><a href="http://chi2013.acm.org/previews/#PTF"><span class="letterCode" style="float:right">PTF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTF">Wed. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481389">Job Opportunities through Entertainment: Virally Spread Speech-Based Services for Low-Literate Users</a></span><br />
<span class="authors">A. Raza (Carnegie Mellon Univ., USA), F. Ul Haq, Z. Tariq, M. Pervaiz, S. Razaq, U. Saif, R. Rosenfeld</span>
<div class="authorList"><span><span class="author">A. Raza</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">F. Ul Haq</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">Z. Tariq</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">M. Pervaiz</span> (Northeastern Univ., USA)</span><span><span class="author">S. Razaq</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">U. Saif</span> (Lahore Univ. of Management Sciences, PK)</span><span><span class="author">R. Rosenfeld</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">A speech-based entertainment service spread virally to low-literate Pakistani telephone users, exceeding 85,000 users and 495,000 calls in four months, while spreading low-skill job opportunities to 27,000 of them.</span><span class="abstract">We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users’ activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.</span></li>
<li id="PAP"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/#PAP"><span class="letterCode" style="float:right">PAP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PAP">Tue. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466152">At Home with Agents: Exploring Attitudes Towards Future Smart Energy Infrastructures</a></span><br />
<span class="authors">T. Rodden (The Univ. of Nottingham, UK), J. Fischer, N. Pantidi, K. Bachour, S. Moran</span>
<div class="authorList"><span><span class="author">T. Rodden</span> (The Univ. of Nottingham, UK)</span><span><span class="author">J. Fischer</span> (The Univ. of Nottingham, UK)</span><span><span class="author">N. Pantidi</span> (The Univ. of Nottingham, UK)</span><span><span class="author">K. Bachour</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Moran</span> (The Univ. of Nottingham, UK)</span></div>
<p><span class="cbStatement">This paper considers critical socio-economical issues regarding how consumers might relate to future smart energy infrastructures and suggests a number of key design principles to address those.</span><span class="abstract">Energy systems researchers are proposing a broad range of future “smart” energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users’ reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings. </span></li>
<li id="PTV"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/#PTV"><span class="letterCode" style="float:right">PTV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTV">Tue. 4pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466227">Screenfinity: Extending the Perception Area of Content on Very Large Public Displays</a></span><br />
<span class="authors">C. Schmidt (Telekom Innovation Laboratories, TU Berlin, DE), J. Müller, G. Bailly</span>
<div class="authorList"><span><span class="author">C. Schmidt</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">J. Müller</span> (Univ. of the Arts, DE)</span><span><span class="author">G. Bailly</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span></div>
<p><span class="cbStatement">Presents a model for the perception area of visual interfaces, and a novel public display increasing the perception area and allowing interaction while walking. Useful for designers of large displays.</span><span class="abstract">We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity, a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find 1) first time users can read content without slowing down or stopping; 2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen.</span></li>
<li id="NFB"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/#NFB"><span class="letterCode" style="float:right">NFB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NFB">Tue. 2pm</a></span><span class="award best"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466193">NailDisplay: Bringing an Always Available Visual Display to Fingertips</a></span><br />
<span class="authors">C. Su (National Taiwan Univ., TW), L. Chan, C. Weng, R. Liang, K. Cheng, B. Chen</span>
<div class="authorList"><span><span class="author">C. Su</span> (National Taiwan Univ., TW)</span><span><span class="author">L. Chan</span> (Academia Sinica, TW)</span><span><span class="author">C. Weng</span> (National Taiwan Univ., TW)</span><span><span class="author">R. Liang</span> (Academia Sinica, TW)</span><span><span class="author">K. Cheng</span> (National Taiwan Univ., TW)</span><span><span class="author">B. Chen</span> (National Taiwan Univ., TW)</span></div>
<p><span class="cbStatement">Explores the possibility of turing fingernails into places for system input and visual output by adding a nail-mounted display.</span><span class="abstract">This work presents a novel and always-available nail mounted display known as NailDisplay. The proposed display augments the use of a finger  by allowing for always-available visual feedback owing to its fast accessibility and  binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface,  helping users to learn an imaginary interface (e.g., on the users&#8217; arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users&#8217; feedbacks gathered from an explorative user study. </span></li>
<li id="PLQ"class="presentation design engineering health"><a href="http://chi2013.acm.org/previews/#PLQ"><span class="letterCode" style="float:right">PLQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PLQ">Tue. 2pm</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466190">Reasons to Question Seven Segment Displays</a></span><br />
<span class="authors">H. Thimbleby (Swansea Univ., UK)</span>
<div class="authorList"><span><span class="author">H. Thimbleby</span> (Swansea Univ., UK)</span></div>
<p><span class="cbStatement">Seven segment displays are familiar and ubiquitous, yet their use is problematic. This paper reviews many readability and use problems, and provides a range design questions and fixes.</span><span class="abstract">Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products.     This paper illustrates many examples of problematic uses of seven segment displays that could have been avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred. </span></li>
<li id="PSX"class="presentation ux"><a href="http://chi2013.acm.org/previews/#PSX"><span class="letterCode" style="float:right">PSX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PSX">Mon. 11am</a></span><span class="award best"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470656">The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive</a></span><br />
<span class="authors">X. Zhao (Cornell Univ., USA), N. Salehi, S. Naranjit, S. Alwaalan, S. Voida, D. Cosley</span>
<div class="authorList"><span><span class="author">X. Zhao</span> (Cornell Univ., USA)</span><span><span class="author">N. Salehi</span> (Sharif Univ. of Technology, IR)</span><span><span class="author">S. Naranjit</span> (Cornell Univ., USA)</span><span><span class="author">S. Alwaalan</span> (King Saud Univ., SA)</span><span><span class="author">S. Voida</span> (Cornell Univ., USA)</span><span><span class="author">D. Cosley</span> (Cornell Univ., USA)</span></div>
<p><span class="cbStatement">We bring new perspectives to the design of social media by drawing from Goffman’s theatrical metaphor and Hogan’s exhibition approach to explore how people manage social media data over time. </span><span class="abstract">The growing use of social media means that an increasing amount of people’s lives are visible online. We draw from Goffman’s theatrical metaphor and Hogan’s exhibition ap-proach to explore how people manage their personal collec-tion of social media data over time. We conducted a quali-tative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for man-aging recent data and impression management, an exhibi-tion region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users’ need for presenting and archiving data in these three regions is mediated by temporality. These find-ings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.</span></li>
<li id="NNF"class="presentation design engineering ux arts"><a href="http://chi2013.acm.org/previews/#NNF"><span class="letterCode" style="float:right">NNF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NNF">Wed. 2pm</a></span><span class="award best"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481361">FreeD – A Freehand Digital Sculpting Tool</a></span><br />
<span class="authors">A. Zoran (Massachusetts Institute of Technology, USA), J. Paradiso</span>
<div class="authorList"><span><span class="author">A. Zoran</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">J. Paradiso</span></span></div>
<p><span class="cbStatement">This paper explores the intersection of craft and digital fabrication through the FreeD, a handheld milling device, preserving the maker’s freedom to sculpt and carve based on virtual 3D models.  </span><span class="abstract">In this paper, we present an approach to combining digital fabrication and craft, emphasizing the user experience. While many researchers strive to enable makers to design and produce 3D objects, our research seeks to present a new fabrication approach to make unique, one-of-a-kind artifacts. To that end, we developed the FreeD, a hand-held digital milling device. The system is guided and monitored by a computer while preserving the maker’s freedom to sculpt and carve, and to manipulate the work in many creative ways. Relying on a predesigned 3D model, the computer gets into action only when the milling bit risks the object’s integrity, by slowing down the spindle’s speed or by drawing back the shaft, while the rest of the time it allows complete gestural freedom. We describe the key concepts of our work and its motivation, present the FreeD’s architecture and technology, and discuss two projects made with the tool.</span></li>
</ul>
<h2 id="bestCaseStudies">Best of CHI case study</h2>
<ul>
<li id="YGU"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#YGU"><span class="letterCode" style="float:right">YGU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#YGU">Wed. 11am</a></span><span class="award best"></span><span class="title"><a href="http://doi.acm.org/10.1145/2468356.2468772">Biometric Interaction – a Case Study of Visual Feedback and Privacy Issues in New Face Recognition Solutions</a></span><br />
<span class="authors">P. Kvarnbrink (Umea Univ., SE), K. Fahlquist, T. Mejtoft</span>
<div class="authorList"><span><span class="author">P. Kvarnbrink</span> (Umea Univ., SE)</span><span><span class="author">K. Fahlquist</span> (Umea Univ., SE)</span><span><span class="author">T. Mejtoft</span> (Umea Univ., SE)</span></div>
<p><span class="cbStatement">This study brings a face recognition algorithm into a real-life gate system at an indoor training facility. The goal was to make the system efficient, easy to use and friendly.</span><span class="abstract">This case study describes how to convert a gate system from using magnetic keycards to face recognition. The gate is placed at one of Europe&#8217;s biggest indoor training facilities, IKSU. The goal with this case study was to make the system efficient, easy to use and friendly.</span></li>
</ul>
<h2 id="honorablePapers">Papers and Notes with Honorable Mentions</h2>
<ul>
<li id="PGU"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#PGU"><span class="letterCode" style="float:right">PGU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGU">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466246">Benevolent Deception in Human Computer Interaction</a></span><br />
<span class="authors">E. Adar (Univ. of Michigan, USA), D. Tan, J. Teevan</span>
<div class="authorList"><span><span class="author">E. Adar</span> (Univ. of Michigan, USA)</span><span><span class="author">D. Tan</span> (Microsoft Research, USA)</span><span><span class="author">J. Teevan</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">In this work we analyze deception intended to help the user.  Using a criminology-inspired metaphor we describe the means, motive, and opportunities for deception and ideas for future research.</span><span class="abstract">Though it has been asserted that “good design is honest,” [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception—in many cases rightfully so—the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception, deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper “Value-Centered HCI” [13], “Traditional disciplines have delivered truth. The goal of HCI is to deliver value.”</span></li>
<li id="NMQ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#NMQ"><span class="letterCode" style="float:right">NMQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NMQ">Wed. 4pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481418">Leading People to Longer Queries</a></span><br />
<span class="authors">E. Agapie (Harvard Univ., USA), G. Golovchinsky, P. Qvarfordt</span>
<div class="authorList"><span><span class="author">E. Agapie</span> (Harvard Univ., USA)</span><span><span class="author">G. Golovchinsky</span> (FX Palo Alto Laboatory, Inc., USA)</span><span><span class="author">P. Qvarfordt</span> (FX Palo Alto Laboatory, Inc., USA)</span></div>
<p><span class="cbStatement">An experiment to test the effects of halos on query length was conducted. Results suggest that the interface may be effective for eliciting longer queries.  </span><span class="abstract">Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries.  </span></li>
<li id="PDH"class="presentation "><a href="http://chi2013.acm.org/previews/#PDH"><span class="letterCode" style="float:right">PDH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDH">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470658">Quantifying the Invisible Audience in Social Networks</a></span><br />
<span class="authors">M. Bernstein (Stanford Univ., USA), E. Bakshy, M. Burke, B. Karrer</span>
<div class="authorList"><span><span class="author">M. Bernstein</span> (Stanford Univ., USA)</span><span><span class="author">E. Bakshy</span> (Facebook, Inc., USA)</span><span><span class="author">M. Burke</span> (Facebook, Inc., USA)</span><span><span class="author">B. Karrer</span> (Facebook, Inc., USA)</span></div>
<p><span class="cbStatement">When you share content in a social network, who is listening? We combine survey and log data to examine how well users&#8217; audience perceptions match their true audience on Facebook.</span><span class="abstract">When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users&#8217; perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users&#8217; posts over the course of one month and find that publicly visible signals &#8212; friend count, likes, and comments &#8212; vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.</span></li>
<li id="PTD"class="presentation "><a href="http://chi2013.acm.org/previews/#PTD"><span class="letterCode" style="float:right">PTD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTD">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466228">Squaring the Circle: How Framing Influences User Behavior around a Seamless Cylindrical Display</a></span><br />
<span class="authors">G. Beyer (Univ. of Munich (LMU), DE), F. Köttner, M. Schiewe, I. Haulsen, A. Butz</span>
<div class="authorList"><span><span class="author">G. Beyer</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">F. Köttner</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">M. Schiewe</span> (Fraunhofer FOKUS, DE)</span><span><span class="author">I. Haulsen</span> (Fraunhofer FOKUS, DE)</span><span><span class="author">A. Butz</span> (Univ. of Munich (LMU), DE)</span></div>
<p><span class="cbStatement">Analyzes user behavior around a cylindrical and seamless interactive column display in the wild. Helps to better understand how framing influences user positions around more complex non-planar display shapes.</span><span class="abstract">Recent research has presented large public displays in novel non-flat shapes such as spheres, curved planes and cylinders, and looked at the influence of the form factor on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting the behavior of passers-by around such displays. In this paper we investigate two further display factors, framedness and seamlessness, that have to be considered in conjunction with the form factor to understand user behavior in front of large non-flat displays. We present the findings from a field study with an interactive column display and take a closer look at how these factors influence actor and bystander behavior. Our results show that rectangular frames act as a sort of funnel for user position and can easily override effects of the non-flat shape on user position and interaction, even though the users didn’t recall the presence of these frames.</span></li>
<li id="PJK"class="presentation engineering"><a href="http://chi2013.acm.org/previews/#PJK"><span class="letterCode" style="float:right">PJK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJK">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470757">GravitySpace: Tracking Users and Their Poses in a Smart Room Using a Pressure-Sensing Floor</a></span><br />
<span class="authors">A. Bränzel (Hasso Plattner Institute, DE), C. Holz, D. Hoffmann, D. Schmidt, M. Knaust, P. Lühne, R. Meusel, S. Richter, P. Baudisch</span>
<div class="authorList"><span><span class="author">A. Bränzel</span> (Hasso Plattner Institute, DE)</span><span><span class="author">C. Holz</span> (Hasso Plattner Institute, DE)</span><span><span class="author">D. Hoffmann</span> (Hasso Plattner Institute, DE)</span><span><span class="author">D. Schmidt</span> (Hasso Plattner Institute, DE)</span><span><span class="author">M. Knaust</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Lühne</span> (Hasso Plattner Institute, DE)</span><span><span class="author">R. Meusel</span> (Hasso Plattner Institute, DE)</span><span><span class="author">S. Richter</span> (Hasso Plattner Institute, DE)</span><span><span class="author">P. Baudisch</span> (Hasso Plattner Institute, DE)</span></div>
<p><span class="cbStatement">Introduces new approach to tracking people and objects in smart rooms based on a high-resolution pressure-sensitive floor. Provides consistent wall-to-wall coverage, is less susceptible and less privacy-critical than camera-based systems.</span><span class="abstract">We explore how to track people and furniture based on a high-resolution pressure-sensitive floor. Gravity pushes people and objects against the floor, causing them to leave imprints of pressure distributions across the surface. While the sensor is limited to sensing direct contact with the surface, we can sometimes conclude what takes place above the surface, such as users’ poses or collisions with virtual objects. We demonstrate how to extend the range of this approach by sensing through passive furniture that propagates pressure to the floor. To explore our approach, we have created an 8 m2 back-projected floor prototype, termed GravitySpace, a set of passive touch-sensitive furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based sensing on the floor offers four potential benefits over camera-based solutions: (1) it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to occlusion between users, (3) allows for the use of simpler recognition algorithms, and (4) intrudes less on users’ privacy.</span></li>
<li id="PRK"class="presentation design"><a href="http://chi2013.acm.org/previews/#PRK"><span class="letterCode" style="float:right">PRK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PRK">Wed. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481348">Digital Portraits: Photo-sharing After Domestic Violence</a></span><br />
<span class="authors">R. Clarke (Newcastle Univ., UK), P. Wright, M. Balaam, J. McCarthy</span>
<div class="authorList"><span><span class="author">R. Clarke</span> (Newcastle Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">M. Balaam</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span></div>
<p><span class="cbStatement">Taking a feminist arts action research approach, we detail an account of engaging women in photo-sharing who have had experiences of domestic violence, in the early stages of longitudinal participatory research.</span><span class="abstract">This paper explores the potential role of photography in re-building of lives after domestic violence. We worked in the context of a women’s centre where women are accessing support after leaving abusive relationships. The paper contributes a feminist participatory arts action research approach to studying photo-sharing practices and helps to frame an understanding of the ongoing tensions in the construction of self with others that the women experience. We argue that the affirmation of new bonds, control in sharing the process of ‘moving on’, and supporting discursive negotiations of privacy are important considerations for design focused on interpersonal social processes around the use of digital technology.</span></li>
<li id="NRU"class="presentation "><a href="http://chi2013.acm.org/previews/#NRU"><span class="letterCode" style="float:right">NRU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NRU">Wed. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481331">Using Fake Cursors to Secure On-Screen Password Entry</a></span><br />
<span class="authors">A. De Luca (Univ. of Munich (LMU), DE), E. von Zezschwitz, L. Pichler, H. Hussmann</span>
<div class="authorList"><span><span class="author">A. De Luca</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">E. von Zezschwitz</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">L. Pichler</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">H. Hussmann</span> (Univ. of Munich (LMU), DE)</span></div>
<p><span class="cbStatement">Presents a system that uses fake cursors to secure password entry on on-screen keyboards. An evaluation of the system shows that shoulder surfing resistance is significantly improved.</span><span class="abstract">In this paper, we present a concept using fake cursors to disguise on-screen password entry. We performed two user studies with different amounts of dummy cursors and differently colored cursors. The results show that dummy cursors significantly improve security. At the same time, decrease in performance is kept within an acceptable range. Depending on the required degree of security, the studies favor 8 or 16 differently colored cursors as the best trade-off between security and usability.</span></li>
<li id="PRV"class="presentation "><a href="http://chi2013.acm.org/previews/#PRV"><span class="letterCode" style="float:right">PRV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PRV">Wed. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481330">Back-of-Device Authentication on Smartphones</a></span><br />
<span class="authors">A. De Luca (Univ. of Munich (LMU), DE), E. von Zezschwitz, N. Nguyen, M. Maurer, E. Rubegni, M. Scipioni, M. Langheinrich</span>
<div class="authorList"><span><span class="author">A. De Luca</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">E. von Zezschwitz</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">N. Nguyen</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">M. Maurer</span> (Univ. of Munich (LMU), DE)</span><span><span class="author">E. Rubegni</span> (Univ. of Lugano, CH)</span><span><span class="author">M. Scipioni</span> (Univ. of Lugano, CH)</span><span><span class="author">M. Langheinrich</span> (Univ. of Lugano, CH)</span></div>
<p><span class="cbStatement">Presents a system that uses gestures on the back of a mobile device to authenticate. Shoulder surfing resistance is significantly improved while remaining reasonably fast and easy to use.</span><span class="abstract">This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.</span></li>
<li id="PQP"class="presentation design ux arts"><a href="http://chi2013.acm.org/previews/#PQP"><span class="letterCode" style="float:right">PQP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQP">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466133">AnyType: Provoking Reflection and Exploration with Aesthetic Interaction</a></span><br />
<span class="authors">L. Devendorf (Univ. of California, Berkeley, USA), K. Ryokai</span>
<div class="authorList"><span><span class="author">L. Devendorf</span> (Univ. of California, Berkeley, USA)</span><span><span class="author">K. Ryokai</span> (Univ. of California, Berkeley, USA)</span></div>
<p><span class="cbStatement">AnyType generates unique typefaces from photographs of shapes people find in their environment. In keeping with the principles of aesthetic interaction, AnyType supports opportunities for surprise, storytelling, and expression.</span><span class="abstract">AnyType is a mobile application that generates unique typefaces from photographs of shapes that people find in their environment. In keeping with the principles of aesthetic interaction, the design of AnyType supports opportunities for surprise, storytelling, and expression. This paper presents data collected from two observational studies of AnyType. In both studies, we found that people appropriated the application to create highly personalized messages. They found inspiration in unexpected locations, created memories from nuanced details in their lives, and creatively explored the design space provided by the system. Drawing from our observations, we discuss possible roles mobile devices could play in people’s personal meaning making, creative process, and discovery, in interaction with elements of their physical environment.</span></li>
<li id="PGE"class="presentation "><a href="http://chi2013.acm.org/previews/#PGE"><span class="letterCode" style="float:right">PGE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGE">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466250">The Effects of Tactile Feedback and Movement Alteration on Interaction and Awareness with Digital Embodiments</a></span><br />
<span class="authors">A. Doucette (Univ. of Saskatchewan, CA), R. Mandryk, C. Gutwin, M. Nacenta, A. Pavlovych</span>
<div class="authorList"><span><span class="author">A. Doucette</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">R. Mandryk</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">M. Nacenta</span> (Univ. of St Andrews, UK)</span><span><span class="author">A. Pavlovych</span> (Univ. of Saskatchewan, CA)</span></div>
<p><span class="cbStatement">Presents and evaluates methods for affecting group behaviour in tabletop groupware by providing cues of physical boundaries in digital space.</span><span class="abstract">Collaborative tabletop systems can employ direct touch, where people’s real arms and hands manipulate objects, or indirect input, where people are represented on the table with digital embodiments. The input type and the resulting embodiment dramatically influence tabletop interaction: in particular, the touch avoidance that naturally governs people’s touching and crossing behavior with physical arms is lost with digital embodiments. One result of this loss is that people are less aware of each others’ arms, and less able to coordinate actions and protect personal territories. To determine whether there are strategies that can influence group interaction on shared digital tabletops, we studied augmented digital arm embodiments that provide tactile feedback or movement alterations when people touched or crossed arms. The study showed that both augmentation types changed people’s behavior (people crossed less than half as often) and also changed their perception (people felt more aware of the other person’s arm, and felt more awkward when touching). This work shows how groupware designers can influence people’s interaction, awareness, and coordination abilities when physical constraints are absent.</span></li>
<li id="NDF"class="presentation "><a href="http://chi2013.acm.org/previews/#NDF"><span class="letterCode" style="float:right">NDF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NDF">Mon. 2pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470703">Age-Related Differences in Performance with Touchscreens Compared to Traditional Mouse Input</a></span><br />
<span class="authors">L. Findlater (Univ. of Maryland, USA), J. Froehlich, K. Fattal, J. Wobbrock, T. Dastyar</span>
<div class="authorList"><span><span class="author">L. Findlater</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Froehlich</span> (Univ. of Maryland, USA)</span><span><span class="author">K. Fattal</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Wobbrock</span> (Univ. of Washington, USA)</span><span><span class="author">T. Dastyar</span> (Univ. of Maryland, USA)</span></div>
<p><span class="cbStatement">We compared performance of older and younger adults on a range of desktop and touchscreen tasks. The touchscreen reduced the performance gap between the two groups relative to the desktop. </span><span class="abstract">Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35% over the mouse for older adults, compared to only 16% for younger adults. Error rates also decreased.</span></li>
<li id="PGD"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#PGD"><span class="letterCode" style="float:right">PGD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PGD">Wed. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481385">Gestures and Widgets: Performance in Text Editing on Multi-Touch Capable Mobile Devices</a></span><br />
<span class="authors">V. Fuccella (Univ. di Salerno, IT), P. Isokoski, B. Martin</span>
<div class="authorList"><span><span class="author">V. Fuccella</span> (Univ. di Salerno, IT)</span><span><span class="author">P. Isokoski</span> (Univ. of Tampere, FI)</span><span><span class="author">B. Martin</span> (Univ. de Lorraine, FR)</span></div>
<p><span class="cbStatement">We present the design and evaluation of a gestural text editing technique for touchscreens.   Gestures drawn on the soft keyboard are often faster than conventional editing techniques.</span><span class="abstract">We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.</span></li>
<li id="PSE"class="presentation "><a href="http://chi2013.acm.org/previews/#PSE"><span class="letterCode" style="float:right">PSE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PSE">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466443">Evaluation of Alternative Glyph Designs for Time Series Data in a Small Multiple Setting</a></span><br />
<span class="authors">J. Fuchs (Univ., DE), F. Fischer, F. Mansmann, E. Bertini, P. Isenberg</span>
<div class="authorList"><span><span class="author">J. Fuchs</span> (Univ., DE)</span><span><span class="author">F. Fischer</span> (Univ., DE)</span><span><span class="author">F. Mansmann</span> (Univ., DE)</span><span><span class="author">E. Bertini</span> (Univ., USA)</span><span><span class="author">P. Isenberg</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">1. Evaluation of alternative glyph designs for time series data.  2. Design considerations and guidelines for creating glyphs for time series data. </span><span class="abstract">We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting.  Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature.  Among these, iconic displays or glyphs are an appropriate choice   because of their expressiveness and effective use of screen space.  Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point.   Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.</span></li>
<li id="PTB"class="presentation design"><a href="http://chi2013.acm.org/previews/#PTB"><span class="letterCode" style="float:right">PTB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PTB">Wed. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481395">Materials, Materiality, and Media</a></span><br />
<span class="authors">V. Fuchsberger (Univ. of Salzburg, AT), M. Murer, M. Tscheligi</span>
<div class="authorList"><span><span class="author">V. Fuchsberger</span> (Univ. of Salzburg, AT)</span><span><span class="author">M. Murer</span> (Univ. of Salzburg, AT)</span><span><span class="author">M. Tscheligi</span> (Univ. of Salzburg, AT)</span></div>
<p><span class="cbStatement">Reflects on Marshall McLuhan’s media analysis, as well as Bruno Latour’s Actor-Network Theory regarding materials in HCI interaction design. Presents transferred ideas and junctures for the materiality discourse. </span><span class="abstract">In HCI, and especially in interaction design, the material aspect of interactions is currently emphasized. Nevertheless, it is challenging to theoretically frame the variety of digital or immaterial, and physical materials. In order to contribute to this materiality discourse, we reflect on McLuhan’s work on media analysis and on Latour’s Actor-Network Theory in this paper. Both emphasize the active role of the material – be it media or any other kind of non-human actors – in the interplay with the human. Thus, we establish junctures between their findings and materials, as used in interaction design in HCI. We discuss McLuhan’s claim to focus on new sensory effects and ways of interaction brought forth by new media. Furthermore, we illustrate how describing the connections between materials, designers, and users in terms of Latour’s Actor-Networks can be beneficial for interaction design. Finally, we discuss the respective methodology and its relation to research through design.</span></li>
<li id="PLG"class="presentation design ux sustainability"><a href="http://chi2013.acm.org/previews/#PLG"><span class="letterCode" style="float:right">PLG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PLG">Thu. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466474">Indoor Weather Stations: Investigating a Ludic Approach to Environmental HCI Through Batch Prototyping</a></span><br />
<span class="authors">W. Gaver (Goldsmiths, Univ. of London, UK), J. Bowers, K. Boehner, A. Boucher, D. Cameron, M. Hauenstein, N. Jarvis, S. Pennington</span>
<div class="authorList"><span><span class="author">W. Gaver</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">J. Bowers</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">K. Boehner</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">A. Boucher</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">D. Cameron</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">M. Hauenstein</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">N. Jarvis</span> (Goldsmiths, Univ. of London, UK)</span><span><span class="author">S. Pennington</span> (Goldsmiths, Univ. of London, UK)</span></div>
<p><span class="cbStatement">Three ‘weatherstations’, designed to take a ludic approach to environmental issues, were deployed to twenty households. The result is a distinctive example of environmental HCI, batch production, and ludic design.</span><span class="abstract">In this project, we investigated how a ludic approach might open new possibilities for environmental HCI by designing three related devices that encourage environmental awareness while eschewing utilitarian or persuasive agendas. In addition, we extended our methodological approach by batch-producing multiple copies of each device and deploying them to 20 households for several months, gathering a range of accounts about how people engaged and used them.  The devices, collectively called the ‘Indoor Weather Stations’, reveal the home’s microclimate by highlighting small gusts of wind, the colour of ambient light, and temperature differentials within the home. We found that participants initially tended to relate to the devices in line with two ‘orienting narratives’ of environmental tools or ludic designs, finding the devices disappointing from either perspective. Most of our participants showed lingering affection for the devices, however, for a variety of reasons. We discuss the implications of this ‘sporadic interaction’, and the more general lessons from the project, both for environmental HCI and ludic design. </span></li>
<li id="PAE"class="presentation design"><a href="http://chi2013.acm.org/previews/#PAE"><span class="letterCode" style="float:right">PAE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PAE">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466240">Digital Artifacts as Legacy: Exploring the Lifespan and Value of Digital Data</a></span><br />
<span class="authors">R. Gulotta (Carnegie Mellon Univ., USA), W. Odom, H. Faste, J. Forlizzi</span>
<div class="authorList"><span><span class="author">R. Gulotta</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">W. Odom</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">H. Faste</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Forlizzi</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We designed interactive systems to investigate how digital materials might be passed down. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. </span><span class="abstract">Legacy is the meaningful and complex way in which information, values, and possessions are passed on to others. As digital systems and information become meaningfully parts of people’s everyday and social relationships, it is essential to develop new insights about how technology intersects with legacy and inheritance practices. We designed three interactive systems to investigate how digital materials might be passed down in the future. We conducted in-home interviews with ten parents using the systems to provoke discussion about how technology might support or complicate their existing practices. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Findings are interpreted to describe design considerations for future work in this emerging space.  </span></li>
<li id="PKG"class="presentation "><a href="http://chi2013.acm.org/previews/#PKG"><span class="letterCode" style="float:right">PKG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PKG">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466134">Stories of the Smartphone in Everyday Discourse: Conflict, Tension &#038; Instability</a></span><br />
<span class="authors">E. Harmon (Univ. of California, Irvine, USA), M. Mazmanian</span>
<div class="authorList"><span><span class="author">E. Harmon</span> (Univ. of California, Irvine, USA)</span><span><span class="author">M. Mazmanian</span> (Univ. of California, Irvine, USA)</span></div>
<p><span class="cbStatement">This analysis of popular stories about the smartphone highlights three areas of conflict, tension and instability relevant to the relationships among values, mobile ICTs, user experience, and everyday practice.</span><span class="abstract">As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.</span></li>
<li id="PLP"class="presentation games cci"><a href="http://chi2013.acm.org/previews/#PLP"><span class="letterCode" style="float:right">PLP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PLP">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470667">In Search of Learning: Facilitating Data Analysis in Educational Games</a></span><br />
<span class="authors">E. Harpstead (Carnegie Mellon Univ., USA), B. Myers, V. Aleven</span>
<div class="authorList"><span><span class="author">E. Harpstead</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">B. Myers</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">V. Aleven</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present a toolkit and methodology for recording and analyzing player log data in educational games, that allows game designers and researches multiple ways to explore student learning.</span><span class="abstract">The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students’ performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game’s environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.</span></li>
<li id="PQR"class="presentation ux"><a href="http://chi2013.acm.org/previews/#PQR"><span class="letterCode" style="float:right">PQR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PQR">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481282">Love it or Hate it!  Interactivity and User Types</a></span><br />
<span class="authors">J. Hart (The Univ. of Manchester, UK), A. Sutcliffe, A. De Angeli</span>
<div class="authorList"><span><span class="author">J. Hart</span> (The Univ. of Manchester, UK)</span><span><span class="author">A. Sutcliffe</span> (The Univ. of Manchester, UK)</span><span><span class="author">A. De Angeli</span> (Univ. of Trento, IT)</span></div>
<p><span class="cbStatement">Demonstrates a mixed methods approach that identifies the importance of interactivity and repeated exposure in positively influencing UX and shows that different levels of UX can be explained through use types</span><span class="abstract">This paper investigates general and individual evaluations of User Experience (UX) with interactive web sites. A series of studies investigate user judgment on web sites with different interactivity levels over repeated exposures. The more interactive websites produced more positive affect, had better design quality ratings, which improved with exposure, and were preferred. Differences between the more interactive sites indicated overall UX was influenced by users’ preferences for interactive styles, with both sites having enthusiast, potential adopter, and non-adopter users. The implications for models and frameworks of UX are discussed.  </span></li>
<li id="PAG"class="presentation ux"><a href="http://chi2013.acm.org/previews/#PAG"><span class="letterCode" style="float:right">PAG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAG">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481286">Extracting Usability and User Experience Information from Online User Reviews</a></span><br />
<span class="authors">S. Hedegaard (Univ. of Copenhagen, DK), J. Simonsen</span>
<div class="authorList"><span><span class="author">S. Hedegaard</span> (Univ. of Copenhagen, DK)</span><span><span class="author">J. Simonsen</span> (Univ. of Copenhagen, DK)</span></div>
<p><span class="cbStatement">We chart the occurrences of usability and user experience dimensions and their associated vocabulary found in online reviews of software and video games.    </span><span class="abstract">Internet review sites allow consumers to write detailed reviews  of products potentially containing information related  to user experience (UX) and usability. Using 5198 sentences  from 3492 online reviews of software and video games, we  investigate the content of online reviews with the aims of (i)  charting the distribution of information in reviews among different  dimensions of usability and UX, and (ii) extracting an  associated vocabulary for each dimension using techniques  from natural language processing and machine learning.     We (a) find that 13%–49% of sentences in our online reviews pool  contain usability or UX information; (b) chart the distribution  of four sets of dimensions of usability and UX across  reviews from two product categories; (c) extract a catalogue  of important word stems for a number of dimensions.     Our results suggest that a greater understanding of users’ preoccupation  with different dimensions of usability and UX may be  inferred from the large volume of self-reported experiences  online, and that research focused on identifying pertinent dimensions  of usability and UX may benefit further from empirical  studies of user-generated experience reports.</span></li>
<li id="PBD"class="presentation games cci"><a href="http://chi2013.acm.org/previews/#PBD"><span class="letterCode" style="float:right">PBD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBD">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466164">Designing Action-based Exergames for Children with Cerebral Palsy</a></span><br />
<span class="authors">H. Hernandez (Queen&#8217;s Univ., CA), Z. Ye, T. Graham, D. Fehlings, L. Switzer</span>
<div class="authorList"><span><span class="author">H. Hernandez</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">Z. Ye</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">T. Graham</span> (Queen&#8217;s Univ., CA)</span><span><span class="author">D. Fehlings</span> (Holland Bloorview Kids Rehabilitation Hospital, CA)</span><span><span class="author">L. Switzer</span> (Holland Bloorview Kids Rehabilitation Hospital, CA)</span></div>
<p><span class="cbStatement">We present guidelines for the design of action-oriented exergames for people with motor disabilities. These preserve the core message of traditional guidelines, while mitigating their push to slow-paced gameplay.</span><span class="abstract">Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames similar to those played by their peers without motor disabilities. This is particularly true of exergames, whose physically-active gameplay matches the fast pace of action games. But disabilities resulting from CP can make it difficult to play action games. Guidelines for developing games for people with motor disabilities steer away from high-paced action, including recommendations to avoid the need for time-sensitive actions and to keep game pace slow. Through a year-long participatory design process with children with CP, we have discovered that it is in fact possible to develop action-oriented exergames for children with CP at level III on the Gross Motor Function Classification Scale. We followed up the design process with an eight-week home trial, in which we found the games to be playable and enjoyable. In this paper, we discuss the design of these games, and present a set of design recommendations for how to achieve both action-orientation and playability.</span></li>
<li id="PSH"class="presentation cci"><a href="http://chi2013.acm.org/previews/#PSH"><span class="letterCode" style="float:right">PSH</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PSH">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466438">Evaluation of Tablet Apps to Encourage Social Interaction in Children with Autism Spectrum Disorders</a></span><br />
<span class="authors">J. Hourcade (Univ. of Iowa, USA), S. Williams, E. Miller, K. Huebner, L. Liang</span>
<div class="authorList"><span><span class="author">J. Hourcade</span> (Univ. of Iowa, USA)</span><span><span class="author">S. Williams</span> (Univ. of Iowa, USA)</span><span><span class="author">E. Miller</span> (Univ. of Iowa, USA)</span><span><span class="author">K. Huebner</span> (Univ. of Iowa, USA)</span><span><span class="author">L. Liang</span> (Univ. of Iowa, USA)</span></div>
<p><span class="cbStatement">Comparison of app-based and paper-based activities by children with autism spectrum disorders. Using the apps was associated with increased verbal communication, physical interaction, and supportive comments.</span><span class="abstract">The increasing rates of diagnosis for Autism Spectrum Disorders (ASDs) have brought unprecedented attention to these conditions. Interventions during childhood can increase the likelihood of independent living later in life, but most adults with ASDs who benefited from early intervention do not live independently. There is a need for novel therapies and interventions that can help children with ASDs develop the social skills necessary to live independently. Since the launch of the iPad, there has been a great deal of excitement in the autism community about multitouch tablets and their possible use in interventions. There are hundreds of apps listed as possibly helping children with ASDs, yet there is little empirical evidence that any of them have positive effects. In this paper we present a study on the use of a set of apps from Open Autism Software at an afterschool program for children with ASDs. The apps are designed to naturally encourage positive social interactions through creative, expressive, and collaborative activities. The study compared activities conducted with the apps to similar activities conducted without the apps. We video recorded the activities, and coded children’s behavior. We found that during the study children spoke more sentences, had more verbal interactions, and were more physically engaged with the activities when using the apps. We also found that children made more supportive comments during activities conducted with two of the apps. The results suggest the approach to using apps evaluated in this paper can increase positive social interactions in children with ASDs.</span></li>
<li id="PEM"class="presentation engineering ux"><a href="http://chi2013.acm.org/previews/#PEM"><span class="letterCode" style="float:right">PEM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PEM">Thu. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466478">Whoo.ly: Facilitating Information Seeking For Hyperlocal Communities Using Social Media</a></span><br />
<span class="authors">Y. Hu (Arizona State Univ., USA), S. Farnham, A. Monroy-Hernández</span>
<div class="authorList"><span><span class="author">Y. Hu</span> (Arizona State Univ., USA)</span><span><span class="author">S. Farnham</span> (Microsoft Research, USA)</span><span><span class="author">A. Monroy-Hernández</span> (Microsoft Research, USA)</span></div>
<p><span class="cbStatement">We present Whoo.ly, an extraction service for hyperlocal information: events, topics, people and places; from neighborhood-specific tweets. We demonstrate that users prefer its use for neighborhood exploration over competing approaches.  </span><span class="abstract">Social media systems promise powerful opportunities for people to connect to timely, relevant information at the hyper local level. Yet, finding the meaningful signal in noisy social media streams can be quite daunting to users. In this paper, we present and evaluate Whoo.ly, a web service that provides neighborhood-specific information based on Twitter posts that were automatically inferred to be hyperlocal. Whoo.ly automatically extracts and summarizes hyperlocal information about events, topics, people, and places from these Twitter posts. We provide an overview of our design goals with Whoo.ly and describe the system including the user interface and our unique event detection and summarization algorithms. We tested the usefulness of the system as a tool for finding neighborhood information through a comprehensive user study. The outcome demonstrated that most participants found Whoo.ly easier to use than Twitter and they would prefer it as a tool for exploring their neighborhoods.</span></li>
<li id="PDS"class="presentation games"><a href="http://chi2013.acm.org/previews/#PDS"><span class="letterCode" style="float:right">PDS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PDS">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470753">Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo</a></span><br />
<span class="authors">J. Huang (Univ. of Washington, USA), T. Zimmermann, N. Nagapan, C. Harrison, B. Phillips</span>
<div class="authorList"><span><span class="author">J. Huang</span> (Univ. of Washington, USA)</span><span><span class="author">T. Zimmermann</span> (Microsoft Research, USA)</span><span><span class="author">N. Nagapan</span> (Microsoft Research, USA)</span><span><span class="author">C. Harrison</span> (Microsoft, USA)</span><span><span class="author">B. Phillips</span> (Microsoft, USA)</span></div>
<p><span class="cbStatement">We look at patterns of skill through large-scale gameplay analysis and player surveys to identify how different factors (play intensity, skill change over time, demographics, breaks, and prior games played) affect players&#8217; skill in Halo.</span><span class="abstract">How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call &#8220;Master Blasters&#8221;, have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players&#8217; self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.</span></li>
<li id="PGJ"class="presentation design engineering"><a href="http://chi2013.acm.org/previews/#PGJ"><span class="letterCode" style="float:right">PGJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PGJ">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466431">Canyon: Providing Location Awareness of Multiple Moving Objects in a Detail View on Large Displays</a></span><br />
<span class="authors">A. Ion (Univ. of Applied Sciences Upper Austria, AT), Y. Chang, M. Haller, M. Hancock, S. Scott</span>
<div class="authorList"><span><span class="author">A. Ion</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">Y. Chang</span> (Univ. of Waterloo, CA)</span><span><span class="author">M. Haller</span> (Univ. of Applied Sciences Upper Austria, AT)</span><span><span class="author">M. Hancock</span> (Univ. of Waterloo, CA)</span><span><span class="author">S. Scott</span> (Univ. of Waterloo, CA)</span></div>
<p><span class="cbStatement">A novel interaction technique, Canyon, was implemented and evaluated addressing the problem of data exiting a person&#8217;s field of view on large displays. Results indicate higher accuracy and comparable speed.</span><span class="abstract">Overview+Detail interfaces can be used to examine the details of complex data while retaining the data&#8217;s overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person’s field of view if they are working at a large interactive surface. To address this &#8220;off-view&#8221; problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually &#8220;folded&#8221; to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.</span></li>
<li id="PST"class="presentation design engineering ux health"><a href="http://chi2013.acm.org/previews/#PST"><span class="letterCode" style="float:right">PST</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PST">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466137">Echoes From the Past: How Technology Mediated Reflection Improves Well-Being</a></span><br />
<span class="authors">E. Isaacs (Palo Alto Research Center (PARC), USA), A. Konrad, A. Walendowski, T. Lennig, V. Hollis, S. Whittaker</span>
<div class="authorList"><span><span class="author">E. Isaacs</span> (Palo Alto Research Center (PARC), USA)</span><span><span class="author">A. Konrad</span> (Univ. of California, Santa Cruz, Santa Cruz)</span><span><span class="author">A. Walendowski</span> (Samsung Research America, USA)</span><span><span class="author">T. Lennig</span> (Univ. of California at Santa Cruz , USA)</span><span><span class="author">V. Hollis</span> (Univ. of California at Santa Cruz , USA)</span><span><span class="author">S. Whittaker</span> (Univ. of California at Santa Cruz, USA)</span></div>
<p><span class="cbStatement">We explored technology mediated reminiscence (TMR) by building Echo, a novel smartphone application for recording and reflecting on everyday experiences. Three deployments with 44 users show TMR improves well-being.</span><span class="abstract">As people document more of their lives online, some recent systems are encouraging people to later revisit those recordings, a practice we’re calling technology-mediated reflection (TMR). Since we know that unmediated reflection benefits psychological well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone application for recording everyday experiences and reflecting on them later. We conducted three system deployments with 44 users who generated over 12,000 recordings and reflections. We found that TMR improves well-being as assessed by four psychological metrics. By analyzing the content of these entries we discovered two mechanisms that explain this improvement. We also report benefits of very long-term TMR.</span></li>
<li id="PMV"class="presentation "><a href="http://chi2013.acm.org/previews/#PMV"><span class="letterCode" style="float:right">PMV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PMV">Wed. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481397">Infrastructure and Vocation: Field, Calling, and Computation in Ecology</a></span><br />
<span class="authors">S. Jackson (Cornell Univ., USA), S. Barbrow</span>
<div class="authorList"><span><span class="author">S. Jackson</span> (Cornell Univ., USA)</span><span><span class="author">S. Barbrow</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">Ethnographic study exploring relationship between computational change and ecology as a vocation. Argues that new computational development remediates ecology&#8217;s crucial field relations, with implications for design and engagement.</span><span class="abstract">HCI studies of computational change in the sciences have made important design and analytic contributions, to other fields of science and to HCI itself. But some of the longer-term effects and complexities of infrastructural change in the sciences aren’t easily captured under short-term, design- or artifact-centered accounts. Drawing on extended ethnographic study of computational development in ecology, this paper explores the relationship between new computational infrastructure and the nature of ecology as a vocation: roughly, the deeply held sense of what it means to ‘be’ an ecologist, and to ‘do’ ecology. We analyze in particular the nature of the field and field work as a central site of ecological practice and identity; how new computational developments are remediating this crucial relation; and the emergent vocational values that new and more computationally-intensive forms of ecology may give rise to.</span></li>
<li id="PJB"class="presentation sustainability arts"><a href="http://chi2013.acm.org/previews/#PJB"><span class="letterCode" style="float:right">PJB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PJB">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470673">A Conversation Between Trees: What Data Feels Like In The Forest</a></span><br />
<span class="authors">R. Jacobs (The Univ. of Nottingham, UK), S. Benford, M. Selby, M. Golembewski, D. Price, G. Giannachi</span>
<div class="authorList"><span><span class="author">R. Jacobs</span> (The Univ. of Nottingham, UK)</span><span><span class="author">S. Benford</span> (The Univ. of Nottingham, UK)</span><span><span class="author">M. Selby</span> (The Univ. of Nottingham, UK)</span><span><span class="author">M. Golembewski</span> (The Univ. of Nottingham, UK)</span><span><span class="author">D. Price</span> (The Univ. of Nottingham, UK)</span><span><span class="author">G. Giannachi</span> (The Univ. of Exeter, UK)</span></div>
<p><span class="cbStatement">Study of an environmentally engaged artwork reveals how artists’ strategies of embodying, performing and juxtaposing different views of climate data fostered emotional engagement and interpretation among visitors.</span><span class="abstract">A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.</span></li>
<li id="NTQ"class="presentation design engineering games"><a href="http://chi2013.acm.org/previews/#NTQ"><span class="letterCode" style="float:right">NTQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NTQ">Thu. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466422">Picode: Inline Photos Representing Posture Data in Source Code</a></span><br />
<span class="authors">J. Kato (The Univ. of Tokyo, JP), D. Sakamoto, T. Igarashi</span>
<div class="authorList"><span><span class="author">J. Kato</span> (The Univ. of Tokyo, JP)</span><span><span class="author">D. Sakamoto</span> (The Univ. of Tokyo, JP)</span><span><span class="author">T. Igarashi</span> (The Univ. of Tokyo, JP)</span></div>
<p><span class="cbStatement">Picode is a text-based development environment augmented with inline photos of human and robots. They contain richer context information than mere posture data, and enhance the programming experience.</span><span class="abstract">Current programming environments use textual or symbolic representations. While these representations are appropriate for describing logical processes, they are not appropriate for representing raw values such as human and robot posture data, which are necessary for handling gesture input and controlling robots. To address this issue, we propose Picode, a text-based development environment integrated with visual representations: photos of human and robots. With Picode, the user first takes a photo to bind it to posture data. S/he then drag-and-drops the photo into the code editor, where it is displayed as an inline image. A preliminary in-house user study implied positive effects of taking photos on the programming experience.</span></li>
<li id="PNT"class="presentation cci"><a href="http://chi2013.acm.org/previews/#PNT"><span class="letterCode" style="float:right">PNT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNT">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466130">Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment</a></span><br />
<span class="authors">A. Kharrufa (Newcastle Univ., UK), M. Balaam, P. Heslop, D. Leat, P. Dolan, P. Olivier</span>
<div class="authorList"><span><span class="author">A. Kharrufa</span> (Newcastle Univ., UK)</span><span><span class="author">M. Balaam</span> (Newcastle Univ., UK)</span><span><span class="author">P. Heslop</span> (Newcastle Univ., UK)</span><span><span class="author">D. Leat</span> (Newcastle Univ., UK)</span><span><span class="author">P. Dolan</span> (Northumbria Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">The paper presents the analysis of our observations and design recommendations for multi-tabletop applications designed for and deployed within a realistic classroom setting.</span><span class="abstract">This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg’s orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its ‘in-the-wild’ character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI’s current design understandings of such settings. </span></li>
<li id="PHY"class="presentation engineering"><a href="http://chi2013.acm.org/previews/#PHY"><span class="letterCode" style="float:right">PHY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHY">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470733">TapBoard: Making a Touch Screen Keyboard More Touchable</a></span><br />
<span class="authors">S. Kim (KAIST (Korea Advanced Institute of Science and Technology), KR), J. Son, G. Lee, H. Kim, W. Lee</span>
<div class="authorList"><span><span class="author">S. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">J. Son</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">G. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">H. Kim</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span><span><span class="author">W. Lee</span> (KAIST (Korea Advanced Institute of Science and Technology), KR)</span></div>
<p><span class="cbStatement">TapBoard is a touch screen software keyboard that regards tapping actions as keystrokes and enables other touches for more useful operations; such as resting, feeling surface textures, and making gestures.</span><span class="abstract">A physical keyboard key has three states, whereas a touch screen usually has only two. Due to this difference, the state corresponding to the touched state of a physical key is missing in a touch screen keyboard. This touched state is an important factor in the usability of a keyboard. In order to recover the role of a touched state in a touch screen, we propose the TapBoard, a touch screen software keyboard that regards tapping actions as keystrokes and other touches as the touched state. In a series of user studies, we validate the effectiveness of the TapBoard concept. First, we show that tapping to type is in fact compatible with the existing typing skill of most touch screen keyboard users. Second, users quickly adapt to the TapBoard and learn to rest their fingers in the touched state. Finally, we confirm by a controlled experiment that there is no difference in text-entry performance between the TapBoard and a traditional touch screen software keyboard. In addition to these experimental results, we demonstrate a few new interaction techniques that will be made possible by the TapBoard.</span></li>
<li id="PAU"class="presentation "><a href="http://chi2013.acm.org/previews/#PAU"><span class="letterCode" style="float:right">PAU</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PAU">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466419">How Tools in IDEs Shape Developers&#8217; Navigation Behavior</a></span><br />
<span class="authors">J. Krämer (RWTH Aachen Univ., DE), T. Karrer, J. Kurz, M. Wittenhagen, J. Borchers</span>
<div class="authorList"><span><span class="author">J. Krämer</span> (RWTH Aachen Univ., DE)</span><span><span class="author">T. Karrer</span> (RWTH Aachen Univ., DE)</span><span><span class="author">J. Kurz</span> (RWTH Aachen Univ., DE)</span><span><span class="author">M. Wittenhagen</span> (RWTH Aachen Univ., DE)</span><span><span class="author">J. Borchers</span> (RWTH Aachen Univ., DE)</span></div>
<p><span class="cbStatement">Introduces a model to describe the code navigation behavior of programmers; this model can be used to analyze the influence of different call graph navigation tools on navigation strategies.</span><span class="abstract">Understanding source code is crucial for successful software maintenance, and navigating the call graph is especially helpful to understand source code. We compared maintenance performance across four different development environments: an IDE without any call graph exploration tool, a Call Hierarchy tool as found in Eclipse, and the tools Stacksplorer and Blaze. Using any of the call graph exploration tools more developers could solve certain maintenance tasks correctly. Only Stacksplorer and Blaze, however, were also able to decrease task completion times, although the Call Hierarchy offers access to a larger part of the call graph. To investigate if this result was caused by a change in navigation behavior between the tools, we used a set of predictive models to create formally comparable descriptions of programmer navigation. The results suggest that the decrease in task completion times has been caused by Stacksplorer and Blaze promoting call graph navigation more than the Call Hierarchy tool.</span></li>
<li id="PJR"class="presentation "><a href="http://chi2013.acm.org/previews/#PJR"><span class="letterCode" style="float:right">PJR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PJR">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466129">Challenges and Opportunities for Technology in Foreign Language Classrooms</a></span><br />
<span class="authors">K. Kuksenok (Univ. of Washington, USA), M. Brooks, Q. Wang, C. Lee</span>
<div class="authorList"><span><span class="author">K. Kuksenok</span> (Univ. of Washington, USA)</span><span><span class="author">M. Brooks</span> (Univ. of Washington, USA)</span><span><span class="author">Q. Wang</span> (Univ. of Washington, USA)</span><span><span class="author">C. Lee</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">The roles of artifacts in language learning, based on ethnographic study of introductory Russian classrooms, informing design for this stressful, yet creative, cooperative environment.</span><span class="abstract">We present the results of a two-month ethnographic study of three introductory Russian classrooms. Through observation and interviews, we identify several distinct roles played by physical artifacts in the classrooms, such as providing a reference to necessary foreign-language material and serving as props in creative role-play. The range of roles taken on by artifacts and the attitudes students have toward them provide a basis for our discussion about how technology might be more effectively introduced into the socially negotiated environment of the introductory foreign-language classroom. We identify the need to balance between collaborative and personal technology in a stressful, but social, context. Our findings inform a range of roles that technology can undertake in replacing or augmenting existing classroom artifacts.</span></li>
<li id="NFD"class="presentation design engineering management"><a href="http://chi2013.acm.org/previews/#NFD"><span class="letterCode" style="float:right">NFD</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NFD">Tue. 4pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466269">Warping Time for More Effective Real-Time Crowdsourcing</a></span><br />
<span class="authors">W. Lasecki (Univ. of Rochester, USA), C. Miller, J. Bigham</span>
<div class="authorList"><span><span class="author">W. Lasecki</span> (Univ. of Rochester, USA)</span><span><span class="author">C. Miller</span> (Univ. of Rochester, USA)</span><span><span class="author">J. Bigham</span> (Univ. of Rochester, USA)</span></div>
<p><span class="cbStatement">We present TimeWarp, a crowdsourcing approach that allows workers to individually complete continuous tasks that involve streaming media at reduced speeds, while the crowd can collectively keep up with real-time.</span><span class="abstract">  In this paper, we introduce the idea of &#8221;warping time&#8221; to improve    crowd performance on the difficult task of captioning speech in    real-time.  Prior work has shown that the crowd can collectively    caption speech in real-time by merging the partial results of    multiple workers.  Because non-expert workers cannot keep up with    natural speaking rates, the task is frustrating and prone to errors    as workers buffer what they hear to type later.  The TimeWarp    approach automatically increases and decreases the speed of speech    playback systematically across individual workers who caption only    the periods played at reduced speed. Studies with 139 remote crowd    workers and 24 local participants show that this approach improves    median coverage (14.8%), precision (11.2%), and per-word latency    (19.1%). Warping time may also help crowds outperform individuals on    other difficult real-time performance tasks.</span></li>
<li id="PER"class="presentation "><a href="http://chi2013.acm.org/previews/#PER"><span class="letterCode" style="float:right">PER</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PER">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466191">Sublimate: State-Changing Virtual and Physical Rendering to Augment Interaction with Shape Displays</a></span><br />
<span class="authors">D. Leithinger (Massachusetts Institute of Technology, USA), S. Follmer, A. Olwal, S. Luescher, A. Hogge, J. Lee, H. Ishii</span>
<div class="authorList"><span><span class="author">D. Leithinger</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Follmer</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">A. Olwal</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">S. Luescher</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">A. Hogge</span></span><span><span class="author">J. Lee</span> (Media Lab, USA)</span><span><span class="author">H. Ishii</span> (Massachusetts Institute of Technology, USA)</span></div>
<p><span class="cbStatement">Sublimate co-locates spatial 3D visuals with actuated shape displays. We introduce interfaces and applications that combine virtual graphics and physical form, and explores the transitions between those states.</span><span class="abstract">Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and vaporization, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video see-through AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how free- hand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.</span></li>
<li id="PCL"class="presentation design"><a href="http://chi2013.acm.org/previews/#PCL"><span class="letterCode" style="float:right">PCL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCL">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481300">Flights in my Hands: Coherence Concerns in Designing Strip’TIC, a Tangible Space for Air Traffic Controllers</a></span><br />
<span class="authors">C. Letondal (ENAC, FR), C. Hurter, R. Lesbordes, J. Vinot, S. Conversy</span>
<div class="authorList"><span><span class="author">C. Letondal</span> (ENAC, FR)</span><span><span class="author">C. Hurter</span> (ENAC, FR)</span><span><span class="author">R. Lesbordes</span> (DGAC DSNA, FR)</span><span><span class="author">J. Vinot</span> (ENAC, FR)</span><span><span class="author">S. Conversy</span> (ENAC, FR)</span></div>
<p><span class="cbStatement">We reflect upon the design of a paper-based tangible space to support air traffic control. We propose a new account of coherence for mixed interaction that integrates cognitive externalization mechanisms.</span><span class="abstract">We reflect upon the design of a paper-based tangible interactive space to support air traffic control. We have observed, studied, prototyped and discussed with controllers a new mixed interaction system based on Anoto, video projection, and tracking. Starting from the understanding of the benefits of tangible paper strips, our goal is to study how mixed physical and virtual augmented data can support the controllers’ mental work. The context of the activity led us to depart from models that are proposed in tangible interfaces research where coherence is based on how physical objects are representative of virtual objects. We propose a new account of coherence in a mixed interaction system that integrates externalization mechanisms. We found that physical objects play two roles: they act both as representation of mental objects and as tangible artifacts for interacting with augmented features. We observed that virtual objects represent physical ones, and not the reverse, and, being virtual representations of physical objects, should seamlessly converge with the cognitive role of the physical object. Finally, we show how coherence is achieved by providing a seamless interactive space.</span></li>
<li id="PDC"class="presentation design engineering arts"><a href="http://chi2013.acm.org/previews/#PDC"><span class="letterCode" style="float:right">PDC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PDC">Thu. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466424">Modeling How People Extract Color Themes from Images</a></span><br />
<span class="authors">S. Lin (Stanford Univ., USA), P. Hanrahan</span>
<div class="authorList"><span><span class="author">S. Lin</span> (Stanford Univ., USA)</span><span><span class="author">P. Hanrahan</span> (Stanford Univ., USA)</span></div>
<p><span class="cbStatement">We present a method for extracting color themes from images, using a regression model trained on themes people extract. Model-extracted themes match the source image more closely than previous approaches.</span><span class="abstract">Color choice plays an important role in works of graphic art and design. However, it can be difficult to choose a compelling set of colors, or emph{color theme}, from scratch. In this work, we present a method for extracting color themes from images using a regression model trained on themes created by people. We collect 1600 themes from Mechanical Turk as well as from artists. We find that themes extracted by Turk participants were similar to ones extracted by artists. In addition, people tended to select diverse colors and focus on colors in salient image regions. We show that our model can match human-extracted themes more closely compared to previous work. Themes extracted by our model were also rated higher as representing the image than previous approaches in a Mechanical Turk study.</span></li>
<li id="PRC"class="presentation health"><a href="http://chi2013.acm.org/previews/#PRC"><span class="letterCode" style="float:right">PRC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PRC">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470663">Health Vlogger-Viewer Interaction in Chronic Illness Management</a></span><br />
<span class="authors">L. Liu (Univ. of Washington, USA), J. Huh, T. Neogi, K. Inkpen, W. Pratt</span>
<div class="authorList"><span><span class="author">L. Liu</span> (Univ. of Washington, USA)</span><span><span class="author">J. Huh</span> (Univ. of Washington, USA)</span><span><span class="author">T. Neogi</span> (Univ. of Washington, USA)</span><span><span class="author">K. Inkpen</span> (Microsoft Research, USA)</span><span><span class="author">W. Pratt</span> (Univ. of Washington, USA)</span></div>
<p><span class="cbStatement">Health vlogs allow individuals with chronic illnesses to share experiences. We examined methods that vloggers use to connect with viewers. We present design implications that facilitate sustainable communities for vloggers.</span><span class="abstract">Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers. </span></li>
<li id="PQJ"class="presentation design sustainability"><a href="http://chi2013.acm.org/previews/#PQJ"><span class="letterCode" style="float:right">PQJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PQJ">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466216">Looking Past Yesterday’s Tomorrow: Using Futures Studies Methods to Extend the Research Horizon</a></span><br />
<span class="authors">J. Mankoff (Carnegie Mellon Univ., USA), H. Faste, J. Rode</span>
<div class="authorList"><span><span class="author">J. Mankoff</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">H. Faste</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Rode</span> (Drexel Univ., USA)</span></div>
<p><span class="cbStatement">A review of futures studies methods used to forecast and think  critically about alternative futures and their relevance for HCI  research.</span><span class="abstract">Doing research is, in part, an act of foresight. Even though it is not  explicit in many projects, we especially value research that is still  relevant five, ten or more years after it is completed. However,  published research in the field of interactive computing (and  technology research in general) often lacks evidence of systematic  thinking about the long-term impacts of current trends.  For example,  trends on an exponential curve change much more rapidly than intuition  predicts. As a result, research may accidentally emphasize near-term  thinking. When thinking about the future is approached systematically,  we can critically examine multiple potential futures, expand the set  of externalities under consideration, and address both negative and  positive forecasts of the future. The field of Futures Studies  provides methods that can support analysis of long-term trends,  support the identification of new research areas and guide design and  evaluation. We survey methods for futuristic thinking and discuss  their relationship to Human Computer Interaction. Using the  sustainability domain an example, we present a case study of a Futures  Studies approach&#8211;the Delphi Method. We show how Futures Studies can  be incorporated into Human Computer Interaction and highlight future  work such as rethinking the role of externalities in the validation  process.</span></li>
<li id="PAV"class="presentation sustainability"><a href="http://chi2013.acm.org/previews/#PAV"><span class="letterCode" style="float:right">PAV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PAV">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470708">Using Crowdsourcing to Support Pro-Environmental Community Activism</a></span><br />
<span class="authors">E. Massung (Univ. of Bristol, UK), D. Coyle, K. Cater, M. Jay, C. Preist</span>
<div class="authorList"><span><span class="author">E. Massung</span> (Univ. of Bristol, UK)</span><span><span class="author">D. Coyle</span> (Univ. of Bristol, UK)</span><span><span class="author">K. Cater</span> (Univ. of Bristol, UK)</span><span><span class="author">M. Jay</span> (Univ. of Bristol, UK)</span><span><span class="author">C. Preist</span> (Univ. of Bristol, UK)</span></div>
<p><span class="cbStatement">We developed mobile applications and investigated motivational techniques to support crowdsourcing and pro-environmental community activism. The paper offers new insights and recommendations for environmental technologies targeting communities, rather than individuals.</span><span class="abstract">Community activist groups typically rely on core groups of highly motivated members. In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns. We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection. We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators. The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification – a subset of gamification – and financial incentives. Prior environmental interest is also assessed as an intrinsic motivation factor. In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.</span></li>
<li id="PHV"class="presentation "><a href="http://chi2013.acm.org/previews/#PHV"><span class="letterCode" style="float:right">PHV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PHV">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470728">Community Insights: Helping Community Leaders Enhance the Value of Enterprise Online Communities</a></span><br />
<span class="authors">T. Matthews (IBM Research, USA), S. Whittaker, H. Badenes, B. Smith, M. Muller, K. Ehrlich, M. Zhou, T. Lau</span>
<div class="authorList"><span><span class="author">T. Matthews</span> (IBM Research, USA)</span><span><span class="author">S. Whittaker</span> (Univ. of California at Santa Cruz, USA)</span><span><span class="author">H. Badenes</span> (IBM, AR)</span><span><span class="author">B. Smith</span> (IBM Research, USA)</span><span><span class="author">M. Muller</span> (IBM, USA)</span><span><span class="author">K. Ehrlich</span> (IBM, USA)</span><span><span class="author">M. Zhou</span> (IBM Research, USA)</span><span><span class="author">T. Lau</span> (Willow Garage, USA)</span></div>
<p><span class="cbStatement">Evidence-based design and evaluation of a novel tool that provides community leaders with useful, actionable, and contextualized analytics. Benefits designers of and practitioners using analytic tools to foster successful communities.</span><span class="abstract">Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.</span></li>
<li id="PTS"class="presentation health"><a href="http://chi2013.acm.org/previews/#PTS"><span class="letterCode" style="float:right">PTS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTS">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466197">Imaging the Body: Embodied Vision in Minimally Invasive Surgery</a></span><br />
<span class="authors">H. Mentis (Microsoft Research, UK), A. Taylor</span>
<div class="authorList"><span><span class="author">H. Mentis</span> (Microsoft Research, UK)</span><span><span class="author">A. Taylor</span> (Microsoft Research, UK)</span></div>
<p><span class="cbStatement">Presents findings concerning the constructed and embodied use of images during neurosurgery. Lends itself to a discussion of the directions for new imaging interaction technologies. </span><span class="abstract">Recent years have seen the possibilities of new imaging and interaction technologies for minimally invasive surgery such as touchless interaction and high definition renderings of three-dimensional anatomy. With this paper we take a step back to review the historical introduction and assimilation of imaging technologies in the surgical theatre in parallel with the productive and cross-referential nature of surgical practice and image use. We present findings from a field study of image use during neurosurgery where we see that the work to see medical images is highly constructed and embodied with the action of manipulating the body. This perspective lends itself to a discussion of the directions for new imaging interaction technologies.</span></li>
<li id="NNM"class="presentation engineering"><a href="http://chi2013.acm.org/previews/#NNM"><span class="letterCode" style="float:right">NNM</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NNM">Tue. 9am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466150">Direct Manipulation Video Navigation in 3D</a></span><br />
<span class="authors">C. Nguyen (Portland State Univ., USA), Y. Niu, F. Liu</span>
<div class="authorList"><span><span class="author">C. Nguyen</span> (Portland State Univ., USA)</span><span><span class="author">Y. Niu</span> (Portland State Univ., USA)</span><span><span class="author">F. Liu</span> (Portland State Univ., USA)</span></div>
<p><span class="cbStatement">This paper presents a 3D DMVN system that visualizes the video frame and motion in 3D, resolves temporal ambiguities, and allows a user to manipulate an object along its trajectory.  </span><span class="abstract">Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion (x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.</span></li>
<li id="NPJ"class="presentation engineering"><a href="http://chi2013.acm.org/previews/#NPJ"><span class="letterCode" style="float:right">NPJ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NPJ">Mon. 4pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470761">Touchbugs: Actuated Tangibles on Multi-Touch Tables</a></span><br />
<span class="authors">D. Nowacka (Newcastle Univ., UK), K. Ladha, N. Hammerla, D. Jackson, C. Ladha, E. Rukzio, P. Olivier</span>
<div class="authorList"><span><span class="author">D. Nowacka</span> (Newcastle Univ., UK)</span><span><span class="author">K. Ladha</span> (Newcastle Univ., UK)</span><span><span class="author">N. Hammerla</span> (Newcastle Univ., UK)</span><span><span class="author">D. Jackson</span> (Newcastle Univ., UK)</span><span><span class="author">C. Ladha</span> (Newcastle Univ., UK)</span><span><span class="author">E. Rukzio</span> (Ulm Univ., DE)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">We present a novel approach to graspable interfaces using Touchbugs, small tangibles that are able to move across surfaces by employing vibrating motors and to communicate with interactive surfaces by using infrared LEDs.</span><span class="abstract">We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications. Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera based multi-touch surfaces using infrared LEDs. Touchbug’s embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.</span></li>
<li id="PRY"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#PRY"><span class="letterCode" style="float:right">PRY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PRY">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466205">Designing for the Living Room: Long-Term User Involvement in a Living Lab</a></span><br />
<span class="authors">C. Ogonowski (Univ. of Siegen, DE), B. Ley, J. Hess, L. Wan, V. Wulf</span>
<div class="authorList"><span><span class="author">C. Ogonowski</span> (Univ. of Siegen, DE)</span><span><span class="author">B. Ley</span> (Univ. of Siegen, DE)</span><span><span class="author">J. Hess</span> (Univ. of Siegen, DE)</span><span><span class="author">L. Wan</span> (Univ. of Siegen, DE)</span><span><span class="author">V. Wulf</span> (Univ. of Siegen, DE)</span></div>
<p><span class="cbStatement">We present lessons learned from a 2.5 year period of a Living Lab project and discuss aspects that need to be considered when setting up such a research framework.</span><span class="abstract">Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants’ motivation, establishment of a trust relationship, and the coordination of collaboration.</span></li>
<li id="NPV"class="presentation engineering"><a href="http://chi2013.acm.org/previews/#NPV"><span class="letterCode" style="float:right">NPV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NPV">Wed. 2pm</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481387">ZoomBoard: A Diminutive QWERTY Soft Keyboard Using Iterative Zooming for Ultra-Small Devices</a></span><br />
<span class="authors">S. Oney (Carnegie Mellon Univ., USA), C. Harrison, A. Ogan, J. Wiese</span>
<div class="authorList"><span><span class="author">S. Oney</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">C. Harrison</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Ogan</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Wiese</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present Zoomboard, a keyboard that uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size.</span><span class="abstract">The proliferation of touchscreen devices has made soft keyboards a routine part of life. However, ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry. This limits their potential, despite the fact they are quite capable computers. In this work, we present a soft keyboard interaction technique called ZoomBoard that enables text entry on ultra-small devices. Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size. We based our design on a QWERTY layout, so that it is immediately familiar to users and leverages existing skill. As the ultimate test, we ran a text entry experiment on a keyboard measuring just 16 x 6mm – smaller than a US penny. After eight practice trials, users achieved an average of 9.3 words per minute, with accuracy comparable to a full-sized physical keyboard. This compares favorably to existing mobile text input methods.</span></li>
<li id="PNZ"class="presentation "><a href="http://chi2013.acm.org/previews/#PNZ"><span class="letterCode" style="float:right">PNZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNZ">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466169">Information Capacity of Full-Body Movements</a></span><br />
<span class="authors">A. Oulasvirta (Max Planck Institute for Informatics, DE), T. Roos, A. Modig, L. Leppänen</span>
<div class="authorList"><span><span class="author">A. Oulasvirta</span> (Max Planck Institute for Informatics, DE)</span><span><span class="author">T. Roos</span> (Univ. of Helsinki, FI)</span><span><span class="author">A. Modig</span> (Aalto Univ., FI)</span><span><span class="author">L. Leppänen</span></span></div>
<p><span class="cbStatement">Presents a novel metric for the information capacity of full-body movements.</span><span class="abstract">We present a novel metric for information capacity of full-body movements. It accommodates HCI scenarios involving continuous movement of multiple limbs. Throughput is calculated as mutual information in repeated motor sequences. It is affected by the complexity of movements and the precision with which an actor reproduces them. Computation requires decorrelating co-dependencies of movement features (e.g., wrist and elbow) and temporal alignment of sequences. HCI researchers can use the metric as an analysis tool when designing and studying user interfaces.</span></li>
<li id="NGN"class="presentation engineering ux games arts"><a href="http://chi2013.acm.org/previews/#NGN"><span class="letterCode" style="float:right">NGN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NGN">Wed. 9am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481303">Reflexive Loopers for Solo Musical Improvisation</a></span><br />
<span class="authors">F. Pachet (Sony CSL Paris, FR), P. Roy, J. Moreira, M. d&#8217;Inverno</span>
<div class="authorList"><span><span class="author">F. Pachet</span> (Sony CSL Paris, FR)</span><span><span class="author">P. Roy</span> (Sony CSL, FR)</span><span><span class="author">J. Moreira</span> (Sony CSL, FR)</span><span><span class="author">M. d&#8217;Inverno</span> (Sony CSL, FR)</span></div>
<p><span class="cbStatement">We describe a system that automatically learns the accompaniement style of a musician from a real-time jazz performance. The system can then be used to perform trios with themselves.</span><span class="abstract">Loop pedals are real-time samplers that playback audio  played previously by a musician. Such pedals are routinely  used for music practice or outdoor “busking”. However,  loop pedals always playback the same material, which can  make performances monotonous and boring both to the  musician and the audience, preventing their widespread  uptake in professional concerts. In response, we propose a  new approach to loop pedals that addresses this issue,  which is based on an analytical multi-modal representation  of the audio input. Instead of simply playing back prerecorded  audio, our system enables real-time generation of  an audio accompaniment reacting to what is currently being  performed by the musician. By combining different modes  of performance – e.g. bass line, chords, solo &#8211; from the musician  and system automatically, solo musicians can perform  duets or trios with themselves, without engendering  the so-called canned (boringly repetitive and unresponsive)  music effect of loop pedals. We describe the technology,  based on supervised classification and concatenative synthesis,  and then illustrate our approach on solo performances  of jazz standards by guitar. We claim this approach  opens up new avenues for concert performance.</span></li>
<li id="PDK"class="presentation ux"><a href="http://chi2013.acm.org/previews/#PDK"><span class="letterCode" style="float:right">PDK</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PDK">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466173">PanoInserts: Mobile Spatial Teleconferencing</a></span><br />
<span class="authors">F. Pece (Univ. College London, UK), W. Steptoe, F. Wanner, S. Julier, T. Weyrich, J. Kautz, A. Steed</span>
<div class="authorList"><span><span class="author">F. Pece</span> (Univ. College London, UK)</span><span><span class="author">W. Steptoe</span> (Univ. College London, UK)</span><span><span class="author">F. Wanner</span> (Univ. College London, UK)</span><span><span class="author">S. Julier</span> (Univ. College London, UK)</span><span><span class="author">T. Weyrich</span> (Univ. College London, UK)</span><span><span class="author">J. Kautz</span> (Univ. College London, UK)</span><span><span class="author">A. Steed</span> (Univ. College London, UK)</span></div>
<p><span class="cbStatement">PanoInserts is a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. </span><span class="abstract">We present PanoInserts: a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. We take a static panoramic image of a location into which we insert live videos from smartphones. We use a combination of marker- and image-based tracking to position the video inserts within the panorama, and transmit this representation to a remote viewer. We conduct a user study comparing our system with fully-panoramic video and conventional webcam video conferencing for two spatial reasoning tasks.  Results indicate that our system performs comparably with fully-panoramic video, and better than webcam video conferencing in tasks that require an accurate surrounding representation of the remote space. We discuss the representational properties and usability of varying video presentations, exploring how they are perceived and how they influence users when performing spatial reasoning tasks.</span></li>
<li id="PAZ"class="presentation games"><a href="http://chi2013.acm.org/previews/#PAZ"><span class="letterCode" style="float:right">PAZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PAZ">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470755">Playing with Leadership and Expertise: Military Tropes and Teamwork in an ARG</a></span><br />
<span class="authors">T. Peyton (The Pennsylvania State Univ., USA), A. Young, W. Lutters</span>
<div class="authorList"><span><span class="author">T. Peyton</span> (The Pennsylvania State Univ., USA)</span><span><span class="author">A. Young</span> (Univ. of Maryland, Baltimore County, USA)</span><span><span class="author">W. Lutters</span> (Univ. of Maryland, Baltimore County, USA)</span></div>
<p><span class="cbStatement">Explores how ARG teams arrange and militarize play within unstructured ludic systems. Illustrates that the development of expertise and emergence of leadership occurs in response to this lack of structure.</span><span class="abstract">Ad-hoc virtual teams often lack tools to formalize leadership and structure collaboration, yet they are often successful. How does this happen? We argue that the emergence of leadership and the development of expertise occurs in the process of taking action and in direct response to a lack of structure. Using a twinned set of eight modality sliders, we examine the interactions of fourteen players in an alternate reality game. We find that players adopted military language and culture to structure and arrange their play. We determine that it is critical to account for the context of play across these modalities in order to design appropriately for effective in-game virtual organizing.</span></li>
<li id="NAC"class="presentation design ux games"><a href="http://chi2013.acm.org/previews/#NAC"><span class="letterCode" style="float:right">NAC</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NAC">Tue. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466165">4 Design Themes for Skateboarding</a></span><br />
<span class="authors">S. Pijnappel (RMIT Univ., AU), F. Mueller</span>
<div class="authorList"><span><span class="author">S. Pijnappel</span> (RMIT Univ., AU)</span><span><span class="author">F. Mueller</span> (RMIT Univ., AU)</span></div>
<p><span class="cbStatement">We explore how to design interactive technologies to enhance the experience of skateboarding, providing thought provoking insights into how technology can have value beyond the context of performance focused sports.</span><span class="abstract">Interactive technology can support exertion activities, with many examples focusing on improving athletic performance. We see an opportunity for technology to also support extreme sports such as skateboarding, which often focus primarily on the experience of doing tricks rather than on athletic performance. However, there is little knowledge on how to design for such experiences. In response, we designed 12 basic skateboarding prototypes inspired by skateboarding theory. Using an autoethnographical approach, we skated with each of these and reflected on our experiences in order to derive four design themes : location of feedback in relation to the skater’s body, timing of feedback in relation to peaks in emotions after attempts, aspects of the trick emphasized by feedback, and aesthetic fittingness of feedback. We hope our work will guide designers of interactive systems for skateboarding, and extreme sports in general, and will therefore further our understanding of how to design for the active human body.</span></li>
<li id="PBS"class="presentation design cci"><a href="http://chi2013.acm.org/previews/#PBS"><span class="letterCode" style="float:right">PBS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBS">Mon. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470670">Why Interactive Learning Environments Can Have It All: Resolving Design Conflicts Between Competing Goals</a></span><br />
<span class="authors">M. Rau (Carnegie Mellon Univ., USA), V. Aleven, N. Rummel, S. Rohrbach</span>
<div class="authorList"><span><span class="author">M. Rau</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">V. Aleven</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">N. Rummel</span> (Ruhr-Univ. Bochum, DE)</span><span><span class="author">S. Rohrbach</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">We present a principled, approach to resolving conflicts between competing goals in educational settings. We provide evidence that our approach lead to the development of a successful interactive learning environment.</span><span class="abstract">Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems, educational games, etc.) is a challenging interdisciplinary process that needs to satisfy multiple stakeholders. ILEs need to function in real educa-tional settings (e.g., schools) in which a number of goals interact. Several instructional design methodologies exist to help developers address these goals. However, they often lead to conflicting recommendations. Due to the lack of an established methodology to resolve such conflicts, develop-ers of ILEs have to rely on ad-hoc solutions. We present a principled methodology to resolve such conflicts. We build on a well-established design process for creating Cognitive Tutors, a highly effective type of ILE. We extend this pro-cess by integrating methods from multiple disciplines to resolve design conflicts. We illustrate our methodology’s effectiveness by describing the iterative development of the Fractions Tutor, which has proven to be effective in class-room studies with 3,000 4th-6th graders.</span></li>
<li id="PFY"class="presentation ux"><a href="http://chi2013.acm.org/previews/#PFY"><span class="letterCode" style="float:right">PFY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PFY">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481281">Predicting Users&#8217; First Impressions of Website Aesthetics With a Quantification of Perceived Visual Complexity and Colorfulness</a></span><br />
<span class="authors">K. Reinecke (Harvard Univ., USA), T. Yeh, L. Miratrix, Y. Zhao, R. Mardiko, J. Liu, K. Gajos</span>
<div class="authorList"><span><span class="author">K. Reinecke</span> (Harvard Univ., USA)</span><span><span class="author">T. Yeh</span> (Univ. of Colorado, USA)</span><span><span class="author">L. Miratrix</span> (Harvard Univ., USA)</span><span><span class="author">Y. Zhao</span> (Harvard Univ., USA)</span><span><span class="author">R. Mardiko</span> (Univ. of Maryland, USA)</span><span><span class="author">J. Liu</span> (Harvard Univ., USA)</span><span><span class="author">K. Gajos</span> (Harvard Univ., USA)</span></div>
<p><span class="cbStatement">We collected colorfulness, complexity, and overall visual appeal ratings from 548 volunteers. Utilizing these data, we developed models that accurately predict perceived visual complexity and perceived colorfulness in websites based on computational image statistics.</span><span class="abstract">Users make lasting judgments about a website&#8217;s appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site&#8217;s usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website&#8217;s colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user&#8217;s education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.</span></li>
<li id="NRB"class="presentation "><a href="http://chi2013.acm.org/previews/#NRB"><span class="letterCode" style="float:right">NRB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#NRB">Thu. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466427">Distraction Beyond the Driver: Predicting the Effects of In-Vehicle Interaction on Surrounding Traffic</a></span><br />
<span class="authors">D. Salvucci (Drexel Univ., USA)</span>
<div class="authorList"><span><span class="author">D. Salvucci</span> (Drexel Univ., USA)</span></div>
<p><span class="cbStatement">Describes a method for simulating the effects of driver distraction across multiple vehicles. Allows users to rapidly prototype and evaluate in-vehicle interfaces based on their potential for distraction.  </span><span class="abstract">Recent studies of driver distraction have reported a number of detrimental effects of in-vehicle interaction on driver performance. This paper examines and predicts the potential effects of such interaction on other vehicles around the driver’s vehicle. Specifically, the paper describes how computational cognitive models can be used to predict the complex interactions among several vehicles driving in a line when one or more of the vehicles’ drivers are performing a secondary task (phone dialing). The results of simulating two distinct car-following scenarios illustrate that in-vehicle interaction by one driver can have significant downstream effects on other drivers, especially with respect to speed deviations relative to a lead vehicle. This work generalizes recent work developing computational evaluation tools for user interfaces in complex domains, and further serves as an example of how user interaction in some domains can have broader effects on the community at large.</span></li>
<li id="PCQ"class="presentation design"><a href="http://chi2013.acm.org/previews/#PCQ"><span class="letterCode" style="float:right">PCQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PCQ">Tue. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466148">Direct Space-Time Trajectory Control  for Visual Media Editing</a></span><br />
<span class="authors">S. Santosa (Univ. of Toronto, CA), F. Chevalier, R. Balakrishnan, K. Singh</span>
<div class="authorList"><span><span class="author">S. Santosa</span> (Univ. of Toronto, CA)</span><span><span class="author">F. Chevalier</span> (Univ. of Toronto, CA)</span><span><span class="author">R. Balakrishnan</span> (Univ. of Toronto, CA)</span><span><span class="author">K. Singh</span> (Univ. of Toronto, CA)</span></div>
<p><span class="cbStatement">An exploration of the design space for using motion trajectories to edit visual elements across space and time. Pen-based techniques are introduced in DirectPaint: a video painting and annotation system.</span><span class="abstract">We explore the design space for using object motion trajectories to create and edit visual elements in various media across space and time. We introduce a suite of pen-based techniques that facilitate fluid stylization, annotation and editing of space-time content such as video, slide presentations and 2D animation, utilizing pressure and multi-touch input. We implemented and evaluated these techniques in DirectPaint, a system for creating free-hand painting and annotation over video. </span></li>
<li id="PKX"class="presentation "><a href="http://chi2013.acm.org/previews/#PKX"><span class="letterCode" style="float:right">PKX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PKX">Thu. 11am</a></span><span class="award honorable"></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466430">Testing the Robustness and Performance of Spatially Consistent Interfaces</a></span><br />
<span class="authors">J. Scarr (Univ. of Canterbury, NZ), A. Cockburn, C. Gutwin, S. Malacria</span>
<div class="authorList"><span><span class="author">J. Scarr</span> (Univ. of Canterbury, NZ)</span><span><span class="author">A. Cockburn</span> (Univ. of Canterbury, NZ)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">S. Malacria</span> (Univ. of Canterbury, NZ)</span></div>
<p><span class="cbStatement">Examines how view transformations such as scaling and rotation influence item selection time. Demonstrates that scaling, which maintains spatial consistency, allows faster performance than the commonly used &#8216;reflow&#8217; layout scheme.</span><span class="abstract">Relative spatial consistency – that is, the stable arrangement of objects in a 2D presentation – provides several benefits for interactive interfaces. Spatial consistency allows users to develop memory of object locations, reducing the time needed for visual search, and because spatial memory is long lasting and has a large capacity these performance benefits are enduring and scalable. This suggests that spatial consistency could be used as a fundamental principle for the design of interfaces. However, there are many display situations where the standard presentation is altered in some way: e.g., a window is moved to a new location, scaled, or rotated on a mobile or tabletop display. It is not known whether the benefits of spatial organization are robust to these common kinds of view transformation. To assess these effects, we tested user performance with a spatial interface that had been transformed in several ways, including different degrees of translation, rotation, scaling, and perspective change. We found that performance was not strongly affected by the changes, except in the case of large rotations. To demonstrate the value of spatial consistency over existing mechanisms for dealing with view changes, we compared user performance with a spatially-stable presentation (using scaling) with that of a &#8216;reflowing&#8217; presentation (widely used in current interfaces). This study showed that spatial stability with scaling dramatically outperforms reflowing. This research provides new evidence of spatial consistency&#8217;s value in interface design: it is robust to the view transformations that occur in typical environments, and it provides substantial performance advantages over traditional methods.</span></li>
<li id="NMT"class="presentation management ux"><a href="http://chi2013.acm.org/previews/#NMT"><span class="letterCode" style="float:right">NMT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#NMT">Mon. 11am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470660">Using Contextual Integrity to Examine Interpersonal Information Boundary on Social Network Sites</a></span><br />
<span class="authors">P. Shi (The Pennsylvania State Univ., USA), H. Xu, Y. Chen</span>
<div class="authorList"><span><span class="author">P. Shi</span> (The Pennsylvania State Univ., USA)</span><span><span class="author">H. Xu</span> (The Pennsylvania State Univ., USA)</span><span><span class="author">Y. Chen</span> (Univ. of California, Irvine, USA)</span></div>
<p><span class="cbStatement">Through a case analysis of Friendship Pages on Facebook, this paper identifies users&#8217; interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity.</span><span class="abstract">Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users&#8217; interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users&#8217; interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.</span></li>
<li id="PCV"class="presentation design engineering ux"><a href="http://chi2013.acm.org/previews/#PCV"><span class="letterCode" style="float:right">PCV</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCV">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470688">Flexpad: Highly Flexible Bending Interactions for Projected Handheld Displays</a></span><br />
<span class="authors">J. Steimle (Massachusetts Institute of Technology, USA), A. Jordt, P. Maes</span>
<div class="authorList"><span><span class="author">J. Steimle</span> (Massachusetts Institute of Technology, USA)</span><span><span class="author">A. Jordt</span> (Kiel Univ. of Applied Sciences, DE)</span><span><span class="author">P. Maes</span> (Massachusetts Institute of Technology, USA)</span></div>
<p><span class="cbStatement">Introduces highly flexible handheld displays as user interfaces. Contributes a novel real-time method for capturing complex deformations of flexible surfaces and novel interactions that leverage highly flexible deformations of displays.</span><span class="abstract">Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays. We present a novel approach for tracking deformed surfaces from depth images in real time. It captures deformations in high detail, is very robust to occlusions created by the user’s hands and fingers, and does not require any kind of markers or visible texture. As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation. We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos. Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.</span></li>
<li id="PCP"class="presentation "><a href="http://chi2013.acm.org/previews/#PCP"><span class="letterCode" style="float:right">PCP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PCP">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470720">Improving Teamwork Using Real-Time Language Feedback</a></span><br />
<span class="authors">Y. Tausczik (Carnegie Mellon Univ., USA), J. Pennebaker</span>
<div class="authorList"><span><span class="author">Y. Tausczik</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">J. Pennebaker</span> (The Univ. of Texas at Austin, USA)</span></div>
<p><span class="cbStatement">We develop a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together.</span><span class="abstract">We develop and evaluate a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together. As an initial step, we determine which group processes are related to better outcomes. We then experimentally test the efficacy of providing real-time instructions which target two of these group processes. The feedback system was successfully able to shape the way groups worked together. However, only appropriate feedback given to groups that were not working well together from the start was able to improve group performance.</span></li>
<li id="PGB"class="presentation "><a href="http://chi2013.acm.org/previews/#PGB"><span class="letterCode" style="float:right">PGB</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PGB">Tue. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466206">Leaving the Wild: Lessons from Community Technology Handovers</a></span><br />
<span class="authors">N. Taylor (Newcastle Univ., UK), K. Cheverst, P. Wright, P. Olivier</span>
<div class="authorList"><span><span class="author">N. Taylor</span> (Newcastle Univ., UK)</span><span><span class="author">K. Cheverst</span> (Lancaster Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">We examine two cases where research prototypes were handed over to participants at the end of projects and suggest best practices for leaving technologies in the wild.</span><span class="abstract">As research increasingly turns to work ‘in the wild’ to design and evaluate technologies under real-world conditions, little consideration has been given to what happens when research ends. In many cases, users are heavily involved in the design process and encouraged to integrate the resulting technologies into their lives before they are withdrawn, while in some cases technologies are being left in place after research concludes. Often, little is done to assess the impact and legacy of these deployments. In this paper, we return to two examples in which we designed technologies with the involvement of communities and examine what steps were taken to ensure their long-term viability and what happened following the departure of researchers. From these examples, we provide guidelines for planning and executing technology handovers when conducting research with communities. </span></li>
<li id="PNS"class="presentation design"><a href="http://chi2013.acm.org/previews/#PNS"><span class="letterCode" style="float:right">PNS</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PNS">Tue. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466255">Crossing the Bridge over Norman&#8217;s Gulf of Execution: Revealing Feedforward&#8217;s True Identity</a></span><br />
<span class="authors">J. Vermeulen (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE), K. Luyten, E. van den Hoven, K. Coninx</span>
<div class="authorList"><span><span class="author">J. Vermeulen</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span><span><span class="author">K. Luyten</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span><span><span class="author">E. van den Hoven</span> (Univ. of Technology, Sydney, AU)</span><span><span class="author">K. Coninx</span> (Hasselt Univ. &#8211; tUL &#8211; iMinds, BE)</span></div>
<p><span class="cbStatement">We reframe feedforward and disambiguate it from feedback and perceived affordances. We describe a reference framework for designers that allows them to explore and recognize different opportunities for feedforward.</span><span class="abstract">Feedback and affordances are two of the most well-known principles in interaction design. Unfortunately, the related and equally important notion of feedforward has not been given as much consideration. Nevertheless, feedforward is a powerful design principle for bridging Norman’s Gulf of Execution. We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward. In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.</span></li>
<li id="PBE"class="presentation design"><a href="http://chi2013.acm.org/previews/#PBE"><span class="letterCode" style="float:right">PBE</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PBE">Mon. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470716">Configuring Participation: On How We Involve People In Design</a></span><br />
<span class="authors">J. Vines (Newcastle Univ., UK), R. Clarke, P. Wright, J. McCarthy, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Vines</span> (Newcastle Univ., UK)</span><span><span class="author">R. Clarke</span> (Newcastle Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">Critically examines the goals of user participation in design processes in contemporary HCI. Highlights limitations in how participatory processes are documented by the community, and outlines strategies for future research.</span><span class="abstract">The term ‘participation’ is traditionally used in HCI to describe the involvement of users and stakeholders in design processes, with a pretext of distributing control to participants to shape their technological future. In this paper we ask whether these values can hold up in practice, particularly as participation takes on new meanings and incorporates new perspectives. We argue that much HCI research leans towards configuring participation. In discussing this claim we explore three questions that we consider important for understanding how HCI configures participation; Who initiates, directs and benefits from user participation in design? In what forms does user participation occur? How is control shared with users in design? In answering these questions we consider the conceptual, ethical and pragmatic problems this raises for current participatory HCI research. Finally, we offer directions for future work explicitly dealing with the configuration of participation.</span></li>
<li id="PBT"class="presentation "><a href="http://chi2013.acm.org/previews/#PBT"><span class="letterCode" style="float:right">PBT</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PBT">Tue. 11am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466170">Body-centric Design Space for Multi-surface Interaction</a></span><br />
<span class="authors">J. Wagner (INRIA, FR), M. Nancel, S. Gustafson, S. Huot, W. Mackay</span>
<div class="authorList"><span><span class="author">J. Wagner</span> (INRIA, FR)</span><span><span class="author">M. Nancel</span> (Univ. Paris Sud, FR)</span><span><span class="author">S. Gustafson</span> (Hasso Plattner Institute, DE)</span><span><span class="author">S. Huot</span> (INRIA, FR)</span><span><span class="author">W. Mackay</span> (INRIA, FR)</span></div>
<p><span class="cbStatement">BodyScape, a body-centric design space, allows researchers and practitioners to describe, classify and systematically compare existing multi-surface interaction techniques, individually or in combination, as well as generate new interaction techniques.  </span><span class="abstract">We introduce BodyScape, a body-centric design space that allows us to describe, classify and systematically compare multi-surface interaction techniques, both individually and in combination.  BodyScape reflects the relationship between users and their environment, specifically how different body parts enhance or restrict movement within particular interaction techniques and can be used to analyze existing techniques or suggest new ones.  We illustrate the use of BodyScape by comparing two free-hand techniques, on-body touch and mid-air pointing, first separately, then combined.   We found that touching the torso is faster than touching the lower legs, since it affects the user&#8217;s balance;  and touching targets on the dominant arm is slower than targets on the torso  because the user must compensate for the applied force. </span></li>
<li id="PAQ"class="presentation design"><a href="http://chi2013.acm.org/previews/#PAQ"><span class="letterCode" style="float:right">PAQ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PAQ">Wed. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481363">A Design-led Inquiry into Personhood in Dementia</a></span><br />
<span class="authors">J. Wallace (Northumbria Univ., UK), P. Wright, J. McCarthy, D. Green, J. Thomas, P. Olivier</span>
<div class="authorList"><span><span class="author">J. Wallace</span> (Northumbria Univ., UK)</span><span><span class="author">P. Wright</span> (Newcastle Univ., UK)</span><span><span class="author">J. McCarthy</span> (Univ. College Cork, IE)</span><span><span class="author">D. Green</span> (Newcastle Univ., UK)</span><span><span class="author">J. Thomas</span> (Northumbria Univ., UK)</span><span><span class="author">P. Olivier</span> (Newcastle Univ., UK)</span></div>
<p><span class="cbStatement">A design-led, co-creative inquiry into personhood with Gillian, who has dementia, and John her husband &#8211; mediated by Design Probes and resulting in Digital Jewellery to support personhood and relationships.</span><span class="abstract">Writers and practitioners in dementia care have invoked personhood to offer potential for preserving the agency of people living with dementia. In this context we use personhood to explore how relationships bring agentive potential to experience-centered design through a co-creative, design-led inquiry with Gillian, a woman living with dementia, and John her husband. We designed bespoke probes to empathically engage the couple in the design of both jewellery and digital jewellery to support Gillian’s personhood. Our design activity addressed the relationships involved in the context of Gillian’s family life and the progression of her illness and how they could be mediated technologically. Reminiscence became, through Gillian and John’s own hands, acts of sense making and legacy. The process of design became the way of conducting the inquiry and the designed artifacts became ways of posing questions to make sense of our experiences together.</span></li>
<li id="PEZ"class="presentation "><a href="http://chi2013.acm.org/previews/#PEZ"><span class="letterCode" style="float:right">PEZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PEZ">Mon. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470774">StrikeAPose: Revealing Mid-Air Gestures on Public Displays</a></span><br />
<span class="authors">R. Walter (Telekom Innovation Laboratories, TU Berlin, DE), G. Bailly, J. Müller</span>
<div class="authorList"><span><span class="author">R. Walter</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">G. Bailly</span> (Telekom Innovation Laboratories, TU Berlin, DE)</span><span><span class="author">J. Müller</span> (Univ. of the Arts, DE)</span></div>
<p><span class="cbStatement">Proposes three strategies to reveal mid-air gestures on interactive public displays and introduces the Teapot gesture as a novel initial mid-air gesture. Shows that users naturally explore gesture variations.</span><span class="abstract">We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users&#8217; variations.</span></li>
<li id="PCG"class="presentation ux HCI4D"><a href="http://chi2013.acm.org/previews/#PCG"><span class="letterCode" style="float:right">PCG</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCG">Wed. 4pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481391">Hustling Online: Understanding Consolidated Facebook Use in an Informal Settlement in Nairobi</a></span><br />
<span class="authors">S. Wyche (Michigan State Univeristy, USA), F. Andrea, S. Yardi Schoenebeck</span>
<div class="authorList"><span><span class="author">S. Wyche</span> (Michigan State Univeristy, USA)</span><span><span class="author">F. Andrea</span> (Drexel Univ., USA)</span><span><span class="author">S. Yardi Schoenebeck</span> (Univ. of Michigan, USA)</span></div>
<p><span class="cbStatement">This is the first study of Facebook use in a Nairobi slum. We find that to overcome the costs associated with Internet use, residents consolidated diverse online activities onto Facebook.</span><span class="abstract">Facebook is a global phenomenon, yet little is known about use of the site in urban parts of the developing world where the social network’s users are increasingly located. We qualitatively studied Facebook use among 28 young adults living in Viwandani, an informal settlement, or slum, in Nairobi, Kenya. We find that to overcome the costs associated with Internet use, participants consolidated diverse online activities onto Facebook; here we focus on the most common practice—using Facebook to support income generation. Viwandani residents used the site to look for employment opportunities, market themselves, and seek remittances from friends and family abroad. We use our findings to motivate a design agenda for the urban poor built on an understanding that Facebook is used, with mixed-success, to support income generation. A key part of this agenda calls for developing ICT interventions grounded in users’ existing practices rather than introducing new and unfamiliar ones. </span></li>
<li id="NDZ"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#NDZ"><span class="letterCode" style="float:right">NDZ</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NDZ">Wed. 9am</a></span><span class="award honorable"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481297">Facilitating Parallel Web Browsing through Multiple-Page View</a></span><br />
<span class="authors">W. Xu (Tsinghua Univ., CN), C. Yu, S. Zhao, J. Liu, Y. Shi</span>
<div class="authorList"><span><span class="author">W. Xu</span> (Tsinghua Univ., CN)</span><span><span class="author">C. Yu</span> (Tsinghua Univ., CN)</span><span><span class="author">S. Zhao</span> (Tsinghua Univ., CN)</span><span><span class="author">J. Liu</span> (Tsinghua Univ., CN)</span><span><span class="author">Y. Shi</span> (Tsinghua Univ., CN)</span></div>
<p><span class="cbStatement">We propose the multiple-page view to provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers.</span><span class="abstract">Parallel web browsing describes the behavior where users visit web pages in multiple concurrent threads. Qualitative studies have observed this activity being performed with multiple browser windows or tabs. However, these solutions are not satisfying since a large amount of time is wasted on switch among windows and tabs. In this paper, we propose the multiple-page view to facilitate parallel web browsing. Specifically, we provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers. Through user study and survey, we found that 2-4 pages within the window size were preferred for multiple-page view in spite of the diverse screen sizes and resolutions. Analytical results of logs from the user study also showed an improvement of 26.3% in users’ efficiency of performing parallel web browsing tasks, compared to traditional browsing with multiple windows or tabs.</span></li>
<li id="PDR"class="presentation "><a href="http://chi2013.acm.org/previews/#PDR"><span class="letterCode" style="float:right">PDR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PDR">Thu. 2pm</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466468">Shifting Dynamics or Breaking Sacred Traditions? The Role of Technology in Twelve-Step Fellowships</a></span><br />
<span class="authors">S. Yarosh (AT&#038;T Research Labs, USA)</span>
<div class="authorList"><span><span class="author">S. Yarosh</span> (AT&#038;T Research Labs, USA)</span></div>
<p><span class="cbStatement">Presents in-depth interviews with member of twelve-step recovery groups to understand the role of technology in these communities. Relates these findings to wider questions of design in social computing.</span><span class="abstract">Twelve-step fellowships are the most common long-term maintenance program for recovery from alcoholism and addiction. Informed by six months of participatory observation of twelve-step fellowship meetings and service structure, I conducted in-depth interviews with twelve members of Alcoholics Anonymous (AA) and Narcotics Anonymous (NA) about the role of technology in recovery. I found that there are a number of tensions in how technology is perceived and adopted. As technology and twelve-step fellowships interact, issues of anonymity, identity, consensus, access, unity, autonomy, and physical presence are foregrounded. I relate these findings to the broader research landscape and provide implications for future design in this space. </span></li>
<li id="PCF"class="presentation management"><a href="http://chi2013.acm.org/previews/#PCF"><span class="letterCode" style="float:right">PCF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#PCF">Wed. 9am</a></span><span class="award honorable"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481311">Effects of Peer Feedback on Contribution: A Field Experiment in Wikipedia</a></span><br />
<span class="authors">H. Zhu (Carnegie Mellon Univ., USA), A. Zhang, J. He, R. Kraut, A. Kittur</span>
<div class="authorList"><span><span class="author">H. Zhu</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Zhang</span></span><span><span class="author">J. He</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">R. Kraut</span> (Carnegie Mellon Univ., USA)</span><span><span class="author">A. Kittur</span> (Carnegie Mellon Univ., USA)</span></div>
<p><span class="cbStatement">The paper furthers our understanding of the effects of peer feedback in online communities and provides practical guidance to design more effective peer feedback systems.</span><span class="abstract">One of the most significant challenges for many online communities is increasing members’ contributions over time. Prior studies on peer feedback in online communities have suggested its impact on contribution, but have been limited by their correlational nature. In this paper, we conducted a field experiment on Wikipedia to test the effects of different feedback types (positive feedback, negative feedback, directive feedback, and social feedback) on members’ contribution. Our results characterize the effects of different feedback types, and suggest trade-offs in the effects of feedback between the focal task and general motivation, as well as differences in how newcomers and experienced editors respond to peer feedback. This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems.</span></li>
</ul>
<h2 id="honorableCaseStudies">Case Studies with Honorable Mentions</h2>
<ul>
<li id="YFR"class="presentation design ux"><a href="http://chi2013.acm.org/previews/#YFR"><span class="letterCode" style="float:right">YFR</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#YFR">Thu. 2pm</a></span><span class="award honorable"></span><span class="title"><a href="http://doi.acm.org/10.1145/2468356.2468779">Multi-modal Location-Aware System  for Paratrooper Team Coordination</a></span><br />
<span class="authors">D. Cummings (Texas A&#038;M Univ., USA), M. Prasad, G. Lucchese, C. Aikens, T. Hammond</span>
<div class="authorList"><span><span class="author">D. Cummings</span> (Texas A&#038;M Univ., USA)</span><span><span class="author">M. Prasad</span> (Texas A&#038;M Univ., USA)</span><span><span class="author">G. Lucchese</span> (Texas A&#038;M Univ., USA)</span><span><span class="author">C. Aikens</span> (Texas A&#038;M Univ., USA)</span><span><span class="author">T. Hammond</span> (Texas A&#038;M Univ., USA)</span></div>
<p><span class="cbStatement">Lessons learned through an ethnographic analysis of Paratroopers facilitated the development of a location-aware navigation system and helped to effectively address common battlefield constraints while capitalizing on users&#8217; expectations.</span><span class="abstract">Navigation and assembly are critical tasks for Soldiers in battlefield situations. Paratroopers, in particular, must be able to parachute into a battlefield and locate and assemble their equipment as quickly and quietly as possible. Current assembly methods rely on bulky and antiquated equipment that inhibit the speed and effectiveness of such operations. To address this we have created a multi-modal mobile navigation system that uses ruggedized to mark assembly points and smartphones to assist in navigating to these points while minimizing cognitive load and maximizing situational awareness. To achieve this task, we implemented a novel beacon receiver protocol that allows an infinite number of receivers to listen to the encrypted beaconing message using only ad-hoc Wi-Fi technologies. The system was evaluated by U.S. Army Paratroopers and proved quick to learn and efficient at moving Soldiers to navigation waypoints. Beyond military operations, this system could be applied to any task that requires the assembly and coordination of many individuals or teams, such as emergency evacuations, fighting wildfires or locating airdropped humanitarian aid.</span></li>
<li id="YXL"class="presentation ux"><a href="http://chi2013.acm.org/previews/#YXL"><span class="letterCode" style="float:right">YXL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#YXL">Tue. 2pm</a></span><span class="award honorable"></span><span class="title"><a href="http://doi.acm.org/10.1145/2468356.2468768">Do You Enjoy Getting Gifts? Keeping Personas Alive Through Marketing Materials</a></span><br />
<span class="authors">C. Hochleitner (CURE &#8211; Center for Usability Research &#038; Engineering, AT), C. Graf, M. Tscheligi</span>
<div class="authorList"><span><span class="author">C. Hochleitner</span> (CURE &#8211; Center for Usability Research &#038; Engineering, AT)</span><span><span class="author">C. Graf</span> (CURE &#8211; Center for Usability Research &#038; Engineering, AT)</span><span><span class="author">M. Tscheligi</span> (Univ. of Salzburg, AT)</span></div>
<p><span class="cbStatement">This case study researches the potential of persona marketing materials to improve the persona method. We present and research the effects and likeability of long-living marketing materials and consumables.</span><span class="abstract">Personas are a design tool to ensure a strong user-focus within projects. In this case study we compare and discuss seven different persona marketing materials used to increase the acceptance of the personas by the project team. The marketing materials are a mixture of consumables (e.g., wine or cake) and long-living marketing materials (e.g., posters or savings box). The insights gained are encouraging and confirm that marketing materials can be useful for increasing the acceptance and usage of personas.</span></li>
<li id="YHY"class="presentation ux health"><a href="http://chi2013.acm.org/previews/#YHY"><span class="letterCode" style="float:right">YHY</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#YHY">Tue. 11am</a></span><span class="award honorable"></span><span class="title"><a href="http://doi.acm.org/10.1145/2468356.2468762">Leverage User Experience through Social Networking to Improve Health Adherence</a></span><br />
<span class="authors">R. Lin (IBM, TW), X. Zhu</span>
<div class="authorList"><span><span class="author">R. Lin</span> (IBM, TW)</span><span><span class="author">X. Zhu</span> (IBM T.J. Watson Research , USA)</span></div>
<p><span class="cbStatement">This case study makes a contribution to Human-Computer and Human-Human Interactions and the use of social media/gaming in the health care sector. </span><span class="abstract">Patient adherence is an important factor in improving health outcomes. However, as one of the causes of increasing population with chronic diseases, low adherence has become a major health care issue globally. Often, due to deferred benefits of treatment or lifestyle recommendations, many fail to adhere to their treatment regimen or health plans given by care providers until their conditions deteriorate. As poor adherence remains a significant yet inadequately addressed problem of severe health issues, it is critical to create effective interventions as part of the solutions.     Previous studies have suggested that peer supports be effective to improve adherence, and social cognitive theories have indicated that personal realization and confidence enhanced through entertaining gaming elements could encourage behavior change. To understand how different motivation factors affect user experience through social networking, a health care adherence website with built-in behavior analyses was constructed to conduct experiments. Users&#8217; health adherence levels can be reported to the website and shared among consenting social members for discussion or competition. Key design and development components are illustrated through the case study, including a social gaming and learning portal, an engineering approach to supporting different application scenarios, and information interventions based on predefined rules to achieve effective adherence. The preliminary analysis showed that people using social media for health care adherence may be motivated differently and act strategically during their social interactions.  </span></li>
</ul>
<h2 id="repliCHI">RepliCHI Papers and Notes</h2>
<ul>
<li id="PMF"class="presentation "><a href="http://chi2013.acm.org/previews/#PMF"><span class="letterCode" style="float:right">PMF</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/monday/#PMF">Mon. 11am</a></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2470684">Crowdsourcing Performance Evaluations of User Interfaces</a></span><br />
<span class="authors">S. Komarov (Harvard Univ., USA), K. Reinecke, K. Gajos</span>
<div class="authorList"><span><span class="author">S. Komarov</span> (Harvard Univ., USA)</span><span><span class="author">K. Reinecke</span> (Harvard Univ., USA)</span><span><span class="author">K. Gajos</span> (Harvard Univ., USA)</span></div>
<p><span class="cbStatement">We explored the feasibility of using Amazon Mechanical Turk for user interface evaluation by replicating three well-known UI experiments both in lab and online. </span><span class="abstract">Online labor markets, such as Amazon&#8217;s Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings.  However, because the experimenter gives up the direct control over the participants&#8217; environments and behavior, concerns about the quality of the data collected in online settings are pervasive.  In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk.  The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments.  These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.</span></li>
<li id="PKX"class="presentation "><a href="http://chi2013.acm.org/previews/#PKX"><span class="letterCode" style="float:right">PKX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PKX">Thu. 11am</a></span><span class="award honorable"></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466430">Testing the Robustness and Performance of Spatially Consistent Interfaces</a></span><br />
<span class="authors">J. Scarr (Univ. of Canterbury, NZ), A. Cockburn, C. Gutwin, S. Malacria</span>
<div class="authorList"><span><span class="author">J. Scarr</span> (Univ. of Canterbury, NZ)</span><span><span class="author">A. Cockburn</span> (Univ. of Canterbury, NZ)</span><span><span class="author">C. Gutwin</span> (Univ. of Saskatchewan, CA)</span><span><span class="author">S. Malacria</span> (Univ. of Canterbury, NZ)</span></div>
<p><span class="cbStatement">Examines how view transformations such as scaling and rotation influence item selection time. Demonstrates that scaling, which maintains spatial consistency, allows faster performance than the commonly used &#8216;reflow&#8217; layout scheme.</span><span class="abstract">Relative spatial consistency – that is, the stable arrangement of objects in a 2D presentation – provides several benefits for interactive interfaces. Spatial consistency allows users to develop memory of object locations, reducing the time needed for visual search, and because spatial memory is long lasting and has a large capacity these performance benefits are enduring and scalable. This suggests that spatial consistency could be used as a fundamental principle for the design of interfaces. However, there are many display situations where the standard presentation is altered in some way: e.g., a window is moved to a new location, scaled, or rotated on a mobile or tabletop display. It is not known whether the benefits of spatial organization are robust to these common kinds of view transformation. To assess these effects, we tested user performance with a spatial interface that had been transformed in several ways, including different degrees of translation, rotation, scaling, and perspective change. We found that performance was not strongly affected by the changes, except in the case of large rotations. To demonstrate the value of spatial consistency over existing mechanisms for dealing with view changes, we compared user performance with a spatially-stable presentation (using scaling) with that of a &#8216;reflowing&#8217; presentation (widely used in current interfaces). This study showed that spatial stability with scaling dramatically outperforms reflowing. This research provides new evidence of spatial consistency&#8217;s value in interface design: it is robust to the view transformations that occur in typical environments, and it provides substantial performance advantages over traditional methods.</span></li>
<li id="PHP"class="presentation "><a href="http://chi2013.acm.org/previews/#PHP"><span class="letterCode" style="float:right">PHP</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/thursday/#PHP">Thu. 11am</a></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466449">Understanding Motivations for Facebook Use: Usage Metrics, Network Structure, and Privacy</a></span><br />
<span class="authors">T. Spiliotopoulos (Univ. of Madeira, PT), I. Oakley</span>
<div class="authorList"><span><span class="author">T. Spiliotopoulos</span> (Univ. of Madeira, PT)</span><span><span class="author">I. Oakley</span> (Univ. of Madeira, PT)</span></div>
<p><span class="cbStatement">A study on motivations for Facebook use that couples social science methods with information captured by the Facebook API in the form of detailed usage data and personal network metrics.</span><span class="abstract">This study explores the links between motives for using a social network service and numerical measures of that activity. Specifically, it identified motives for Facebook use by employing a Uses and Gratifications (U&#038;G) approach and then investigated the extent to which these motives can be predicted through usage and network metrics collected automatically via the Facebook API. In total, 11 Facebook usage metrics and eight personal network metrics served as predictors. Results showed that all three variable types in this expanded U&#038;G frame of analysis (covering social antecedents, usage metrics, and personal network metrics) effectively predicted motives and highlighted interesting behaviors. To further illustrate the power of this framework, the intricate nature of privacy in social media was explored and relationships drawn between privacy attitudes (and acts) and measures of use and network structure.</span></li>
<li id="NMX"class="presentation design"><a href="http://chi2013.acm.org/previews/#NMX"><span class="letterCode" style="float:right">NMX</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#NMX">Tue. 9am</a></span><span class="award repliCHI"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466139">Multiple Notification Modalities and Older Users</a></span><br />
<span class="authors">D. Warnock (Univ. of Glasgow, UK), S. Brewster, M. McGee-Lennon</span>
<div class="authorList"><span><span class="author">D. Warnock</span> (Univ. of Glasgow, UK)</span><span><span class="author">S. Brewster</span> (Univ. of Glasgow, UK)</span><span><span class="author">M. McGee-Lennon</span> (Univ. of Glasgow, UK)</span></div>
<p><span class="cbStatement">An experiment tested the way older users react to notifications delivered in 8 different modalities. Interesting differences were found between notifications requiring a response and ones that should be ignored.</span><span class="abstract">Multimodal interaction can make home care reminder systems more accessible to their users, most of whom are older and/or have sensory impairments. Existing research into the properties of different notification modalities have used younger participants rather than members of the older population at which they are aimed. This paper presents the results of a user study with older adults that examined how different notification modalities affected (a) performance in a card matching game and (b) how effective the different modalities were at delivering information. Participants were all aged over 50 and notifications were delivered using textual, pictographic, abstract visual, speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the game. The results showed that older users were influenced by the same factors as younger users, yet there were subjective differences. The implications for the design of multimodal reminder systems for home care are discussed.</span></li>
<li id="NBL"class="presentation ux"><a href="http://chi2013.acm.org/previews/#NBL"><span class="letterCode" style="float:right">NBL</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/wednesday/#NBL">Wed. 9am</a></span><span class="award repliCHI"></span>Note: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2481298">Swipe Vs. Scroll: Web Page Switching on Mobile Browsers</a></span><br />
<span class="authors">A. Warr (Google, Inc., USA), E. Chi</span>
<div class="authorList"><span><span class="author">A. Warr</span> (Google, Inc., USA)</span><span><span class="author">E. Chi</span> (Google, Inc., USA)</span></div>
<p><span class="cbStatement">We present an experiment comparing Safari’s pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome.</span><span class="abstract">Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari’s pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.</span></li>
<li id="PTN"class="presentation health"><a href="http://chi2013.acm.org/previews/#PTN"><span class="letterCode" style="float:right">PTN</span></a><span class="when"><a href="http://chi2013.acm.org/program/by-day/tuesday/#PTN">Tue. 4pm</a></span><span class="award repliCHI"></span>Paper: <span class="title"><a href="http://doi.acm.org/10.1145/2470654.2466233">A Text Message a Day Keeps the Pulmonologist Away</a></span><br />
<span class="authors">T. Yun (Samsung Electronics, KR), R. Arriaga</span>
<div class="authorList"><span><span class="author">T. Yun</span> (Samsung Electronics, KR)</span><span><span class="author">R. Arriaga</span> (Georgia Institute of Technology, USA)</span></div>
<p><span class="cbStatement">This paper encourages the use of ubiquitous technology for the primary stakeholder, and  promotes designing technology to both replicate and extend results by using a social theory of behavior change.</span><span class="abstract">The goal of this study was to extend and replicate an SMS health intervention for pediatric asthma patients. This intervention was designed using the Health Belief Model (HBM). Thirty patients were randomly assigned to one of three conditions. In the Knowledge condition patients were queried about their asthma knowledge every other day. In the Knowledge and Symptoms condition patients received a daily text message. They were queried about their symptoms and knowledge of asthma on alternate days. The Control group received no texts. Our main finding is that daily text messages lead to improved health outcomes.     We explain our results in the context of interview data and the HBM. We conclude by suggesting that the HBM can be used to inform and evaluate system design for chronic care beyond asthma and by considering the role that replication studies can play in HCI research.   </span></li>
</ul>
						
					</div><!-- .entry-content -->
				</div><!-- #post-## -->
				

<div style="clear:both;"></div>	
				<div style="clear:both;width:100%;">
	
	<div style="float:left;width:48%;"></div>
	<div  style="float:right;width:48%;"></div>
</div>
								
<!-- You can start editing here. -->


			<!-- If comments are closed. -->
		<p class="nocomments"></p>

	
	<div  style="clear:both;"></div><div style="clear:both;height:40px;"></div>
      
                      <div class="clr"></div>
                </div><!--content midd end -->
        <!-- c-ao 23jan13 adjustment for page id 1213 to make it wider and eliminate the right sidebar -->
				
        </div><!-- content wrapper end -->
        
              <div id="footer"><!--footer-->
        
        				<div id="footer_nav">
                
                                <ul>                   
<!--                                     <li><a href="#">Home</a></li>
                                     <li><a href="#">Sample Page</a></li>
                                     <li><a href="#">Sample Page 2</a></li>               -->     
                                </ul>
                
                		</div>
                        
                        
                         <div id="copyright">
                        
                        		© copyright 2012, <a href=""> ACM SIGCHI</a>
      <a href="http://jigsaw.w3.org/css-validator/check/referer">
</a>   
                        
               	    </div>
        
       			 </div><!--footer end-->

        
        

<div class="clr"></div>
</div><!--####  wrapper  ###-->




</body>
</html>